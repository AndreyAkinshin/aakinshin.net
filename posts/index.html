<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <meta name="description" content="Andrey Akinshin&#39;s blog">
    <meta name="author" content="Andrey Akinshin">
    <link href="/img/favicon.ico" rel="icon" type="image/x-icon"/>
    <meta name="keywords" content=''>

    <title>Andrey Akinshin&#39;s blog</title>

    <!-- Bootstrap CSS & Highlight.js-->
    <link href="/css/lumen-bootstrap.min.css" theme="light" rel="stylesheet" type="text/css" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)">
    <link href="/css/slate-bootstrap.min.css" theme="dark" rel="stylesheet" type="text/css" media="(prefers-color-scheme: dark)">
    <link href="/css/github-highlight.css" theme="light" rel="stylesheet" type="text/css" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)">
    <link href="/css/darcula-highlight.css" theme="dark" rel="stylesheet" type="text/css" media="(prefers-color-scheme: dark)">
    <script src="/js/theme-before.js"></script>

    <!-- DarkModeToggle -->
    <script type="module" src="https://googlechromelabs.github.io/dark-mode-toggle/src/dark-mode-toggle.mjs"></script>

    <!-- FontAwesome -->
    <link href="/css/fontawesome-all.min.css" rel="stylesheet" type="text/css" media="all">
    
    <!-- Custom styles -->
    <link href="/css/about.css" rel="stylesheet" type="text/css" media="all">
    <link href="/css/blog.css" rel="stylesheet" type="text/css" media="all">

    <!-- Feeds -->
    <link href="/en/rss.xml" type="application/rss+xml" rel="alternate" title="Blog RSS Feed" />
    <link href="/en/atom.xml" type="application/atom+xml" rel="alternate" title="Blog ATOM Feed" />

    <!-- Google analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-41419012-5', 'auto');
      ga('send', 'pageview');
    </script>
    <!-- Yandex.Metrika counter -->
    <script type="text/javascript" >
        (function (d, w, c) {
            (w[c] = w[c] || []).push(function() {
                try {
                    w.yaCounter28700916 = new Ya.Metrika({
                        id:28700916,
                        clickmap:true,
                        trackLinks:true,
                        accurateTrackBounce:true,
                        webvisor:true,
                        trackHash:true
                    });
                } catch(e) { }
            });

            var n = d.getElementsByTagName("script")[0],
                s = d.createElement("script"),
                f = function () { n.parentNode.insertBefore(s, n); };
            s.type = "text/javascript";
            s.async = true;
            s.src = "https://mc.yandex.ru/metrika/watch.js";

            if (w.opera == "[object Opera]") {
                d.addEventListener("DOMContentLoaded", f, false);
            } else { f(); }
        })(document, window, "yandex_metrika_callbacks");
    </script>
    <noscript><div><img src="https://mc.yandex.ru/watch/28700916" style="position:absolute; left:-9999px;" alt="" /></div></noscript>
    <!-- /Yandex.Metrika counter -->

    <!-- jQuery -->
    <script src="/js/jquery-3.3.1.slim.min.js"></script>
  </head>

  <body>
    <div class="bg-primary">
      <div class="container bg-primary">
        <nav class="navbar navbar-expand-lg navbar-dark bg-primary">
          <ul class="navbar-nav mr-auto">
            <li class="nav-item">
              <a class="nav-link" id="nav-link-blog" href="/posts/">Posts</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" id="nav-link-blog-content" href="/content/">Content</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" id="nav-link-about" href="/about/">About</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" id="nav-link-about" href="/prodotnetbenchmarking/">Pro .NET Benchmarking</a>
            </li>
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">En</a>
              <div class="dropdown-menu">
                  <a class="dropdown-item" href='/ru/posts/'>Ru</a>
              </div>
            </li>
            <li class="nav-item"></li>
              <dark-mode-toggle permanent="true"></dark-mode-toggle>
            </li>
          </ul>
          <ul class="navbar-nav ml-auto">
            <li class="nav-item"><a class="nav-link" href="https://github.com/AndreyAkinshin"><i class="fab fa-github" title="GitHub" style="color:white"></i></a></li>
            <li class="nav-item"><a class="nav-link" href="https://twitter.com/andrey_akinshin"><i class="fab fa-twitter" title="Twitter" style="color:white"></i></a></li>
            <li class="nav-item"><a class="nav-link" href="/rss.xml"><i class="fas fa-rss" title="RSS" style="color:white"></i></a></li>
          </ul>
        </nav>
      </div>
    </div>

    <div class="container">
      <div class="blog-main">
    <div class="blog-post">
        <h2 class="blog-post-title"><a href='/posts/shift-and-ratio-functions/'>Distribution comparison via the shift and ratio functions</a></h2>
        <span class="blog-post-meta">
          <b>Date:</b> October 11, 2019.
          <b>Tags:</b>
                <a href="/tags/statistics"><span class="badge badge-pill badge-info">Statistics</span></a>
        </span><br /><br />
        <p>When we compare two distributions, it's not always enough to detect a statistically significant difference between them.
In many cases, we also want to evaluate the magnitude of this difference.
Let's look at the following image:</p>
<div class="mx-auto">
<a href="/img/posts/shift-and-ratio-functions/compare1-light.png" target="_blank">
<picture>
<source theme='dark' srcset="/img/posts/shift-and-ratio-functions/compare1-dark.png" media="(prefers-color-scheme: dark)">
<source theme='light' srcset="/img/posts/shift-and-ratio-functions/compare1-light.png" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)">
<img class="mx-auto d-block" width="800" src="/img/posts/shift-and-ratio-functions/compare1-light.png">
</picture>
</a>
</div>
<p>On the left side, we can see a timeline plot with 2000 points
(at the middle of this plot, the distribution was significantly changed).
On the right side, you can see density plots for the left and the right side of
the timeline plot (before and after the change).
It's a pretty simple case, the difference between distributions be expressed via the
difference between mean values.</p>
<p>Now let's look at a more tricky case:</p>
<div class="mx-auto">
<a href="/img/posts/shift-and-ratio-functions/compare2-light.png" target="_blank">
<picture>
<source theme='dark' srcset="/img/posts/shift-and-ratio-functions/compare2-dark.png" media="(prefers-color-scheme: dark)">
<source theme='light' srcset="/img/posts/shift-and-ratio-functions/compare2-light.png" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)">
<img class="mx-auto d-block" width="800" src="/img/posts/shift-and-ratio-functions/compare2-light.png">
</picture>
</a>
</div>
<p>Here we have a bimodal distribution; after the change, the left mode &quot;moved right.&quot;
Now it's much harder to evaluate the difference between distributions
because the mean and the median values almost not changed:
the right mode has the biggest impact on these metrics than the left more.</p>
<p>And here is a much more tricky case:</p>
<div class="mx-auto">
<a href="/img/posts/shift-and-ratio-functions/compare3-light.png" target="_blank">
<picture>
<source theme='dark' srcset="/img/posts/shift-and-ratio-functions/compare3-dark.png" media="(prefers-color-scheme: dark)">
<source theme='light' srcset="/img/posts/shift-and-ratio-functions/compare3-light.png" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)">
<img class="mx-auto d-block" width="800" src="/img/posts/shift-and-ratio-functions/compare3-light.png">
</picture>
</a>
</div>
<p>Here we also have a bimodal distribution; after the change, both modes moved:
the left mode &quot;moved right&quot; and the right mode &quot;moved left.&quot;
How should we describe the difference between these distributions now?</p>
</p>
        <a href='/posts/shift-and-ratio-functions/'>Read more</a><br /><br />
        <hr />
    </div>
    <div class="blog-post">
        <h2 class="blog-post-title"><a href='/posts/normality/'>Normality is a myth</a></h2>
        <span class="blog-post-meta">
          <b>Date:</b> October 09, 2019.
          <b>Tags:</b>
                <a href="/tags/statistics"><span class="badge badge-pill badge-info">Statistics</span></a>
                <a href="/tags/normality"><span class="badge badge-pill badge-info">Normality</span></a>
                <a href="/tags/central-limit-theorem"><span class="badge badge-pill badge-info">Central Limit Theorem</span></a>
                <a href="/tags/performance"><span class="badge badge-pill badge-info">Performance</span></a>
                <a href="/tags/r"><span class="badge badge-pill badge-info">R</span></a>
        </span><br /><br />
        <p>In many statistical papers, you can find the following phrase: &quot;assuming that we have a normal distribution.&quot;
Probably, you saw plots of the normal distribution density function in some statistics textbooks,
it looks like this:</p>
<div class="mx-auto">
<a href="/img/posts/normality/normal-light.png" target="_blank">
<picture>
<source theme='dark' srcset="/img/posts/normality/normal-dark.png" media="(prefers-color-scheme: dark)">
<source theme='light' srcset="/img/posts/normality/normal-light.png" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)">
<img class="mx-auto d-block" width="800" src="/img/posts/normality/normal-light.png">
</picture>
</a>
</div>
<p>The normal distribution is a pretty user-friendly mental model when we are trying to interpret the statistical metrics
like mean and standard deviation.
However, it may also be an insidious and misleading model when your distribution is not normal.
There is a great sentence in the <a href="https://doi.org/10.1093/biomet/34.3-4.209">&quot;Testing for normality&quot;</a> paper by R.C. Geary, 1947 (the quote was found <a href="https://garstats.wordpress.com/2019/06/17/myth/">here</a>):</p>
<blockquote>
<p>Normality is a myth; there never was, and never will be, a normal distribution.</p>
</blockquote>
<p>I 100% agree with this statement.
At least, if you are working with performance distributions
(that are based on the multiple iterations of your benchmarks that measure the performance metrics of your applications),
you should forget about normality.
That's how a typical performance distribution looks like
(I built the below picture based on a real benchmark that measures the load time of assemblies
when we open the <a href="https://github.com/OrchardCMS/Orchard">Orchard</a> solution in <a href="https://www.jetbrains.com/rider/">Rider</a> on Linux):</p>
<div class="mx-auto">
<a href="/img/posts/normality/performance-light.png" target="_blank">
<picture>
<source theme='dark' srcset="/img/posts/normality/performance-dark.png" media="(prefers-color-scheme: dark)">
<source theme='light' srcset="/img/posts/normality/performance-light.png" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)">
<img class="mx-auto d-block" width="800" src="/img/posts/normality/performance-light.png">
</picture>
</a>
</div>
</p>
        <a href='/posts/normality/'>Read more</a><br /><br />
        <hr />
    </div>
    <div class="blog-post">
        <h2 class="blog-post-title"><a href='/posts/edpelt/'>Implementation of efficient algorithm for changepoint detection: ED-PELT</a></h2>
        <span class="blog-post-meta">
          <b>Date:</b> October 07, 2019.
          <b>Tags:</b>
                <a href="/tags/dotnet"><span class="badge badge-pill badge-info">.NET</span></a>
                <a href="/tags/csharp"><span class="badge badge-pill badge-info">C#</span></a>
                <a href="/tags/ed-pelt"><span class="badge badge-pill badge-info">ED-PELT</span></a>
                <a href="/tags/statistics"><span class="badge badge-pill badge-info">Statistics</span></a>
                <a href="/tags/changepoints"><span class="badge badge-pill badge-info">ChangePoints</span></a>
        </span><br /><br />
        <p><a href="https://en.wikipedia.org/wiki/Change_detection">Changepoint detection</a> is an important task that has a lot of applications.
For example, I use it to detect changes in the <a href="https://www.jetbrains.com/rider/">Rider</a> performance test suite.
It's very important to detect not only performance degradations, but any kinds of performance changes
(e.g., the variance may increase, or a unimodal distribution may be split to several modes).
You can see examples of such changes on the following picture (we change the color when a changepoint is detected):</p>
<div class="mx-auto">
<a href="/img/posts/edpelt/edpelt-light.png" target="_blank">
<picture>
<source theme='dark' srcset="/img/posts/edpelt/edpelt-dark.png" media="(prefers-color-scheme: dark)">
<source theme='light' srcset="/img/posts/edpelt/edpelt-light.png" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)">
<img class="mx-auto d-block" width="600" src="/img/posts/edpelt/edpelt-light.png">
</picture>
</a>
</div>
<p>Unfortunately, it's pretty hard to write a reliable and fast algorithm for changepoint detection.
Recently, I found a cool paper (<a href="https://link.springer.com/article/10.1007/s11222-016-9687-5">Haynes, K., Fearnhead, P. &amp; Eckley, I.A. &quot;A computationally efficient nonparametric approach for changepoint detection,&quot; Stat Comput (2017) 27: 1293</a>) that describes the ED-PELT algorithm.
It has <code>O(N*log(N))</code> complexity and pretty good detection accuracy.
The reference implementation can be used via the <a href="https://cran.r-project.org/web/packages/changepoint.np/index.html">changepoint.np</a> R package.
However, I can't use <a href="https://www.r-project.org/">R</a> on our build server, so I decided to write my own C# implementation.</p>
</p>
        <a href='/posts/edpelt/'>Read more</a><br /><br />
        <hr />
    </div>
    <div class="blog-post">
        <h2 class="blog-post-title"><a href='/posts/nuget-package-browsing/'>A story about slow NuGet package browsing</a></h2>
        <span class="blog-post-meta">
          <b>Date:</b> May 08, 2018.
          <b>Tags:</b>
                <a href="/tags/nuget"><span class="badge badge-pill badge-info">NuGet</span></a>
                <a href="/tags/rider"><span class="badge badge-pill badge-info">Rider</span></a>
        </span><br /><br />
        <p>In <a href="https://www.jetbrains.com/rider/">Rider</a>, we have integration tests which interact with <a href="https://api.nuget.org/">api.nuget.org</a>.
Also, we have an internal service which monitors the performance of these tests.
Two days ago, I noticed that some of these tests sometimes are running for too long.
For example, <code>nuget_NuGetTest_shouldUpgradeVersionForDotNetCore</code> usually takes around <code>10 sec</code>.
However, in some cases, it takes around <code>110 sec</code>, <code>210 sec</code>, or <code>310 sec</code>:</p>
<div class="mx-auto"><a href="/img/posts/nuget-package-browsing/perf-chart.png" target="_blank"><img class="mx-auto d-block" width="600" src="/img/posts/nuget-package-browsing/perf-chart.png" /></a></div>
<p>It looks very suspicious and increases the whole test suite duration.
Also, our dashboard with performance degradations contains only such tests
and some real degradations (which are introduced by the changes in our codebase) can go unnoticed.
So, my colleagues and I decided to investigate it.</p>
</p>
        <a href='/posts/nuget-package-browsing/'>Read more</a><br /><br />
        <hr />
    </div>
    <div class="blog-post">
        <h2 class="blog-post-title"><a href='/posts/dotnet-crossruntime-disasm/'>Cross-runtime .NET disassembly with BenchmarkDotNet</a></h2>
        <span class="blog-post-meta">
          <b>Date:</b> April 10, 2018.
          <b>Tags:</b>
                <a href="/tags/dotnet"><span class="badge badge-pill badge-info">.NET</span></a>
                <a href="/tags/csharp"><span class="badge badge-pill badge-info">C#</span></a>
                <a href="/tags/benchmarkdotnet"><span class="badge badge-pill badge-info">BenchmarkDotNet</span></a>
                <a href="/tags/benchmarking"><span class="badge badge-pill badge-info">benchmarking</span></a>
                <a href="/tags/disassembly"><span class="badge badge-pill badge-info">disassembly</span></a>
        </span><br /><br />
        <p><a href="https://github.com/dotnet/BenchmarkDotNet">BenchmarkDotNet</a> is a cool tool for benchmarking.
It has a lot of useful features that help you with performance investigations.
However, you can use these features even if you are not actually going to benchmark something.
One of these features is <code>DisassemblyDiagnoser</code>.
It shows you a disassembly listing of your code for all required runtimes.
In this post, I will show you how to get disassembly listing for .NET Framework, .NET Core, and Mono with one click!
You can do it with a very small code snippet like this:</p>
<pre><code class="language-cs">[DryCoreJob, DryMonoJob, DryClrJob(Platform.X86)]
[DisassemblyDiagnoser]
public class IntroDisasm
{
    [Benchmark]
    public double Sum()
    {
        double res = 0;
        for (int i = 0; i &lt; 64; i++)
            res += i;
        return res;
    }
}
</code></pre>
</p>
        <a href='/posts/dotnet-crossruntime-disasm/'>Read more</a><br /><br />
        <hr />
    </div>
    <div class="blog-post">
        <h2 class="blog-post-title"><a href='/posts/bdn-v0_10_14/'>BenchmarkDotNet v0.10.14</a></h2>
        <span class="blog-post-meta">
          <b>Date:</b> April 09, 2018.
          <b>Tags:</b>
                <a href="/tags/dotnet"><span class="badge badge-pill badge-info">.NET</span></a>
                <a href="/tags/csharp"><span class="badge badge-pill badge-info">C#</span></a>
                <a href="/tags/benchmarkdotnet"><span class="badge badge-pill badge-info">BenchmarkDotNet</span></a>
                <a href="/tags/benchmarking"><span class="badge badge-pill badge-info">benchmarking</span></a>
        </span><br /><br />
        <p>BenchmarkDotNet v0.10.14 has been released! This release includes:</p>
<ul>
<li><strong>Per-method parameterization</strong> (<a href="http://benchmarkdotnet.org/Advanced/Arguments.htm">Read more</a>)</li>
<li><strong>Console histograms and multimodal disribution detection</strong> (<a href="/blog/post/dotnet-crossruntime-disasm/">Read more</a>)</li>
<li><strong>Many improvements for Mono disassembly support on Windows</strong> (A blog post is coming soon)</li>
<li><strong>Many bugfixes</strong></li>
</ul>
<p>In the <a href="https://github.com/dotnet/BenchmarkDotNet/issues?q=milestone:v0.10.14">v0.10.14</a> scope,
8 issues were resolved and 11 pull requests where merged.
This release includes 47 commits by 8 contributors.</p>
</p>
        <a href='/posts/bdn-v0_10_14/'>Read more</a><br /><br />
        <hr />
    </div>
    <div class="blog-post">
        <h2 class="blog-post-title"><a href='/posts/bdn-v0_10_13/'>BenchmarkDotNet v0.10.13</a></h2>
        <span class="blog-post-meta">
          <b>Date:</b> March 02, 2018.
          <b>Tags:</b>
                <a href="/tags/dotnet"><span class="badge badge-pill badge-info">.NET</span></a>
                <a href="/tags/csharp"><span class="badge badge-pill badge-info">C#</span></a>
                <a href="/tags/benchmarkdotnet"><span class="badge badge-pill badge-info">BenchmarkDotNet</span></a>
                <a href="/tags/benchmarking"><span class="badge badge-pill badge-info">benchmarking</span></a>
        </span><br /><br />
        <p>BenchmarkDotNet v0.10.13 has been released! This release includes:</p>
<ul>
<li><strong>Mono Support for DisassemblyDiagnoser:</strong>
Now you can easily get an assembly listing not only on .NET Framework/.NET Core, but also on Mono.
It works on Linux, macOS, and Windows (Windows requires installed cygwin with <code>obj</code> and <code>as</code>).
(See <a href="https://github.com/dotnet/BenchmarkDotNet/issues/541">#541</a>)</li>
<li><strong>Support ANY CoreFX and CoreCLR builds:</strong>
BenchmarkDotNet allows the users to run their benchmarks against ANY CoreCLR and CoreFX builds.
You can compare your local build vs MyGet feed or Debug vs Release or one version vs another.
(See <a href="https://github.com/dotnet/BenchmarkDotNet/issues/651">#651</a>)</li>
<li><strong>C# 7.2 support</strong>
(See <a href="https://github.com/dotnet/BenchmarkDotNet/issues/643">#643</a>)</li>
<li><strong>.NET 4.7.1 support</strong>
(See <a href="https://github.com/dotnet/BenchmarkDotNet/commit/28aa946a9a277b6c2b1166af0397134b02bedf2d">28aa94</a>)</li>
<li><strong>Support Visual Basic project files (.vbroj) targeting .NET Core</strong>
(See <a href="https://github.com/dotnet/BenchmarkDotNet/issues/626">#626</a>)</li>
<li><strong>DisassemblyDiagnoser now supports generic types</strong>
(See <a href="https://github.com/dotnet/BenchmarkDotNet/issues/640">#640</a>)</li>
<li><strong>Now it's possible to benchmark both Mono and .NET Core from the same app</strong>
(See <a href="https://github.com/dotnet/BenchmarkDotNet/issues/653">#653</a>)</li>
<li><strong>Many bug fixes</strong>
(See details below)</li>
</ul>
</p>
        <a href='/posts/bdn-v0_10_13/'>Read more</a><br /><br />
        <hr />
    </div>
    <div class="blog-post">
        <h2 class="blog-post-title"><a href='/posts/mono-gc-collects/'>Analyzing distribution of Mono GC collections</a></h2>
        <span class="blog-post-meta">
          <b>Date:</b> February 20, 2018.
          <b>Tags:</b>
                <a href="/tags/dotnet"><span class="badge badge-pill badge-info">.NET</span></a>
                <a href="/tags/csharp"><span class="badge badge-pill badge-info">C#</span></a>
                <a href="/tags/r"><span class="badge badge-pill badge-info">R</span></a>
                <a href="/tags/rider"><span class="badge badge-pill badge-info">Rider</span></a>
                <a href="/tags/mono"><span class="badge badge-pill badge-info">Mono</span></a>
                <a href="/tags/gc"><span class="badge badge-pill badge-info">GC</span></a>
        </span><br /><br />
        <p>Sometimes I want to understand the GC performance impact on an application quickly.
I know that there are many powerful diagnostic tools and approaches,
but I'm a fan of the &quot;right tool for the job&quot; idea.
In simple cases, I prefer simple noninvasive approaches which provide a quick way
to get an overview of the current situation
(if everything is terrible, I always can switch to an advanced approach).
Today I want to share with you my favorite way to quickly get statistics
of GC pauses in Mono and generate nice plots like this:</p>
<div class="mx-auto"><a href="/img/posts/mono-gc-collects/plot-64.png" target="_blank"><img class="mx-auto d-block" width="600" src="/img/posts/mono-gc-collects/plot-64.png" /></a></div>
</p>
        <a href='/posts/mono-gc-collects/'>Read more</a><br /><br />
        <hr />
    </div>
    <div class="blog-post">
        <h2 class="blog-post-title"><a href='/posts/bdn-v0_10_12/'>BenchmarkDotNet v0.10.12</a></h2>
        <span class="blog-post-meta">
          <b>Date:</b> January 15, 2018.
          <b>Tags:</b>
                <a href="/tags/dotnet"><span class="badge badge-pill badge-info">.NET</span></a>
                <a href="/tags/csharp"><span class="badge badge-pill badge-info">C#</span></a>
                <a href="/tags/benchmarkdotnet"><span class="badge badge-pill badge-info">BenchmarkDotNet</span></a>
                <a href="/tags/benchmarking"><span class="badge badge-pill badge-info">benchmarking</span></a>
        </span><br /><br />
        <p>BenchmarkDotNet v0.10.12 has been released! This release includes:</p>
<ul>
<li><strong>Improved DisassemblyDiagnoser:</strong>
BenchmarkDotNet contains an embedded disassembler so that it can print assembly code for all benchmarks;
it's not easy, but the disassembler evolves in every release.</li>
<li><strong>Improved MemoryDiagnoser:</strong>
it has a better precision level, and it takes less time to evaluate memory allocations in a benchmark.</li>
<li><strong>New TailCallDiagnoser:</strong>
now you get notifications when JIT applies the tail call optimizations to your methods.</li>
<li><strong>Better environment info:</strong>
when your share performance results, it's very important to share information about your environment.
The library generates the environment summary for you by default.
Now it contains information about the amount of physical CPU, physical cores, and logic cores.
If you run a benchmark on a virtual machine, you will get the name of the hypervisor
(e.g., Hyper-V, VMware, or VirtualBox).</li>
<li><strong>Better summary table:</strong>
one of the greatest features of BenchmarkDotNet is the summary table.
It shows all important information about results in a compact and understandable form.
Now it has better customization options: you can display relative performance of different environments
(e.g., compare .NET Framework and .NET Core) and group benchmarks by categories.</li>
<li><strong>New GC settings:</strong> now we support <code>NoAffinitize</code>, <code>HeapAffinitizeMask</code>, <code>HeapCount</code>.</li>
<li>Other minor improvements and bug fixes</li>
</ul>
</p>
        <a href='/posts/bdn-v0_10_12/'>Read more</a><br /><br />
        <hr />
    </div>
    <div class="blog-post">
        <h2 class="blog-post-title"><a href='/posts/bdn-v0_10_10/'>BenchmarkDotNet v0.10.10</a></h2>
        <span class="blog-post-meta">
          <b>Date:</b> November 03, 2017.
          <b>Tags:</b>
                <a href="/tags/dotnet"><span class="badge badge-pill badge-info">.NET</span></a>
                <a href="/tags/csharp"><span class="badge badge-pill badge-info">C#</span></a>
                <a href="/tags/benchmarkdotnet"><span class="badge badge-pill badge-info">BenchmarkDotNet</span></a>
                <a href="/tags/benchmarking"><span class="badge badge-pill badge-info">benchmarking</span></a>
        </span><br /><br />
        <p>BenchmarkDotNet v0.10.10 has been released!
This release includes many new features like Disassembly Diagnoser, ParamsSources, .NET Core x86 support, Environment variables, and more!</p>
</p>
        <a href='/posts/bdn-v0_10_10/'>Read more</a><br /><br />
        <hr />
    </div>
</div>
<nav>
  <ul class="pagination">
          <li class="page-item disabled">
        <a class="page-link" href="#" aria-label="Previous">
          <span aria-hidden="true">&laquo;</span>
          <span class="sr-only">Previous</span>
        </a>
      </li>
            <li class="page-item active">
          <a class="page-link" href="/posts/">1 <span class="sr-only">(current)</span></a>
        </li>
        <li class="page-item"><a class="page-link" href="/posts/page/2/">2</a></li>
        <li class="page-item"><a class="page-link" href="/posts/page/3/">3</a></li>
        <li class="page-item"><a class="page-link" href="/posts/page/4/">4</a></li>
        <li class="page-item"><a class="page-link" href="/posts/page/5/">5</a></li>
          <li class="page-item">
        <a class="page-link" href='/posts/page/2/' aria-label="Next">
          <span aria-hidden="true">&raquo;</span>
          <span class="sr-only">Next</span>
        </a>
      </li>
      </ul>
</nav>
<hr />
<p style="font-size:150%"><a href="/ru/blog/">More posts in Russian</a></p>
<p>Subscribe: <a href="/rss.xml">RSS</a> <a href="/atom.xml">Atom</a></p>
    </div>

    <footer class="blog-footer">
      <div class="container">
        <p>&copy; 2013–2019 Andrey Akinshin</p>
      </div>
    </footer>

    <script src="/js/theme-after.js"></script>
    <!-- jQuery first (header), then popper, then Bootstrap JS. -->
    <script src="/js/popper.min.js"></script>
    <script src="/js/bootstrap.min.js"></script>
    <!-- Other scripts -->
    <script src="/js/highlight.pack.js"></script>
    <script src="/js/anchor.min.js"></script>
    <script src="/js/custom.js"></script>
  </body>
</html>
