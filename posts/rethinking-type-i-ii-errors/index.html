<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.123.3"><meta name=author content='Andrey Akinshin'><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content='Mathematics,Statistics,Research,Thoughts'><title>Rethinking Type I/II error rates with power curves | Andrey Akinshin</title>
<meta name=description content="Discussing power curves that show the dependency of the positive detection rate on the actual effect size"><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><meta name=og:image content="https://aakinshin.net/posts/rethinking-type-i-ii-errors/img/pc10-light.png"><script>localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?document.documentElement.classList.add("dark"):document.documentElement.classList.remove("dark")</script><link href=https://aakinshin.net/css/main.min.5108205eaabc89b26ffd82359e0fe4fb2b5e8c9825e57ed51687cc18a3c75b9b.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"></head><body><nav><div class="container flex flex-wrap items-center justify-between mx-auto max-w-6xl h-12 px-2 xs:px-6"><div class="flex items-center justify-start justify-self-start"><div class="flex nav-item h-12 w-12 items-center justify-center"><a class=text-white href=https://aakinshin.net/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#house-chimney"/></svg></a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/posts/>Posts</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/research/>Research</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/library/>Library</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/about/>About</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/search/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#magnifying-glass"/></svg></a></div></div><button id=theme-toggle type=button title="Alt+Click to match OS color theme" class="nav-item p-3 content-center justify-self-end"><svg id="theme-toggle-dark-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001.0 1010.586 10.586z"/></svg><svg id="theme-toggle-light-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M10 2a1 1 0 011 1v1A1 1 0 119 4V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707A1 1 0 1113.536 5.05l.707-.707a1 1 0 011.414.0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707A1 1 0 004.343 5.757l.707.707zm1.414 8.486-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z" fill-rule="evenodd" clip-rule="evenodd"/></svg></button></div></nav><div class="main container mx-auto max-w-6xl px-6"><div class=main-post><h1 class=blog-post-title id=post-title>Rethinking Type I/II Error Rates with Power Curves</h1><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg>
<time datetime=2023-04-11>April 11, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#statistics"/></svg>
Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/>Research
</a><a class=label-link href=https://aakinshin.net/tags/thoughts/>Thoughts</a></div></div><br><div class=main-content><p>When it comes to the analysis of a statistical significance test design,
many people tend to overfocus purely on the Type I error rate.
Those who are aware of the importance of power analysis
often stop at expressing the Type II error rate as a single number.
It is better than nothing, but such an approach always confuses me.</p><p>Let us say that the declared Type II error rate is 20% (or the declared statistical power is 80%).
What does it actually mean?
If the sample size and the significance level (or any other significance criteria) are given,
the Type II error rate is a function of the effect size.
When we express the Type II error rate as a single number,
we always (implicitly or explicitly) assume the target effect size.
In most cases, it is an arbitrary number
that is somehow chosen to reflect our expectations of the &ldquo;reasonable&rdquo; effect size.
However, the actual Type II error rate and the corresponding statistical power
depend on the actual effect size that we do not know.
Some researchers estimate the Type II error rate / statistical power using the measured effect size,
but it does not make a lot of sense since
it does not provide new information in addition to the measured effect size or p-value.
In reality, we have high statistical power (low Type II error rate) for large effect sizes
and low statistical power (high Type II error rate) for small effect sizes.
Without the knowledge of the actual effect size (which we do not have),
the Type II error rate expressed as a single number mostly describes this arbitrarily chosen expected effect size,
rather than the actual properties of our statistical test.</p><p>A similar problem arises with the Type I error rate.
I believe that working with the traditional nil hypothesis (that assumes that the effect size is <em>exactly</em> zero)
or other kinds of point hypotheses (that compare the effect size with an <em>exact</em> number) are meaningless.
In real life, nil hypotheses are almost always wrong.
Any kind of changes in the experimental setup almost always have an impact on the measurements.
And it is almost impossible to design such an experiment
in which two tested distributions are identical with an infinite level of precision.
Therefore, it is always possible to detect a statistically significant difference
if we can indefinitely increase the sample size.
A reasonable solution to this problem is switching to the null hypothesis
that assumes that the effect size is negligible.
This approach has multiple names: practical significance tests, minimum-effect tests, equivalence tests, and so on.
Regardless of the name, the null hypothesis now covers a range of effect sizes that are marked as non-significant.
When we operate with the word &ldquo;negligible&rdquo;,
we tend to think that this range is so small that we can act like it is almost a point.
However, such an assumption is often misleading.
In order to solve the described nil hypothesis problem, this &ldquo;negligible&rdquo; range should be reasonably large.
Thus, the classic definition of the Type I error rate (positive rate for the case when the effect size is zero)
stops being fully applicable.
Indeed, the positive rate for the zero effect size case describes only a single point of the &ldquo;negligible&rdquo; range.
Since we extended the null hypothesis assumption, we also extended the bounds of Type I errors.
If the true effect size falls within the &ldquo;negligible&rdquo; range, but it is not exactly zero,
the actual positive rate will be different from the classic Type I error rate for zero effect size.</p><p>Thus, when we express Type I and Type II error rates as two numbers, such an approach can be misleading
since it does not provide the full picture.
Also, this makes it much more difficult
to compare different statistical tests in terms of statistical significance and power,
if these tests use different &ldquo;negligible&rdquo; ranges for Type I errors or
different &ldquo;expected&rdquo; effect sizes for Type II errors.</p><h3 id=power-curve-by-effect-size>Power curve by effect size</h3><p>So, what can we do to resolve the described problem with the classic Type I/II error rates?
I would like to share an approach that I use to compare various test procedures.
Instead of focusing on separate numbers for specific effect sizes,
I evaluate the whole function that describes the dependency of the positive detection rate on the actual effect size.
Sometimes, such a function is referenced as the
<em>power curve by effect size</em> (e.g., see <a href=https://aakinshin.net/library/papers/bartlett2022/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>bartlett2022</a>).</p><p>Let me demonstrate this approach using a classic example.
We compare two samples from two normal distributions $\mathcal{N}(\mu_1, 1)$ and $\mathcal{N}(\mu_2, 1)$
and we want to check if there is a difference between their means $\mu_1$ and $\mu_2$.
We try to use the classic one-tailed Student&rsquo;s t-test and the one-tailed Mann–Whitney U test
with the classic nil hypothesis that states that there is no difference between distributions.
In our experiment, we set the statistical significance level to the notorious $\alpha = 0.05$.</p><p>In order to evaluate the properties of each test, we do the following:</p><ul><li>Enumerate various actual effect sizes $d$;</li><li>For each effect size $d$, we generate pairs of random samples from $\mathcal{N}(0, 1)$ and $\mathcal{N}(d, 1)$;
for each pair, we perform both statistical tests and check if they return a positive result
respecting the given $\alpha = 0.05$;</li><li>Repeat the previous step multiple times so that we can evaluate
the probability of getting the positive result for the given effect size $d$ using the Monte-Carlo method;</li><li>Build a power curve plot that demonstrates the dependency of the positive detection rate on the actual effect size.</li></ul><p>Below, you can see the results for the sample size $n=10$:</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/rethinking-type-i-ii-errors/img/pc10-light.png target=_blank alt=pc10><img src=/posts/rethinking-type-i-ii-errors/img/pc10-light.png width=800>
</a><a class="img-dark hidden" href=/posts/rethinking-type-i-ii-errors/img/pc10-dark.png target=_blank alt=pc10><img src=/posts/rethinking-type-i-ii-errors/img/pc10-dark.png width=800></a></div><p>Here are some relevant observations:</p><ul><li>For the zero effect size, the positive rate is 0.05,
which matches the specified $\alpha = 0.05$ (the &ldquo;classic&rdquo; Type I error rate).</li><li>For the positive effect sizes, these charts show the corresponding statistical power of the two tests.
As we can see, in the context of the considered problem,
the Student&rsquo;s t-test is more powerful than the Mann–Whitney U test.
This matches our expectations since the Student&rsquo;s t-test assumes normality (and this assumption is valid)
and therefore has more information about the given samples
(unlike the Mann–Whitney U test that does not have the normality assumption).</li><li>While the Mann–Whitney U test is less powerful,
the actual difference between the powers of these two tests is not so big.
To be more specific, in the given experiment,
the maximum observed difference of $\approx 0.05$ appears for $d = 0.95$.
For large and small effect sizes, the observed difference is even smaller:
for $d<0$ or $d>2$ it is less than $\approx 0.007$.</li><li>The transition from the Student&rsquo;s t-test to the Mann–Whitney U test is a reasonable switch
if we expect a deviation from normality expressed in the form of occasional outliers.
However, such a switch reduces the statistical power of the testing procedure.
Using the above chart, we can see the exact power loss for the whole range of various effect sizes.</li></ul><p>Now let us look at the similar plots for $n \in \{ 20, 30, 100 \}$:</p><p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/rethinking-type-i-ii-errors/img/pc20-light.png target=_blank alt=pc20><img src=/posts/rethinking-type-i-ii-errors/img/pc20-light.png width=800>
</a><a class="img-dark hidden" href=/posts/rethinking-type-i-ii-errors/img/pc20-dark.png target=_blank alt=pc20><img src=/posts/rethinking-type-i-ii-errors/img/pc20-dark.png width=800></a></div><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/rethinking-type-i-ii-errors/img/pc30-light.png target=_blank alt=pc30><img src=/posts/rethinking-type-i-ii-errors/img/pc30-light.png width=800>
</a><a class="img-dark hidden" href=/posts/rethinking-type-i-ii-errors/img/pc30-dark.png target=_blank alt=pc30><img src=/posts/rethinking-type-i-ii-errors/img/pc30-dark.png width=800></a></div><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/rethinking-type-i-ii-errors/img/pc100-light.png target=_blank alt=pc100><img src=/posts/rethinking-type-i-ii-errors/img/pc100-light.png width=800>
</a><a class="img-dark hidden" href=/posts/rethinking-type-i-ii-errors/img/pc100-dark.png target=_blank alt=pc100><img src=/posts/rethinking-type-i-ii-errors/img/pc100-dark.png width=800></a></div></p><p>As we can see, with larger sample sizes,
the difference in the statistical power between the considered tests almost disappears.
For $n=100$, the maximum observed difference of $\approx 0.02$ appears for $d = 0.3$
(for $d<0$ or $d>0.65$, the difference is less than $\approx 0.0008$).</p><h3 id=conclusion>Conclusion</h3><p>While the suggested approach of analyzing the power curves is more complicated than the classic Type I/II error rate
(it forces you to consider the whole function instead of two numbers),
I believe that it reduces the level of misleadingness and helps to improve the testing procedure design.</p></div><hr><h3 id=references>References (1)</h3><ol><li><a href=https://aakinshin.net/library/papers/ title="Library / Papers"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>
</a><a href=https://aakinshin.net/library/papers/bartlett2022/>Power to the People
</a>(2022)
by
<a href=https://aakinshin.net/library/authors/james-bartlett/>James Bartlett</a>
et al.
<span class=label title=Backlinks:1><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>1</span>
<a href=https://aakinshin.net/tags/psychology/><svg class="rating-icon"><title>Psychology</title><use xlink:href="/img/fa/all.svg#psychology"/></svg></a></li></ol><h3 id=backlinks>Backlinks (2)</h3><ol><li><a href=https://aakinshin.net/posts/ title="Library / Posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/mw-confusing-tie-correction/>Confusing Tie Correction in the Classic Mann-Whitney U Test Implementation
</a>(2023-05-23)
<span class=label title=References:3><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>3</span>
<span class=label title=Backlinks:2><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>2</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / Posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/wmw3/>Weighted Mann-Whitney U Test, Part 3
</a>(2024-01-30)
<span class=label title=References:8><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>8</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li></ol></div></div><script>var themeToggleDarkIcon=document.getElementById("theme-toggle-dark-icon"),themeToggleBtn,themeToggleLightIcon=document.getElementById("theme-toggle-light-icon");const imagesDark=document.querySelectorAll(".img-dark"),imagesLight=document.querySelectorAll(".img-light");localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?(themeToggleLightIcon.classList.remove("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")})):(themeToggleDarkIcon.classList.remove("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}));function toggleTheme(e){e?(document.documentElement.classList.add("dark"),themeToggleLightIcon.classList.remove("hidden"),themeToggleDarkIcon.classList.add("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")}),imagesLight.forEach(e=>{e.classList.add("hidden")})):(document.documentElement.classList.remove("dark"),themeToggleDarkIcon.classList.remove("hidden"),themeToggleLightIcon.classList.add("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}),imagesDark.forEach(e=>{e.classList.add("hidden")}))}themeToggleBtn=document.getElementById("theme-toggle"),themeToggleBtn.addEventListener("click",function(){themeToggleDarkIcon.classList.toggle("hidden"),themeToggleLightIcon.classList.toggle("hidden"),imagesLight.forEach(e=>{e.classList.toggle("hidden")}),imagesDark.forEach(e=>{e.classList.toggle("hidden")}),event.altKey?(localStorage.removeItem("color-theme"),toggleTheme(window.matchMedia("(prefers-color-scheme: dark)").matches)):localStorage.getItem("color-theme")?localStorage.getItem("color-theme")==="light"?(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark")):(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):document.documentElement.classList.contains("dark")?(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark"))}),window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",e=>{if(localStorage.getItem("color-theme")===null){const t=e.matches?"dark":"light";toggleTheme(t==="dark")}})</script><footer class="z-20 p-4 md:p-6 mt-3 w-full border-t border-gray-200 shadow flex items-center justify-center dark:border-gray-600 bg-white dark:bg-zinc-800"><span class="dark:text-gray-400 text-center">© 2013—2024 <span class=whitespace-nowrap>Andrey Akinshin</span></span><ul class="flex flex-wrap items-center px-4 mb-1"><li><a href=https://github.com/AndreyAkinshin><svg class="fai fai-link w-5 h-5"><title>GitHub</title><use xlink:href="/img/fa/all.svg#github"/></svg></a></li><li><a href=https://twitter.com/andrey_akinshin><svg class="fai fai-link w-5 h-5"><title>Twitter</title><use xlink:href="/img/fa/all.svg#twitter"/></svg></a></li><li><a href=https://aakinshin.net/posts/index.xml><svg class="fai fai-link w-5 h-5"><title>RSS</title><use xlink:href="/img/fa/all.svg#rss"/></svg></a></li></ul><div class=main-content><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></div></footer><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+=" has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script></body></html>