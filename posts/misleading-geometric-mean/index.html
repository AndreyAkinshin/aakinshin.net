<!doctype html><html lang=en class=h-100><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.103.0-DEV"><meta name=author content="Andrey Akinshin"><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content="Mathematics,Statistics"><title>Misleading geometric mean | Andrey Akinshin</title><meta name=description content="There are multiple ways to compute the &amp;ldquo;average&amp;rdquo; value of an array of numbers. One of such ways is the geometric mean. For a sample \(x = \{ x_..."><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><link href=https://aakinshin.net/sass/bootstrap-light.min.css theme=light rel=stylesheet type=text/css media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link href=https://aakinshin.net/sass/bootstrap-dark.min.css theme=dark rel=stylesheet type=text/css media="(prefers-color-scheme: dark)"><script src=https://aakinshin.net/js/theme-before.min.d7f6578e23ad3f0c33c589f9bcb34f995b45121f1f3ce888869c86b26826c845.js></script>
<script type=module src=https://aakinshin.net/js/dark-mode-toggle.min.9e68d431432744c07a43381a8a833ffe0921cc0e006d84ad97f0b0d43c5cd82d.mjs></script>
<link href=https://aakinshin.net/css/main.min.d3894e60e337fa8d9f2c81dcda5dcb9144502462aaabed3c6bad2fcf178a8410.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"></head><body class="d-flex flex-column min-vh-100"><div class=bg-primary><div class="container bg-primary"><nav class="navbar navbar-expand-sm navbar-dark bg-primary"><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link id=nav-link-blog href=https://aakinshin.net/><svg class="fai"><use xlink:href="/img/fa/all.svg#house-chimney"/></svg></a></li><li class=nav-item><a class=nav-link id=nav-link-posts href=https://aakinshin.net/posts/>Posts</a></li><li class=nav-item><a class=nav-link id=nav-link-about href=https://aakinshin.net/about/>About</a></li></ul><ul class="navbar-nav ms-auto"><li class=nav-item><dark-mode-toggle permanent=true></dark-mode-toggle></li></ul></nav></div></div><div class=container><main id=main><div class=blog-main><div class="blog-post table-sm"><h1 class=blog-post-title id=post-title>Misleading geometric mean</h1><span class=blog-post-meta><svg class="fai"><use xlink:href="/img/fa/all.svg#calendar-days"/></svg><time datetime=2021-12-28>December 28, 2021</time>
&nbsp;&nbsp;<svg class="fai"><use xlink:href="/img/fa/all.svg#tag"/></svg>
<a href=https://aakinshin.net/tags/mathematics/ class="badge badge-info">Mathematics</a>
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a></span><br><br><p>There are multiple ways to compute the &ldquo;average&rdquo; value of an array of numbers.
One of such ways is the <em>geometric mean</em>.
For a sample <span class="math inline">\(x = \{ x_1, x_2, \ldots, x_n \}\)</span>, the geometric means is defined as follows:</p><p><span class="math display">\[\operatorname{GM}(x) = \sqrt[n]{x_1 x_2 \ldots x_n}
\]</span></p><p>This approach is widely recommended for some specific tasks.
Let&rsquo;s say we want to compare the performance of two machines <span class="math inline">\(M_x\)</span> and <span class="math inline">\(M_y\)</span>.
In order to do this, we design a set of benchmarks <span class="math inline">\(b = \{b_1, b_2, \ldots, b_n \}\)</span>
and obtain two sets of measurements
<span class="math inline">\(x = \{ x_1, x_2, \ldots, x_n \}\)</span> and <span class="math inline">\(y = \{ y_1, y_2, \ldots, y_n \}\)</span>.
Once we have these two samples, we may have a desire to express the difference
between two machines as a single number and get a conclusion like
&ldquo;Machine <span class="math inline">\(M_y\)</span> works two times faster than <span class="math inline">\(M_x\)</span>.&rdquo;
I think that this approach is flawed because such a difference couldn&rsquo;t be expressed as a single number:
the result heavily depends on the workloads that we analyze.
For example, imagine that <span class="math inline">\(M_x\)</span> is a machine with HDD and fast CPU, <span class="math inline">\(M_y\)</span> is a machine with SSD and slow CPU.
In this case, <span class="math inline">\(M_x\)</span> could be faster on CPU-bound workloads while <span class="math inline">\(M_y\)</span> could be faster on disk-bound workloads.
I really like this summary from
<a href=https://www.eecs.umich.edu/techreports/cse/95/CSE-TR-231-95.pdf>&ldquo;Notes on Calculating Computer Performance&rdquo;</a>
by Bruce Jacob and Trevor Mudge (in the same paper, the authors criticize the approach with the geometric mean):</p><blockquote><p>Performance is therefore not a single number, but really a collection of implications.
It is nothing more or less than the measure of
how much time <em>we</em> save running <em>our</em> tests on the machines in question.
If someone else has similar needs to ours, our performance numbers will be useful to them.
However, two people with different sets of criteria will likely walk away
with two completely different performance numbers for the same machine.</p></blockquote><p>However, some other authors (e.g., <a href=https://doi.org/10.1145/5666.5673>&ldquo;How not to lie with statistics: the correct way to summarize benchmark results&rdquo;</a>)
actually recommend using the geometric mean to get such a number
that describes the performance ratio of <span class="math inline">\(M_x\)</span> and <span class="math inline">\(M_y\)</span>.
I have to admit that the geometric mean <em>could</em> provide a reasonable result in <em>some simple cases</em>.
Indeed, on normalized numbers, it works much better than the arithmetic mean
(that provides meaningless result) because of its nice <a href=https://en.wikipedia.org/wiki/Geometric_mean#Application_to_normalized_values>property</a>:
<span class="math inline">\(\operatorname{GM}(x_i/y_i) = \operatorname{GM}(x_i) / \operatorname{GM}(y_i)\)</span>.
However, it doesn&rsquo;t work properly in the general case.
Firstly, the desire to express the difference between two machines is vicious:
the result heavily depends on the chosen workloads.
Secondly, the performance of a single benchmark <span class="math inline">\(b_i\)</span> couldn&rsquo;t be described as a single number <span class="math inline">\(x_i\)</span>:
we should consider the whole performance distributions.
In order to describe the difference between two distributions,
we could consider the <a href=https://aakinshin.net/posts/shift-and-ratio-functions/>shift and ration functions</a>
(that work much better than the <a href=https://aakinshin.net/posts/shift-function-vs-distribution/>shift</a> and
<a href=https://aakinshin.net/posts/ratio-function-vs-distribution/>ratio</a> distributions).</p><p>Even if you consider a pretty homogenous set of benchmarks and all the distributions are pretty narrow,
the geometric mean has severe drawbacks that you should keep in mind.
In this post, I briefly cover some of these drawbacks and highlight problems that you may have if you use this metric.</p><h3 id=computational-problems>Computational problems</h3><p>If <span class="math inline">\(n\)</span> is large, the straightforward way to compute the geometric mean
may lead to a low accuracy due to overflow in the product <span class="math inline">\(x_1 x_2 \ldots x_n\)</span>.
This problem is a non-critical one because it could be easily solved using the exponential form of the geometric mean:</p><p><span class="math display">\[\operatorname{GM}(x) =
\sqrt[n]{x_1 x_2 \ldots x_n} =
e^{\frac{\sum_{i=1}^n \ln x_i}{n}}
\]</span></p><h3 id=zero-values>Zero values</h3><p>The usage of geometric mean makes sense only for positive numbers.
However, in real life, we may get a situation when our samples contain zero values.
If we discuss <span class="math inline">\(\operatorname{GM}\)</span> in the context of software benchmarks,
we may have zero because of poor benchmark design
(if we forget to use the benchmark result, the compiler may eliminate the benchmark body)
or small <a href=https://aakinshin.net/posts/discrete-performance-distributions/>granularity of our measurements</a>
(e.g., we express the measurements in milliseconds, but a benchmark takes less than 1 millisecond).
It&rsquo;s enough to get a single zero measurement to completely spoil the final results.
If <span class="math inline">\(x_1=0\)</span>, <span class="math inline">\(\operatorname{GM}(x)=0\)</span> regardless of other <span class="math inline">\(x_i\)</span> values.</p><h3 id=non-stability-on-small-values>Non-stability on small values</h3><p>We shouldn&rsquo;t consider the ratio of the geometric means as a stable indicator of the true ratio
(especially when the sample elements are small).</p><p>Let&rsquo;s say that we randomly take two samples of size <span class="math inline">\(100\)</span> from the standard uniform distribution <span class="math inline">\(\mathcal{U}(0,1)\)</span>
and calculate the ratio of the corresponding geometric means <span class="math inline">\(\operatorname{GM}(x_i) / \operatorname{GM}(y_i)\)</span>.
Using the below R snippet, I have performed this experiment <span class="math inline">\(1000\)</span> times:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=cl><span class=n>gm</span> <span class=o>&lt;-</span> <span class=nf>function</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=nf>exp</span><span class=p>(</span><span class=nf>mean</span><span class=p>(</span><span class=nf>log</span><span class=p>(</span><span class=n>x</span><span class=p>)))</span>
</span></span><span class=line><span class=cl><span class=nf>set.seed</span><span class=p>(</span><span class=m>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>u</span> <span class=o>&lt;-</span> <span class=nf>sort</span><span class=p>(</span><span class=nf>replicate</span><span class=p>(</span><span class=m>1000</span><span class=p>,</span> <span class=nf>gm</span><span class=p>(</span><span class=nf>runif</span><span class=p>(</span><span class=m>100</span><span class=p>))</span> <span class=o>/</span> <span class=nf>gm</span><span class=p>(</span><span class=nf>runif</span><span class=p>(</span><span class=m>100</span><span class=p>))))</span>
</span></span></code></pre></div><p>Here are the TOP 5 lowest and the TOP 5 highest results:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=cl><span class=o>&gt;</span> <span class=nf>head</span><span class=p>(</span><span class=n>u</span><span class=p>,</span> <span class=m>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>[1]</span> <span class=m>0.6367051</span> <span class=m>0.6471006</span> <span class=m>0.6783169</span> <span class=m>0.6809434</span> <span class=m>0.6845263</span>
</span></span><span class=line><span class=cl><span class=o>&gt;</span> <span class=nf>tail</span><span class=p>(</span><span class=n>u</span><span class=p>,</span> <span class=m>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>[1]</span> <span class=m>1.464806</span> <span class=m>1.468903</span> <span class=m>1.495844</span> <span class=m>1.519174</span> <span class=m>1.520818</span>
</span></span></code></pre></div><p>As we can see, the obtained ratio goes from <span class="math inline">\(\approx 0.6\)</span> to <span class="math inline">\(\approx 1.5\)</span>
while both samples had been taken from the same distribution
and the sample size is quite large (<span class="math inline">\(n=100\)</span>).
Thus, we shouldn&rsquo;t always interpret <span class="math inline">\(\operatorname{GM}(x_i) / \operatorname{GM}(y_i) = 1.5\)</span>
as 1.5x difference between distributions <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>:
such a value could be easily observed by chance without the actual difference between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p><h3 id=robustness>Robustness</h3><p>While the geometric mean is much more resistant to outliers than the arithmetic mean,
it&rsquo;s not robust.
It means that a single outlier could corrupt our result.</p><p>Let&rsquo;s consider the Weibull distribution with <span class="math inline">\(\textrm{shape}=0.1\)</span> (which is a heavy-tailed distribution):</p><div class=row><div class=mx-auto><a href=/posts/misleading-geometric-mean/img/weibull-light.png target=_blank class=imgldlink alt=weibull><picture><source theme=dark srcset=/posts/misleading-geometric-mean/img/weibull-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/misleading-geometric-mean/img/weibull-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/misleading-geometric-mean/img/weibull-light.png></picture></a></div></div><br><p>Next, let&rsquo;s perform the experiment from the previous section using the Weibull distribution:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=cl><span class=nf>library</span><span class=p>(</span><span class=n>evd</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nf>set.seed</span><span class=p>(</span><span class=m>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>u</span> <span class=o>&lt;-</span> <span class=nf>sort</span><span class=p>(</span><span class=nf>replicate</span><span class=p>(</span><span class=m>1000</span><span class=p>,</span> <span class=nf>gm</span><span class=p>(</span><span class=nf>rweibull</span><span class=p>(</span><span class=m>100</span><span class=p>,</span> <span class=m>0.1</span><span class=p>))</span> <span class=o>/</span> <span class=nf>gm</span><span class=p>(</span><span class=nf>rweibull</span><span class=p>(</span><span class=m>100</span><span class=p>,</span> <span class=m>0.1</span><span class=p>))))</span>
</span></span></code></pre></div><p>Here are the TOP 5 lowest and the TOP 5 highest results:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=cl><span class=o>&gt;</span> <span class=nf>head</span><span class=p>(</span><span class=n>u</span><span class=p>,</span> <span class=m>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>[1]</span> <span class=m>0.001484348</span> <span class=m>0.004923385</span> <span class=m>0.005668490</span> <span class=m>0.006009496</span> <span class=m>0.006248911</span>
</span></span><span class=line><span class=cl><span class=o>&gt;</span> <span class=nf>tail</span><span class=p>(</span><span class=n>u</span><span class=p>,</span> <span class=m>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>[1]</span> <span class=m>131.4244</span> <span class=m>200.4754</span> <span class=m>242.1431</span> <span class=m>273.2267</span> <span class=m>312.9481</span>
</span></span></code></pre></div><p>While both samples had been taken from the same distribution,
the corresponding geometric mean ratio could be <span class="math inline">\(\approx 0.001\)</span> or <span class="math inline">\(\approx 300\)</span>
which is pretty far from the expected <span class="math inline">\(1\)</span>.</p><p>Performance distributions are often heavy-tailed,
the corresponding samples may contain extreme outliers.
We should remember that such outliers could completely distort our conclusions
if they are not handled properly.</p><h3 id=conclusion>Conclusion</h3><p>We shouldn&rsquo;t consider the geometric mean as a universal approach to compare two sets of numbers.
While it may work fine in some applications, it doesn&rsquo;t produce reliable results in the general case.
I recommend avoiding aggregation values to a single number and considering the whole distributions.</p><br><br><div class=row><div class="justify-content-center share-block"><div class=share-title>Share:</div><div class=share-button><a href="https://www.reddit.com/submit?url=https%3a%2f%2faakinshin.net%2fposts%2fmisleading-geometric-mean%2f&title=Misleading%20geometric%20mean" target=_blank title="Share on Reddit"><svg class="fai"><use xlink:href="/img/fa/all.svg#reddit"/></svg></a></div><div class=share-button><a href="https://twitter.com/intent/tweet?text=Misleading%20geometric%20mean&url=https%3a%2f%2faakinshin.net%2fposts%2fmisleading-geometric-mean%2f&via=andrey_akinshin&related=andrey_akinshin" rel=nofollow target=_blank title="Share on Twitter"><svg class="fai"><use xlink:href="/img/fa/all.svg#twitter"/></svg></a></div><div class=share-button><a href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2faakinshin.net%2fposts%2fmisleading-geometric-mean%2f" target=_blank title="Share on HackerNews"><svg class="fai"><use xlink:href="/img/fa/all.svg#hacker-news"/></svg></a></div><div class=share-button><a href="https://getpocket.com/save?url=https%3a%2f%2faakinshin.net%2fposts%2fmisleading-geometric-mean%2f&title=Misleading%20geometric%20mean" target=_blank title="Add to Pocket"><svg class="fai"><use xlink:href="/img/fa/all.svg#get-pocket"/></svg></a></div></div></div></div><hr></div></div></main></div><footer class="blog-footer mt-auto"><div class=container><p>&copy; 2013&mdash;2022 Andrey Akinshin
|
<a href=https://github.com/AndreyAkinshin><svg class="fai"><title>GitHub</title><use xlink:href="/img/fa/all.svg#github"/></svg></a><a href=https://twitter.com/andrey_akinshin><svg class="fai"><title>Twitter</title><use xlink:href="/img/fa/all.svg#twitter"/></svg></a><a href=https://aakinshin.net/posts/index.xml><svg class="fai"><title>RSS</title><use xlink:href="/img/fa/all.svg#rss"/></svg></a>|
<a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></p></div></footer><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.2.0/dist/js/bootstrap.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.3.1/anchor.min.js integrity="sha512-zPB79j2C+3sFS9zcA3vg/z6bVKzJVEyu9pY5w89akQRys76zpAT2t6S3wZKla3QQ14O5l/Yt0RUQ/DHXx82Y5g==" crossorigin=anonymous referrerpolicy=no-referrer></script>
<script src=https://aakinshin.net/js/theme-after.min.29520a8e1176193da7ea4e6cb56cf9b3e634b867c9979234d8dafb5ab61dd494.js></script>
<script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script></body></html>