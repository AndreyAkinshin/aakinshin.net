<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.123.3"><meta name=author content='Andrey Akinshin'><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content='Mathematics,Statistics'><title>Misleading geometric mean | Andrey Akinshin</title>
<meta name=description content="There are multiple ways to compute the &amp;ldquo;average&amp;rdquo; value of an array of numbers. One of such ways is the geometric mean. For a sample $x = \{ x_1, x_2, \ldots, x_n \}$, the geometric means is defined as follows:
$$ \operatorname{GM}(x) = \sqrt[n]{..."><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><script>localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?document.documentElement.classList.add("dark"):document.documentElement.classList.remove("dark")</script><link href=https://aakinshin.net/css/main.min.25504b87a17cfaf1c000a5bcca42b1c4888fa4efc097d640d9139388b3e67e55.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"></head><body><nav><div class="container flex flex-wrap items-center justify-between mx-auto max-w-6xl h-12 px-2 xs:px-6"><div class="flex items-center justify-start justify-self-start"><div class="flex nav-item h-12 w-12 items-center justify-center"><a class=text-white href=https://aakinshin.net/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#house-chimney"/></svg></a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/posts/>Posts</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/research/>Research</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/library/>Library</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/about/>About</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/search/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#magnifying-glass"/></svg></a></div></div><button id=theme-toggle type=button title="Alt+Click to match OS color theme" class="nav-item p-3 content-center justify-self-end"><svg id="theme-toggle-dark-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001.0 1010.586 10.586z"/></svg><svg id="theme-toggle-light-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M10 2a1 1 0 011 1v1A1 1 0 119 4V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707A1 1 0 1113.536 5.05l.707-.707a1 1 0 011.414.0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707A1 1 0 004.343 5.757l.707.707zm1.414 8.486-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z" fill-rule="evenodd" clip-rule="evenodd"/></svg></button></div></nav><div class="main container mx-auto max-w-6xl px-6"><div class=main-post><h1 class=blog-post-title id=post-title>Misleading Geometric Mean</h1><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg>
<time datetime=2021-12-28>December 28, 2021</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/>Mathematics</a>
<a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics</a></div></div><br><div class=main-content><p>There are multiple ways to compute the &ldquo;average&rdquo; value of an array of numbers.
One of such ways is the <em>geometric mean</em>.
For a sample $x = \{ x_1, x_2, \ldots, x_n \}$, the geometric means is defined as follows:</p>$$
\operatorname{GM}(x) = \sqrt[n]{x_1 x_2 \ldots x_n}
$$<p>This approach is widely recommended for some specific tasks.
Let&rsquo;s say we want to compare the performance of two machines $M_x$ and $M_y$.
In order to do this, we design a set of benchmarks $b = \{b_1, b_2, \ldots, b_n \}$
and obtain two sets of measurements
$x = \{ x_1, x_2, \ldots, x_n \}$ and $y = \{ y_1, y_2, \ldots, y_n \}$.
Once we have these two samples, we may have a desire to express the difference
between two machines as a single number and get a conclusion like
&ldquo;Machine $M_y$ works two times faster than $M_x$.&rdquo;
I think that this approach is flawed because such a difference couldn&rsquo;t be expressed as a single number:
the result heavily depends on the workloads that we analyze.
For example, imagine that $M_x$ is a machine with HDD and fast CPU, $M_y$ is a machine with SSD and slow CPU.
In this case, $M_x$ could be faster on CPU-bound workloads while $M_y$ could be faster on disk-bound workloads.
I really like this summary from
<a href=https://www.eecs.umich.edu/techreports/cse/95/CSE-TR-231-95.pdf>&ldquo;Notes on Calculating Computer Performance&rdquo;</a>
by Bruce Jacob and Trevor Mudge (in the same paper, the authors criticize the approach with the geometric mean):</p><blockquote><p>Performance is therefore not a single number, but really a collection of implications.
It is nothing more or less than the measure of
how much time <em>we</em> save running <em>our</em> tests on the machines in question.
If someone else has similar needs to ours, our performance numbers will be useful to them.
However, two people with different sets of criteria will likely walk away
with two completely different performance numbers for the same machine.</p></blockquote><p>However, some other authors (e.g., <a href=https://doi.org/10.1145/5666.5673>&ldquo;How not to lie with statistics: the correct way to summarize benchmark results&rdquo;</a>)
actually recommend using the geometric mean to get such a number
that describes the performance ratio of $M_x$ and $M_y$.
I have to admit that the geometric mean <em>could</em> provide a reasonable result in <em>some simple cases</em>.
Indeed, on normalized numbers, it works much better than the arithmetic mean
(that provides meaningless result) because of its nice <a href=https://en.wikipedia.org/wiki/Geometric_mean#Application_to_normalized_values>property</a>:
$\operatorname{GM}(x_i/y_i) = \operatorname{GM}(x_i) / \operatorname{GM}(y_i)$.
However, it doesn&rsquo;t work properly in the general case.
Firstly, the desire to express the difference between two machines is vicious:
the result heavily depends on the chosen workloads.
Secondly, the performance of a single benchmark $b_i$ couldn&rsquo;t be described as a single number $x_i$:
we should consider the whole performance distributions.
In order to describe the difference between two distributions,
we could consider the <a href=https://aakinshin.net/posts/shift-and-ratio-functions/>shift and ration functions</a>
(that work much better than the <a href=https://aakinshin.net/posts/shift-function-vs-distribution/>shift</a> and
<a href=https://aakinshin.net/posts/ratio-function-vs-distribution/>ratio</a> distributions).</p><p>Even if you consider a pretty homogenous set of benchmarks and all the distributions are pretty narrow,
the geometric mean has severe drawbacks that you should keep in mind.
In this post, I briefly cover some of these drawbacks and highlight problems that you may have if you use this metric.</p><h3 id=computational-problems>Computational problems</h3><p>If $n$ is large, the straightforward way to compute the geometric mean
may lead to a low accuracy due to overflow in the product $x_1 x_2 \ldots x_n$.
This problem is a non-critical one because it could be easily solved using the exponential form of the geometric mean:</p>$$
\operatorname{GM}(x) =
\sqrt[n]{x_1 x_2 \ldots x_n} =
e^{\frac{\sum_{i=1}^n \ln x_i}{n}}
$$<h3 id=zero-values>Zero values</h3><p>The usage of geometric mean makes sense only for positive numbers.
However, in real life, we may get a situation when our samples contain zero values.
If we discuss $\operatorname{GM}$ in the context of software benchmarks,
we may have zero because of poor benchmark design
(if we forget to use the benchmark result, the compiler may eliminate the benchmark body)
or small <a href=https://aakinshin.net/posts/discrete-performance-distributions/>granularity of our measurements</a>
(e.g., we express the measurements in milliseconds, but a benchmark takes less than 1 millisecond).
It&rsquo;s enough to get a single zero measurement to completely spoil the final results.
If $x_1=0$, $\operatorname{GM}(x)=0$ regardless of other $x_i$ values.</p><h3 id=non-stability-on-small-values>Non-stability on small values</h3><p>We shouldn&rsquo;t consider the ratio of the geometric means as a stable indicator of the true ratio
(especially when the sample elements are small).</p><p>Let&rsquo;s say that we randomly take two samples of size $100$ from the standard uniform distribution $\mathcal{U}(0,1)$
and calculate the ratio of the corresponding geometric means $\operatorname{GM}(x_i) / \operatorname{GM}(y_i)$.
Using the below R snippet, I have performed this experiment $1000$ times:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=cl><span class=n>gm</span> <span class=o>&lt;-</span> <span class=kr>function</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=nf>exp</span><span class=p>(</span><span class=nf>mean</span><span class=p>(</span><span class=nf>log</span><span class=p>(</span><span class=n>x</span><span class=p>)))</span>
</span></span><span class=line><span class=cl><span class=nf>set.seed</span><span class=p>(</span><span class=m>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>u</span> <span class=o>&lt;-</span> <span class=nf>sort</span><span class=p>(</span><span class=nf>replicate</span><span class=p>(</span><span class=m>1000</span><span class=p>,</span> <span class=nf>gm</span><span class=p>(</span><span class=nf>runif</span><span class=p>(</span><span class=m>100</span><span class=p>))</span> <span class=o>/</span> <span class=nf>gm</span><span class=p>(</span><span class=nf>runif</span><span class=p>(</span><span class=m>100</span><span class=p>))))</span>
</span></span></code></pre></div><p>Here are the TOP 5 lowest and the TOP 5 highest results:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=cl><span class=o>&gt;</span> <span class=nf>head</span><span class=p>(</span><span class=n>u</span><span class=p>,</span> <span class=m>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>[1]</span> <span class=m>0.6367051</span> <span class=m>0.6471006</span> <span class=m>0.6783169</span> <span class=m>0.6809434</span> <span class=m>0.6845263</span>
</span></span><span class=line><span class=cl><span class=o>&gt;</span> <span class=nf>tail</span><span class=p>(</span><span class=n>u</span><span class=p>,</span> <span class=m>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>[1]</span> <span class=m>1.464806</span> <span class=m>1.468903</span> <span class=m>1.495844</span> <span class=m>1.519174</span> <span class=m>1.520818</span>
</span></span></code></pre></div><p>As we can see, the obtained ratio goes from $\approx 0.6$ to $\approx 1.5$
while both samples had been taken from the same distribution
and the sample size is quite large ($n=100$).
Thus, we shouldn&rsquo;t always interpret $\operatorname{GM}(x_i) / \operatorname{GM}(y_i) = 1.5$
as 1.5x difference between distributions $X$ and $Y$:
such a value could be easily observed by chance without the actual difference between $X$ and $Y$.</p><h3 id=robustness>Robustness</h3><p>While the geometric mean is much more resistant to outliers than the arithmetic mean,
it&rsquo;s not robust.
It means that a single outlier could corrupt our result.</p><p>Let&rsquo;s consider the Weibull distribution with $\textrm{shape}=0.1$ (which is a heavy-tailed distribution):</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/misleading-geometric-mean/img/weibull-light.png target=_blank alt=weibull><img src=/posts/misleading-geometric-mean/img/weibull-light.png width=800>
</a><a class="img-dark hidden" href=/posts/misleading-geometric-mean/img/weibull-dark.png target=_blank alt=weibull><img src=/posts/misleading-geometric-mean/img/weibull-dark.png width=800></a></div><p>Next, let&rsquo;s perform the experiment from the previous section using the Weibull distribution:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=cl><span class=nf>library</span><span class=p>(</span><span class=n>evd</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nf>set.seed</span><span class=p>(</span><span class=m>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>u</span> <span class=o>&lt;-</span> <span class=nf>sort</span><span class=p>(</span><span class=nf>replicate</span><span class=p>(</span><span class=m>1000</span><span class=p>,</span> <span class=nf>gm</span><span class=p>(</span><span class=nf>rweibull</span><span class=p>(</span><span class=m>100</span><span class=p>,</span> <span class=m>0.1</span><span class=p>))</span> <span class=o>/</span> <span class=nf>gm</span><span class=p>(</span><span class=nf>rweibull</span><span class=p>(</span><span class=m>100</span><span class=p>,</span> <span class=m>0.1</span><span class=p>))))</span>
</span></span></code></pre></div><p>Here are the TOP 5 lowest and the TOP 5 highest results:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=cl><span class=o>&gt;</span> <span class=nf>head</span><span class=p>(</span><span class=n>u</span><span class=p>,</span> <span class=m>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>[1]</span> <span class=m>0.001484348</span> <span class=m>0.004923385</span> <span class=m>0.005668490</span> <span class=m>0.006009496</span> <span class=m>0.006248911</span>
</span></span><span class=line><span class=cl><span class=o>&gt;</span> <span class=nf>tail</span><span class=p>(</span><span class=n>u</span><span class=p>,</span> <span class=m>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>[1]</span> <span class=m>131.4244</span> <span class=m>200.4754</span> <span class=m>242.1431</span> <span class=m>273.2267</span> <span class=m>312.9481</span>
</span></span></code></pre></div><p>While both samples had been taken from the same distribution,
the corresponding geometric mean ratio could be $\approx 0.001$ or $\approx 300$
which is pretty far from the expected $1$.</p><p>Performance distributions are often heavy-tailed,
the corresponding samples may contain extreme outliers.
We should remember that such outliers could completely distort our conclusions
if they are not handled properly.</p><h3 id=conclusion>Conclusion</h3><p>We shouldn&rsquo;t consider the geometric mean as a universal approach to compare two sets of numbers.
While it may work fine in some applications, it doesn&rsquo;t produce reliable results in the general case.
I recommend avoiding aggregation values to a single number and considering the whole distributions.</p></div><hr><h3 id=references>References (4)</h3><ol><li><a href=https://aakinshin.net/posts/>Posts</a> /
<a href=https://aakinshin.net/posts/discrete-performance-distributions/>Discrete Performance Distributions
</a>(2021-06-15)</li><li><a href=https://aakinshin.net/posts/>Posts</a> /
<a href=https://aakinshin.net/posts/ratio-function-vs-distribution/>Ratio Function vs. Ratio Distribution
</a>(2021-12-14)</li><li><a href=https://aakinshin.net/posts/>Posts</a> /
<a href=https://aakinshin.net/posts/shift-and-ratio-functions/>Distribution Comparison via the Shift and Ratio Functions
</a>(2019-10-11)</li><li><a href=https://aakinshin.net/posts/>Posts</a> /
<a href=https://aakinshin.net/posts/shift-function-vs-distribution/>Shift Function vs. Shift Distribution
</a>(2021-12-07)</li></ol></div></div><script>var themeToggleDarkIcon=document.getElementById("theme-toggle-dark-icon"),themeToggleBtn,themeToggleLightIcon=document.getElementById("theme-toggle-light-icon");const imagesDark=document.querySelectorAll(".img-dark"),imagesLight=document.querySelectorAll(".img-light");localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?(themeToggleLightIcon.classList.remove("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")})):(themeToggleDarkIcon.classList.remove("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}));function toggleTheme(e){e?(document.documentElement.classList.add("dark"),themeToggleLightIcon.classList.remove("hidden"),themeToggleDarkIcon.classList.add("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")}),imagesLight.forEach(e=>{e.classList.add("hidden")})):(document.documentElement.classList.remove("dark"),themeToggleDarkIcon.classList.remove("hidden"),themeToggleLightIcon.classList.add("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}),imagesDark.forEach(e=>{e.classList.add("hidden")}))}themeToggleBtn=document.getElementById("theme-toggle"),themeToggleBtn.addEventListener("click",function(){themeToggleDarkIcon.classList.toggle("hidden"),themeToggleLightIcon.classList.toggle("hidden"),imagesLight.forEach(e=>{e.classList.toggle("hidden")}),imagesDark.forEach(e=>{e.classList.toggle("hidden")}),event.altKey?(localStorage.removeItem("color-theme"),toggleTheme(window.matchMedia("(prefers-color-scheme: dark)").matches)):localStorage.getItem("color-theme")?localStorage.getItem("color-theme")==="light"?(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark")):(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):document.documentElement.classList.contains("dark")?(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark"))}),window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",e=>{if(localStorage.getItem("color-theme")===null){const t=e.matches?"dark":"light";toggleTheme(t==="dark")}})</script><footer class="z-20 p-4 md:p-6 mt-3 w-full border-t border-gray-200 shadow flex items-center justify-center dark:border-gray-600 bg-white dark:bg-zinc-800"><span class="dark:text-gray-400 text-center">© 2013—2024 <span class=whitespace-nowrap>Andrey Akinshin</span></span><ul class="flex flex-wrap items-center px-4 mb-1"><li><a href=https://github.com/AndreyAkinshin><svg class="fai fai-link w-5 h-5"><title>GitHub</title><use xlink:href="/img/fa/all.svg#github"/></svg></a></li><li><a href=https://twitter.com/andrey_akinshin><svg class="fai fai-link w-5 h-5"><title>Twitter</title><use xlink:href="/img/fa/all.svg#twitter"/></svg></a></li><li><a href=https://aakinshin.net/posts/index.xml><svg class="fai fai-link w-5 h-5"><title>RSS</title><use xlink:href="/img/fa/all.svg#rss"/></svg></a></li></ul><div class=main-content><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></div></footer><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+=" has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script></body></html>