<!doctype html><html lang=en class=h-100><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.103.0-DEV"><meta name=author content="Andrey Akinshin"><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content="Mathematics,Statistics,Research,Research: Weighted quantile estimators,Quantile,Confidence Interval"><title>Quantile confidence intervals for weighted samples | Andrey Akinshin</title><meta name=description content="How to modify the Maritz-Jarrett method to estimate confidence intervals around given quantiles on weighted samples"><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><link href=https://aakinshin.net/sass/bootstrap-light.min.css theme=light rel=stylesheet type=text/css media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link href=https://aakinshin.net/sass/bootstrap-dark.min.css theme=dark rel=stylesheet type=text/css media="(prefers-color-scheme: dark)"><script src=https://aakinshin.net/js/theme-before.min.d7f6578e23ad3f0c33c589f9bcb34f995b45121f1f3ce888869c86b26826c845.js></script>
<script type=module src=https://aakinshin.net/js/dark-mode-toggle.min.9e68d431432744c07a43381a8a833ffe0921cc0e006d84ad97f0b0d43c5cd82d.mjs></script>
<link href=https://aakinshin.net/css/main.min.d3894e60e337fa8d9f2c81dcda5dcb9144502462aaabed3c6bad2fcf178a8410.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"></head><body class="d-flex flex-column min-vh-100"><div class=bg-primary><div class="container bg-primary"><nav class="navbar navbar-expand-sm navbar-dark bg-primary"><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link id=nav-link-blog href=https://aakinshin.net/><svg class="fai"><use xlink:href="/img/fa/all.svg#house-chimney"/></svg></a></li><li class=nav-item><a class=nav-link id=nav-link-posts href=https://aakinshin.net/posts/>Posts</a></li><li class=nav-item><a class=nav-link id=nav-link-about href=https://aakinshin.net/about/>About</a></li></ul><ul class="navbar-nav ms-auto"><li class=nav-item><dark-mode-toggle permanent=true></dark-mode-toggle></li></ul></nav></div></div><div class=container><main id=main><div class=blog-main><div class="blog-post table-sm"><h1 class=blog-post-title id=post-title>Quantile confidence intervals for weighted samples</h1><span class=blog-post-meta><svg class="fai"><use xlink:href="/img/fa/all.svg#calendar-days"/></svg><time datetime=2020-12-08>December 8, 2020</time>
&nbsp;&nbsp;<svg class="fai"><use xlink:href="/img/fa/all.svg#tag"/></svg>
<a href=https://aakinshin.net/tags/mathematics/ class="badge badge-info">Mathematics</a>
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research/ class="badge badge-info">Research</a>
<a href=https://aakinshin.net/tags/research-wqe/ class="badge badge-info">Research: Weighted quantile estimators</a>
<a href=https://aakinshin.net/tags/quantile/ class="badge badge-info">Quantile</a>
<a href=https://aakinshin.net/tags/confidence-interval/ class="badge badge-info">Confidence Interval</a></span><br><br><p><strong>Update 2021-07-06:
the approach was updated using the <a href=https://aakinshin.net/posts/kish-ess-weighted-quantiles/>Kish&rsquo;s effective sample size</a>.</strong></p><p>When you work with non-parametric distributions,
quantile estimations are essential to get the main distribution properties.
Once you get the estimation values, you may be interested in measuring the accuracy of these estimations.
Without it, it&rsquo;s hard to understand how trustable the obtained values are.
One of the most popular ways to evaluate accuracy is confidence interval estimation.</p><p>Now imagine that you collect some measurements every day.
Each day you get a small sample of values that is not enough to get the accurate daily quantile estimations.
However, the full time-series over the last several weeks has a decent size.
You suspect that past measurements should be similar to today measurements,
but you are not 100% sure about it.
You feel a temptation to extend the up-to-date sample by the previously collected values,
but it may spoil the estimation (e.g., in the case of recent change points or positive/negative trends).</p><p>One of the possible approaches in this situation is to use <em>weighted samples</em>.
This assumes that we add past measurements to the &ldquo;today sample,&rdquo;
but these values should have smaller weight.
The older measurement we take, the smaller weight it gets.
If you have consistent values across the last several days,
this approach works like a charm.
If you have any recent changes, you can detect such situations by huge confidence intervals
due to the sample inconsistency.</p><p>So, how do we estimate confidence intervals around quantiles for the weighted samples?
In one of the previous posts, I have already shown how to <a href=https://aakinshin.net/posts/weighted-quantiles/>estimate quantiles on weighted samples</a>.
In this post, I will show how to estimate quantile confidence intervals for weighted samples.</p><h3 id=quantile-confidence-interval-estimators>Quantile confidence interval estimators</h3><p>There are many different ways to estimate quantiles.
Here are some of the popular approaches:</p><ul><li><strong>Density estimation</strong><br>The exact equation for the standard error of the <span class="math inline">\(p^\textrm{th}\)</span> quantile is well-known,
it equals <span class="math inline">\(\sqrt{p(1-p)}/(\sqrt{n} f(q_p))\)</span> where <span class="math inline">\(f\)</span> is the <a href=https://en.wikipedia.org/wiki/Probability_density_function>probability density function</a>.
Unfortunately, this equation <a href=https://xkcd.com/688/>requires the knowledge</a>
of the density function, which we are actually trying to estimate using quantile.
Although we can still try to estimate it in different ways.
For example, we can use Rosenblatt&rsquo;s shifted histogram (see <a href=#Wilcox2017>[Wilcox2017]</a>).
However, these approaches don&rsquo;t provide good confidence interval estimation on non-normal distribution.</li><li><strong>Bootstrap</strong><br>I&rsquo;m not a fan of the <a href=https://en.wikipedia.org/wiki/Bootstrapping_(statistics)>bootstrap</a> method.
Firstly, it uses randomization, so its results are not repeatable by default.
Secondly, it&rsquo;s often inefficient: you should spend some time to get reasonable estimations.
Finally, it works poorly on small samples.
While bootstrapping is a good option when you don&rsquo;t have any alternatives,
but we will try to find a better approach.</li><li><strong>Jackknife</strong><br>In comparison with bootstrap, the <a href=https://en.wikipedia.org/wiki/Jackknife_resampling>jackknife</a>
doesn&rsquo;t have the repeatability problem and can be used to estimate different distribution parameters.
However, it works poorly in the case of quantile estimation (e.g., see <a href=#Martin1990>[Martin1990]</a>)</li></ul><p>I tried different variations of the above approaches,
but I wasn&rsquo;t satisfied with the results.
Based on my experience, the most optimal approach in terms of accuracy and performance
is <strong>the Maritz-Jarrett method</strong> (<a href=#Maritz1979>[Maritz1979]</a>).
Also, it works as a natural extension of the Harrell-Davis quantile estimator (<a href=#Harrell1982>[Harrell1982]</a>)
which is my favorite way to estimate quantiles.
Let&rsquo;s discuss how we can adopt the Maritz-Jarrett method to the weighted samples.</p><h3 id=the-maritz-jarrett-method>The Maritz-Jarrett method</h3><p>First of all, let&rsquo;s introduce the following notation:</p><ul><li><span class="math inline">\(x = \{ x_1, x_2, \ldots x_n \}\)</span>: original sample. Assuming that it&rsquo;s always contain sorted real numbers.</li><li><span class="math inline">\(w = \{ w_1, w_2, \ldots w_n \}\)</span>: a vector of weights. It has the same length as <span class="math inline">\(x\)</span>. Assuming <span class="math inline">\(w_i \geq 0\)</span>, <span class="math inline">\(\sum_{i=1}^n w > 0\)</span>.</li><li><span class="math inline">\(s_i(w)\)</span>: partial sum of weights, <span class="math inline">\(s_i(w) = \sum_{j=1}^{i} w_j\)</span>. Assuming <span class="math inline">\(s_0(w) = 0\)</span>.</li><li><span class="math inline">\(q_p\)</span>: estimation of the <span class="math inline">\(p^\textrm{th}\)</span> quantile based on <span class="math inline">\(x\)</span>.</li></ul><p>Next, let&rsquo;s recall the basic equations of the Harrell-Davis quantile estimator:</p><p><span class="math display">\[q_p = \sum_{i=1}^{n} W_{n,i} \cdot x_i,\quad
W_{n,i} = I_{r_i}(a, b) - I_{l_i}(a, b),
\]</span></p><p>where</p><ul><li><span class="math inline">\(I_t(a, b)\)</span> is the <a href=https://en.wikipedia.org/wiki/Beta_function#Incomplete_beta_function>regularized incomplete beta function</a>,</li><li><span class="math inline">\(a = p \cdot (n + 1), \;\; b = (1-p) \cdot (n + 1)\)</span>,</li><li><span class="math inline">\(l_i = (i - 1) / n, \;\; r_i = i / n\)</span>.</li></ul><p>Now we introduce notation for the <span class="math inline">\(k^\textrm{th}\)</span> <a href=https://en.wikipedia.org/wiki/Moment_(mathematics)>moment</a> of the <span class="math inline">\(p^\textrm{th}\)</span> quantile:</p><p><span class="math display">\[C_k = \sum_{i=1}^n W_{n,i} \cdot x_i^k
\]</span></p><p>Thus, <span class="math inline">\(p^\textrm{th}\)</span> quantile estimation <span class="math inline">\(q_p\)</span> is just the first moment <span class="math inline">\(C_1\)</span>.</p><p>Using the first and the second moments, we can express the standard error as:</p><p><span class="math display">\[s_{q_p} = \sqrt{C_2 - C_1^2}
\]</span></p><p>Here we apply the same idea that we use to express the variance of <span class="math inline">\(X\)</span> as the difference between
the mean of the square of <span class="math inline">\(X\)</span> and the square of the mean of <span class="math inline">\(X\)</span>:</p><p><span class="math display">\[\begin{align}
\operatorname{Var}(X) &= \operatorname{E}\left[(X - \operatorname{E}[X])^2\right] \\
&= \operatorname{E}\left[X^2 - 2X\operatorname{E}[X] + \operatorname{E}[X]^2\right] \\
&= \operatorname{E}\left[X^2\right] - 2\operatorname{E}[X]\operatorname{E}[X] + \operatorname{E}[X]^2 \\
&= \operatorname{E}\left[X^2 \right] - \operatorname{E}[X]^2
\end{align}
\]</span></p><h3 id=the-weighted-version-of-the-maritz-jarrett-method>The weighted version of the Maritz-Jarrett method</h3><p>To adopt the Maritz-Jarrett method to the weighted samples,
we can use <a href=https://aakinshin.net/posts/weighted-quantiles/>the same trick</a> we used for the Harrell-Davis quantile estimator (see <a href=#Harrell1982>[Harrell1982]</a>).
First, we should replace the sample size by the weighted sample size using the <a href=https://aakinshin.net/posts/kish-ess-weighted-quantiles/>Kish&rsquo;s effective sample size</a>:</p><p><span class="math display">\[n^* = \frac{\Big( \sum_{i=1}^n w_i \Big)^2}{\sum_{i=1}^n w_i^2 }.
\]</span></p><p>Next, we should redefine <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> as follows:</p><p><span class="math display">\[\left\{
\begin{array}{rccl}
a^* = & p     & \cdot & (n^* + 1),\\
b^* = & (1-p) & \cdot & (n^* + 1).
\end{array}
\right.
\]</span></p><p>The segment borders of <span class="math inline">\(I_t(a, b)\)</span> should be updated as well:</p><p><span class="math display">\[\left\{
\begin{array}{rcc}
l^*_i & = & \dfrac{s_{i-1}(w)}{s_n(w)},\\
r^*_i & = & \dfrac{s_i(w)}{s_n(w)}.
\end{array}
\right.
\]</span></p><p>With all the replacements, we get a version of Harrell-Davis quantile estimator adopted for the weighted case:</p><p><span class="math display">\[q^*_p = \sum_{i=1}^{n} W^*_{n,i} \cdot x_i,\quad
W^*_{n,i} = I_{r^*_i}(a^*, b^*) - I_{l^*_i}(a^*, b^*).
\]</span></p><p>At this point, we can introduce a generalized version of the quantile moments:</p><p><span class="math display">\[C^*_k = \sum_{i=1}^n W^*_{n,i} \cdot x_i^k
\]</span></p><p>Finally, we get the formula for the standard error in the weighted case:</p><p><span class="math display">\[s^*_{q_p} = \sqrt{C^*_2 - (C^*_1)^2}
\]</span></p><h3 id=building-the-confidence-interval>Building the confidence interval</h3><p>Based on the given sample, we can get only an estimation of the quantile standard error
instead of the true standard error.
It means that it would be better to use the Student&rsquo;s t-distribution to estimate
the confidence interval instead of the normal distribution.</p><p>Since we have a weighted sample, we should also use the weighted sample size <span class="math inline">\(n^*\)</span>
instead of the original sample size <span class="math inline">\(n\)</span> to determine the degree of freedom:</p><p><span class="math display">\[\nu^* = n^* - 1.
\]</span></p><p>Thus, the confidence interval with confidence level <span class="math inline">\(\alpha\)</span> may be estimated as follows:</p><p><span class="math display">\[q^*_p \pm t_{\alpha, \nu^*} s^*_{q_p}
\]</span></p><h3 id=reference-implementation>Reference implementation</h3><p>If you use R, here are functions that you can use in your scripts:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=cl><span class=n>mj</span> <span class=o>&lt;-</span> <span class=nf>function</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>weights</span><span class=p>,</span> <span class=n>p</span><span class=p>,</span> <span class=n>alpha</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nf>if </span><span class=p>(</span><span class=nf>any</span><span class=p>(</span><span class=nf>is.na</span><span class=p>(</span><span class=n>weights</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>    <span class=n>weights</span> <span class=o>&lt;-</span> <span class=nf>rep</span><span class=p>(</span><span class=m>1</span> <span class=o>/</span> <span class=nf>length</span><span class=p>(</span><span class=n>x</span><span class=p>),</span> <span class=nf>length</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  <span class=n>indexes</span> <span class=o>&lt;-</span> <span class=nf>order</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>x</span> <span class=o>&lt;-</span> <span class=n>x[indexes]</span>
</span></span><span class=line><span class=cl>  <span class=n>weights</span> <span class=o>&lt;-</span> <span class=n>weights[indexes]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>nw</span> <span class=o>&lt;-</span> <span class=nf>sum</span><span class=p>(</span><span class=n>weights</span><span class=p>)</span><span class=n>^2</span> <span class=o>/</span> <span class=nf>sum</span><span class=p>(</span><span class=n>weights^2</span><span class=p>)</span> <span class=c1># Kish&#39;s effective sample size</span>
</span></span><span class=line><span class=cl>  <span class=n>a</span> <span class=o>&lt;-</span> <span class=n>p</span> <span class=o>*</span> <span class=p>(</span><span class=n>nw</span> <span class=o>+</span> <span class=m>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>b</span> <span class=o>&lt;-</span> <span class=p>(</span><span class=m>1</span> <span class=o>-</span> <span class=n>p</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=n>nw</span> <span class=o>+</span> <span class=m>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  <span class=n>cdfs.probs</span> <span class=o>&lt;-</span> <span class=nf>cumsum</span><span class=p>(</span><span class=nf>c</span><span class=p>(</span><span class=m>0</span><span class=p>,</span> <span class=n>weights</span> <span class=o>/</span> <span class=nf>sum</span><span class=p>(</span><span class=n>weights</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>  <span class=n>cdfs</span> <span class=o>&lt;-</span> <span class=nf>pbeta</span><span class=p>(</span><span class=n>cdfs.probs</span><span class=p>,</span> <span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>W</span> <span class=o>&lt;-</span> <span class=nf>tail</span><span class=p>(</span><span class=n>cdfs</span><span class=p>,</span> <span class=m>-1</span><span class=p>)</span> <span class=o>-</span> <span class=nf>head</span><span class=p>(</span><span class=n>cdfs</span><span class=p>,</span> <span class=m>-1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  <span class=n>c1</span> <span class=o>&lt;-</span> <span class=nf>sum</span><span class=p>(</span><span class=n>W</span> <span class=o>*</span> <span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>c2</span> <span class=o>&lt;-</span> <span class=nf>sum</span><span class=p>(</span><span class=n>W</span> <span class=o>*</span> <span class=n>x^2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>se</span> <span class=o>&lt;-</span> <span class=nf>sqrt</span><span class=p>(</span><span class=n>c2</span> <span class=o>-</span> <span class=n>c1^2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>estimation</span> <span class=o>&lt;-</span> <span class=n>c1</span>
</span></span><span class=line><span class=cl>  <span class=n>margin</span> <span class=o>&lt;-</span> <span class=n>se</span> <span class=o>*</span> <span class=nf>qt</span><span class=p>(</span><span class=m>1</span> <span class=o>-</span> <span class=p>(</span><span class=m>1</span> <span class=o>-</span> <span class=n>alpha</span><span class=p>)</span> <span class=o>/</span> <span class=m>2</span><span class=p>,</span> <span class=n>df</span> <span class=o>=</span> <span class=n>nw</span> <span class=o>-</span> <span class=m>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nf>c</span><span class=p>(</span><span class=n>estimation</span> <span class=o>-</span> <span class=n>margin</span><span class=p>,</span> <span class=n>estimation</span> <span class=o>+</span> <span class=n>margin</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>If you use C#, you can take an implementation from
the latest nightly version (0.3.0-nightly.72+) of <a href=https://github.com/AndreyAkinshin/perfolizer>Perfolizer</a>
(you need <code>HarrellDavisQuantileEstimator</code>).</p><h3 id=references>References</h3><ul><li><b id=Harrell1982>[Harrell1982]</b><br>Harrell, F.E. and Davis, C.E., 1982. A new distribution-free quantile estimator.
<em>Biometrika</em>, 69(3), pp.635-640.<br><a href=https://pdfs.semanticscholar.org/1a48/9bb74293753023c5bb6bff8e41e8fe68060f.pdf>https://pdfs.semanticscholar.org/1a48/9bb74293753023c5bb6bff8e41e8fe68060f.pdf</a></li><li><b id=Maritz1979>[Maritz1979]</b><br>Maritz, J. S., and R. G. Jarrett. 1978.
“A Note on Estimating the Variance of the Sample Median.”
Journal of the American Statistical Association 73 (361): 194–196.<br><a href=https://doi.org/10.1080/01621459.1978.10480027>https://doi.org/10.1080/01621459.1978.10480027</a></li><li><b id=Wilcox2017>[Wilcox2017]</b><br>Wilcox, Rand R. 2017. Introduction to Robust Estimation and Hypothesis Testing. 4th edition. Waltham, MA: Elsevier. ISBN 978-0-12-804733-0</li><li><b id=Martin1990>[Martin1990]</b><br>Martin, Michael A. &ldquo;On using the jackknife to estimate quantile variance.&rdquo; Canadian Journal of Statistics 18, no. 2 (1990): 149-153.</li></ul><br><br><div class=row><div class="justify-content-center share-block"><div class=share-title>Share:</div><div class=share-button><a href="https://www.reddit.com/submit?url=https%3a%2f%2faakinshin.net%2fposts%2fweighted-quantiles-ci%2f&title=Quantile%20confidence%20intervals%20for%20weighted%20samples" target=_blank title="Share on Reddit"><svg class="fai"><use xlink:href="/img/fa/all.svg#reddit"/></svg></a></div><div class=share-button><a href="https://twitter.com/intent/tweet?text=Quantile%20confidence%20intervals%20for%20weighted%20samples&url=https%3a%2f%2faakinshin.net%2fposts%2fweighted-quantiles-ci%2f&via=andrey_akinshin&related=andrey_akinshin" rel=nofollow target=_blank title="Share on Twitter"><svg class="fai"><use xlink:href="/img/fa/all.svg#twitter"/></svg></a></div><div class=share-button><a href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2faakinshin.net%2fposts%2fweighted-quantiles-ci%2f" target=_blank title="Share on HackerNews"><svg class="fai"><use xlink:href="/img/fa/all.svg#hacker-news"/></svg></a></div><div class=share-button><a href="https://getpocket.com/save?url=https%3a%2f%2faakinshin.net%2fposts%2fweighted-quantiles-ci%2f&title=Quantile%20confidence%20intervals%20for%20weighted%20samples" target=_blank title="Add to Pocket"><svg class="fai"><use xlink:href="/img/fa/all.svg#get-pocket"/></svg></a></div></div></div></div><hr></div></div></main></div><footer class="blog-footer mt-auto"><div class=container><p>&copy; 2013&mdash;2022 Andrey Akinshin
|
<a href=https://github.com/AndreyAkinshin><svg class="fai"><title>GitHub</title><use xlink:href="/img/fa/all.svg#github"/></svg></a><a href=https://twitter.com/andrey_akinshin><svg class="fai"><title>Twitter</title><use xlink:href="/img/fa/all.svg#twitter"/></svg></a><a href=https://aakinshin.net/posts/index.xml><svg class="fai"><title>RSS</title><use xlink:href="/img/fa/all.svg#rss"/></svg></a>|
<a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></p></div></footer><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.2.0/dist/js/bootstrap.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.3.1/anchor.min.js integrity="sha512-zPB79j2C+3sFS9zcA3vg/z6bVKzJVEyu9pY5w89akQRys76zpAT2t6S3wZKla3QQ14O5l/Yt0RUQ/DHXx82Y5g==" crossorigin=anonymous referrerpolicy=no-referrer></script>
<script src=https://aakinshin.net/js/theme-after.min.29520a8e1176193da7ea4e6cb56cf9b3e634b867c9979234d8dafb5ab61dd494.js></script>
<script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></body></html>