<!doctype html><html lang=en class=h-100><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.103.0-DEV"><meta name=author content="Andrey Akinshin"><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content="Mathematics,Statistics,Research,Research: Quantile absolute deviation"><title>Caveats of using the median absolute deviation | Andrey Akinshin</title><meta name=description content="The median absolute deviation is a measure of dispersion which can be used as a robust alternative to the standard deviation. It works great for slight dev..."><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><link href=https://aakinshin.net/sass/bootstrap-light.min.css theme=light rel=stylesheet type=text/css media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link href=https://aakinshin.net/sass/bootstrap-dark.min.css theme=dark rel=stylesheet type=text/css media="(prefers-color-scheme: dark)"><script src=https://aakinshin.net/js/theme-before.min.d7f6578e23ad3f0c33c589f9bcb34f995b45121f1f3ce888869c86b26826c845.js></script>
<script type=module src=https://aakinshin.net/js/dark-mode-toggle.min.9e68d431432744c07a43381a8a833ffe0921cc0e006d84ad97f0b0d43c5cd82d.mjs></script>
<link href=https://aakinshin.net/css/fontawesome-all.min.178e95bba6ea2e9a90838cd646658f4bf6667a6ceaa057cb587bf7e6eb8412d3.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/about.min.60773ab7266ecc6e9625306f57c0a82a219b011dc3ea2d83763d1ecdf11c86d2.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/blog.min.7e186db80d8c431d196b3e0718afb0636b82a269a8c92521c11a55267a24fc27.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZVB6MXSX32"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-ZVB6MXSX32")</script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-41419012-5"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","UA-41419012-5")</script><script type=text/javascript>(function(e,t,n,s,o,i,a){e[o]=e[o]||function(){(e[o].a=e[o].a||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym"),ym(28700916,"init",{clickmap:!0,trackLinks:!0,accurateTrackBounce:!0})</script><noscript><div><img src=https://mc.yandex.ru/watch/28700916 style=position:absolute;left:-9999px alt></div></noscript><script src=/js/jquery-3.3.1.slim.min.js></script></head><body><div class=bg-primary><div class="container bg-primary"><nav class="navbar navbar-expand-sm navbar-dark bg-primary"><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link id=nav-link-blog href=https://aakinshin.net/><i class="fas fa-home" title=Home style=color:#fff></i></a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-expanded=false>Blog</a><ul class="dropdown-menu bg-primary"><li><a class=dropdown-item href=https://aakinshin.net/posts/>All Posts</a></li><li><a class=dropdown-item href=https://aakinshin.net/tags/statistics/>Posts about Statistics</a></li><li></li><a class=dropdown-item href=https://aakinshin.net/tags/>All Tags</a></li></ul></li><li class=nav-item><a class=nav-link id=nav-link-about href=https://aakinshin.net/about/>About</a></li></ul><ul class="navbar-nav ms-auto"><li class=nav-item><dark-mode-toggle permanent=true></dark-mode-toggle></li></ul></nav></div></div><div class=container><main id=main><div class=blog-main><div class="blog-post table-sm"><h1 class=blog-post-title id=post-title>Caveats of using the median absolute deviation</h1><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2022-08-02>August 2, 2022</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>
&nbsp;
<a href=https://aakinshin.net/tags/mathematics/ class="badge badge-info">Mathematics</a>
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research/ class="badge badge-info">Research</a>
<a href=https://aakinshin.net/tags/research-qad/ class="badge badge-info">Research: Quantile absolute deviation</a></span><br><br><strong>Update: this blog post is a part of research that aimed to build a new measure of statistical dispersion called quantile absolute deviation. A <a href=/posts/preprint-qad/>preprint with final results</a> is available on arXiv: <a href=https://arxiv.org/abs/2208.13459>arXiv:2208.13459 [stat.ME]</a>. Some information in this blog post can be obsolete: please, use the preprint as the primary reference.</strong><br><br><p>The median absolute deviation is a measure of dispersion
which can be used as a robust alternative to the standard deviation.
It works great for slight deviations from normality
(e.g., for contaminated normal distributions or slightly skewed unimodal distributions).
Unfortunately, if we apply it to distributions with huge deviations from normality,
we may experience a lot of troubles.
In this post, I discuss some of the most important caveats which we should keep in mind
if we use the median absolute deviation.</p><h3 id=introduction>Introduction</h3><p>Let <span class="math inline">\(X\)</span> be a sample of i.i.d. random variables: <span class="math inline">\(X = \{ X_1, X_2, \ldots, X_n \}\)</span>.
The median absolute deviation is defined as follows</p><p><span class="math display">\[\operatorname{MAD}(X) = C \cdot \operatorname{median}(|X - \operatorname{median}(X)|),
\]</span></p><p>where <span class="math inline">\(C\)</span> is the scale constant, <span class="math inline">\(\operatorname{median}\)</span> is the median estimator.
In the scope of this post, we use only the classic sample median
(if <span class="math inline">\(n\)</span> is odd, the median is the middle order statistic;
if <span class="math inline">\(n\)</span> is even, the median is the arithmetic average of the two middle order statistics).
The scale constant <span class="math inline">\(C\)</span> allows using <span class="math inline">\(\operatorname{MAD}\)</span> as a consistent estimator of the standard deviation.
In order to make <span class="math inline">\(\operatorname{MAD}\)</span> asymptotically consistent with the standard deviation under normality,
we should use <span class="math inline">\(C = 1 / \Phi^{-1}(0.75) \approx 1.4826\)</span>.
In practice, we may need <a href=https://aakinshin.net/posts/preprint-mad-factors/>adjusted values</a>
of <span class="math inline">\(C\)</span> for small samples to obtain an unbiased estimator.</p><p>Using <span class="math inline">\(\operatorname{MAD}\)</span> as a robust replacement for the standard deviation
may be reasonable in the case of slight deviations from normality.
However, it could be quite misleading in the case of large deviations.
Let us review some of the typical assumptions that may lead to incorrect conclusions.</p><h3 id=caveat-1-beware-of-the-narrow-estimation-range-assumption>Caveat 1: Beware of the narrow estimation range assumption</h3><p>With non-robust estimators, a single corrupted element can easily distort the estimation.
A transition towards robust approaches brings a lot of benefits in terms of stability:
a single altered element cannot introduce extreme changes in the estimation value.
Having this knowledge, many researchers typically expect that robust estimations would fit a narrow range of values.
Therefore, they can omit the phase of exploring the distribution of estimations
and draw conclusions based on a single trial assuming
that all possible estimations are close enough to each other.
However, while robust estimators indeed provide a decent defense against extreme outliers,
they still can have a wide range of possible values.</p><p>Let us consider an example.
In the below figure, we can see a density plot of a trimodal distribution.</p><div class=row><div class=mx-auto><a href=/posts/mad-caveats/img/instability1-light.png target=_blank class=imgldlink alt=instability1><picture><source theme=dark srcset=/posts/mad-caveats/img/instability1-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/mad-caveats/img/instability1-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/mad-caveats/img/instability1-light.png></picture></a></div></div><br><p>This distribution has three non-intersecting intervals:
<span class="math inline">\([0;1]\)</span> (<span class="math inline">\(25\%\)</span> of the distribution),
<span class="math inline">\([4;5]\)</span> (<span class="math inline">\(50\%\)</span> of the distribution),
and <span class="math inline">\([8;9]\)</span> (<span class="math inline">\(25\%\)</span> of the distribution).
While the distribution has an unambiguously defined median <span class="math inline">\(M = 4.5\)</span>,
its quantile function of the absolute deviations around the median (<span class="math inline">\(|X - \operatorname{median}(X)|\)</span>)
has a discontinuity at 0.5.
This means unambiguously define the <span class="math inline">\(\operatorname{MAD}\)</span> value.
Indeed, the <span class="math inline">\([M-\operatorname{MAD}; M+\operatorname{MAD}]\)</span> interval should cover exactly <span class="math inline">\(50\%\)</span> of the distribution.
In the considered case, there are multiple ways to define such an interval.
The interval value various from <span class="math inline">\([4;5]\)</span> to <span class="math inline">\([1;8]\)</span>.</p><p>Now we explore practical implications of working with such a distribution.
Let us take <span class="math inline">\(1\,000\)</span> random samples of size <span class="math inline">\(100\)</span> from this distribution,
estimate the <span class="math inline">\(\operatorname{MAD}\)</span> value for each sample,
and build a new distribution based on the obtained estimations.
The density plot of the observed sampling distribution is presented in the below figure
(we use the kernel density estimation with the normal kernel and the Sheather & Jones method to select the bandwidth).</p><div class=row><div class=mx-auto><a href=/posts/mad-caveats/img/instability2-light.png target=_blank class=imgldlink alt=instability2><picture><source theme=dark srcset=/posts/mad-caveats/img/instability2-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/mad-caveats/img/instability2-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/mad-caveats/img/instability2-light.png></picture></a></div></div><br><p>As we can see, the sampling <span class="math inline">\(\operatorname{MAD}\)</span> distribution is also trimodal.
In the general case, the distance between these modes could be as large as a gap around the <span class="math inline">\(0.5^\textrm{th}\)</span> quantile
of <span class="math inline">\(|X - \operatorname{median}(X)|\)</span>.</p><p>Thus, if the original distribution is not unimodal,
we cannot speculate on the form of the sampling <span class="math inline">\(\operatorname{MAD}\)</span> distribution
based just on a few of the <span class="math inline">\(\operatorname{MAD}\)</span> estimations.</p><h3 id=caveat-2-beware-of-the-non-zero-dispersion-assumption>Caveat 2: Beware of the non-zero dispersion assumption</h3><p>Another popular assumption about the measures of dispersion is that they always positive.
It is almost true for the standard deviation: unless all sample elements are equal to each other,
the standard deviation is always positive.
Thanks to this property, the standard deviation is often used as a denominator in various statistical equations
(e.g., in effect size measures like the Cohen&rsquo;s d or null hypothesis significance tests like the Student&rsquo;s t-test).
In most cases, we shouldn&rsquo;t expect division by zero because
it&rsquo;s almost impossible to get a sample taken from a continuous distribution
in which all the elements are equal.
Unfortunately, when we switch to robust measures of dispersion of non-parametric distributions,
the risk of getting zero dispersion increases.
We should be ready to get zero dispersion
when we work with discrete distributions or mixtures of discrete and continuous distributions.</p><p>As an example of a discrete distribution,
let us consider the Poisson distribution <span class="math inline">\(\operatorname{Pois}(\lambda)\)</span>.
Its probability mass function is defined as <span class="math inline">\(p(k)=\lambda^k e^{-\lambda} / k!\)</span>.
It&rsquo;s easy to see that when <span class="math inline">\(\lambda < \lambda_0 = -\ln(0.5) \approx 0.6931\)</span>, <span class="math inline">\(p(0) > 0.5\)</span>.
In this case, more than half of the distribution elements are equal to zero.
Therefore, the median absolute deviation also becomes zero.
In the below figure, a probability mass function of <span class="math inline">\(\operatorname{Pois}(0.6)\)</span> is presented.
We can see that <span class="math inline">\(p(0) \approx 0.55\)</span> which gives us zero <span class="math inline">\(\operatorname{MAD}\)</span>.</p><div class=row><div class=mx-auto><a href=/posts/mad-caveats/img/zero1-light.png target=_blank class=imgldlink alt=zero1><picture><source theme=dark srcset=/posts/mad-caveats/img/zero1-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/mad-caveats/img/zero1-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/mad-caveats/img/zero1-light.png></picture></a></div></div><br><p>As an example of a mixture of discrete and continuous distributions,
we can consider the rectified Gaussian distribution (presented in the below figure).
It is a modification of the normal distribution in which all negative elements are replaced by zeros.
It can be also represented
as a mixture of the Dirac delta function <span class="math inline">\(\delta(0)\)</span> and the positive part of the normal distribution.
Since <span class="math inline">\(\delta(0)\)</span> occupies exactly <span class="math inline">\(50\%\)</span> of the distribution, its median absolute deviation is also zero.</p><div class=row><div class=mx-auto><a href=/posts/mad-caveats/img/zero2-light.png target=_blank class=imgldlink alt=zero2><picture><source theme=dark srcset=/posts/mad-caveats/img/zero2-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/mad-caveats/img/zero2-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/mad-caveats/img/zero2-light.png></picture></a></div></div><br><p>Distributions with zero <span class="math inline">\(\operatorname{MAD}\)</span> often arise in various disciplines.
Since they are obviously non-normal, they require robust non-parametric analysis approach.
However, the median absolute deviation is not always a good choice.
For example, it doesn&rsquo;t allow comparing dispersion estimations
of two rectified Gaussian distributions
or two Poisson distributions with <span class="math inline">\(\lambda < 0.6931\)</span>.
A blind usage of <span class="math inline">\(\operatorname{MAD}\)</span> as a denominator in automated statistical analysis
can lead to a critical failure of the system.</p><h3 id=caveat-3-beware-of-the-6895997-assumption>Caveat 3: Beware of the 68–95–99.7 assumption</h3><p>In the previous sections, we have reviewed multimodal distributions and discrete distributions.
Once such features of the distributions are discovered, it becomes obvious that we cannot use classic assumptions
that are valid for the normal distribution.
Now we consider a case of an unimodal continuous distribution.
With distributions, researchers often tend to use the normal distribution as a mental model.
In the below figure, the normal distribution density plot is presented.</p><div class=row><div class=mx-auto><a href=/posts/mad-caveats/img/normality1-light.png target=_blank class=imgldlink alt=normality1><picture><source theme=dark srcset=/posts/mad-caveats/img/normality1-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/mad-caveats/img/normality1-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/mad-caveats/img/normality1-light.png></picture></a></div></div><br><p>A typical assumption about the normal distribution is the 68–95–99.7 rule.
It says that intervals <span class="math inline">\([\mu-\sigma;\mu+\sigma]\)</span>, <span class="math inline">\([\mu-2\sigma;\mu+2\sigma]\)</span>, and <span class="math inline">\([\mu-3\sigma;\mu+3\sigma]\)</span>
cover <span class="math inline">\(68\%\)</span>, <span class="math inline">\(95\%\)</span>, and <span class="math inline">\(99.7\%\)</span> of the normal distribution respectively.
This rule is linked with the three-sigma rule of thumb that implies that the interval <span class="math inline">\([\mu-3\sigma;\mu+3\sigma]\)</span>
covers <span class="math inline">\(99.7\%\)</span> of the distribution values.
While this empirical rule is applicable to many unimodal continuous light-tailed distributions,
it can be violated in the case of heavy-tailed distributions.</p><p>Let us consider the Fréchet distribution with shape equals <span class="math inline">\(1\)</span>, scale equals <span class="math inline">\(1\)</span>, location equals <span class="math inline">\(0\)</span>.
It is a commonly used example of heavy-tailed distribution.
Its true median value is <span class="math inline">\(M \approx 1.44\)</span> and
the true median absolute deviation values is <span class="math inline">\(\operatorname{MAD} \approx 0.9\)</span>.
Its density plot is presented in the below figure:</p><div class=row><div class=mx-auto><a href=/posts/mad-caveats/img/normality2-light.png target=_blank class=imgldlink alt=normality2><picture><source theme=dark srcset=/posts/mad-caveats/img/normality2-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/mad-caveats/img/normality2-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/mad-caveats/img/normality2-light.png></picture></a></div></div><br><p>The variance of this distribution is infinite, therefore we can&rsquo;t use the standard deviation as a measure of dispersion.
However, we will check what would happen with the three-sigma rule if we try to apply it
using a scaled <span class="math inline">\(\operatorname{MAD}\)</span> as a standard deviation estimator.
Using the conventional value <span class="math inline">\(C = 1.4826\)</span>, we get <span class="math inline">\(C\cdot \mathrm{MAD} \approx 2.14\)</span>.
Now let us consider intervals <span class="math inline">\([M-k \cdot \mathrm{MAD}; M+k \cdot \mathrm{MAD}]\)</span> for <span class="math inline">\(k \in \{ 1, C, 2C, 3C \}\)</span>.
The actual coverage of each interval is presented in the following table:</p><table><thead><tr><th align=right><span class="math inline">\(k\)</span></th><th align=left><span class="math inline">\(\mathbb{P}(M - k\cdot \mathrm{MAD} \leq X \leq \mathbb{P}(M + k\cdot \mathrm{MAD})\)</span></th></tr></thead><tbody><tr><td align=right>1.00</td><td align=left>0.500</td></tr><tr><td align=right>1.48</td><td align=left>0.699</td></tr><tr><td align=right>2.97</td><td align=left>0.786</td></tr><tr><td align=right>4.45</td><td align=left>0.833</td></tr></tbody></table><p>As we can see, a blind usage of the three-sigma rule in the heavy-tailed case can lead to misleading insights.
In the above example, the interval <span class="math inline">\([M- 3C \cdot \mathrm{MAD}; M+ 3C \cdot \mathrm{MAD}]\)</span>
actually cover only <span class="math inline">\(83.3\%\)</span> of the distribution instead of the typical <span class="math inline">\(99.7\%\)</span>.</p><h3 id=conclusion>Conclusion</h3><p>If we use a scaled median absolute deviation as a robust replacement to the standard deviation,
we should be careful.
It can work in an acceptable way for some unimodal continuous light-tailed distributions.
However, distribution features like multimodality, discretization, or heavy-tailedness can easily violate
our typical assumptions that we use with the normal distribution and the standard deviation.</p><br><br><div class=row><div class="justify-content-center share-block"><div class=share-title>Share:</div><div class=share-button><a href="https://www.reddit.com/submit?url=https%3a%2f%2faakinshin.net%2fposts%2fmad-caveats%2f&title=Caveats%20of%20using%20the%20median%20absolute%20deviation" target=_blank title="Share on Reddit"><i class="fab fa-reddit fa-2x"></i></a></div><div class=share-button><a href="https://twitter.com/intent/tweet?text=Caveats%20of%20using%20the%20median%20absolute%20deviation&url=https%3a%2f%2faakinshin.net%2fposts%2fmad-caveats%2f&via=andrey_akinshin&related=andrey_akinshin" rel=nofollow target=_blank title="Share on Twitter"><i class="fab fa-twitter fa-2x"></i></a></div><div class=share-button><a href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2faakinshin.net%2fposts%2fmad-caveats%2f" target=_blank title="Share on HackerNews"><i class="fab fa-hacker-news fa-2x"></i></a></div><div class=share-button><a href="https://getpocket.com/save?url=https%3a%2f%2faakinshin.net%2fposts%2fmad-caveats%2f&title=Caveats%20of%20using%20the%20median%20absolute%20deviation" target=_blank title="Add to Pocket"><i class="fab fa-get-pocket fa-2x"></i></a></div></div></div></div><hr></div></div></main></div><footer class=blog-footer><div class=container><p>&copy; 2013&mdash;2022 Andrey Akinshin
|
<a href=https://github.com/AndreyAkinshin><i class="fab fa-github" title=GitHub></i></a>
<a href=https://twitter.com/andrey_akinshin><i class="fab fa-twitter" title=Twitter></i></a>
<a href=https://aakinshin.net/posts/index.xml><i class="fas fa-rss" title=RSS></i></a>
|
<a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></p></div></footer><script src=https://aakinshin.net/js/theme-after.min.c26550621ac13c2221d7f6f5e6fe862345d3919723c50d730893e3e4856ecf35.js></script>
<script src=/js/bootstrap.bundle.min.js></script>
<script src=/js/anchor.min.js></script>
<script src=https://aakinshin.net/js/custom.min.f6e5d13fe39f305056cc743ee4cb8d117c1aba26176e58c82c79a480d02fe4b7.js></script>
<script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></body></html>