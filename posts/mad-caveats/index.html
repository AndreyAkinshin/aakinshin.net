<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.103.0-DEV"><meta name=author content="Andrey Akinshin"><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content="Mathematics,Statistics,Research,Research: Quantile absolute deviation"><title>Caveats of using the median absolute deviation | Andrey Akinshin</title><meta name=description content="The median absolute deviation is a measure of dispersion which can be used as a robust alternative to the standard deviation. It works great for slight dev..."><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><script>localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?document.documentElement.classList.add("dark"):document.documentElement.classList.remove("dark")</script><link href=https://aakinshin.net/css/main.min.13341ac97e21004cde7f286e6b392a1234aa8b2656426c008cfd9f98cd200dd1.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"></head><body><nav><div class="container flex flex-wrap items-center justify-between mx-auto max-w-6xl h-12 px-6"><div class="flex items-center justify-start justify-self-start"><div class="flex nav-item h-12 w-12 items-center justify-center"><a class=text-white href=https://aakinshin.net/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#house-chimney"/></svg></a></div><div class="flex nav-item h-12 items-center"><a class="px-3 text-white" href=https://aakinshin.net/posts/>Posts</a></div><div class="flex nav-item h-12 items-center"><a class="px-3 text-white" href=https://aakinshin.net/research/>Research</a></div><div class="flex nav-item h-12 items-center"><a class="px-3 text-white" href=https://aakinshin.net/about/>About</a></div></div><button id=theme-toggle type=button class="nav-item p-3 content-center justify-self-end"><svg id="theme-toggle-dark-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001.0 1010.586 10.586z"/></svg><svg id="theme-toggle-light-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M10 2a1 1 0 011 1v1A1 1 0 119 4V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707A1 1 0 1113.536 5.05l.707-.707a1 1 0 011.414.0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707A1 1 0 004.343 5.757l.707.707zm1.414 8.486-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z" fill-rule="evenodd" clip-rule="evenodd"/></svg></button></div></nav><div class="main container mx-auto max-w-6xl px-6"><div class=main-post><h1 class=blog-post-title id=post-title>Caveats of using the median absolute deviation</h1><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg><time datetime=2022-08-02>August 2, 2022</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/>Mathematics</a>
<a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics</a>
<a class=label-link href=https://aakinshin.net/tags/research/>Research</a>
<a class=label-link href=https://aakinshin.net/tags/research-qad/>Research: Quantile absolute deviation</a></div></div><br><div class="main-content mb-3 px-2 py-1 rounded border text-alert-text-l border-alert-frame-l dark:text-alert-text-d dark:border-alert-frame-d">Update: this blog post is a part of research that aimed to build a new measure of statistical dispersion called quantile absolute deviation. A <a href=/posts/preprint-qad/>preprint with final results</a> is available on arXiv: <a href=https://arxiv.org/abs/2208.13459>arXiv:2208.13459 [stat.ME]</a>. Some information in this blog post can be obsolete: please, use the preprint as the primary reference.</div><div class=main-content><p>The median absolute deviation is a measure of dispersion
which can be used as a robust alternative to the standard deviation.
It works great for slight deviations from normality
(e.g., for contaminated normal distributions or slightly skewed unimodal distributions).
Unfortunately, if we apply it to distributions with huge deviations from normality,
we may experience a lot of troubles.
In this post, I discuss some of the most important caveats which we should keep in mind
if we use the median absolute deviation.</p><h3 id=introduction>Introduction</h3><p>Let <span class="math inline">\(X\)</span> be a sample of i.i.d. random variables: <span class="math inline">\(X = \{ X_1, X_2, \ldots, X_n \}\)</span>.
The median absolute deviation is defined as follows</p><p><span class="math display">\[\operatorname{MAD}(X) = C \cdot \operatorname{median}(|X - \operatorname{median}(X)|),
\]</span></p><p>where <span class="math inline">\(C\)</span> is the scale constant, <span class="math inline">\(\operatorname{median}\)</span> is the median estimator.
In the scope of this post, we use only the classic sample median
(if <span class="math inline">\(n\)</span> is odd, the median is the middle order statistic;
if <span class="math inline">\(n\)</span> is even, the median is the arithmetic average of the two middle order statistics).
The scale constant <span class="math inline">\(C\)</span> allows using <span class="math inline">\(\operatorname{MAD}\)</span> as a consistent estimator of the standard deviation.
In order to make <span class="math inline">\(\operatorname{MAD}\)</span> asymptotically consistent with the standard deviation under normality,
we should use <span class="math inline">\(C = 1 / \Phi^{-1}(0.75) \approx 1.4826\)</span>.
In practice, we may need <a href=https://aakinshin.net/posts/preprint-mad-factors/>adjusted values</a>
of <span class="math inline">\(C\)</span> for small samples to obtain an unbiased estimator.</p><p>Using <span class="math inline">\(\operatorname{MAD}\)</span> as a robust replacement for the standard deviation
may be reasonable in the case of slight deviations from normality.
However, it could be quite misleading in the case of large deviations.
Let us review some of the typical assumptions that may lead to incorrect conclusions.</p><h3 id=caveat-1-beware-of-the-narrow-estimation-range-assumption>Caveat 1: Beware of the narrow estimation range assumption</h3><p>With non-robust estimators, a single corrupted element can easily distort the estimation.
A transition towards robust approaches brings a lot of benefits in terms of stability:
a single altered element cannot introduce extreme changes in the estimation value.
Having this knowledge, many researchers typically expect that robust estimations would fit a narrow range of values.
Therefore, they can omit the phase of exploring the distribution of estimations
and draw conclusions based on a single trial assuming
that all possible estimations are close enough to each other.
However, while robust estimators indeed provide a decent defense against extreme outliers,
they still can have a wide range of possible values.</p><p>Let us consider an example.
In the below figure, we can see a density plot of a trimodal distribution.</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/mad-caveats/img/instability1-light.png target=_blank alt=instability1><img src=/posts/mad-caveats/img/instability1-light.png width=800></a>
<a class="img-dark hidden" href=/posts/mad-caveats/img/instability1-dark.png target=_blank alt=instability1><img src=/posts/mad-caveats/img/instability1-dark.png width=800></a></div><p>This distribution has three non-intersecting intervals:
<span class="math inline">\([0;1]\)</span> (<span class="math inline">\(25\%\)</span> of the distribution),
<span class="math inline">\([4;5]\)</span> (<span class="math inline">\(50\%\)</span> of the distribution),
and <span class="math inline">\([8;9]\)</span> (<span class="math inline">\(25\%\)</span> of the distribution).
While the distribution has an unambiguously defined median <span class="math inline">\(M = 4.5\)</span>,
its quantile function of the absolute deviations around the median (<span class="math inline">\(|X - \operatorname{median}(X)|\)</span>)
has a discontinuity at 0.5.
This means unambiguously define the <span class="math inline">\(\operatorname{MAD}\)</span> value.
Indeed, the <span class="math inline">\([M-\operatorname{MAD}; M+\operatorname{MAD}]\)</span> interval should cover exactly <span class="math inline">\(50\%\)</span> of the distribution.
In the considered case, there are multiple ways to define such an interval.
The interval value various from <span class="math inline">\([4;5]\)</span> to <span class="math inline">\([1;8]\)</span>.</p><p>Now we explore practical implications of working with such a distribution.
Let us take <span class="math inline">\(1\,000\)</span> random samples of size <span class="math inline">\(100\)</span> from this distribution,
estimate the <span class="math inline">\(\operatorname{MAD}\)</span> value for each sample,
and build a new distribution based on the obtained estimations.
The density plot of the observed sampling distribution is presented in the below figure
(we use the kernel density estimation with the normal kernel and the Sheather & Jones method to select the bandwidth).</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/mad-caveats/img/instability2-light.png target=_blank alt=instability2><img src=/posts/mad-caveats/img/instability2-light.png width=800></a>
<a class="img-dark hidden" href=/posts/mad-caveats/img/instability2-dark.png target=_blank alt=instability2><img src=/posts/mad-caveats/img/instability2-dark.png width=800></a></div><p>As we can see, the sampling <span class="math inline">\(\operatorname{MAD}\)</span> distribution is also trimodal.
In the general case, the distance between these modes could be as large as a gap around the <span class="math inline">\(0.5^\textrm{th}\)</span> quantile
of <span class="math inline">\(|X - \operatorname{median}(X)|\)</span>.</p><p>Thus, if the original distribution is not unimodal,
we cannot speculate on the form of the sampling <span class="math inline">\(\operatorname{MAD}\)</span> distribution
based just on a few of the <span class="math inline">\(\operatorname{MAD}\)</span> estimations.</p><h3 id=caveat-2-beware-of-the-non-zero-dispersion-assumption>Caveat 2: Beware of the non-zero dispersion assumption</h3><p>Another popular assumption about the measures of dispersion is that they always positive.
It is almost true for the standard deviation: unless all sample elements are equal to each other,
the standard deviation is always positive.
Thanks to this property, the standard deviation is often used as a denominator in various statistical equations
(e.g., in effect size measures like the Cohen&rsquo;s d or null hypothesis significance tests like the Student&rsquo;s t-test).
In most cases, we shouldn&rsquo;t expect division by zero because
it&rsquo;s almost impossible to get a sample taken from a continuous distribution
in which all the elements are equal.
Unfortunately, when we switch to robust measures of dispersion of non-parametric distributions,
the risk of getting zero dispersion increases.
We should be ready to get zero dispersion
when we work with discrete distributions or mixtures of discrete and continuous distributions.</p><p>As an example of a discrete distribution,
let us consider the Poisson distribution <span class="math inline">\(\operatorname{Pois}(\lambda)\)</span>.
Its probability mass function is defined as <span class="math inline">\(p(k)=\lambda^k e^{-\lambda} / k!\)</span>.
It&rsquo;s easy to see that when <span class="math inline">\(\lambda < \lambda_0 = -\ln(0.5) \approx 0.6931\)</span>, <span class="math inline">\(p(0) > 0.5\)</span>.
In this case, more than half of the distribution elements are equal to zero.
Therefore, the median absolute deviation also becomes zero.
In the below figure, a probability mass function of <span class="math inline">\(\operatorname{Pois}(0.6)\)</span> is presented.
We can see that <span class="math inline">\(p(0) \approx 0.55\)</span> which gives us zero <span class="math inline">\(\operatorname{MAD}\)</span>.</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/mad-caveats/img/zero1-light.png target=_blank alt=zero1><img src=/posts/mad-caveats/img/zero1-light.png width=800></a>
<a class="img-dark hidden" href=/posts/mad-caveats/img/zero1-dark.png target=_blank alt=zero1><img src=/posts/mad-caveats/img/zero1-dark.png width=800></a></div><p>As an example of a mixture of discrete and continuous distributions,
we can consider the rectified Gaussian distribution (presented in the below figure).
It is a modification of the normal distribution in which all negative elements are replaced by zeros.
It can be also represented
as a mixture of the Dirac delta function <span class="math inline">\(\delta(0)\)</span> and the positive part of the normal distribution.
Since <span class="math inline">\(\delta(0)\)</span> occupies exactly <span class="math inline">\(50\%\)</span> of the distribution, its median absolute deviation is also zero.</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/mad-caveats/img/zero2-light.png target=_blank alt=zero2><img src=/posts/mad-caveats/img/zero2-light.png width=800></a>
<a class="img-dark hidden" href=/posts/mad-caveats/img/zero2-dark.png target=_blank alt=zero2><img src=/posts/mad-caveats/img/zero2-dark.png width=800></a></div><p>Distributions with zero <span class="math inline">\(\operatorname{MAD}\)</span> often arise in various disciplines.
Since they are obviously non-normal, they require robust non-parametric analysis approach.
However, the median absolute deviation is not always a good choice.
For example, it doesn&rsquo;t allow comparing dispersion estimations
of two rectified Gaussian distributions
or two Poisson distributions with <span class="math inline">\(\lambda < 0.6931\)</span>.
A blind usage of <span class="math inline">\(\operatorname{MAD}\)</span> as a denominator in automated statistical analysis
can lead to a critical failure of the system.</p><h3 id=caveat-3-beware-of-the-6895997-assumption>Caveat 3: Beware of the 68–95–99.7 assumption</h3><p>In the previous sections, we have reviewed multimodal distributions and discrete distributions.
Once such features of the distributions are discovered, it becomes obvious that we cannot use classic assumptions
that are valid for the normal distribution.
Now we consider a case of an unimodal continuous distribution.
With distributions, researchers often tend to use the normal distribution as a mental model.
In the below figure, the normal distribution density plot is presented.</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/mad-caveats/img/normality1-light.png target=_blank alt=normality1><img src=/posts/mad-caveats/img/normality1-light.png width=800></a>
<a class="img-dark hidden" href=/posts/mad-caveats/img/normality1-dark.png target=_blank alt=normality1><img src=/posts/mad-caveats/img/normality1-dark.png width=800></a></div><p>A typical assumption about the normal distribution is the 68–95–99.7 rule.
It says that intervals <span class="math inline">\([\mu-\sigma;\mu+\sigma]\)</span>, <span class="math inline">\([\mu-2\sigma;\mu+2\sigma]\)</span>, and <span class="math inline">\([\mu-3\sigma;\mu+3\sigma]\)</span>
cover <span class="math inline">\(68\%\)</span>, <span class="math inline">\(95\%\)</span>, and <span class="math inline">\(99.7\%\)</span> of the normal distribution respectively.
This rule is linked with the three-sigma rule of thumb that implies that the interval <span class="math inline">\([\mu-3\sigma;\mu+3\sigma]\)</span>
covers <span class="math inline">\(99.7\%\)</span> of the distribution values.
While this empirical rule is applicable to many unimodal continuous light-tailed distributions,
it can be violated in the case of heavy-tailed distributions.</p><p>Let us consider the Fréchet distribution with shape equals <span class="math inline">\(1\)</span>, scale equals <span class="math inline">\(1\)</span>, location equals <span class="math inline">\(0\)</span>.
It is a commonly used example of heavy-tailed distribution.
Its true median value is <span class="math inline">\(M \approx 1.44\)</span> and
the true median absolute deviation values is <span class="math inline">\(\operatorname{MAD} \approx 0.9\)</span>.
Its density plot is presented in the below figure:</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/mad-caveats/img/normality2-light.png target=_blank alt=normality2><img src=/posts/mad-caveats/img/normality2-light.png width=800></a>
<a class="img-dark hidden" href=/posts/mad-caveats/img/normality2-dark.png target=_blank alt=normality2><img src=/posts/mad-caveats/img/normality2-dark.png width=800></a></div><p>The variance of this distribution is infinite, therefore we can&rsquo;t use the standard deviation as a measure of dispersion.
However, we will check what would happen with the three-sigma rule if we try to apply it
using a scaled <span class="math inline">\(\operatorname{MAD}\)</span> as a standard deviation estimator.
Using the conventional value <span class="math inline">\(C = 1.4826\)</span>, we get <span class="math inline">\(C\cdot \mathrm{MAD} \approx 2.14\)</span>.
Now let us consider intervals <span class="math inline">\([M-k \cdot \mathrm{MAD}; M+k \cdot \mathrm{MAD}]\)</span> for <span class="math inline">\(k \in \{ 1, C, 2C, 3C \}\)</span>.
The actual coverage of each interval is presented in the following table:</p><table><thead><tr><th align=right><span class="math inline">\(k\)</span></th><th align=left><span class="math inline">\(\mathbb{P}(M - k\cdot \mathrm{MAD} \leq X \leq \mathbb{P}(M + k\cdot \mathrm{MAD})\)</span></th></tr></thead><tbody><tr><td align=right>1.00</td><td align=left>0.500</td></tr><tr><td align=right>1.48</td><td align=left>0.699</td></tr><tr><td align=right>2.97</td><td align=left>0.786</td></tr><tr><td align=right>4.45</td><td align=left>0.833</td></tr></tbody></table><p>As we can see, a blind usage of the three-sigma rule in the heavy-tailed case can lead to misleading insights.
In the above example, the interval <span class="math inline">\([M- 3C \cdot \mathrm{MAD}; M+ 3C \cdot \mathrm{MAD}]\)</span>
actually cover only <span class="math inline">\(83.3\%\)</span> of the distribution instead of the typical <span class="math inline">\(99.7\%\)</span>.</p><h3 id=conclusion>Conclusion</h3><p>If we use a scaled median absolute deviation as a robust replacement to the standard deviation,
we should be careful.
It can work in an acceptable way for some unimodal continuous light-tailed distributions.
However, distribution features like multimodality, discretization, or heavy-tailedness can easily violate
our typical assumptions that we use with the normal distribution and the standard deviation.</p></div><br><br><div class="flex flex-wrap justify-center items-center">The source code of this post and all the relevant files are&nbsp;<a href=https://github.com/AndreyAkinshin/aakinshin.net/tree/master/content/en/posts/2022/08/mad-caveats/index.md>available on GitHub</a>.</div><div class="flex flex-wrap justify-center items-center mb-5"><span>Share:</span><div class="text-4xl pl-3"><a href="https://www.reddit.com/submit?url=https%3a%2f%2faakinshin.net%2fposts%2fmad-caveats%2f&title=Caveats%20of%20using%20the%20median%20absolute%20deviation" target=_blank title="Share on Reddit"><svg class="fai fai-link"><use xlink:href="/img/fa/all.svg#reddit"/></svg></a></div><div class="text-4xl pl-3"><a href="https://twitter.com/intent/tweet?text=Caveats%20of%20using%20the%20median%20absolute%20deviation&url=https%3a%2f%2faakinshin.net%2fposts%2fmad-caveats%2f&via=andrey_akinshin&related=andrey_akinshin" rel=nofollow target=_blank title="Share on Twitter"><svg class="fai fai-link"><use xlink:href="/img/fa/all.svg#twitter"/></svg></a></div><div class="text-4xl pl-3"><a href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2faakinshin.net%2fposts%2fmad-caveats%2f" target=_blank title="Share on HackerNews"><svg class="fai fai-link"><use xlink:href="/img/fa/all.svg#hacker-news"/></svg></a></div><div class="text-4xl pl-3"><a href="https://getpocket.com/save?url=https%3a%2f%2faakinshin.net%2fposts%2fmad-caveats%2f&title=Caveats%20of%20using%20the%20median%20absolute%20deviation" target=_blank title="Add to Pocket"><svg class="fai fai-link"><use xlink:href="/img/fa/all.svg#get-pocket"/></svg></a></div></div></div></div><script>var themeToggleDarkIcon=document.getElementById("theme-toggle-dark-icon"),themeToggleBtn,themeToggleLightIcon=document.getElementById("theme-toggle-light-icon");const imagesDark=document.querySelectorAll(".img-dark"),imagesLight=document.querySelectorAll(".img-light");localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?(themeToggleLightIcon.classList.remove("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")})):(themeToggleDarkIcon.classList.remove("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")})),themeToggleBtn=document.getElementById("theme-toggle"),themeToggleBtn.addEventListener("click",function(){themeToggleDarkIcon.classList.toggle("hidden"),themeToggleLightIcon.classList.toggle("hidden"),imagesLight.forEach(e=>{e.classList.toggle("hidden")}),imagesDark.forEach(e=>{e.classList.toggle("hidden")}),localStorage.getItem("color-theme")?localStorage.getItem("color-theme")==="light"?(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark")):(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):document.documentElement.classList.contains("dark")?(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark"))})</script><footer class="z-20 p-4 md:p-6 mt-3 w-full border-t border-gray-200 shadow flex items-center justify-center dark:border-gray-600 bg-white dark:bg-zinc-800"><span class="dark:text-gray-400 text-center">© 2013—2023 <span class=whitespace-nowrap>Andrey Akinshin</span></span><ul class="flex flex-wrap items-center px-4 mb-1"><li><a href=https://github.com/AndreyAkinshin><svg class="fai fai-link w-5 h-5"><title>GitHub</title><use xlink:href="/img/fa/all.svg#github"/></svg></a></li><li><a href=https://twitter.com/andrey_akinshin><svg class="fai fai-link w-5 h-5"><title>Twitter</title><use xlink:href="/img/fa/all.svg#twitter"/></svg></a></li><li><a href=https://aakinshin.net/posts/index.xml><svg class="fai fai-link w-5 h-5"><title>RSS</title><use xlink:href="/img/fa/all.svg#rss"/></svg></a></li></ul><div class=main-content><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></div></footer><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script></body></html>