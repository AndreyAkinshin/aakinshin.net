<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.123.3"><meta name=author content='Andrey Akinshin'><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content='Mathematics,Statistics,Research,Research: Quantile absolute deviation'><title>Caveats of using the median absolute deviation | Andrey Akinshin</title>
<meta name=description content="The median absolute deviation is a measure of dispersion which can be used as a robust alternative to the standard deviation. It works great for slight deviations from normality (e.g., for contaminated normal distributions or slightly skewed unimodal distri..."><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><script>localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?document.documentElement.classList.add("dark"):document.documentElement.classList.remove("dark")</script><link href=https://aakinshin.net/css/main.min.25504b87a17cfaf1c000a5bcca42b1c4888fa4efc097d640d9139388b3e67e55.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"></head><body><nav><div class="container flex flex-wrap items-center justify-between mx-auto max-w-6xl h-12 px-2 xs:px-6"><div class="flex items-center justify-start justify-self-start"><div class="flex nav-item h-12 w-12 items-center justify-center"><a class=text-white href=https://aakinshin.net/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#house-chimney"/></svg></a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/posts/>Posts</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/research/>Research</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/library/>Library</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/about/>About</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/search/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#magnifying-glass"/></svg></a></div></div><button id=theme-toggle type=button title="Alt+Click to match OS color theme" class="nav-item p-3 content-center justify-self-end"><svg id="theme-toggle-dark-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001.0 1010.586 10.586z"/></svg><svg id="theme-toggle-light-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M10 2a1 1 0 011 1v1A1 1 0 119 4V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707A1 1 0 1113.536 5.05l.707-.707a1 1 0 011.414.0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707A1 1 0 004.343 5.757l.707.707zm1.414 8.486-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z" fill-rule="evenodd" clip-rule="evenodd"/></svg></button></div></nav><div class="main container mx-auto max-w-6xl px-6"><div class=main-post><h1 class=blog-post-title id=post-title>Caveats of Using the Median Absolute Deviation</h1><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg>
<time datetime=2022-08-02>August 2, 2022</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/>Mathematics</a>
<a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics</a>
<a class=label-link href=https://aakinshin.net/tags/research/>Research</a>
<a class=label-link href=https://aakinshin.net/tags/research-qad/>Research: Quantile Absolute Deviation</a></div></div><br><div class="main-content mb-3 px-2 py-1 rounded border text-alert-text-l border-alert-frame-l dark:text-alert-text-d dark:border-alert-frame-d">Update: this blog post is a part of research that aimed to build a new measure of statistical dispersion called quantile absolute deviation. A <a href=/posts/preprint-qad/>preprint with final results</a> is available on arXiv: <a href=https://arxiv.org/abs/2208.13459>arXiv:2208.13459 [stat.ME]</a>. Some information in this blog post can be obsolete: please, use the preprint as the primary reference.</div><div class=main-content><p>The median absolute deviation is a measure of dispersion
which can be used as a robust alternative to the standard deviation.
It works great for slight deviations from normality
(e.g., for contaminated normal distributions or slightly skewed unimodal distributions).
Unfortunately, if we apply it to distributions with huge deviations from normality,
we may experience a lot of troubles.
In this post, I discuss some of the most important caveats which we should keep in mind
if we use the median absolute deviation.</p><h3 id=introduction>Introduction</h3><p>Let $X$ be a sample of i.i.d. random variables: $X = \{ X_1, X_2, \ldots, X_n \}$.
The median absolute deviation is defined as follows</p>$$
\operatorname{MAD}(X) = C \cdot \operatorname{median}(|X - \operatorname{median}(X)|),
$$<p>where $C$ is the scale constant, $\operatorname{median}$ is the median estimator.
In the scope of this post, we use only the classic sample median
(if $n$ is odd, the median is the middle order statistic;
if $n$ is even, the median is the arithmetic average of the two middle order statistics).
The scale constant $C$ allows using $\operatorname{MAD}$ as a consistent estimator of the standard deviation.
In order to make $\operatorname{MAD}$ asymptotically consistent with the standard deviation under normality,
we should use $C = 1 / \Phi^{-1}(0.75) \approx 1.4826$.
In practice, we may need <a href=https://aakinshin.net/posts/preprint-mad-factors/>adjusted values</a>
of $C$ for small samples to obtain an unbiased estimator.</p><p>Using $\operatorname{MAD}$ as a robust replacement for the standard deviation
may be reasonable in the case of slight deviations from normality.
However, it could be quite misleading in the case of large deviations.
Let us review some of the typical assumptions that may lead to incorrect conclusions.</p><h3 id=caveat-1-beware-of-the-narrow-estimation-range-assumption>Caveat 1: Beware of the narrow estimation range assumption</h3><p>With non-robust estimators, a single corrupted element can easily distort the estimation.
A transition towards robust approaches brings a lot of benefits in terms of stability:
a single altered element cannot introduce extreme changes in the estimation value.
Having this knowledge, many researchers typically expect that robust estimations would fit a narrow range of values.
Therefore, they can omit the phase of exploring the distribution of estimations
and draw conclusions based on a single trial assuming
that all possible estimations are close enough to each other.
However, while robust estimators indeed provide a decent defense against extreme outliers,
they still can have a wide range of possible values.</p><p>Let us consider an example.
In the below figure, we can see a density plot of a trimodal distribution.</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/mad-caveats/img/instability1-light.png target=_blank alt=instability1><img src=/posts/mad-caveats/img/instability1-light.png width=800>
</a><a class="img-dark hidden" href=/posts/mad-caveats/img/instability1-dark.png target=_blank alt=instability1><img src=/posts/mad-caveats/img/instability1-dark.png width=800></a></div><p>This distribution has three non-intersecting intervals:
$[0;1]$ ($25\%$ of the distribution),
$[4;5]$ ($50\%$ of the distribution),
and $[8;9]$ ($25\%$ of the distribution).
While the distribution has an unambiguously defined median $M = 4.5$,
its quantile function of the absolute deviations around the median ($|X - \operatorname{median}(X)|$)
has a discontinuity at 0.5.
This means unambiguously define the $\operatorname{MAD}$ value.
Indeed, the $[M-\operatorname{MAD}; M+\operatorname{MAD}]$ interval should cover exactly $50\%$ of the distribution.
In the considered case, there are multiple ways to define such an interval.
The interval value various from $[4;5]$ to $[1;8]$.</p><p>Now we explore practical implications of working with such a distribution.
Let us take $1\,000$ random samples of size $100$ from this distribution,
estimate the $\operatorname{MAD}$ value for each sample,
and build a new distribution based on the obtained estimations.
The density plot of the observed sampling distribution is presented in the below figure
(we use the kernel density estimation with the normal kernel and the Sheather & Jones method to select the bandwidth).</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/mad-caveats/img/instability2-light.png target=_blank alt=instability2><img src=/posts/mad-caveats/img/instability2-light.png width=800>
</a><a class="img-dark hidden" href=/posts/mad-caveats/img/instability2-dark.png target=_blank alt=instability2><img src=/posts/mad-caveats/img/instability2-dark.png width=800></a></div><p>As we can see, the sampling $\operatorname{MAD}$ distribution is also trimodal.
In the general case, the distance between these modes could be as large as a gap around the $0.5^\textrm{th}$ quantile
of $|X - \operatorname{median}(X)|$.</p><p>Thus, if the original distribution is not unimodal,
we cannot speculate on the form of the sampling $\operatorname{MAD}$ distribution
based just on a few of the $\operatorname{MAD}$ estimations.</p><h3 id=caveat-2-beware-of-the-non-zero-dispersion-assumption>Caveat 2: Beware of the non-zero dispersion assumption</h3><p>Another popular assumption about the measures of dispersion is that they always positive.
It is almost true for the standard deviation: unless all sample elements are equal to each other,
the standard deviation is always positive.
Thanks to this property, the standard deviation is often used as a denominator in various statistical equations
(e.g., in effect size measures like the Cohen&rsquo;s d or null hypothesis significance tests like the Student&rsquo;s t-test).
In most cases, we shouldn&rsquo;t expect division by zero because
it&rsquo;s almost impossible to get a sample taken from a continuous distribution
in which all the elements are equal.
Unfortunately, when we switch to robust measures of dispersion of non-parametric distributions,
the risk of getting zero dispersion increases.
We should be ready to get zero dispersion
when we work with discrete distributions or mixtures of discrete and continuous distributions.</p><p>As an example of a discrete distribution,
let us consider the Poisson distribution $\operatorname{Pois}(\lambda)$.
Its probability mass function is defined as $p(k)=\lambda^k e^{-\lambda} / k!$.
It&rsquo;s easy to see that when $\lambda < \lambda_0 = -\ln(0.5) \approx 0.6931$, $p(0) > 0.5$.
In this case, more than half of the distribution elements are equal to zero.
Therefore, the median absolute deviation also becomes zero.
In the below figure, a probability mass function of $\operatorname{Pois}(0.6)$ is presented.
We can see that $p(0) \approx 0.55$ which gives us zero $\operatorname{MAD}$.</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/mad-caveats/img/zero1-light.png target=_blank alt=zero1><img src=/posts/mad-caveats/img/zero1-light.png width=800>
</a><a class="img-dark hidden" href=/posts/mad-caveats/img/zero1-dark.png target=_blank alt=zero1><img src=/posts/mad-caveats/img/zero1-dark.png width=800></a></div><p>As an example of a mixture of discrete and continuous distributions,
we can consider the rectified Gaussian distribution (presented in the below figure).
It is a modification of the normal distribution in which all negative elements are replaced by zeros.
It can be also represented
as a mixture of the Dirac delta function $\delta(0)$ and the positive part of the normal distribution.
Since $\delta(0)$ occupies exactly $50\%$ of the distribution, its median absolute deviation is also zero.</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/mad-caveats/img/zero2-light.png target=_blank alt=zero2><img src=/posts/mad-caveats/img/zero2-light.png width=800>
</a><a class="img-dark hidden" href=/posts/mad-caveats/img/zero2-dark.png target=_blank alt=zero2><img src=/posts/mad-caveats/img/zero2-dark.png width=800></a></div><p>Distributions with zero $\operatorname{MAD}$ often arise in various disciplines.
Since they are obviously non-normal, they require robust non-parametric analysis approach.
However, the median absolute deviation is not always a good choice.
For example, it doesn&rsquo;t allow comparing dispersion estimations
of two rectified Gaussian distributions
or two Poisson distributions with $\lambda < 0.6931$.
A blind usage of $\operatorname{MAD}$ as a denominator in automated statistical analysis
can lead to a critical failure of the system.</p><h3 id=caveat-3-beware-of-the-6895997-assumption>Caveat 3: Beware of the 68–95–99.7 assumption</h3><p>In the previous sections, we have reviewed multimodal distributions and discrete distributions.
Once such features of the distributions are discovered, it becomes obvious that we cannot use classic assumptions
that are valid for the normal distribution.
Now we consider a case of an unimodal continuous distribution.
With distributions, researchers often tend to use the normal distribution as a mental model.
In the below figure, the normal distribution density plot is presented.</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/mad-caveats/img/normality1-light.png target=_blank alt=normality1><img src=/posts/mad-caveats/img/normality1-light.png width=800>
</a><a class="img-dark hidden" href=/posts/mad-caveats/img/normality1-dark.png target=_blank alt=normality1><img src=/posts/mad-caveats/img/normality1-dark.png width=800></a></div><p>A typical assumption about the normal distribution is the 68–95–99.7 rule.
It says that intervals $[\mu-\sigma;\mu+\sigma]$, $[\mu-2\sigma;\mu+2\sigma]$, and $[\mu-3\sigma;\mu+3\sigma]$
cover $68\%$, $95\%$, and $99.7\%$ of the normal distribution respectively.
This rule is linked with the three-sigma rule of thumb that implies that the interval $[\mu-3\sigma;\mu+3\sigma]$
covers $99.7\%$ of the distribution values.
While this empirical rule is applicable to many unimodal continuous light-tailed distributions,
it can be violated in the case of heavy-tailed distributions.</p><p>Let us consider the Fréchet distribution with shape equals $1$, scale equals $1$, location equals $0$.
It is a commonly used example of heavy-tailed distribution.
Its true median value is $M \approx 1.44$ and
the true median absolute deviation values is $\operatorname{MAD} \approx 0.9$.
Its density plot is presented in the below figure:</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/mad-caveats/img/normality2-light.png target=_blank alt=normality2><img src=/posts/mad-caveats/img/normality2-light.png width=800>
</a><a class="img-dark hidden" href=/posts/mad-caveats/img/normality2-dark.png target=_blank alt=normality2><img src=/posts/mad-caveats/img/normality2-dark.png width=800></a></div><p>The variance of this distribution is infinite, therefore we can&rsquo;t use the standard deviation as a measure of dispersion.
However, we will check what would happen with the three-sigma rule if we try to apply it
using a scaled $\operatorname{MAD}$ as a standard deviation estimator.
Using the conventional value $C = 1.4826$, we get $C\cdot \mathrm{MAD} \approx 2.14$.
Now let us consider intervals $[M-k \cdot \mathrm{MAD}; M+k \cdot \mathrm{MAD}]$ for $k \in \{ 1, C, 2C, 3C \}$.
The actual coverage of each interval is presented in the following table:</p><table><thead><tr><th align=right>$k$</th><th align=left>$\mathbb{P}(M - k\cdot \mathrm{MAD} \leq X \leq \mathbb{P}(M + k\cdot \mathrm{MAD})$</th></tr></thead><tbody><tr><td align=right>1.00</td><td align=left>0.500</td></tr><tr><td align=right>1.48</td><td align=left>0.699</td></tr><tr><td align=right>2.97</td><td align=left>0.786</td></tr><tr><td align=right>4.45</td><td align=left>0.833</td></tr></tbody></table><p>As we can see, a blind usage of the three-sigma rule in the heavy-tailed case can lead to misleading insights.
In the above example, the interval $[M- 3C \cdot \mathrm{MAD}; M+ 3C \cdot \mathrm{MAD}]$
actually cover only $83.3\%$ of the distribution instead of the typical $99.7\%$.</p><h3 id=conclusion>Conclusion</h3><p>If we use a scaled median absolute deviation as a robust replacement to the standard deviation,
we should be careful.
It can work in an acceptable way for some unimodal continuous light-tailed distributions.
However, distribution features like multimodality, discretization, or heavy-tailedness can easily violate
our typical assumptions that we use with the normal distribution and the standard deviation.</p></div><hr><h3 id=references>References (1)</h3><ol><li><a href=https://aakinshin.net/posts/>Posts</a> /
<a href=https://aakinshin.net/posts/preprint-mad-factors/>Preprint Announcement: 'Finite-Sample Bias-Correction Factors for the Median Absolute Deviation Based on the Harrell-Davis Quantile Estimator and Its Trimmed Modification'
</a>(2022-07-26)</li></ol></div></div><script>var themeToggleDarkIcon=document.getElementById("theme-toggle-dark-icon"),themeToggleBtn,themeToggleLightIcon=document.getElementById("theme-toggle-light-icon");const imagesDark=document.querySelectorAll(".img-dark"),imagesLight=document.querySelectorAll(".img-light");localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?(themeToggleLightIcon.classList.remove("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")})):(themeToggleDarkIcon.classList.remove("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}));function toggleTheme(e){e?(document.documentElement.classList.add("dark"),themeToggleLightIcon.classList.remove("hidden"),themeToggleDarkIcon.classList.add("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")}),imagesLight.forEach(e=>{e.classList.add("hidden")})):(document.documentElement.classList.remove("dark"),themeToggleDarkIcon.classList.remove("hidden"),themeToggleLightIcon.classList.add("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}),imagesDark.forEach(e=>{e.classList.add("hidden")}))}themeToggleBtn=document.getElementById("theme-toggle"),themeToggleBtn.addEventListener("click",function(){themeToggleDarkIcon.classList.toggle("hidden"),themeToggleLightIcon.classList.toggle("hidden"),imagesLight.forEach(e=>{e.classList.toggle("hidden")}),imagesDark.forEach(e=>{e.classList.toggle("hidden")}),event.altKey?(localStorage.removeItem("color-theme"),toggleTheme(window.matchMedia("(prefers-color-scheme: dark)").matches)):localStorage.getItem("color-theme")?localStorage.getItem("color-theme")==="light"?(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark")):(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):document.documentElement.classList.contains("dark")?(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark"))}),window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",e=>{if(localStorage.getItem("color-theme")===null){const t=e.matches?"dark":"light";toggleTheme(t==="dark")}})</script><footer class="z-20 p-4 md:p-6 mt-3 w-full border-t border-gray-200 shadow flex items-center justify-center dark:border-gray-600 bg-white dark:bg-zinc-800"><span class="dark:text-gray-400 text-center">© 2013—2024 <span class=whitespace-nowrap>Andrey Akinshin</span></span><ul class="flex flex-wrap items-center px-4 mb-1"><li><a href=https://github.com/AndreyAkinshin><svg class="fai fai-link w-5 h-5"><title>GitHub</title><use xlink:href="/img/fa/all.svg#github"/></svg></a></li><li><a href=https://twitter.com/andrey_akinshin><svg class="fai fai-link w-5 h-5"><title>Twitter</title><use xlink:href="/img/fa/all.svg#twitter"/></svg></a></li><li><a href=https://aakinshin.net/posts/index.xml><svg class="fai fai-link w-5 h-5"><title>RSS</title><use xlink:href="/img/fa/all.svg#rss"/></svg></a></li></ul><div class=main-content><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></div></footer><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+=" has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script></body></html>