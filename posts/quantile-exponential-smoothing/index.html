<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.103.0-DEV"><meta name=author content="Andrey Akinshin"><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content="Mathematics,Statistics,Research,Quantile,Harrell-Davis quantile estimator,Exponential smoothing,Moving Quantile"><title>Quantile exponential smoothing | Andrey Akinshin</title><meta name=description content="One of the popular problems in time series analysis is estimating the moving &amp;ldquo;average&amp;rdquo; value. Let&amp;rsquo;s define the &amp;ldquo;average&amp;rdquo; as a..."><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><script>localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?document.documentElement.classList.add("dark"):document.documentElement.classList.remove("dark")</script><link href=https://aakinshin.net/css/main.min.3746982c0855975eba2f485ef34018c70576ba5fe5ea2f4333daa717341a2831.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"></head><body><nav><div class="container flex flex-wrap items-center justify-between mx-auto max-w-6xl h-12 px-6"><div class="flex items-center justify-start justify-self-start"><div class="flex nav-item h-12 w-12 items-center justify-center"><a class=text-white href=https://aakinshin.net/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#house-chimney"/></svg></a></div><div class="flex nav-item h-12 items-center"><a class="px-3 text-white" href=https://aakinshin.net/posts/>Posts</a></div><div class="flex nav-item h-12 items-center"><a class="px-3 text-white" href=https://aakinshin.net/research/>Research</a></div><div class="flex nav-item h-12 items-center"><a class="px-3 text-white" href=https://aakinshin.net/about/>About</a></div></div><div class="flex items-center justify-end justify-self-start"><div class="flex nav-item h-12 items-center" title='Support this blog'><a class="px-3 text-white" href=https://github.com/sponsors/AndreyAkinshin><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#heart"/></svg></a></div><button id=theme-toggle type=button class="nav-item p-3 content-center justify-self-end"><svg id="theme-toggle-dark-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001.0 1010.586 10.586z"/></svg><svg id="theme-toggle-light-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M10 2a1 1 0 011 1v1A1 1 0 119 4V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707A1 1 0 1113.536 5.05l.707-.707a1 1 0 011.414.0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707A1 1 0 004.343 5.757l.707.707zm1.414 8.486-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z" fill-rule="evenodd" clip-rule="evenodd"/></svg></button></div></div></nav><div class="main container mx-auto max-w-6xl px-6"><div class=main-post><h1 class=blog-post-title id=post-title>Quantile exponential smoothing</h1><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg><time datetime=2021-05-04>May 4, 2021</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/>Mathematics</a>
<a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics</a>
<a class=label-link href=https://aakinshin.net/tags/research/>Research</a>
<a class=label-link href=https://aakinshin.net/tags/quantile/>Quantile</a>
<a class=label-link href=https://aakinshin.net/tags/harrell-davis-quantile-estimator/>Harrell-Davis quantile estimator</a>
<a class=label-link href=https://aakinshin.net/tags/exponential-smoothing/>Exponential smoothing</a>
<a class=label-link href=https://aakinshin.net/tags/moving-quantile/>Moving Quantile</a></div></div><br><div class=main-content><p>One of the popular problems in time series analysis is estimating the moving &ldquo;average&rdquo; value.
Let&rsquo;s define the &ldquo;average&rdquo; as a central tendency metric like the mean or the median.
When we talk about the moving value, we assume that we are interested in
the average value &ldquo;at the end&rdquo; of the time series
instead of the average of all available observations.</p><p>One of the most straightforward approaches to estimate the moving average is the <em>simple moving mean</em>.
Unfortunately, this approach is not robust: outliers can instantly spoil the evaluated mean value.
As an alternative, we can consider <em>simple moving median</em>.
I already discussed a few of such methods:
<a href=https://aakinshin.net/posts/mp2-quantile-estimator/>the MP² quantile estimator</a> and
<a href=https://aakinshin.net/posts/partitioning-heaps-quantile-estimator2/>a moving quantile estimator based on partitioning heaps</a>
(a modification of the Hardle-Steiger method).
When we talk about <em>simple moving averages</em>, we typically assume
that we estimate the average value over the last <span class="math inline">\(k\)</span> observations (<span class="math inline">\(k\)</span> is the <em>window size</em>).
This approach is also known as <em>unweighted moving averages</em> because
all target observations have the same weight.</p><p>As an alternative to the simple moving average, we can also consider the <em>weighted moving average</em>.
In this case, we assign a weight for each observation and aggregate the whole time series according to these weights.
A famous example of such a weight function is <em>exponential smoothing</em>.
And the simplest form of exponential smoothing is the <em>exponentially weighted moving mean</em>.
This approach estimates the weighted moving mean using exponentially decreasing weights.
Switching from the simple moving mean to the exponentially weighted moving mean provides some benefits
in terms of smoothness and estimation efficiency.</p><p>Although exponential smoothing has advantages over the simple moving mean,
it still estimates the mean value which is not robust.
We can improve the robustness of this approach if we reuse the same idea for weighted moving quantiles.
It&rsquo;s possible because the quantiles also can be estimated for weighted samples.
In one of my previous posts, I <a href=https://aakinshin.net/posts/weighted-quantiles/>showed</a> how to adapt
the Hyndman-Fan Type 7 and Harrell-Davis quantile estimators to the weighted samples.
In this post, I&rsquo;m going to show how we can use this technique to estimate
the weighted moving quantiles using exponentially decreasing weights.</p><h3 id=mean-exponential-smoothing>Mean exponential smoothing</h3><p>First of all, let&rsquo;s recall the idea of the mean exponential smoothing.
Let&rsquo;s say we have a series <span class="math inline">\(\{ x_1, x_2, \ldots \}\)</span>.
The exponentially weighted moving mean can be defined as follows:</p><p><span class="math display">\[\left\{
\begin{array}{l}
s_1 = x_1,\\
s_i = \alpha x_i + (1 - \alpha)s_{i-1} \quad \textrm{for}\;\; i > 1
\end{array}
\right.
\]</span></p><p>where <span class="math inline">\(\alpha\)</span> is the <em>smoothing factor</em> (<span class="math inline">\(0 < \alpha < 1\)</span>).
This recursive form allows calculation of the exponentially weighted moving mean using <span class="math inline">\(O(1)\)</span> complexity.
However, this can be rewritten without recursion as a weighted sum of all observations <span class="math inline">\(x_i\)</span>:</p><p><span class="math display">\[s_n = \sum_{i=1}^n w_i x_i
\]</span></p><p>where</p><p><span class="math display">\[\left\{
\begin{array}{l}
w_1 = (1 - \alpha)^{(n-1)},\\
w_i = \alpha (1 - \alpha)^{n-i} \quad \textrm{for}\;\; i > 1
\end{array}
\right.
\]</span></p><p>Now let&rsquo;s try to test this approach.
One of my favorite data sets for testing moving average estimators is
a noisy, monotonically increasing sine wave pattern with high outliers.
Here is how it looks like:</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/quantile-exponential-smoothing/img/raw-light.png target=_blank alt=raw><img src=/posts/quantile-exponential-smoothing/img/raw-light.png width=800></a>
<a class="img-dark hidden" href=/posts/quantile-exponential-smoothing/img/raw-dark.png target=_blank alt=raw><img src=/posts/quantile-exponential-smoothing/img/raw-dark.png width=800></a></div><p>Now let&rsquo;s calculate the exponentially weighted moving mean using <span class="math inline">\(\alpha = 0.9\)</span>:</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/quantile-exponential-smoothing/img/mean90-light.png target=_blank alt=mean90><img src=/posts/quantile-exponential-smoothing/img/mean90-light.png width=800></a>
<a class="img-dark hidden" href=/posts/quantile-exponential-smoothing/img/mean90-dark.png target=_blank alt=mean90><img src=/posts/quantile-exponential-smoothing/img/mean90-dark.png width=800></a></div><p>As we can see, exponential smoothing doesn&rsquo;t help us to get a smooth line.
The values of the moving mean are heavily affected by outliers.
Let&rsquo;s try to reduce the value of <span class="math inline">\(\alpha\)</span> to <span class="math inline">\(0.5\)</span>:</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/quantile-exponential-smoothing/img/mean50-light.png target=_blank alt=mean50><img src=/posts/quantile-exponential-smoothing/img/mean50-light.png width=800></a>
<a class="img-dark hidden" href=/posts/quantile-exponential-smoothing/img/mean50-dark.png target=_blank alt=mean50><img src=/posts/quantile-exponential-smoothing/img/mean50-dark.png width=800></a></div><p>It looks a little bit better, but we still have too many &ldquo;poor&rdquo; values.
Let&rsquo;s try to reduce the value of <span class="math inline">\(\alpha\)</span> to <span class="math inline">\(0.1\)</span>:</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/quantile-exponential-smoothing/img/mean10-light.png target=_blank alt=mean10><img src=/posts/quantile-exponential-smoothing/img/mean10-light.png width=800></a>
<a class="img-dark hidden" href=/posts/quantile-exponential-smoothing/img/mean10-dark.png target=_blank alt=mean10><img src=/posts/quantile-exponential-smoothing/img/mean10-dark.png width=800></a></div><p>Now it looks much better, but the line is still not so smooth.
It&rsquo;s not a problem of exponential smoothing, it&rsquo;s a problem of the mean as a measure of central tendency.
When the underlying distribution has a heavy tail (and the corresponding samples have extreme outliers),
the mean is not a good way to estimate the &ldquo;average.&rdquo;
Let&rsquo;s consider the density plot of the Pareto distribution (<span class="math inline">\(x_m = 1, \alpha = 1.05\)</span>):</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/quantile-exponential-smoothing/img/pareto-mean-light.png target=_blank alt=pareto-mean><img src=/posts/quantile-exponential-smoothing/img/pareto-mean-light.png width=800></a>
<a class="img-dark hidden" href=/posts/quantile-exponential-smoothing/img/pareto-mean-dark.png target=_blank alt=pareto-mean><img src=/posts/quantile-exponential-smoothing/img/pareto-mean-dark.png width=800></a></div><p>For this distribution, the mean value is about the <span class="math inline">\(96^\textrm{th}\)</span> percentile.
This value is pretty far from the most significant part of the distribution.
In such cases, the median is a more stable and more acceptable choice of the &ldquo;average&rdquo; metric.</p><h3 id=quantile-exponential-smoothing>Quantile exponential smoothing</h3><p>To estimate distribution quantiles, we will use the Harrell-Davis quantile estimator
because it&rsquo;s much <a href=https://aakinshin.net/posts/hdqe-efficiency/>more efficient</a> than the traditional quantile estimators.
If we want to get a better robustness level, we can also consider
the <a href=https://aakinshin.net/posts/winsorized-hdqe/>winsorized</a> and <a href=https://aakinshin.net/posts/trimmed-hdqe/>trimmed</a> modifications
of the Harrell-Davis quantile estimator
(the corresponding efficiency overview can be found <a href=https://aakinshin.net/posts/wthdqe-efficiency/>here</a>).</p><p>The easiest way to assign exponential weights to our observations is exponential decay.
If we want to assign weights <span class="math inline">\(w\)</span> for observations <span class="math inline">\(\{ x_1, \ldots, x_n \}\)</span>,
we can use the following equation:</p><p><span class="math display">\[w_t = e^{-\lambda (n-t)}
\]</span></p><p>where <span class="math inline">\(\lambda\)</span> is the decay constant.
In order to set the <span class="math inline">\(\lambda\)</span> value, we can express it via the half-life value <span class="math inline">\(t_{1/2}\)</span>:</p><p><span class="math display">\[\lambda = \frac{\ln(2)}{t_{1/2}}.
\]</span></p><p>The half-life gives us a nice property of the weight function: <span class="math inline">\(w_{i-t_{1/2}} = 0.5 w_i\)</span>.
Thus,</p><p><span class="math display">\[w_n = 1, \quad
w_{n-t_{1/2}} = 0.5, \quad
w_{n-2t_{1/2}} = 0.25, \quad
w_{n-3t_{1/2}} = 0.125, \quad
\ldots
\]</span></p><p>Once we defined the weight function, the Harrell-Davis quantile estimation <span class="math inline">\(q^*_p\)</span> of the <span class="math inline">\(p^\textrm{th}\)</span> quantile
can be expressed as follows (the complete overview of this method can be found <a href=https://aakinshin.net/posts/weighted-quantiles/>here</a>):</p><p><span class="math display">\[q^*_p = \sum_{i=1}^{n} W^*_{i} \cdot x_i,\quad
W^*_{i} = I_{r^*_i}(a^*, b^*) - I_{l^*_i}(a^*, b^*),
\]</span></p><p><span class="math display">\[\left\{
\begin{array}{rcc}
l^*_i & = & \dfrac{s_{i-1}(w)}{s_n(w)},\\
r^*_i & = & \dfrac{s_i(w)}{s_n(w)},
\end{array}
\right.
\]</span></p><p><span class="math display">\[s_i(w) = \sum_{j=1}^i w_j,
\]</span></p><p><span class="math display">\[\left\{
\begin{array}{rccl}
a^* = & p     & \cdot & (n^* + 1),\\
b^* = & (1-p) & \cdot & (n^* + 1),
\end{array}
\right.
\]</span></p><p><span class="math display">\[n^* = \frac{\Big( \sum_{i=1}^n w_i \Big)^2}{\sum_{i=1}^n w_i^2 }
\]</span></p><p>where <span class="math inline">\(I_t(a, b)\)</span> is the <a href=https://en.wikipedia.org/wiki/Beta_function#Incomplete_beta_function>regularized incomplete beta function</a>.</p><p>The corresponding confidence interval can also be estimated using the
<a href=https://aakinshin.net/posts/weighted-quantiles-ci/>modification of the Maritz-Jarrett method for weighted samples</a>.</p><p>Now let&rsquo;s try to apply the above equation to our data set using <span class="math inline">\(\textrm{half-life} = 10\)</span>:</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/quantile-exponential-smoothing/img/median10-light.png target=_blank alt=median10><img src=/posts/quantile-exponential-smoothing/img/median10-light.png width=800></a>
<a class="img-dark hidden" href=/posts/quantile-exponential-smoothing/img/median10-dark.png target=_blank alt=median10><img src=/posts/quantile-exponential-smoothing/img/median10-dark.png width=800></a></div><p>Increasing the half-life value gives more smooth but less adaptive line:</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/quantile-exponential-smoothing/img/median200-light.png target=_blank alt=median200><img src=/posts/quantile-exponential-smoothing/img/median200-light.png width=800></a>
<a class="img-dark hidden" href=/posts/quantile-exponential-smoothing/img/median200-dark.png target=_blank alt=median200><img src=/posts/quantile-exponential-smoothing/img/median200-dark.png width=800></a></div><h3 id=incremental-implementation-of-quantile-exponential-smoothing>Incremental implementation of quantile exponential smoothing</h3><p>The most significant advantage of the exponentially weighted moving mean is its computational efficiency:
it can be recalculated using <span class="math inline">\(O(1)\)</span> complexity based on the previous value.
In the case of quantile exponential smoothing, we can&rsquo;t do it using <span class="math inline">\(O(1)\)</span> complexity because we need
a sorted array of values to estimate the quantile value.
To improve the algorithm performance, we can use a data structure that allows maintaining a sorted version of <span class="math inline">\(\{ x_i \}\)</span>
with <span class="math inline">\(O(\log n)\)</span> update operation (e.g., a balanced binary tree).
However, the Harrell-Davis quantile estimator still has <span class="math inline">\(O(n)\)</span> complexity.
This also can be improved using
the <a href=https://aakinshin.net/posts/winsorized-hdqe/>winsorized</a> and <a href=https://aakinshin.net/posts/trimmed-hdqe/>trimmed</a> modifications
of the Harrell-Davis quantile estimator</p><h3 id=conclusion>Conclusion</h3><p>In this post, we discussed quantile exponential smoothing using
the exponentially weighted moving Harrell-Davis quantile estimations.
This approach allows getting the moving quantile values that are more stable and smooth than
the classic exponentially weighted mean values.
The only disadvantage of this method is its computational complexity which is <span class="math inline">\(O(n)\)</span> for each estimated value.</p></div><br><br><div class="flex flex-wrap justify-center items-center">The source code of this post and all the relevant files are&nbsp;<a href=https://github.com/AndreyAkinshin/aakinshin.net/tree/master/content/en/posts/2021/05/quantile-exponential-smoothing/index.md>available on GitHub</a>.</div><div class="flex flex-wrap justify-center items-center mb-5"><span>Share:</span><div class="text-4xl pl-3"><a href="https://www.reddit.com/submit?url=https%3a%2f%2faakinshin.net%2fposts%2fquantile-exponential-smoothing%2f&title=Quantile%20exponential%20smoothing" target=_blank title="Share on Reddit"><svg class="fai fai-link"><use xlink:href="/img/fa/all.svg#reddit"/></svg></a></div><div class="text-4xl pl-3"><a href="https://twitter.com/intent/tweet?text=Quantile%20exponential%20smoothing&url=https%3a%2f%2faakinshin.net%2fposts%2fquantile-exponential-smoothing%2f&via=andrey_akinshin&related=andrey_akinshin" rel=nofollow target=_blank title="Share on Twitter"><svg class="fai fai-link"><use xlink:href="/img/fa/all.svg#twitter"/></svg></a></div><div class="text-4xl pl-3"><a href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2faakinshin.net%2fposts%2fquantile-exponential-smoothing%2f" target=_blank title="Share on HackerNews"><svg class="fai fai-link"><use xlink:href="/img/fa/all.svg#hacker-news"/></svg></a></div><div class="text-4xl pl-3"><a href="https://getpocket.com/save?url=https%3a%2f%2faakinshin.net%2fposts%2fquantile-exponential-smoothing%2f&title=Quantile%20exponential%20smoothing" target=_blank title="Add to Pocket"><svg class="fai fai-link"><use xlink:href="/img/fa/all.svg#get-pocket"/></svg></a></div></div></div></div><script>var themeToggleDarkIcon=document.getElementById("theme-toggle-dark-icon"),themeToggleBtn,themeToggleLightIcon=document.getElementById("theme-toggle-light-icon");const imagesDark=document.querySelectorAll(".img-dark"),imagesLight=document.querySelectorAll(".img-light");localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?(themeToggleLightIcon.classList.remove("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")})):(themeToggleDarkIcon.classList.remove("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")})),themeToggleBtn=document.getElementById("theme-toggle"),themeToggleBtn.addEventListener("click",function(){themeToggleDarkIcon.classList.toggle("hidden"),themeToggleLightIcon.classList.toggle("hidden"),imagesLight.forEach(e=>{e.classList.toggle("hidden")}),imagesDark.forEach(e=>{e.classList.toggle("hidden")}),localStorage.getItem("color-theme")?localStorage.getItem("color-theme")==="light"?(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark")):(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):document.documentElement.classList.contains("dark")?(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark"))})</script><footer class="z-20 p-4 md:p-6 mt-3 w-full border-t border-gray-200 shadow flex items-center justify-center dark:border-gray-600 bg-white dark:bg-zinc-800"><span class="dark:text-gray-400 text-center">© 2013—2023 <span class=whitespace-nowrap>Andrey Akinshin</span></span><ul class="flex flex-wrap items-center px-4 mb-1"><li><a href=https://github.com/AndreyAkinshin><svg class="fai fai-link w-5 h-5"><title>GitHub</title><use xlink:href="/img/fa/all.svg#github"/></svg></a></li><li><a href=https://twitter.com/andrey_akinshin><svg class="fai fai-link w-5 h-5"><title>Twitter</title><use xlink:href="/img/fa/all.svg#twitter"/></svg></a></li><li><a href=https://aakinshin.net/posts/index.xml><svg class="fai fai-link w-5 h-5"><title>RSS</title><use xlink:href="/img/fa/all.svg#rss"/></svg></a></li><li><a href=https://github.com/sponsors/AndreyAkinshin><svg class="fai fai-link w-5 h-5"><title>Support this blog</title><use xlink:href="/img/fa/all.svg#heart"/></svg></a></li></ul><div class=main-content><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></div></footer><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script></body></html>