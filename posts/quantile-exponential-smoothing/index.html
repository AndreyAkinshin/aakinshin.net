<!doctype html><html lang=en class=h-100><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.103.0-DEV"><meta name=author content="Andrey Akinshin"><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content="Mathematics,Statistics,Research,Quantile,Harrell-Davis quantile estimator,Exponential smoothing,Moving Quantile"><title>Quantile exponential smoothing | Andrey Akinshin</title><meta name=description content="One of the popular problems in time series analysis is estimating the moving &amp;ldquo;average&amp;rdquo; value. Let&amp;rsquo;s define the &amp;ldquo;average&amp;rdquo; as a..."><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><link href=https://aakinshin.net/sass/bootstrap-light.min.css theme=light rel=stylesheet type=text/css media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link href=https://aakinshin.net/sass/bootstrap-dark.min.css theme=dark rel=stylesheet type=text/css media="(prefers-color-scheme: dark)"><script src=https://aakinshin.net/js/theme-before.min.d7f6578e23ad3f0c33c589f9bcb34f995b45121f1f3ce888869c86b26826c845.js></script>
<script type=module src=https://aakinshin.net/js/dark-mode-toggle.min.9e68d431432744c07a43381a8a833ffe0921cc0e006d84ad97f0b0d43c5cd82d.mjs></script>
<link href=https://aakinshin.net/css/fontawesome-all.min.178e95bba6ea2e9a90838cd646658f4bf6667a6ceaa057cb587bf7e6eb8412d3.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/about.min.60773ab7266ecc6e9625306f57c0a82a219b011dc3ea2d83763d1ecdf11c86d2.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/blog.min.7e186db80d8c431d196b3e0718afb0636b82a269a8c92521c11a55267a24fc27.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZVB6MXSX32"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-ZVB6MXSX32")</script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-41419012-5"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","UA-41419012-5")</script><script type=text/javascript>(function(e,t,n,s,o,i,a){e[o]=e[o]||function(){(e[o].a=e[o].a||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym"),ym(28700916,"init",{clickmap:!0,trackLinks:!0,accurateTrackBounce:!0})</script><noscript><div><img src=https://mc.yandex.ru/watch/28700916 style=position:absolute;left:-9999px alt></div></noscript><script src=/js/jquery-3.3.1.slim.min.js></script></head><body class="d-flex flex-column min-vh-100"><div class=bg-primary><div class="container bg-primary"><nav class="navbar navbar-expand-sm navbar-dark bg-primary"><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link id=nav-link-blog href=https://aakinshin.net/><i class="fas fa-home" title=Home style=color:#fff></i></a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-expanded=false>Blog</a><ul class="dropdown-menu bg-primary"><li><a class=dropdown-item href=https://aakinshin.net/posts/>All Posts</a></li><li><a class=dropdown-item href=https://aakinshin.net/tags/statistics/>Posts about Statistics</a></li><li></li><a class=dropdown-item href=https://aakinshin.net/tags/>All Tags</a></li></ul></li><li class=nav-item><a class=nav-link id=nav-link-about href=https://aakinshin.net/about/>About</a></li></ul><ul class="navbar-nav ms-auto"><li class=nav-item><dark-mode-toggle permanent=true></dark-mode-toggle></li></ul></nav></div></div><div class=container><main id=main><div class=blog-main><div class="blog-post table-sm"><h1 class=blog-post-title id=post-title>Quantile exponential smoothing</h1><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-05-04>May 4, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>
&nbsp;
<a href=https://aakinshin.net/tags/mathematics/ class="badge badge-info">Mathematics</a>
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research/ class="badge badge-info">Research</a>
<a href=https://aakinshin.net/tags/quantile/ class="badge badge-info">Quantile</a>
<a href=https://aakinshin.net/tags/harrell-davis-quantile-estimator/ class="badge badge-info">Harrell-Davis quantile estimator</a>
<a href=https://aakinshin.net/tags/exponential-smoothing/ class="badge badge-info">Exponential smoothing</a>
<a href=https://aakinshin.net/tags/moving-quantile/ class="badge badge-info">Moving Quantile</a></span><br><br><p>One of the popular problems in time series analysis is estimating the moving &ldquo;average&rdquo; value.
Let&rsquo;s define the &ldquo;average&rdquo; as a central tendency metric like the mean or the median.
When we talk about the moving value, we assume that we are interested in
the average value &ldquo;at the end&rdquo; of the time series
instead of the average of all available observations.</p><p>One of the most straightforward approaches to estimate the moving average is the <em>simple moving mean</em>.
Unfortunately, this approach is not robust: outliers can instantly spoil the evaluated mean value.
As an alternative, we can consider <em>simple moving median</em>.
I already discussed a few of such methods:
<a href=https://aakinshin.net/posts/mp2-quantile-estimator/>the MPÂ² quantile estimator</a> and
<a href=https://aakinshin.net/posts/partitioning-heaps-quantile-estimator2/>a moving quantile estimator based on partitioning heaps</a>
(a modification of the Hardle-Steiger method).
When we talk about <em>simple moving averages</em>, we typically assume
that we estimate the average value over the last <span class="math inline">\(k\)</span> observations (<span class="math inline">\(k\)</span> is the <em>window size</em>).
This approach is also known as <em>unweighted moving averages</em> because
all target observations have the same weight.</p><p>As an alternative to the simple moving average, we can also consider the <em>weighted moving average</em>.
In this case, we assign a weight for each observation and aggregate the whole time series according to these weights.
A famous example of such a weight function is <em>exponential smoothing</em>.
And the simplest form of exponential smoothing is the <em>exponentially weighted moving mean</em>.
This approach estimates the weighted moving mean using exponentially decreasing weights.
Switching from the simple moving mean to the exponentially weighted moving mean provides some benefits
in terms of smoothness and estimation efficiency.</p><p>Although exponential smoothing has advantages over the simple moving mean,
it still estimates the mean value which is not robust.
We can improve the robustness of this approach if we reuse the same idea for weighted moving quantiles.
It&rsquo;s possible because the quantiles also can be estimated for weighted samples.
In one of my previous posts, I <a href=https://aakinshin.net/posts/weighted-quantiles/>showed</a> how to adapt
the Hyndman-Fan Type 7 and Harrell-Davis quantile estimators to the weighted samples.
In this post, I&rsquo;m going to show how we can use this technique to estimate
the weighted moving quantiles using exponentially decreasing weights.</p><h3 id=mean-exponential-smoothing>Mean exponential smoothing</h3><p>First of all, let&rsquo;s recall the idea of the mean exponential smoothing.
Let&rsquo;s say we have a series <span class="math inline">\(\{ x_1, x_2, \ldots \}\)</span>.
The exponentially weighted moving mean can be defined as follows:</p><p><span class="math display">\[\left\{
\begin{array}{l}
s_1 = x_1,\\
s_i = \alpha x_i + (1 - \alpha)s_{i-1} \quad \textrm{for}\;\; i > 1
\end{array}
\right.
\]</span></p><p>where <span class="math inline">\(\alpha\)</span> is the <em>smoothing factor</em> (<span class="math inline">\(0 < \alpha < 1\)</span>).
This recursive form allows calculation of the exponentially weighted moving mean using <span class="math inline">\(O(1)\)</span> complexity.
However, this can be rewritten without recursion as a weighted sum of all observations <span class="math inline">\(x_i\)</span>:</p><p><span class="math display">\[s_n = \sum_{i=1}^n w_i x_i
\]</span></p><p>where</p><p><span class="math display">\[\left\{
\begin{array}{l}
w_1 = (1 - \alpha)^{(n-1)},\\
w_i = \alpha (1 - \alpha)^{n-i} \quad \textrm{for}\;\; i > 1
\end{array}
\right.
\]</span></p><p>Now let&rsquo;s try to test this approach.
One of my favorite data sets for testing moving average estimators is
a noisy, monotonically increasing sine wave pattern with high outliers.
Here is how it looks like:</p><div class=row><div class=mx-auto><a href=/posts/quantile-exponential-smoothing/img/raw-light.png target=_blank class=imgldlink alt=raw><picture><source theme=dark srcset=/posts/quantile-exponential-smoothing/img/raw-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/quantile-exponential-smoothing/img/raw-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/quantile-exponential-smoothing/img/raw-light.png></picture></a></div></div><br><p>Now let&rsquo;s calculate the exponentially weighted moving mean using <span class="math inline">\(\alpha = 0.9\)</span>:</p><div class=row><div class=mx-auto><a href=/posts/quantile-exponential-smoothing/img/mean90-light.png target=_blank class=imgldlink alt=mean90><picture><source theme=dark srcset=/posts/quantile-exponential-smoothing/img/mean90-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/quantile-exponential-smoothing/img/mean90-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/quantile-exponential-smoothing/img/mean90-light.png></picture></a></div></div><br><p>As we can see, exponential smoothing doesn&rsquo;t help us to get a smooth line.
The values of the moving mean are heavily affected by outliers.
Let&rsquo;s try to reduce the value of <span class="math inline">\(\alpha\)</span> to <span class="math inline">\(0.5\)</span>:</p><div class=row><div class=mx-auto><a href=/posts/quantile-exponential-smoothing/img/mean50-light.png target=_blank class=imgldlink alt=mean50><picture><source theme=dark srcset=/posts/quantile-exponential-smoothing/img/mean50-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/quantile-exponential-smoothing/img/mean50-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/quantile-exponential-smoothing/img/mean50-light.png></picture></a></div></div><br><p>It looks a little bit better, but we still have too many &ldquo;poor&rdquo; values.
Let&rsquo;s try to reduce the value of <span class="math inline">\(\alpha\)</span> to <span class="math inline">\(0.1\)</span>:</p><div class=row><div class=mx-auto><a href=/posts/quantile-exponential-smoothing/img/mean10-light.png target=_blank class=imgldlink alt=mean10><picture><source theme=dark srcset=/posts/quantile-exponential-smoothing/img/mean10-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/quantile-exponential-smoothing/img/mean10-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/quantile-exponential-smoothing/img/mean10-light.png></picture></a></div></div><br><p>Now it looks much better, but the line is still not so smooth.
It&rsquo;s not a problem of exponential smoothing, it&rsquo;s a problem of the mean as a measure of central tendency.
When the underlying distribution has a heavy tail (and the corresponding samples have extreme outliers),
the mean is not a good way to estimate the &ldquo;average.&rdquo;
Let&rsquo;s consider the density plot of the Pareto distribution (<span class="math inline">\(x_m = 1, \alpha = 1.05\)</span>):</p><div class=row><div class=mx-auto><a href=/posts/quantile-exponential-smoothing/img/pareto-mean-light.png target=_blank class=imgldlink alt=pareto-mean><picture><source theme=dark srcset=/posts/quantile-exponential-smoothing/img/pareto-mean-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/quantile-exponential-smoothing/img/pareto-mean-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/quantile-exponential-smoothing/img/pareto-mean-light.png></picture></a></div></div><br><p>For this distribution, the mean value is about the <span class="math inline">\(96^\textrm{th}\)</span> percentile.
This value is pretty far from the most significant part of the distribution.
In such cases, the median is a more stable and more acceptable choice of the &ldquo;average&rdquo; metric.</p><h3 id=quantile-exponential-smoothing>Quantile exponential smoothing</h3><p>To estimate distribution quantiles, we will use the Harrell-Davis quantile estimator
because it&rsquo;s much <a href=https://aakinshin.net/posts/hdqe-efficiency/>more efficient</a> than the traditional quantile estimators.
If we want to get a better robustness level, we can also consider
the <a href=https://aakinshin.net/posts/winsorized-hdqe/>winsorized</a> and <a href=https://aakinshin.net/posts/trimmed-hdqe/>trimmed</a> modifications
of the Harrell-Davis quantile estimator
(the corresponding efficiency overview can be found <a href=https://aakinshin.net/posts/wthdqe-efficiency/>here</a>).</p><p>The easiest way to assign exponential weights to our observations is exponential decay.
If we want to assign weights <span class="math inline">\(w\)</span> for observations <span class="math inline">\(\{ x_1, \ldots, x_n \}\)</span>,
we can use the following equation:</p><p><span class="math display">\[w_t = e^{-\lambda (n-t)}
\]</span></p><p>where <span class="math inline">\(\lambda\)</span> is the decay constant.
In order to set the <span class="math inline">\(\lambda\)</span> value, we can express it via the half-life value <span class="math inline">\(t_{1/2}\)</span>:</p><p><span class="math display">\[\lambda = \frac{\ln(2)}{t_{1/2}}.
\]</span></p><p>The half-life gives us a nice property of the weight function: <span class="math inline">\(w_{i-t_{1/2}} = 0.5 w_i\)</span>.
Thus,</p><p><span class="math display">\[w_n = 1, \quad
w_{n-t_{1/2}} = 0.5, \quad
w_{n-2t_{1/2}} = 0.25, \quad
w_{n-3t_{1/2}} = 0.125, \quad
\ldots
\]</span></p><p>Once we defined the weight function, the Harrell-Davis quantile estimation <span class="math inline">\(q^*_p\)</span> of the <span class="math inline">\(p^\textrm{th}\)</span> quantile
can be expressed as follows (the complete overview of this method can be found <a href=https://aakinshin.net/posts/weighted-quantiles/>here</a>):</p><p><span class="math display">\[q^*_p = \sum_{i=1}^{n} W^*_{i} \cdot x_i,\quad
W^*_{i} = I_{r^*_i}(a^*, b^*) - I_{l^*_i}(a^*, b^*),
\]</span></p><p><span class="math display">\[\left\{
\begin{array}{rcc}
l^*_i & = & \dfrac{s_{i-1}(w)}{s_n(w)},\\
r^*_i & = & \dfrac{s_i(w)}{s_n(w)},
\end{array}
\right.
\]</span></p><p><span class="math display">\[s_i(w) = \sum_{j=1}^i w_j,
\]</span></p><p><span class="math display">\[\left\{
\begin{array}{rccl}
a^* = & p     & \cdot & (n^* + 1),\\
b^* = & (1-p) & \cdot & (n^* + 1),
\end{array}
\right.
\]</span></p><p><span class="math display">\[n^* = \frac{\Big( \sum_{i=1}^n w_i \Big)^2}{\sum_{i=1}^n w_i^2 }
\]</span></p><p>where <span class="math inline">\(I_t(a, b)\)</span> is the <a href=https://en.wikipedia.org/wiki/Beta_function#Incomplete_beta_function>regularized incomplete beta function</a>.</p><p>The corresponding confidence interval can also be estimated using the
<a href=https://aakinshin.net/posts/weighted-quantiles-ci/>modification of the Maritz-Jarrett method for weighted samples</a>.</p><p>Now let&rsquo;s try to apply the above equation to our data set using <span class="math inline">\(\textrm{half-life} = 10\)</span>:</p><div class=row><div class=mx-auto><a href=/posts/quantile-exponential-smoothing/img/median10-light.png target=_blank class=imgldlink alt=median10><picture><source theme=dark srcset=/posts/quantile-exponential-smoothing/img/median10-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/quantile-exponential-smoothing/img/median10-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/quantile-exponential-smoothing/img/median10-light.png></picture></a></div></div><br><p>Increasing the half-life value gives more smooth but less adaptive line:</p><div class=row><div class=mx-auto><a href=/posts/quantile-exponential-smoothing/img/median200-light.png target=_blank class=imgldlink alt=median200><picture><source theme=dark srcset=/posts/quantile-exponential-smoothing/img/median200-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/quantile-exponential-smoothing/img/median200-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/quantile-exponential-smoothing/img/median200-light.png></picture></a></div></div><br><h3 id=incremental-implementation-of-quantile-exponential-smoothing>Incremental implementation of quantile exponential smoothing</h3><p>The most significant advantage of the exponentially weighted moving mean is its computational efficiency:
it can be recalculated using <span class="math inline">\(O(1)\)</span> complexity based on the previous value.
In the case of quantile exponential smoothing, we can&rsquo;t do it using <span class="math inline">\(O(1)\)</span> complexity because we need
a sorted array of values to estimate the quantile value.
To improve the algorithm performance, we can use a data structure that allows maintaining a sorted version of <span class="math inline">\(\{ x_i \}\)</span>
with <span class="math inline">\(O(\log n)\)</span> update operation (e.g., a balanced binary tree).
However, the Harrell-Davis quantile estimator still has <span class="math inline">\(O(n)\)</span> complexity.
This also can be improved using
the <a href=https://aakinshin.net/posts/winsorized-hdqe/>winsorized</a> and <a href=https://aakinshin.net/posts/trimmed-hdqe/>trimmed</a> modifications
of the Harrell-Davis quantile estimator</p><h3 id=conclusion>Conclusion</h3><p>In this post, we discussed quantile exponential smoothing using
the exponentially weighted moving Harrell-Davis quantile estimations.
This approach allows getting the moving quantile values that are more stable and smooth than
the classic exponentially weighted mean values.
The only disadvantage of this method is its computational complexity which is <span class="math inline">\(O(n)\)</span> for each estimated value.</p><br><br><div class=row><div class="justify-content-center share-block"><div class=share-title>Share:</div><div class=share-button><a href="https://www.reddit.com/submit?url=https%3a%2f%2faakinshin.net%2fposts%2fquantile-exponential-smoothing%2f&title=Quantile%20exponential%20smoothing" target=_blank title="Share on Reddit"><i class="fab fa-reddit fa-2x"></i></a></div><div class=share-button><a href="https://twitter.com/intent/tweet?text=Quantile%20exponential%20smoothing&url=https%3a%2f%2faakinshin.net%2fposts%2fquantile-exponential-smoothing%2f&via=andrey_akinshin&related=andrey_akinshin" rel=nofollow target=_blank title="Share on Twitter"><i class="fab fa-twitter fa-2x"></i></a></div><div class=share-button><a href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2faakinshin.net%2fposts%2fquantile-exponential-smoothing%2f" target=_blank title="Share on HackerNews"><i class="fab fa-hacker-news fa-2x"></i></a></div><div class=share-button><a href="https://getpocket.com/save?url=https%3a%2f%2faakinshin.net%2fposts%2fquantile-exponential-smoothing%2f&title=Quantile%20exponential%20smoothing" target=_blank title="Add to Pocket"><i class="fab fa-get-pocket fa-2x"></i></a></div></div></div></div><hr></div></div></main></div><footer class="blog-footer mt-auto"><div class=container><p>&copy; 2013&mdash;2022 Andrey Akinshin
|
<a href=https://github.com/AndreyAkinshin><i class="fab fa-github" title=GitHub></i></a>
<a href=https://twitter.com/andrey_akinshin><i class="fab fa-twitter" title=Twitter></i></a>
<a href=https://aakinshin.net/posts/index.xml><i class="fas fa-rss" title=RSS></i></a>
|
<a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></p></div></footer><script src=https://aakinshin.net/js/theme-after.min.c26550621ac13c2221d7f6f5e6fe862345d3919723c50d730893e3e4856ecf35.js></script>
<script src=/js/bootstrap.bundle.min.js></script>
<script src=/js/anchor.min.js></script>
<script src=https://aakinshin.net/js/custom.min.f6e5d13fe39f305056cc743ee4cb8d117c1aba26176e58c82c79a480d02fe4b7.js></script>
<script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></body></html>