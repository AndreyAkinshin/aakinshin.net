<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.123.8"><meta name=author content='Andrey Akinshin'><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content='Mathematics,Statistics,Research,Quantile,Harrell-Davis quantile estimator,Exponential smoothing,Moving quantile'><title>Quantile exponential smoothing | Andrey Akinshin</title>
<meta name=description content="One of the popular problems in time series analysis is estimating the moving &amp;ldquo;average&amp;rdquo; value. Let&amp;rsquo;s define the &amp;ldquo;average&amp;rdquo; as a central tendency metric like the mean or the median. When we talk about the moving value, we assume t..."><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><script>localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?document.documentElement.classList.add("dark"):document.documentElement.classList.remove("dark")</script><link href=https://aakinshin.net/css/main.min.beef8b4fb043af14c2883e35de1b55e76fb412aa04a92889080ed30141cda7b6.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"></head><body class="flex flex-col min-h-screen"><nav><div class="container flex flex-wrap items-center justify-between mx-auto max-w-6xl h-12 px-2 xs:px-6"><div class="flex items-center justify-start justify-self-start"><div class="flex nav-item h-12 w-12 items-center justify-center"><a class=text-white href=https://aakinshin.net/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#house-chimney"/></svg></a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/feed/>Feed</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/library/>Library</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/research-projects/>Research</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/about/>About</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/search/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#magnifying-glass"/></svg></a></div></div><button id=theme-toggle type=button title="Alt+Click to match OS color theme" class="nav-item p-3 content-center justify-self-end"><svg id="theme-toggle-dark-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001.0 1010.586 10.586z"/></svg><svg id="theme-toggle-light-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M10 2a1 1 0 011 1v1A1 1 0 119 4V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707A1 1 0 1113.536 5.05l.707-.707a1 1 0 011.414.0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707A1 1 0 004.343 5.757l.707.707zm1.414 8.486-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z" fill-rule="evenodd" clip-rule="evenodd"/></svg></button></div></nav><div class="main container mx-auto max-w-6xl px-6 flex-grow"><div class=main-post><h1 class=blog-post-title id=post-title>Quantile exponential smoothing</h1><div class="flex flex-wrap justify-start items-center"><div class="flex flex-wrap gap-y-1"><span class=label><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#calendar"/></svg>
<time datetime=2021-05-04>May 4, 2021</time>
</span><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#statistics"/></svg>
Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#research"/></svg>
Research
</a><a class=label-link href=https://aakinshin.net/tags/quantile/>Quantile
</a><a class=label-link href=https://aakinshin.net/tags/harrell-davis-quantile-estimator/>Harrell-Davis quantile estimator
</a><a class=label-link href=https://aakinshin.net/tags/exponential-smoothing/>Exponential smoothing
</a><a class=label-link href=https://aakinshin.net/tags/moving-quantile/>Moving quantile</a></div></div><br><div class=main-content><p>One of the popular problems in time series analysis is estimating the moving &ldquo;average&rdquo; value.
Let&rsquo;s define the &ldquo;average&rdquo; as a central tendency metric like the mean or the median.
When we talk about the moving value, we assume that we are interested in
the average value &ldquo;at the end&rdquo; of the time series
instead of the average of all available observations.</p><p>One of the most straightforward approaches to estimate the moving average is the <em>simple moving mean</em>.
Unfortunately, this approach is not robust: outliers can instantly spoil the evaluated mean value.
As an alternative, we can consider <em>simple moving median</em>.
I already discussed a few of such methods:
<a href=https://aakinshin.net/posts/mp2-quantile-estimator/>the MP² quantile estimator</a> and
<a href=https://aakinshin.net/posts/partitioning-heaps-quantile-estimator2/>a moving quantile estimator based on partitioning heaps</a>
(a modification of the Hardle-Steiger method).
When we talk about <em>simple moving averages</em>, we typically assume
that we estimate the average value over the last $k$ observations ($k$ is the <em>window size</em>).
This approach is also known as <em>unweighted moving averages</em> because
all target observations have the same weight.</p><p>As an alternative to the simple moving average, we can also consider the <em>weighted moving average</em>.
In this case, we assign a weight for each observation and aggregate the whole time series according to these weights.
A famous example of such a weight function is <em>exponential smoothing</em>.
And the simplest form of exponential smoothing is the <em>exponentially weighted moving mean</em>.
This approach estimates the weighted moving mean using exponentially decreasing weights.
Switching from the simple moving mean to the exponentially weighted moving mean provides some benefits
in terms of smoothness and estimation efficiency.</p><p>Although exponential smoothing has advantages over the simple moving mean,
it still estimates the mean value which is not robust.
We can improve the robustness of this approach if we reuse the same idea for weighted moving quantiles.
It&rsquo;s possible because the quantiles also can be estimated for weighted samples.
In one of my previous posts, I <a href=https://aakinshin.net/posts/weighted-quantiles/>showed</a> how to adapt
the Hyndman-Fan Type 7 and Harrell-Davis quantile estimators to the weighted samples.
In this post, I&rsquo;m going to show how we can use this technique to estimate
the weighted moving quantiles using exponentially decreasing weights.</p><h3 id=mean-exponential-smoothing>Mean exponential smoothing</h3><p>First of all, let&rsquo;s recall the idea of the mean exponential smoothing.
Let&rsquo;s say we have a series $\{ x_1, x_2, \ldots \}$.
The exponentially weighted moving mean can be defined as follows:</p>$$
\left\{
\begin{array}{l}
s_1 = x_1,\\
s_i = \alpha x_i + (1 - \alpha)s_{i-1} \quad \textrm{for}\;\; i > 1
\end{array}
\right.
$$<p>where $\alpha$ is the <em>smoothing factor</em> ($0 < \alpha < 1$).
This recursive form allows calculation of the exponentially weighted moving mean using $O(1)$ complexity.
However, this can be rewritten without recursion as a weighted sum of all observations $x_i$:</p>$$
s_n = \sum_{i=1}^n w_i x_i
$$<p>where</p>$$
\left\{
\begin{array}{l}
w_1 = (1 - \alpha)^{(n-1)},\\
w_i = \alpha (1 - \alpha)^{n-i} \quad \textrm{for}\;\; i > 1
\end{array}
\right.
$$<p>Now let&rsquo;s try to test this approach.
One of my favorite data sets for testing moving average estimators is
a noisy, monotonically increasing sine wave pattern with high outliers.
Here is how it looks like:</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/quantile-exponential-smoothing/img/raw-light.png target=_blank alt=raw><img src=/posts/quantile-exponential-smoothing/img/raw-light.png width=800>
</a><a class="img-dark hidden" href=/posts/quantile-exponential-smoothing/img/raw-dark.png target=_blank alt=raw><img src=/posts/quantile-exponential-smoothing/img/raw-dark.png width=800></a></div><p>Now let&rsquo;s calculate the exponentially weighted moving mean using $\alpha = 0.9$:</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/quantile-exponential-smoothing/img/mean90-light.png target=_blank alt=mean90><img src=/posts/quantile-exponential-smoothing/img/mean90-light.png width=800>
</a><a class="img-dark hidden" href=/posts/quantile-exponential-smoothing/img/mean90-dark.png target=_blank alt=mean90><img src=/posts/quantile-exponential-smoothing/img/mean90-dark.png width=800></a></div><p>As we can see, exponential smoothing doesn&rsquo;t help us to get a smooth line.
The values of the moving mean are heavily affected by outliers.
Let&rsquo;s try to reduce the value of $\alpha$ to $0.5$:</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/quantile-exponential-smoothing/img/mean50-light.png target=_blank alt=mean50><img src=/posts/quantile-exponential-smoothing/img/mean50-light.png width=800>
</a><a class="img-dark hidden" href=/posts/quantile-exponential-smoothing/img/mean50-dark.png target=_blank alt=mean50><img src=/posts/quantile-exponential-smoothing/img/mean50-dark.png width=800></a></div><p>It looks a little bit better, but we still have too many &ldquo;poor&rdquo; values.
Let&rsquo;s try to reduce the value of $\alpha$ to $0.1$:</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/quantile-exponential-smoothing/img/mean10-light.png target=_blank alt=mean10><img src=/posts/quantile-exponential-smoothing/img/mean10-light.png width=800>
</a><a class="img-dark hidden" href=/posts/quantile-exponential-smoothing/img/mean10-dark.png target=_blank alt=mean10><img src=/posts/quantile-exponential-smoothing/img/mean10-dark.png width=800></a></div><p>Now it looks much better, but the line is still not so smooth.
It&rsquo;s not a problem of exponential smoothing, it&rsquo;s a problem of the mean as a measure of central tendency.
When the underlying distribution has a heavy tail (and the corresponding samples have extreme outliers),
the mean is not a good way to estimate the &ldquo;average.&rdquo;
Let&rsquo;s consider the density plot of the Pareto distribution ($x_m = 1, \alpha = 1.05$):</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/quantile-exponential-smoothing/img/pareto-mean-light.png target=_blank alt=pareto-mean><img src=/posts/quantile-exponential-smoothing/img/pareto-mean-light.png width=800>
</a><a class="img-dark hidden" href=/posts/quantile-exponential-smoothing/img/pareto-mean-dark.png target=_blank alt=pareto-mean><img src=/posts/quantile-exponential-smoothing/img/pareto-mean-dark.png width=800></a></div><p>For this distribution, the mean value is about the $96^\textrm{th}$ percentile.
This value is pretty far from the most significant part of the distribution.
In such cases, the median is a more stable and more acceptable choice of the &ldquo;average&rdquo; metric.</p><h3 id=quantile-exponential-smoothing>Quantile exponential smoothing</h3><p>To estimate distribution quantiles, we will use the Harrell-Davis quantile estimator
because it&rsquo;s much <a href=https://aakinshin.net/posts/hdqe-efficiency/>more efficient</a> than the traditional quantile estimators.
If we want to get a better robustness level, we can also consider
the <a href=https://aakinshin.net/posts/winsorized-hdqe/>winsorized</a> and <a href=https://aakinshin.net/posts/trimmed-hdqe/>trimmed</a> modifications
of the Harrell-Davis quantile estimator
(the corresponding efficiency overview can be found <a href=https://aakinshin.net/posts/wthdqe-efficiency/>here</a>).</p><p>The easiest way to assign exponential weights to our observations is exponential decay.
If we want to assign weights $w$ for observations $\{ x_1, \ldots, x_n \}$,
we can use the following equation:</p>$$
w_t = e^{-\lambda (n-t)}
$$<p>where $\lambda$ is the decay constant.
In order to set the $\lambda$ value, we can express it via the half-life value $t_{1/2}$:</p>$$
\lambda = \frac{\ln(2)}{t_{1/2}}.
$$<p>The half-life gives us a nice property of the weight function: $w_{i-t_{1/2}} = 0.5 w_i$.
Thus,</p>$$
w_n = 1, \quad
w_{n-t_{1/2}} = 0.5, \quad
w_{n-2t_{1/2}} = 0.25, \quad
w_{n-3t_{1/2}} = 0.125, \quad
\ldots
$$<p>Once we defined the weight function, the Harrell-Davis quantile estimation $q^*_p$ of the $p^\textrm{th}$ quantile
can be expressed as follows (the complete overview of this method can be found <a href=https://aakinshin.net/posts/weighted-quantiles/>here</a>):</p>$$
q^*_p = \sum_{i=1}^{n} W^*_{i} \cdot x_i,\quad
W^*_{i} = I_{r^*_i}(a^*, b^*) - I_{l^*_i}(a^*, b^*),
$$
$$
\left\{
\begin{array}{rcc}
l^*_i & = & \dfrac{s_{i-1}(w)}{s_n(w)},\\
r^*_i & = & \dfrac{s_i(w)}{s_n(w)},
\end{array}
\right.
$$
$$
s_i(w) = \sum_{j=1}^i w_j,
$$
$$
\left\{
\begin{array}{rccl}
a^* = & p     & \cdot & (n^* + 1),\\
b^* = & (1-p) & \cdot & (n^* + 1),
\end{array}
\right.
$$
$$
n^* = \frac{\Big( \sum_{i=1}^n w_i \Big)^2}{\sum_{i=1}^n w_i^2 }
$$<p>where $I_t(a, b)$ is the <a href=https://en.wikipedia.org/wiki/Beta_function#Incomplete_beta_function>regularized incomplete beta function</a>.</p><p>The corresponding confidence interval can also be estimated using the
<a href=https://aakinshin.net/posts/weighted-quantiles-ci/>modification of the Maritz-Jarrett method for weighted samples</a>.</p><p>Now let&rsquo;s try to apply the above equation to our data set using $\textrm{half-life} = 10$:</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/quantile-exponential-smoothing/img/median10-light.png target=_blank alt=median10><img src=/posts/quantile-exponential-smoothing/img/median10-light.png width=800>
</a><a class="img-dark hidden" href=/posts/quantile-exponential-smoothing/img/median10-dark.png target=_blank alt=median10><img src=/posts/quantile-exponential-smoothing/img/median10-dark.png width=800></a></div><p>Increasing the half-life value gives more smooth but less adaptive line:</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/quantile-exponential-smoothing/img/median200-light.png target=_blank alt=median200><img src=/posts/quantile-exponential-smoothing/img/median200-light.png width=800>
</a><a class="img-dark hidden" href=/posts/quantile-exponential-smoothing/img/median200-dark.png target=_blank alt=median200><img src=/posts/quantile-exponential-smoothing/img/median200-dark.png width=800></a></div><h3 id=incremental-implementation-of-quantile-exponential-smoothing>Incremental implementation of quantile exponential smoothing</h3><p>The most significant advantage of the exponentially weighted moving mean is its computational efficiency:
it can be recalculated using $O(1)$ complexity based on the previous value.
In the case of quantile exponential smoothing, we can&rsquo;t do it using $O(1)$ complexity because we need
a sorted array of values to estimate the quantile value.
To improve the algorithm performance, we can use a data structure that allows maintaining a sorted version of $\{ x_i \}$
with $O(\log n)$ update operation (e.g., a balanced binary tree).
However, the Harrell-Davis quantile estimator still has $O(n)$ complexity.
This also can be improved using
the <a href=https://aakinshin.net/posts/winsorized-hdqe/>winsorized</a> and <a href=https://aakinshin.net/posts/trimmed-hdqe/>trimmed</a> modifications
of the Harrell-Davis quantile estimator</p><h3 id=conclusion>Conclusion</h3><p>In this post, we discussed quantile exponential smoothing using
the exponentially weighted moving Harrell-Davis quantile estimations.
This approach allows getting the moving quantile values that are more stable and smooth than
the classic exponentially weighted mean values.
The only disadvantage of this method is its computational complexity which is $O(n)$ for each estimated value.</p></div><hr><h3 id=references>References (7)</h3><ol><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/hdqe-efficiency/>Efficiency of the Harrell-Davis quantile estimator
</a>(2021-03-23)
<span class=label title=References:2><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>2</span>
<span class=label title=Backlinks:4><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>4</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg>
</a><a href=https://aakinshin.net/tags/research/><svg class="rating-icon"><title>Research</title><use xlink:href="/img/fa/all.svg#research"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/partitioning-heaps-quantile-estimator2/>Better moving quantile estimations using the partitioning heaps
</a>(2021-01-19)
<span class=label title=References:2><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>2</span>
<span class=label title=Backlinks:1><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>1</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg>
</a><a href=https://aakinshin.net/tags/research/><svg class="rating-icon"><title>Research</title><use xlink:href="/img/fa/all.svg#research"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/trimmed-hdqe/>Trimmed modification of the Harrell-Davis quantile estimator
</a>(2021-03-30)
<span class=label title=References:3><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>3</span>
<span class=label title=Backlinks:11><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>11</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg>
</a><a href=https://aakinshin.net/tags/research/><svg class="rating-icon"><title>Research</title><use xlink:href="/img/fa/all.svg#research"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/weighted-quantiles/>Weighted quantile estimators
</a>(2020-09-29)
<span class=label title=References:6><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>6</span>
<span class=label title=Backlinks:8><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>8</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg>
</a><a href=https://aakinshin.net/tags/research/><svg class="rating-icon"><title>Research</title><use xlink:href="/img/fa/all.svg#research"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/weighted-quantiles-ci/>Quantile confidence intervals for weighted samples
</a>(2020-12-08)
<span class=label title=References:3><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>3</span>
<span class=label title=Backlinks:5><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>5</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg>
</a><a href=https://aakinshin.net/tags/research/><svg class="rating-icon"><title>Research</title><use xlink:href="/img/fa/all.svg#research"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/winsorized-hdqe/>Winsorized modification of the Harrell-Davis quantile estimator
</a>(2021-03-02)
<span class=label title=References:1><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>1</span>
<span class=label title=Backlinks:8><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>8</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg>
</a><a href=https://aakinshin.net/tags/research/><svg class="rating-icon"><title>Research</title><use xlink:href="/img/fa/all.svg#research"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/wthdqe-efficiency/>Efficiency of the winsorized and trimmed Harrell-Davis quantile estimators
</a>(2021-04-06)
<span class=label title=References:4><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>4</span>
<span class=label title=Backlinks:6><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>6</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg>
</a><a href=https://aakinshin.net/tags/research/><svg class="rating-icon"><title>Research</title><use xlink:href="/img/fa/all.svg#research"/></svg></a></li></ol><h3 id=backlinks>Backlinks (3)</h3><ol><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/dispersion-exponential-smoothing/>Dispersion exponential smoothing
</a>(2021-05-11)
<span class=label title=References:4><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>4</span>
<span class=label title=Backlinks:3><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>3</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg>
</a><a href=https://aakinshin.net/tags/research/><svg class="rating-icon"><title>Research</title><use xlink:href="/img/fa/all.svg#research"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/kish-ess-weighted-quantiles/>Using Kish's effective sample size with weighted quantiles
</a>(2021-07-06)
<span class=label title=References:6><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>6</span>
<span class=label title=Backlinks:5><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>5</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg>
</a><a href=https://aakinshin.net/tags/research/><svg class="rating-icon"><title>Research</title><use xlink:href="/img/fa/all.svg#research"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/weighted-quantiles/>Weighted quantile estimators
</a>(2020-09-29)
<span class=label title=References:6><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>6</span>
<span class=label title=Backlinks:8><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>8</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg>
</a><a href=https://aakinshin.net/tags/research/><svg class="rating-icon"><title>Research</title><use xlink:href="/img/fa/all.svg#research"/></svg></a></li></ol></div></div><script>var themeToggleDarkIcon=document.getElementById("theme-toggle-dark-icon"),themeToggleBtn,themeToggleLightIcon=document.getElementById("theme-toggle-light-icon");const imagesDark=document.querySelectorAll(".img-dark"),imagesLight=document.querySelectorAll(".img-light");localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?(themeToggleLightIcon.classList.remove("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")})):(themeToggleDarkIcon.classList.remove("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}));function toggleTheme(e){e?(document.documentElement.classList.add("dark"),themeToggleLightIcon.classList.remove("hidden"),themeToggleDarkIcon.classList.add("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")}),imagesLight.forEach(e=>{e.classList.add("hidden")})):(document.documentElement.classList.remove("dark"),themeToggleDarkIcon.classList.remove("hidden"),themeToggleLightIcon.classList.add("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}),imagesDark.forEach(e=>{e.classList.add("hidden")}))}themeToggleBtn=document.getElementById("theme-toggle"),themeToggleBtn.addEventListener("click",function(){themeToggleDarkIcon.classList.toggle("hidden"),themeToggleLightIcon.classList.toggle("hidden"),imagesLight.forEach(e=>{e.classList.toggle("hidden")}),imagesDark.forEach(e=>{e.classList.toggle("hidden")}),event.altKey?(localStorage.removeItem("color-theme"),toggleTheme(window.matchMedia("(prefers-color-scheme: dark)").matches)):localStorage.getItem("color-theme")?localStorage.getItem("color-theme")==="light"?(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark")):(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):document.documentElement.classList.contains("dark")?(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark"))}),window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",e=>{if(localStorage.getItem("color-theme")===null){const t=e.matches?"dark":"light";toggleTheme(t==="dark")}})</script><footer class="z-20 p-4 md:p-6 mt-3 w-full border-t border-gray-200 shadow flex items-center justify-center dark:border-gray-600 bg-white dark:bg-zinc-800"><span class="dark:text-gray-400 text-center">© 2013—2024 <span class=whitespace-nowrap>Andrey Akinshin</span></span><ul class="flex flex-wrap items-center px-4 mb-1"><li><a href=https://github.com/AndreyAkinshin><svg class="fai fai-link w-5 h-5"><title>GitHub</title><use xlink:href="/img/fa/all.svg#github"/></svg></a></li><li><a href=https://twitter.com/andrey_akinshin><svg class="fai fai-link w-5 h-5"><title>Twitter</title><use xlink:href="/img/fa/all.svg#twitter"/></svg></a></li><li><a href=https://aakinshin.net/posts/index.xml><svg class="fai fai-link w-5 h-5"><title>RSS</title><use xlink:href="/img/fa/all.svg#rss"/></svg></a></li></ul><div class=main-content><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></div></footer><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+=" has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script></body></html>