<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.123.8"><meta name=author content='Andrey Akinshin'><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content='Mathematics,Statistics,Performance analysis'><title>Statistical approaches for performance analysis | Andrey Akinshin</title>
<meta name=description content="A brief overview of statistical approaches that can be useful for performance analysis"><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><script>localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?document.documentElement.classList.add("dark"):document.documentElement.classList.remove("dark")</script><link href=https://aakinshin.net/css/main.min.beef8b4fb043af14c2883e35de1b55e76fb412aa04a92889080ed30141cda7b6.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"></head><body class="flex flex-col min-h-screen"><nav><div class="container flex flex-wrap items-center justify-between mx-auto max-w-6xl h-12 px-2 xs:px-6"><div class="flex items-center justify-start justify-self-start"><div class="flex nav-item h-12 w-12 items-center justify-center"><a class=text-white href=https://aakinshin.net/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#house-chimney"/></svg></a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/feed/>Feed</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/library/>Library</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/research-projects/>Research</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/about/>About</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/search/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#magnifying-glass"/></svg></a></div></div><button id=theme-toggle type=button title="Alt+Click to match OS color theme" class="nav-item p-3 content-center justify-self-end"><svg id="theme-toggle-dark-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001.0 1010.586 10.586z"/></svg><svg id="theme-toggle-light-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M10 2a1 1 0 011 1v1A1 1 0 119 4V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707A1 1 0 1113.536 5.05l.707-.707a1 1 0 011.414.0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707A1 1 0 004.343 5.757l.707.707zm1.414 8.486-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z" fill-rule="evenodd" clip-rule="evenodd"/></svg></button></div></nav><div class="main container mx-auto max-w-6xl px-6 flex-grow"><div class=main-post><h1 class=blog-post-title id=post-title>Statistical approaches for performance analysis</h1><div class="flex flex-wrap justify-start items-center"><div class="flex flex-wrap gap-y-1"><span class=label><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#calendar"/></svg>
<time datetime=2020-12-15>December 15, 2020</time>
</span><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#statistics"/></svg>
Statistics
</a><a class=label-link href=https://aakinshin.net/tags/performance-analysis/>Performance analysis</a></div></div><br><div class=main-content><p>Software performance is a complex discipline that requires knowledge in different areas
from benchmarking to the internals of modern runtimes, operating systems, and hardware.
Surprisingly, the most difficult challenges in performance analysis are not about programming,
they are about mathematical statistics!</p><p>Many software developers can drill into performance problems and implement excellent optimizations,
but they are not always know how to correctly verify these optimizations.
This may not look like a problem in the case of a single performance investigation.
However, the situation became worse when developers try to set up an infrastructure that
should automatically find performance problems or prevent degradations from merging.
In order to make such an infrastructure reliable and useful,
it&rsquo;s crucial to achieve an extremely low false-positive rate (otherwise, it&rsquo;s not trustable)
and be able to detect most of the degradations (otherwise, it&rsquo;s not so useful).
It&rsquo;s not easy if you don&rsquo;t know which statistical approaches should be used.
If you try to google it, you may find thousands of papers about statistics,
but only a small portion of them really works in practice.</p><p>In this post, I want to share some approaches that I use for performance analysis in everyday life.
I have been analyzing performance distributions for the last seven years,
and I have found a lot of approaches, metrics, and tricks which nice to have
in your statistical toolbox.
I would not say that all of them are must have to know,
but they can definitely help you to improve the reliability of your statistical checks
in different problems of performance analysis.
Consider the below list as a letter to a younger version of myself with a brief list of topics that are good to learn.</p><h3 id=bad-approaches>Bad approaches</h3><p>The classic statistics aggressively promotes a lot of approaches that don&rsquo;t work well on performance distributions.
I&rsquo;m not sure that I know the best tools for performance analysis,
but I&rsquo;m sure that I know dozens of approaches that shouldn&rsquo;t be used.
Let me briefly highlight the most popular sources of trouble.</p><h4 id=dont-assume-normal-distributions>Don&rsquo;t assume normal distributions</h4><p>The first thing you should remember about performance distributions: they are not <a href=https://en.wikipedia.org/wiki/Normal_distribution>normal</a>.
Of course, some of them could remind the normal distribution, but you can&rsquo;t assume normality in advance.
Performance distributions can be asymmetric and heavy-tailed,
can contain extremely high outliers,
can be multimodal,
can have a strange distribution shape.</p><p>Thus, it&rsquo;s not a good idea to use any approaches that require normality.
Instead, you should look for <em>distribution-free</em> methods that support <a href=https://en.wikipedia.org/wiki/Nonparametric_statistics><em>non-parametric distributions</em></a>.</p><p>References:</p><ul><li><a href=/posts/normality>Normality is a myth</a></li><li><a href=https://doi.org/10.1093/biomet/34.3-4.209>Testing for normality</a> (1947) by R.C. Geary</li><li><a href=https://www.goodreads.com/book/show/12086837-introduction-to-robust-estimation-and-hypothesis-testing>Introduction to Robust Estimation and Hypothesis Testing</a> (4th edition) Rand R. Wilcox</li></ul><h4 id=dont-use-null-hypothesis-significance-testing-with-p-values>Don&rsquo;t use null hypothesis significance testing with p-values</h4><p>The null hypothesis significance testing (NHST) is an awful technique that typically creates more problems than solves.
I had been using it for many years, I had been trying a lot of different tests,
and now I am completely disappointed in this.</p><p>To be honest, if you aware of all the possible pitfalls,
it&rsquo;s possible to conduct a good performance analysis with NHST.
Note that most of the significance tests assume normality,
so if you decide to use NHST, make sure that you use non-parametric tests
(e.g., the <a href=https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test>Mann–Whitney U test</a> or
the <a href=https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test>Kolmogorov–Smirnov test</a>).</p><p>However, there are other approaches that are much more reliable than NHST.
For example, you can look at the <a href=https://en.wikipedia.org/wiki/Bayesian_statistics>Bayesian statistics</a> and the <a href=https://en.wikipedia.org/wiki/Estimation_statistics>Estimation statistics</a> (also known as the <em>new statistics</em>).</p><p>If you use NHST, I highly recommend to read the following books and papers:</p><ul><li><a href=https://www.goodreads.com/book/show/2023435.What_If_There_Were_No_Significance_Tests_>What If There Were No Significance Tests?</a>
(1997) by Lisa L. Harlow, Stanley A. Mulaik, James H. Steiger</li><li>Amrhein, Valentin, Fränzi Korner-Nievergelt, and Tobias Roth. &ldquo;The earth is flat (p> 0.05): significance thresholds and the crisis of unreplicable research.&rdquo; PeerJ 5 (2017): e3544.<br><a href=https://peerj.com/articles/3544/>https://peerj.com/articles/3544/</a></li><li>Wasserstein, Ronald L., Allen L. Schirm, and Nicole A. Lazar. &ldquo;Moving to a world beyond “p&lt; 0.05”.&rdquo; (2019): 1-19.<br><a href=https://www.tandfonline.com/doi/full/10.1080/00031305.2019.1583913>https://www.tandfonline.com/doi/full/10.1080/00031305.2019.1583913</a></li><li>Matthews, Robert AJ. &ldquo;Moving towards the post p&lt; 0.05 era via the analysis of credibility.&rdquo; The American Statistician 73, no. sup1 (2019): 202-212.<br><a href=https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1543136>https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1543136</a></li><li>Andrade, Chittaranjan. &ldquo;The P value and statistical significance: misunderstandings, explanations, challenges, and alternatives.&rdquo; Indian Journal of Psychological Medicine 41, no. 3 (2019): 210-215.
<a href=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6532382/>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6532382/</a></li><li>Winder, W. C. &ldquo;What you always wanted to know about testing but were afraid to ask.&rdquo; American dairy review (1973).<br><a href=https://www.researchgate.net/publication/241372934>https://www.researchgate.net/publication/241372934</a></li><li>Grieve, Andrew P. &ldquo;How to test hypotheses if you must.&rdquo; Pharmaceutical statistics 14, no. 2 (2015): 139-150.<br><a href=http://doi.wiley.com/10.1002/pst.1667>http://doi.wiley.com/10.1002/pst.1667</a></li><li>Krawczyk, Michał. &ldquo;The search for significance: a few peculiarities in the distribution of P values in experimental psychology literature.&rdquo; PloS one 10, no. 6 (2015).<br><a href=https://dx.plos.org/10.1371/journal.pone.0127872>https://dx.plos.org/10.1371/journal.pone.0127872</a></li><li>&ldquo;Still Not Significant&rdquo; by Matthew Hankins<br><a href=https://mchankins.wordpress.com/2013/04/21/still-not-significant-2/>https://mchankins.wordpress.com/2013/04/21/still-not-significant-2/</a></li></ul><p>A few good books about alternative approaches:</p><ul><li><a href=https://www.goodreads.com/book/show/10765705-understanding-the-new-statistics>Understanding the New Statistics: Effect Sizes, Confidence Intervals, and Meta-Analysis</a> (2011) by Geoff Cumming</li><li><a href=https://www.goodreads.com/book/show/9003187-doing-bayesian-data-analysis>Doing Bayesian Data Analysis: A Tutorial Introduction with R</a> (2010) by John K. Kruschke</li><li><a href=https://www.goodreads.com/book/show/12086837-introduction-to-robust-estimation-and-hypothesis-testing>Introduction to Robust Estimation and Hypothesis Testing</a> (2017, 4th edition) Rand R. Wilcox</li></ul><h4 id=dont-use-non-robust-metrics-and-approaches>Don&rsquo;t use non-robust metrics and approaches</h4><p>If your performance metrics can be spoiled by a single outlier value, these metrics are not robust.
If you use <a href=https://en.wikipedia.org/wiki/Robust_statistics>robust statistics</a>,
a lot of nasty problems will be resolved automatically.</p><hr><h3 id=basic-descriptive-analysis>Basic descriptive analysis</h3><p>Now it&rsquo;s time to talk about good approaches for descriptive analysis of your distributions.</p><h4 id=central-tendency-the-median-instead-of-the-mean>Central tendency: the median instead of the mean</h4><p>The <a href=https://en.wikipedia.org/wiki/Arithmetic_mean>arithmetic mean</a> is not robust metric.
It can be spoiled by a single outlier, which makes it unreliable.
Instead of the mean, it&rsquo;s much better to use the <a href=https://en.wikipedia.org/wiki/Median>median</a>, which is much more robust.</p><h4 id=quantile-analysis>Quantile analysis</h4><p>In the case of non-parametric distributions,
you can&rsquo;t describe your distribution by a limited number of parameters
(that&rsquo;s why they are called <em>non-parametric</em>).
It&rsquo;s recommended to use all the <a href=https://en.wikipedia.org/wiki/Quantile>quantile</a> values instead of a single median value.</p><h4 id=the-harrell-davis-quantile-estimator>The Harrell-Davis quantile estimator</h4><p>The default quantile estimators that can be found in many programming languages are not so good.
They are typically based on linear interpolation of two subsequent elements,
and they don&rsquo;t provide a good estimation of the actual quantile values.</p><p>To improve the situation, it&rsquo;s recommended to use the Harrell-Davis quantile estimator.
It&rsquo;s more robust, and it provides better quantile estimations.</p><p>References:</p><ul><li>Harrell, F.E. and Davis, C.E., 1982. A new distribution-free quantile estimator.
<em>Biometrika</em>, 69(3), pp.635-640.<br><a href=https://pdfs.semanticscholar.org/1a48/9bb74293753023c5bb6bff8e41e8fe68060f.pdf>https://pdfs.semanticscholar.org/1a48/9bb74293753023c5bb6bff8e41e8fe68060f.pdf</a></li></ul><h4 id=the-maritz-jarrett-method-for-quantile-confidence-interval-estimations>The Maritz-Jarrett method for quantile confidence interval estimations</h4><p>It&rsquo;s also important to know how to estimate confidence intervals around the given quantiles.
Based on my experience, one of the best solutions for this is the Maritz-Jarrett method.</p><ul><li>Maritz, J. S., and R. G. Jarrett. 1978.
“A Note on Estimating the Variance of the Sample Median.”
Journal of the American Statistical Association 73 (361): 194–196.<br><a href=https://doi.org/10.1080/01621459.1978.10480027>https://doi.org/10.1080/01621459.1978.10480027</a></li><li><a href=https://www.goodreads.com/book/show/12086837-introduction-to-robust-estimation-and-hypothesis-testing>Introduction to Robust Estimation and Hypothesis Testing</a> (2017, 4th edition) Rand R. Wilcox</li></ul><h4 id=dispersion-the-median-absolute-deviation-instead-of-the-standard-deviation>Dispersion: the median absolute deviation instead of the standard deviation</h4><p>Typically, people use the <a href=https://en.wikipedia.org/wiki/Standard_deviation>standard deviation</a> as a measure of the <a href=https://en.wikipedia.org/wiki/Statistical_dispersion>statistical dispersion</a>.
It works great for normal distribution, but it may be very misleading in the case of non-parametric distribution.
It&rsquo;s recommended to use alternative measures of dispersion such as the <a href=https://en.wikipedia.org/wiki/Median_absolute_deviation>median absolute deviation</a>.
The efficiency of this metric can be significantly improved with the help of the Harrell-Davis quantile estimator.</p><h4 id=quantile-absolute-deviation>Quantile absolute deviation</h4><p>In classic statistics, the median absolute deviation is calculated around the median value.
However, we can calculate the <em>median absolute deviation around any quantile</em>.
We can also calculate the <a href=(https://aakinshin.net/posts/qad/)>quantile absolute deviation</a> which provides a more robust set of dispersion values for the given quantile.</p><h4 id=extreme-value-theory-for-higher-quantile-estimations>Extreme value theory for higher quantile estimations</h4><p>The above methods allow getting an accurate estimation and a confidence interval around the median value.
However, if you apply these techniques to higher quantiles (e.g., 95th, 99th, or 99.9th <a href=https://en.wikipedia.org/wiki/Percentile>percentiles</a>),
you may get inaccurate values that can&rsquo;t be trusted.
To get better estimations, you can approximate tails of your distributions using
the <a href=https://en.wikipedia.org/wiki/Extreme_value_theory>extreme value theory</a>.</p><p>References:</p><ul><li><a href=https://www.goodreads.com/book/show/646395.Statistical_Analysis_of_Extreme_Values>Statistical Analysis of Extreme Values: With Applications to Insurance, Finance, Hydrology and Other Fields</a>
(2007) by Rolf-Dieter Reiß, Michael Thomas</li></ul><h4 id=quantile-respectful-density-plots>Quantile-respectful density plots</h4><p>It&rsquo;s also important to know how to visualize the density plot for your distributions.
Typically, people use <a href=https://en.wikipedia.org/wiki/Histogram>histograms</a> and <a href=https://en.wikipedia.org/wiki/Kernel_density_estimation>kernel density estimations</a> (KDE).
Unfortunately, these visualizations require tricky parameter tuning.
If you plot a histogram or a KDE using the default settings, you may easily get a misleading chart.
To prevent such problems, I prefer using the quantile-respectful density plots based on the Harrell-Davis quantile estimators.</p><p>References:</p><ul><li><a href=https://aakinshin.net/posts/misleading-histograms/>Misleading histograms</a></li><li><a href=https://aakinshin.net/posts/kde-bw/>The importance of kernel density estimation bandwidth</a></li><li><a href=https://aakinshin.net/posts/qrde-hd/>Quantile-respectful density estimation based on the Harrell-Davis quantile estimator</a></li></ul><h4 id=outlier-detection>Outlier detection</h4><p>Many statistical techniques don&rsquo;t work well when you have <a href=https://en.wikipedia.org/wiki/Outlier>outliers</a> (extreme values).
Thus, it&rsquo;s good to know how to detect such values.
Unfortunately, most popular approaches like <a href=https://en.wikipedia.org/wiki/Outlier#Tukey%27s_fences>Tukey&rsquo;s fences</a> may produce strange results on multimodal distributions.
If you are looking for a simple and fast outlier checker, you can use
<a href=https://aakinshin.net/posts/harrell-davis-double-mad-outlier-detector/>DoubleMAD outlier detector based on the Harrell-Davis quantile estimator</a>.
You can also achieve better results in outlier detection using different techniques from
the <a href=https://en.wikipedia.org/wiki/Cluster_analysis>cluster analysis</a>.</p><p>Note that outliers are not always extremely low or high values.
In the case of multimodal distributions, you may also have <a href=https://aakinshin.net/posts/intermodal-outliers/>intermodal outliers</a>.</p><h4 id=highest-density-intervals>Highest density intervals</h4><p>It&rsquo;s also important to know how to report ranges that cover the major part of the distribution.
If you just report the minimum and the maximum, you may get a misleading range because of the outliers.
Of course, you can just remove outliers and report the min/max for the rest of the collected values,
but this approach is not robust.
One of the alternative approaches is to use the highest density intervals (HDI).
It&rsquo;s a variation of the <a href=https://en.wikipedia.org/wiki/Credible_interval>credible intervals</a>
from the Bayesian statistics.</p><p>References:</p><ul><li><a href=https://www.goodreads.com/book/show/9003187-doing-bayesian-data-analysis>Doing Bayesian Data Analysis: A Tutorial Introduction with R</a> (2010) by John K. Kruschke</li></ul><h4 id=multimodality-detection>Multimodality detection</h4><p>Multimodality is one of the biggest challenges in performance analysis.
If your distribution is multimodal, it makes most of your metrics such as the median and the median absolute deviation.
To prevent such situations, you should check the distribution modality first.
I didn&rsquo;t find any workable approaches on the internet,
so I came up with my own: <a href=https://aakinshin.net/posts/lowland-multimodality-detection/>Lowland multimodality detection</a>.</p><p>When you process hundreds of different distribution each day,
it may be inconvenient to look at the density plots for each distribution.
In most cases, I prefer to work with command-line or plain text reports.
So, I also came up with a <a href=https://aakinshin.net/posts/modality-summary-notation/>plain text notation for multimodality distributions</a> that significantly simplifies the analysis routine.</p><hr><h3 id=comparing-distributions>Comparing distributions</h3><p>Now we know about methods that can be used to describe a single distribution.
Let&rsquo;s say that we have two distributions, and we want to compare them.
How should we do it?</p><h4 id=shift-and-ratio-functions>Shift and ratio functions</h4><p>One of my favorite approaches is to use the <a href=https://aakinshin.net/posts/shift-and-ratio-functions/>shift and ration functions</a>.
The idea is simple: we should just calculate all the quantiles for each distribution and compare them!
The shift functions show the absolute difference between quantiles.
The ratio functions show the relative difference between quantiles.</p><h4 id=effect-sizes>Effect sizes</h4><p>It&rsquo;s not always easy to work with absolute/relative quantile differences because it&rsquo;s hard to specify thresholds. 1 millisecond may be a huge difference for a nano-benchmark, and it may be insignificant for a benchmark that takes minutes.
10% may be a huge difference for a benchmark with a small dispersion (e.g., around 1% of the quantile value), and it may be insignificant for a benchmark with a huge dispersion (e.g., around 300% of the quantile value).</p><p>The <a href=https://en.wikipedia.org/wiki/Effect_size>effect size</a> resolves this problem.
In most cases, it&rsquo;s just the absolute difference normalized by the dispersion.
The effect sizes report the difference using abstract units that have the same meaning for all kinds of distributions.</p><h4 id=quantile-specific-effect-sizes>Quantile-specific effect sizes</h4><p>Unfortunately, most of the classic effect size equations assume normal distributions and estimate the difference between the distribution mean values.
So, I came up with a generalization of <a href="https://en.wikipedia.org/wiki/Effect_size#Cohen's_d">Cohen&rsquo;s d</a> (which is one of the most popular measures of the effect size) that
supports non-parametric distributions and estimates the difference between given quantiles.</p><p>References:</p><ul><li><a href=https://aakinshin.net/posts/nonparametric-effect-size/>Nonparametric Cohen&rsquo;s d-consistent effect size</a></li></ul><hr><h3 id=other-useful-approaches>Other useful approaches</h3><p>In addition, I want to say a few words about other approaches that can also be extremely useful in performance analysis.</p><h4 id=sequential-analysis>Sequential analysis</h4><p>Let&rsquo;s say you want to execute several iterations of a benchmark.
How many iterations should you run?
If the number of iterations is too low, you may get unreliable statistical metrics.
If the number of iterations is too big, you will wait for the benchmark results too long
without visible benefits in terms of accuracy.
Unfortunately, you can&rsquo;t predict the perfect number of iterations in advance because you don&rsquo;t know
the exact distribution form for your benchmark.</p><p>This problem can be solved using the <a href=https://en.wikipedia.org/wiki/Sequential_analysis>sequential analysis</a> and <a href=https://en.wikipedia.org/wiki/Optimal_stopping>optimal stopping</a>.
The idea is simple.
After each iteration,
we should reevaluate statistical metrics and make a decision: do we need one more iteration or not.</p><h4 id=weighted-samples>Weighted samples</h4><p>Now imagine that you collect some performance measurements every day on your CI server.
Each day you get a small sample of values that is not enough to get the accurate daily quantile estimations.
However, the full time-series over the last several weeks has a decent size.
You suspect that past measurements should be similar to today measurements,
but you are not 100% sure about it.
You feel a temptation to extend the up-to-date sample by the previously collected values,
but it may spoil the estimation (e.g., in the case of recent change points or positive/negative trends).</p><p>One of the possible approaches in this situation is to use <em>weighted samples</em>.
This assumes that we add past measurements to the &ldquo;today sample,&rdquo;
but these values should have a smaller weight.
The older measurement we take, the smaller weight it gets.
If you have consistent values across the last several days,
this approach works like a charm.
If you have any recent changes, you can detect such situations by huge confidence intervals
due to the sample inconsistency.</p><p>To determine the exact weights for each measurement, I prefer using the
<a href=https://en.wikipedia.org/wiki/Exponential_decay>exponential decay</a>.</p><p>It&rsquo;s also worth to note that the Harrell-Davis quantile estimator and the Maritz-Jarrett method can be generalized to the weighed case (see
<a href=https://aakinshin.net/posts/weighted-quantiles/>Weighted quantile estimators</a>
and
<a href=https://aakinshin.net/posts/weighted-quantiles-ci/>Quantile confidence intervals for weighted samples</a>
).</p><h4 id=change-point-detection>Change point detection</h4><p>Let&rsquo;s say you want to analyze the history of your performance values and find moments when
the form of the underlying distribution was changed.
For this problem, you need a <a href=https://en.wikipedia.org/wiki/Change_detection>change point detection</a> (CPD) algorithm.</p><p>There are a lot of different CPD algorithms (e.g., you can find a good overview in <a href=https://aakinshin.net/library/papers/truong2020/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>truong2020</a>:</p><div class=row><div class=mx-auto><a href=/posts/statistics-for-performance/img/cpd-overview.png target=_blank alt=cpd-overview><img class="mx-auto d-block img-fluid" width=800 src=/posts/statistics-for-performance/img/cpd-overview.png></a></div></div><br><p>From all the algorithms I tried, I found the only one that satisfied me in terms of speed and accuracy: <a href=https://link.springer.com/article/10.1007/s11222-016-9687-5>ED-PELT</a>
(an implementation can be found <a href=https://aakinshin.net/posts/edpelt/>here</a>).
Unfortunately, it didn&rsquo;t work well on long time-series with a high number of change points.
So, I came up with my own algorithm called <em>RqqPelt</em>.
I haven&rsquo;t written a post/paper about it yet, but you can try it yourself with the help of <a href=https://github.com/AndreyAkinshin/perfolizer#changepoint-detection>perfolizer</a>.</p><p>References:</p><ul><li>Truong, Charles, Laurent Oudre, and Nicolas Vayatis. &ldquo;Selective review of offline change point detection methods.&rdquo; Signal Processing 167 (2020): 107299.<br><a href=https://arxiv.org/pdf/1801.00718.pdf>https://arxiv.org/pdf/1801.00718.pdf</a></li><li>Haynes, Kaylea, Paul Fearnhead, and Idris A. Eckley. &ldquo;A computationally efficient nonparametric approach for changepoint detection.&rdquo; Statistics and Computing 27, no. 5 (2017): 1293-1305.<br><a href=https://link.springer.com/article/10.1007/s11222-016-9687-5>https://link.springer.com/article/10.1007/s11222-016-9687-5</a></li></ul><h4 id=streaming-quantile-estimators>Streaming quantile estimators</h4><p>Imagine that you are implementing performance telemetry in your application.
There is an operation that is executed millions of times, and you want to get its &ldquo;average&rdquo; duration.
It&rsquo;s not a good idea to use the arithmetic mean because the obtained value can be easily spoiled by outliers.
It&rsquo;s much better to use the median which is one of the most robust ways to describe the average.</p><p>The straightforward median estimation approach requires storing all the values.
In our case, it&rsquo;s a bad idea to keep all the values because it will significantly increase the memory footprint.
Such telemetry is harmful because it may become a new bottleneck instead of monitoring the actual performance.</p><p>Another way to get the median value is to use a sequential quantile estimator
(also known as an online quantile estimator or a streaming quantile estimator).</p><p>There are a lot of good sequential quantile estimators that work well.
One of my favorites is the <a href=https://aakinshin.net/posts/p2-quantile-estimator/>P² quantile estimator</a> because it has low overhead and it&rsquo;s very simple.</p><hr><h3 id=conclusion>Conclusion</h3><p>In this post, I covered some of the statistical approaches that I use for performance analysis.
This list is based on real-life experience.
It worth to say that if you conduct a performance investigation one time per month,
you probably don&rsquo;t actually need all these metrics and approaches.
However, if you want to set up a reliable infrastructure for performance monitoring that
processes thousands of distribution each day,
robust non-parametric approaches are required.
Without them, you can&rsquo;t achieve a decent level of reliability.</p><p>Several month ago, I have <a href=https://aakinshin.net/posts/introducing-perfolizer/>decided</a> to
implement the most useful algorithms and assemble them in a single place.
So, if you are looking for reference implementations of the above algorithms,
you can check out <a href=https://github.com/AndreyAkinshin/perfolizer>perfolizer</a>.
Note that most of the approaches are available only in the nightly versions,
but I&rsquo;m going to release a new stable version soon.
Keep tuned!</p></div><hr><h3 id=references>References (16)</h3><ol><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/edpelt/>Implementation of an efficient algorithm for changepoint detection: ED-PELT
</a>(2019-10-07)
<span class=label title=References:1><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>1</span>
<span class=label title=Backlinks:2><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>2</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/harrell-davis-double-mad-outlier-detector/>DoubleMAD outlier detector based on the Harrell-Davis quantile estimator
</a>(2020-06-22)
<span class=label title=References:4><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>4</span>
<span class=label title=Backlinks:2><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>2</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/intermodal-outliers/>Intermodal outliers
</a>(2020-11-10)
<span class=label title=References:1><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>1</span>
<span class=label title=Backlinks:2><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>2</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/introducing-perfolizer/>Introducing perfolizer
</a>(2020-03-04)
<span class=label title=Backlinks:1><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>1</span></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/kde-bw/>The importance of kernel density estimation bandwidth
</a>(2020-10-13)
<span class=label title=References:1><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>1</span>
<span class=label title=Backlinks:7><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>7</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/lowland-multimodality-detection/>Lowland multimodality detection
</a>(2020-11-03)
<span class=label title=References:3><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>3</span>
<span class=label title=Backlinks:8><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>8</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/misleading-histograms/>Misleading histograms
</a>(2020-10-20)
<span class=label title=References:2><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>2</span>
<span class=label title=Backlinks:4><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>4</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/modality-summary-notation/>Plain-text summary notation for multimodal distributions
</a>(2020-11-17)
<span class=label title=References:3><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>3</span>
<span class=label title=Backlinks:1><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>1</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/nonparametric-effect-size/>Nonparametric Cohen's d-consistent effect size
</a>(2020-06-25)
<span class=label title=References:7><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>7</span>
<span class=label title=Backlinks:8><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>8</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/p2-quantile-estimator/>P² quantile estimator: estimating the median without storing values
</a>(2020-11-24)
<span class=label title=References:5><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>5</span>
<span class=label title=Backlinks:7><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>7</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/qad/>Quantile absolute deviation: estimating statistical dispersion around quantiles
</a>(2020-12-01)
<span class=label title=References:3><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>3</span>
<span class=label title=Backlinks:11><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>11</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/qrde-hd/>Quantile-respectful density estimation based on the Harrell-Davis quantile estimator
</a>(2020-10-27)
<span class=label title=References:4><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>4</span>
<span class=label title=Backlinks:8><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>8</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/shift-and-ratio-functions/>Distribution comparison via the shift and ratio functions
</a>(2019-10-11)
<span class=label title=Backlinks:6><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>6</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/library/papers/ title="Library / papers"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>
</a><a href=https://aakinshin.net/library/papers/truong2020/>Selective Review of Offline Change Point Detection Methods
</a>(2020)
by
<a href=https://aakinshin.net/library/authors/charles-truong/>Charles Truong</a>
et al.
<svg class="rating-icon"><title>Has notes</title><use xlink:href="/img/fa/all.svg#note"/></svg>
<span class=label title=Backlinks:2><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>2</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/weighted-quantiles/>Weighted quantile estimators
</a>(2020-09-29)
<span class=label title=References:6><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>6</span>
<span class=label title=Backlinks:8><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>8</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/weighted-quantiles-ci/>Quantile confidence intervals for weighted samples
</a>(2020-12-08)
<span class=label title=References:3><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>3</span>
<span class=label title=Backlinks:5><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>5</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li></ol></div></div><script>var themeToggleDarkIcon=document.getElementById("theme-toggle-dark-icon"),themeToggleBtn,themeToggleLightIcon=document.getElementById("theme-toggle-light-icon");const imagesDark=document.querySelectorAll(".img-dark"),imagesLight=document.querySelectorAll(".img-light");localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?(themeToggleLightIcon.classList.remove("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")})):(themeToggleDarkIcon.classList.remove("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}));function toggleTheme(e){e?(document.documentElement.classList.add("dark"),themeToggleLightIcon.classList.remove("hidden"),themeToggleDarkIcon.classList.add("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")}),imagesLight.forEach(e=>{e.classList.add("hidden")})):(document.documentElement.classList.remove("dark"),themeToggleDarkIcon.classList.remove("hidden"),themeToggleLightIcon.classList.add("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}),imagesDark.forEach(e=>{e.classList.add("hidden")}))}themeToggleBtn=document.getElementById("theme-toggle"),themeToggleBtn.addEventListener("click",function(){themeToggleDarkIcon.classList.toggle("hidden"),themeToggleLightIcon.classList.toggle("hidden"),imagesLight.forEach(e=>{e.classList.toggle("hidden")}),imagesDark.forEach(e=>{e.classList.toggle("hidden")}),event.altKey?(localStorage.removeItem("color-theme"),toggleTheme(window.matchMedia("(prefers-color-scheme: dark)").matches)):localStorage.getItem("color-theme")?localStorage.getItem("color-theme")==="light"?(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark")):(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):document.documentElement.classList.contains("dark")?(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark"))}),window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",e=>{if(localStorage.getItem("color-theme")===null){const t=e.matches?"dark":"light";toggleTheme(t==="dark")}})</script><footer class="z-20 p-4 md:p-6 mt-3 w-full border-t border-gray-200 shadow flex items-center justify-center dark:border-gray-600 bg-white dark:bg-zinc-800"><span class="dark:text-gray-400 text-center">© 2013—2024 <span class=whitespace-nowrap>Andrey Akinshin</span></span><ul class="flex flex-wrap items-center px-4 mb-1"><li><a href=https://github.com/AndreyAkinshin><svg class="fai fai-link w-5 h-5"><title>GitHub</title><use xlink:href="/img/fa/all.svg#github"/></svg></a></li><li><a href=https://twitter.com/andrey_akinshin><svg class="fai fai-link w-5 h-5"><title>Twitter</title><use xlink:href="/img/fa/all.svg#twitter"/></svg></a></li><li><a href=https://aakinshin.net/posts/index.xml><svg class="fai fai-link w-5 h-5"><title>RSS</title><use xlink:href="/img/fa/all.svg#rss"/></svg></a></li></ul><div class=main-content><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></div></footer><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+=" has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script></body></html>