<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.123.8"><meta name=author content='Andrey Akinshin'><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content='Mathematics,Statistics,Research,Statistical efficiency'><title>Robust alternative to statistical efficiency | Andrey Akinshin</title>
<meta name=description content="Statistical efficiency is a common measure of the quality of an estimator. Typically, it&amp;rsquo;s expressed via the mean square error ($\operatorname{MSE}$). For the given estimator $T$ and the true parameter value $\theta$, the $\operatorname{MSE}$ can be e..."><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><script>localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?document.documentElement.classList.add("dark"):document.documentElement.classList.remove("dark")</script><link href=https://aakinshin.net/css/main.min.beef8b4fb043af14c2883e35de1b55e76fb412aa04a92889080ed30141cda7b6.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"></head><body class="flex flex-col min-h-screen"><nav><div class="container flex flex-wrap items-center justify-between mx-auto max-w-6xl h-12 px-2 xs:px-6"><div class="flex items-center justify-start justify-self-start"><div class="flex nav-item h-12 w-12 items-center justify-center"><a class=text-white href=https://aakinshin.net/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#house-chimney"/></svg></a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/feed/>Feed</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/library/>Library</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/research-projects/>Research</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/about/>About</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/search/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#magnifying-glass"/></svg></a></div></div><button id=theme-toggle type=button title="Alt+Click to match OS color theme" class="nav-item p-3 content-center justify-self-end"><svg id="theme-toggle-dark-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001.0 1010.586 10.586z"/></svg><svg id="theme-toggle-light-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M10 2a1 1 0 011 1v1A1 1 0 119 4V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707A1 1 0 1113.536 5.05l.707-.707a1 1 0 011.414.0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707A1 1 0 004.343 5.757l.707.707zm1.414 8.486-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z" fill-rule="evenodd" clip-rule="evenodd"/></svg></button></div></nav><div class="main container mx-auto max-w-6xl px-6 flex-grow"><div class=main-post><h1 class=blog-post-title id=post-title>Robust alternative to statistical efficiency</h1><div class="flex flex-wrap justify-start items-center"><div class="flex flex-wrap gap-y-1"><span class=label><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#calendar"/></svg>
<time datetime=2021-06-01>June 1, 2021</time>
</span><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#statistics"/></svg>
Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/>Research
</a><a class=label-link href=https://aakinshin.net/tags/statistical-efficiency/>Statistical efficiency</a></div></div><br><div class=main-content><p>Statistical efficiency is a common measure of the quality of an estimator.
Typically, it&rsquo;s expressed via the mean square error ($\operatorname{MSE}$).
For the given estimator $T$ and the true parameter value $\theta$,
the $\operatorname{MSE}$ can be expressed as follows:</p>$$
\operatorname{MSE}(T) = \operatorname{E}[(T-\theta)^2]
$$<p>In numerical simulations, the $\operatorname{MSE}$ can&rsquo;t be used as a robust metric
because its breakdown point is zero
(a corruption of a single measurement leads to a corrupted result).
Typically, it&rsquo;s not a problem for light-tailed distributions.
Unfortunately, in the heavy-tailed case,
the $\operatorname{MSE}$ becomes an unreliable and unreproducible metric
because it can be easily spoiled by a single outlier.</p><p>I suggest an alternative way to compare statistical estimators.
Instead of using non-robust $\operatorname{MSE}$,
we can use robust quantile estimations of the absolute error distribution.
In this post, I want to share numerical simulations
that show a problem of irreproducible $\operatorname{MSE}$ values
and how they can be replaced by reproducible quantile values.</p><p>We are going to compare four quantile estimators:</p><ul><li><code>hf7</code>: the traditional quantile estimator (also known as the Hyndman-Fan Type 7, see <a href=https://aakinshin.net/library/papers/hyndman1996/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>hyndman1996</a>)</li><li><code>hd</code>: the Harrell-Davis quantile estimator (see <a href=https://aakinshin.net/library/papers/harrell1982/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>harrell1982</a>)</li><li><code>sv1</code>: the first <a href=https://aakinshin.net/posts/sfakianakis-verginis-quantile-estimator/>Sfakianakis-Verginis quantile estimator</a>
(see <a href=https://aakinshin.net/library/papers/sfakianakis2008/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>sfakianakis2008</a>)</li><li><code>no</code>: the <a href=https://aakinshin.net/posts/navruz-ozdemir-quantile-estimator/>Navruz-Ã–zdemir quantile estimator</a>
(see <a href=https://aakinshin.net/library/papers/navruz2020/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>navruz2020</a>)</li></ul><p>With these estimators, we are going to estimate the median of the following distributions:</p><ul><li>The standard uniform distribution $\mathcal{U}(0, 1)$ <em>(light-tailed)</em></li><li>The standard normal distribution $\mathcal{N}(0, 1)$ <em>(light-tailed)</em></li><li>The pareto distribution $\textrm{Pareto}(x_m = 1, \alpha = 1)$ <em>(heavy-tailed)</em></li></ul><p>In each experiment, we generate 20'000 random samples,
each sample contains exactly 3 elements.
For each sample, we estimate the median using the current estimator.
Next, we build the distribution of absolute errors between the obtained median estimations and the true median value.
For each absolute error distribution, we estimate all the quantile values and draw corresponding plots.</p><h3 id=uniform-distribution>Uniform distribution</h3><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/robust-statistical-efficiency/img/uniform3-seed1-light.png target=_blank alt=uniform3-seed1><img src=/posts/robust-statistical-efficiency/img/uniform3-seed1-light.png width=800>
</a><a class="img-dark hidden" href=/posts/robust-statistical-efficiency/img/uniform3-seed1-dark.png target=_blank alt=uniform3-seed1><img src=/posts/robust-statistical-efficiency/img/uniform3-seed1-dark.png width=800></a></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl> <span class=nx>estimator</span>      <span class=nx>mse</span>      <span class=nx>p25</span>     <span class=nx>p50</span>     <span class=nx>p75</span>     <span class=nx>p90</span>     <span class=nx>p95</span>     <span class=nx>p99</span>
</span></span><span class=line><span class=cl>       <span class=nx>hf7</span> <span class=mf>0.049761</span> <span class=mf>0.082785</span> <span class=mf>0.17217</span> <span class=mf>0.27775</span> <span class=mf>0.36512</span> <span class=mf>0.40580</span> <span class=mf>0.45873</span>
</span></span><span class=line><span class=cl>        <span class=nx>hd</span> <span class=mf>0.030902</span> <span class=mf>0.062728</span> <span class=mf>0.12931</span> <span class=mf>0.21104</span> <span class=mf>0.28773</span> <span class=mf>0.33363</span> <span class=mf>0.40441</span>
</span></span><span class=line><span class=cl>       <span class=nx>sv1</span> <span class=mf>0.031096</span> <span class=mf>0.062015</span> <span class=mf>0.12936</span> <span class=mf>0.21394</span> <span class=mf>0.28739</span> <span class=mf>0.33340</span> <span class=mf>0.40215</span>
</span></span><span class=line><span class=cl>        <span class=nx>no</span> <span class=mf>0.030811</span> <span class=mf>0.061727</span> <span class=mf>0.13005</span> <span class=mf>0.21173</span> <span class=mf>0.28704</span> <span class=mf>0.33156</span> <span class=mf>0.40228</span>
</span></span></code></pre></div><p>In the case of standard uniform distribution, both the $\operatorname{MSE}$ and the absolute error quantile values
provide consistent results.
According to the simulations, <code>hd</code>/<code>sv1</code>/<code>no</code> perform much better than <code>hf7</code>.
Meanwhile, we don&rsquo;t see a noticeable difference between <code>hd</code>, <code>sv1</code>, and <code>no</code>.</p><h3 id=normal-distribution>Normal distribution</h3><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/robust-statistical-efficiency/img/normal3-seed1-light.png target=_blank alt=normal3-seed1><img src=/posts/robust-statistical-efficiency/img/normal3-seed1-light.png width=800>
</a><a class="img-dark hidden" href=/posts/robust-statistical-efficiency/img/normal3-seed1-dark.png target=_blank alt=normal3-seed1><img src=/posts/robust-statistical-efficiency/img/normal3-seed1-dark.png width=800></a></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl> <span class=nx>estimator</span>     <span class=nx>mse</span>     <span class=nx>p25</span>     <span class=nx>p50</span>     <span class=nx>p75</span>     <span class=nx>p90</span>    <span class=nx>p95</span>    <span class=nx>p99</span>
</span></span><span class=line><span class=cl>       <span class=nx>hf7</span> <span class=mf>0.45162</span> <span class=mf>0.21470</span> <span class=mf>0.44859</span> <span class=mf>0.77262</span> <span class=mf>1.10815</span> <span class=mf>1.3174</span> <span class=mf>1.7413</span>
</span></span><span class=line><span class=cl>        <span class=nx>hd</span> <span class=mf>0.33698</span> <span class=mf>0.18662</span> <span class=mf>0.38851</span> <span class=mf>0.66673</span> <span class=mf>0.96248</span> <span class=mf>1.1328</span> <span class=mf>1.4903</span>
</span></span><span class=line><span class=cl>       <span class=nx>sv1</span> <span class=mf>0.34164</span> <span class=mf>0.18439</span> <span class=mf>0.39484</span> <span class=mf>0.67337</span> <span class=mf>0.96364</span> <span class=mf>1.1482</span> <span class=mf>1.4905</span>
</span></span><span class=line><span class=cl>        <span class=nx>no</span> <span class=mf>0.34263</span> <span class=mf>0.18713</span> <span class=mf>0.39773</span> <span class=mf>0.67639</span> <span class=mf>0.95694</span> <span class=mf>1.1420</span> <span class=mf>1.5073</span>
</span></span></code></pre></div><p>In the case of the standard normal distribution, we have a similar picture:
the absolute error quantile values give the same overview of the quantile estimator efficiency
as the $\operatorname{MSE}$.</p><h3 id=pareto-distribution-attempt-1>Pareto distribution, attempt #1</h3><p>It&rsquo;s time to check a heavy-tailed distribution!</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/robust-statistical-efficiency/img/pareto3-seed1-light.png target=_blank alt=pareto3-seed1><img src=/posts/robust-statistical-efficiency/img/pareto3-seed1-light.png width=800>
</a><a class="img-dark hidden" href=/posts/robust-statistical-efficiency/img/pareto3-seed1-dark.png target=_blank alt=pareto3-seed1><img src=/posts/robust-statistical-efficiency/img/pareto3-seed1-dark.png width=800></a></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl> <span class=nx>estimator</span>        <span class=nx>mse</span>     <span class=nx>p25</span>     <span class=nx>p50</span>    <span class=nx>p75</span>    <span class=nx>p90</span>    <span class=nx>p95</span>    <span class=nx>p99</span>
</span></span><span class=line><span class=cl>       <span class=nx>hf7</span>     <span class=mf>31.978</span> <span class=mf>0.32446</span> <span class=mf>0.63152</span> <span class=mf>1.0811</span> <span class=mf>3.0858</span>  <span class=mf>5.293</span> <span class=mf>14.905</span>
</span></span><span class=line><span class=cl>        <span class=nx>hd</span>   <span class=mf>2640.998</span> <span class=mf>0.37870</span> <span class=mf>0.83140</span> <span class=mf>2.9100</span> <span class=mf>8.5205</span> <span class=mf>16.756</span> <span class=mf>77.500</span>
</span></span><span class=line><span class=cl>       <span class=nx>sv1</span>   <span class=mf>9322.438</span> <span class=mf>0.37274</span> <span class=mf>0.82331</span> <span class=mf>2.9271</span> <span class=mf>8.2836</span> <span class=mf>16.796</span> <span class=mf>75.108</span>
</span></span><span class=line><span class=cl>        <span class=nx>no</span> <span class=mf>128130.912</span> <span class=mf>0.36925</span> <span class=mf>0.83511</span> <span class=mf>3.0203</span> <span class=mf>8.4807</span> <span class=mf>17.054</span> <span class=mf>84.659</span>
</span></span></code></pre></div><p>From the plot, we can see that <code>hd</code>/<code>sv1</code>/<code>no</code> perform the same way (worse than <code>hf7</code>):
there is no noticeable difference between them.
However, if we build an overview based on the $\operatorname{MSE}$ values, we get another conclusion.
Let&rsquo;s estimate the relative efficiency of <code>hd</code>, <code>sv1</code>, and <code>no</code> using <code>hf7</code> as the baseline estimator:</p>$$
e(T_{\operatorname{HD}}) \approx \frac{31.978}{2640.998} \approx 0.0121
$$
$$
e(T_{\operatorname{SV1}}) \approx \frac{31.978}{9322.438} \approx 0.0034
$$
$$
e(T_{\operatorname{NO}}) \approx \frac{31.978}{128130.912} \approx 0.00025
$$<p>According to the $\operatorname{MSE}$ values, <code>hd</code> is 3.5 times better than <code>sv1</code> and 48.5 times better than <code>no</code>!</p><h3 id=pareto-distribution-attempt-2>Pareto distribution, attempt #2</h3><p>Now let&rsquo;s repeat the previous experiment with another set of random samples.</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/robust-statistical-efficiency/img/pareto3-seed2-light.png target=_blank alt=pareto3-seed2><img src=/posts/robust-statistical-efficiency/img/pareto3-seed2-light.png width=800>
</a><a class="img-dark hidden" href=/posts/robust-statistical-efficiency/img/pareto3-seed2-dark.png target=_blank alt=pareto3-seed2><img src=/posts/robust-statistical-efficiency/img/pareto3-seed2-dark.png width=800></a></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl> <span class=nx>estimator</span>        <span class=nx>mse</span>     <span class=nx>p25</span>     <span class=nx>p50</span>    <span class=nx>p75</span>    <span class=nx>p90</span>     <span class=nx>p95</span>    <span class=nx>p99</span>
</span></span><span class=line><span class=cl>       <span class=nx>hf7</span>     <span class=mf>27.384</span> <span class=mf>0.32309</span> <span class=mf>0.63282</span> <span class=mf>1.0515</span> <span class=mf>3.1039</span>  <span class=mf>5.5155</span> <span class=mf>15.703</span>
</span></span><span class=line><span class=cl>        <span class=nx>hd</span> <span class=mf>811526.384</span> <span class=mf>0.38036</span> <span class=mf>0.84433</span> <span class=mf>3.0360</span> <span class=mf>8.6536</span> <span class=mf>17.0931</span> <span class=mf>85.511</span>
</span></span><span class=line><span class=cl>       <span class=nx>sv1</span> <span class=mf>718886.400</span> <span class=mf>0.38023</span> <span class=mf>0.82743</span> <span class=mf>2.9420</span> <span class=mf>8.4412</span> <span class=mf>16.0745</span> <span class=mf>71.577</span>
</span></span><span class=line><span class=cl>        <span class=nx>no</span>  <span class=mf>14857.025</span> <span class=mf>0.37242</span> <span class=mf>0.81987</span> <span class=mf>2.9058</span> <span class=mf>8.4988</span> <span class=mf>17.0583</span> <span class=mf>77.767</span>
</span></span></code></pre></div><p>If we look at the absolute error quantile values, the second attempt is pretty similar to the first attempt.
Of course, the numbers are not identical, but the difference is negligible.
Such repeatability is impressive in the case of heavy-tailed distributions.</p><p>However, if we look at the $\operatorname{MSE}$ values, we can see that they are not so repeatable.
Here are the relative efficiency values of <code>hd</code>, <code>sv1</code>, and <code>no</code> against <code>hf7</code> in the second simulation:</p>$$
e(T_{\operatorname{HD}}) \approx \frac{27.384}{811526.38} \approx 0.000034
$$
$$
e(T_{\operatorname{SV1}}) \approx \frac{27.384}{718886.400} \approx 0.000038
$$
$$
e(T_{\operatorname{NO}}) \approx \frac{27.384}{14857.025} \approx 0.0018432
$$<p>Now the winner is <code>no</code>: it&rsquo;s 54 times better than <code>hd</code> and 48 times better than <code>sv1</code>.</p><h3 id=pareto-distribution-attempt-3>Pareto distribution, attempt #3</h3><p>Let&rsquo;s do the same experiment one more time.</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/robust-statistical-efficiency/img/pareto3-seed3-light.png target=_blank alt=pareto3-seed3><img src=/posts/robust-statistical-efficiency/img/pareto3-seed3-light.png width=800>
</a><a class="img-dark hidden" href=/posts/robust-statistical-efficiency/img/pareto3-seed3-dark.png target=_blank alt=pareto3-seed3><img src=/posts/robust-statistical-efficiency/img/pareto3-seed3-dark.png width=800></a></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl> <span class=nx>estimator</span>       <span class=nx>mse</span>     <span class=nx>p25</span>     <span class=nx>p50</span>    <span class=nx>p75</span>    <span class=nx>p90</span>    <span class=nx>p95</span>    <span class=nx>p99</span>
</span></span><span class=line><span class=cl>       <span class=nx>hf7</span>     <span class=mf>30.42</span> <span class=mf>0.32526</span> <span class=mf>0.63699</span> <span class=mf>1.0355</span> <span class=mf>3.0922</span>  <span class=mf>5.328</span> <span class=mf>14.707</span>
</span></span><span class=line><span class=cl>        <span class=nx>hd</span> <span class=mf>571078.71</span> <span class=mf>0.37972</span> <span class=mf>0.82261</span> <span class=mf>2.9377</span> <span class=mf>8.4516</span> <span class=mf>16.400</span> <span class=mf>75.704</span>
</span></span><span class=line><span class=cl>       <span class=nx>sv1</span> <span class=mf>129449.18</span> <span class=mf>0.37659</span> <span class=mf>0.82254</span> <span class=mf>2.8794</span> <span class=mf>8.2823</span> <span class=mf>16.356</span> <span class=mf>84.715</span>
</span></span><span class=line><span class=cl>        <span class=nx>no</span>   <span class=mf>4729.29</span> <span class=mf>0.38240</span> <span class=mf>0.83073</span> <span class=mf>2.9837</span> <span class=mf>8.3501</span> <span class=mf>16.606</span> <span class=mf>74.399</span>
</span></span></code></pre></div><p>Here are the updated $\operatorname{MSE}$-based relative efficiency values of <code>hd</code>, <code>sv1</code>, and <code>no</code> against <code>hf7</code>:</p>$$
e(T_{\operatorname{HD}}) \approx \frac{30.42}{571078.71} \approx 0.000053
$$
$$
e(T_{\operatorname{SV1}}) \approx \frac{30.42}{129449.18} \approx 0.000235
$$
$$
e(T_{\operatorname{NO}}) \approx \frac{30.42}{4729.29} \approx 0.0064323
$$<p>The winner is still <code>no</code>, but we have other relationships with two other estimators:
it&rsquo;s 120 times better than <code>hd</code> and 27 times better than <code>sv1</code>.</p><p>Here are the aggregated values of the relative efficiency from all three experiments:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl><span class=nx>Attempt</span>    <span class=mi>1</span>        <span class=mi>2</span>          <span class=mi>3</span>
</span></span><span class=line><span class=cl><span class=nx>HD</span>      <span class=mf>0.0121</span>   <span class=mf>0.000034</span>   <span class=mf>0.000053</span>
</span></span><span class=line><span class=cl><span class=nx>SV1</span>     <span class=mf>0.0034</span>   <span class=mf>0.000038</span>   <span class=mf>0.000235</span>
</span></span><span class=line><span class=cl><span class=nx>NO</span>      <span class=mf>0.0002</span>   <span class=mf>0.001843</span>   <span class=mf>0.006432</span>
</span></span></code></pre></div><p>Here we can expect to observe similar values for all three estimators in all experiments.
However, the actual values differ not only between estimators but also between experiments.
Such an irreproducibility makes the $\operatorname{MSE}$ useless for quantile estimator comparison
in the case of heavy-tailed distributions.</p><h3 id=conclusion>Conclusion</h3><p>The &ldquo;classic&rdquo; $\operatorname{MSE}$-based statistical efficiency estimation
may be an impractical way to compare estimators
in the case of heavy-tailed distributions because this metric is not robust.
Its breakdown point is zero, which means that a single outlier may completely distort the final value.</p><p>Instead of it, we can estimate quantiles of the absolute error distributions.
This approach provides a more reproducible way to compare the actual efficiency of different estimators.</p><h3 id=references>References</h3><ul><li><b id=Harrell1982>[Harrell1982]</b><br>Harrell, F.E. and Davis, C.E., 1982. A new distribution-free quantile estimator.
<em>Biometrika</em>, 69(3), pp.635-640.<br><a href=https://doi.org/10.2307/2335999>https://doi.org/10.2307/2335999</a></li><li><b id=Hyndman1996>[Hyndman1996]</b><br>Hyndman, R. J. and Fan, Y. 1996. Sample quantiles in statistical packages, <em>American Statistician</em> 50, 361â€“365.<br><a href=https://doi.org/10.2307/2684934>https://doi.org/10.2307/2684934</a></li><li><b id=Sfakianakis2008>[Sfakianakis2008]</b><br>Sfakianakis, Michael E., and Dimitris G. Verginis. &ldquo;A new family of nonparametric quantile estimators.&rdquo;
Communications in Statisticsâ€”Simulation and ComputationÂ® 37, no. 2 (2008): 337-345.<br><a href=https://doi.org/10.1080/03610910701790491>https://doi.org/10.1080/03610910701790491</a></li><li><b id=Navruz2020>[Navruz2020]</b><br>Navruz, GÃ¶zde, and A. FÄ±rat Ã–zdemir. &ldquo;A new quantile estimator with weights based on a subsampling approach.&rdquo;
British Journal of Mathematical and Statistical Psychology 73, no. 3 (2020): 506-521.<br><a href=https://doi.org/10.1111/bmsp.12198>https://doi.org/10.1111/bmsp.12198</a></li></ul></div><hr><h3 id=references>References (4)</h3><ol><li><a href=https://aakinshin.net/library/papers/ title="Library / papers"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>
</a><a href=https://aakinshin.net/library/papers/harrell1982/>A New distribution-free Quantile Estimator
</a>(1982)
by
<a href=https://aakinshin.net/library/authors/frank-e-harrell/>Frank E Harrell</a>
et al.
<span class=label title=Backlinks:23><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>23</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg>
</a><a href=https://aakinshin.net/tags/decent/><svg class="rating-icon"><title>Decent</title><use xlink:href="/img/fa/all.svg#decent"/></svg></a></li><li><a href=https://aakinshin.net/library/papers/ title="Library / papers"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>
</a><a href=https://aakinshin.net/library/papers/hyndman1996/>Sample Quantiles in Statistical Packages
</a>(1996)
by
<a href=https://aakinshin.net/library/authors/rob-j-hyndman/>Rob J Hyndman</a>
et al.
<span class=label title=Backlinks:12><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>12</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/library/papers/ title="Library / papers"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>
</a><a href=https://aakinshin.net/library/papers/navruz2020/>A New Quantile Estimator with Weights Based on a Subsampling Approach
</a>(2020)
by
<a href=https://aakinshin.net/library/authors/gozde-navruz/>G"ozde Navruz</a>
et al.
<span class=label title=Backlinks:3><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>3</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/library/papers/ title="Library / papers"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>
</a><a href=https://aakinshin.net/library/papers/sfakianakis2008/>A New Family of Nonparametric Quantile Estimators
</a>(2008)
by
<a href=https://aakinshin.net/library/authors/michael-e-sfakianakis/>Michael E Sfakianakis</a>
et al.
<span class=label title=Backlinks:3><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>3</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li></ol><h3 id=backlinks>Backlinks (3)</h3><ol><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/kish-ess-weighted-quantiles/>Using Kish's effective sample size with weighted quantiles
</a>(2021-07-06)
<span class=label title=References:6><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>6</span>
<span class=label title=Backlinks:5><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>5</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/kosqe1/>Quantile estimators based on k order statistics, Part 1: Motivation
</a>(2021-08-03)
<span class=label title=References:7><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>7</span>
<span class=label title=Backlinks:4><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>4</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/nonparametric-effect-size2/>Customization of the nonparametric Cohen's d-consistent effect size
</a>(2021-06-08)
<span class=label title=References:17><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>17</span>
<span class=label title=Backlinks:4><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>4</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li></ol></div></div><script>var themeToggleDarkIcon=document.getElementById("theme-toggle-dark-icon"),themeToggleBtn,themeToggleLightIcon=document.getElementById("theme-toggle-light-icon");const imagesDark=document.querySelectorAll(".img-dark"),imagesLight=document.querySelectorAll(".img-light");localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?(themeToggleLightIcon.classList.remove("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")})):(themeToggleDarkIcon.classList.remove("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}));function toggleTheme(e){e?(document.documentElement.classList.add("dark"),themeToggleLightIcon.classList.remove("hidden"),themeToggleDarkIcon.classList.add("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")}),imagesLight.forEach(e=>{e.classList.add("hidden")})):(document.documentElement.classList.remove("dark"),themeToggleDarkIcon.classList.remove("hidden"),themeToggleLightIcon.classList.add("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}),imagesDark.forEach(e=>{e.classList.add("hidden")}))}themeToggleBtn=document.getElementById("theme-toggle"),themeToggleBtn.addEventListener("click",function(){themeToggleDarkIcon.classList.toggle("hidden"),themeToggleLightIcon.classList.toggle("hidden"),imagesLight.forEach(e=>{e.classList.toggle("hidden")}),imagesDark.forEach(e=>{e.classList.toggle("hidden")}),event.altKey?(localStorage.removeItem("color-theme"),toggleTheme(window.matchMedia("(prefers-color-scheme: dark)").matches)):localStorage.getItem("color-theme")?localStorage.getItem("color-theme")==="light"?(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark")):(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):document.documentElement.classList.contains("dark")?(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark"))}),window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",e=>{if(localStorage.getItem("color-theme")===null){const t=e.matches?"dark":"light";toggleTheme(t==="dark")}})</script><footer class="z-20 p-4 md:p-6 mt-3 w-full border-t border-gray-200 shadow flex items-center justify-center dark:border-gray-600 bg-white dark:bg-zinc-800"><span class="dark:text-gray-400 text-center">Â© 2013â€”2024 <span class=whitespace-nowrap>Andrey Akinshin</span></span><ul class="flex flex-wrap items-center px-4 mb-1"><li><a href=https://github.com/AndreyAkinshin><svg class="fai fai-link w-5 h-5"><title>GitHub</title><use xlink:href="/img/fa/all.svg#github"/></svg></a></li><li><a href=https://twitter.com/andrey_akinshin><svg class="fai fai-link w-5 h-5"><title>Twitter</title><use xlink:href="/img/fa/all.svg#twitter"/></svg></a></li><li><a href=https://aakinshin.net/posts/index.xml><svg class="fai fai-link w-5 h-5"><title>RSS</title><use xlink:href="/img/fa/all.svg#rss"/></svg></a></li></ul><div class=main-content><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></div></footer><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+=" has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script></body></html>