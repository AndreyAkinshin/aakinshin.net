<!doctype html><html lang=en class=h-100><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.74.3"><meta name=author content="Andrey Akinshin"><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content="Mathematics,Statistics,Research,Statistical efficiency"><title>Robust alternative to statistical efficiency | Andrey Akinshin</title><meta name=description content="Statistical efficiency is a common measure of the quality of an estimator. Typically, it&amp;rsquo;s expressed via the mean square error (\(\operatorname{MSE}\..."><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><link href=/css/lumen-bootstrap.min.css theme=light rel=stylesheet type=text/css media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link href=/css/slate-bootstrap.min.css theme=dark rel=stylesheet type=text/css media="(prefers-color-scheme: dark)"><link href=/css/syntax-light.css theme=light rel=stylesheet type=text/css media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link href=/css/syntax-dark.css theme=dark rel=stylesheet type=text/css media="(prefers-color-scheme: dark)"><script src=https://aakinshin.net/js/theme-before.min.26d61b7027fe55e642f0001cef94cb75b567d721086492aab6b4e32d9ee7811d.js></script><script type=module src=https://aakinshin.net/js/dark-mode-toggle.min.882998740b9c4c24677576b997bde5a487246e2e3bd72128a0e922eaa59db029.mjs></script><link href=https://aakinshin.net/css/fontawesome-all.min.50da8736f05b35aac9691de67fe993cbe01b7d88fcf0cb682c3a8f39933fe4a3.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/about.min.2a76db7cc14055b3bafacc363f453917ab54a818a7db2a0a9b2409c0f6bf07c5.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/blog.min.b7c11be17efd31d4852ff062694551596a7625c992103c0605c98f85d6569f11.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZVB6MXSX32"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','G-ZVB6MXSX32');</script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-41419012-5"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-41419012-5');</script><script type=text/javascript>(function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym");ym(28700916,"init",{clickmap:true,trackLinks:true,accurateTrackBounce:true});</script><noscript><div><img src=https://mc.yandex.ru/watch/28700916 style=position:absolute;left:-9999px alt></div></noscript><script src=/js/jquery-3.3.1.slim.min.js></script></head><body><div class=bg-primary><div class="container bg-primary"><nav class="navbar navbar-expand-sm navbar-dark bg-primary"><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link id=nav-link-blog href=https://aakinshin.net/><i class="fas fa-home" title=Home style=color:#fff></i></a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" data-toggle=dropdown href=# role=button aria-haspopup=true aria-expanded=false>Posts</a><div class=dropdown-menu><a class=dropdown-item href=https://aakinshin.net/posts/>All Posts</a>
<a class=dropdown-item href=https://aakinshin.net/tags/statistics/>Posts about Statistics</a>
<a class=dropdown-item href=https://aakinshin.net/tags/>All Tags</a></div></li><li class=nav-item><a class=nav-link id=nav-link-about href=https://aakinshin.net/about/>About</a></li></ul><ul class="navbar-nav ml-auto"><li class=nav-item><dark-mode-toggle permanent=true></dark-mode-toggle></li></ul></nav></div></div><div class=container><main id=main><div class=blog-main><div class="blog-post table-sm"><h1 class=blog-post-title id=post-title>Robust alternative to statistical efficiency</h1><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-06-01>June 1, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/mathematics/ class="badge badge-info">Mathematics</a>
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research/ class="badge badge-info">Research</a>
<a href=https://aakinshin.net/tags/statistical-efficiency/ class="badge badge-info">Statistical efficiency</a></span><br><br><p>Statistical efficiency is a common measure of the quality of an estimator.
Typically, it&rsquo;s expressed via the mean square error (<span class="math inline">\(\operatorname{MSE}\)</span>).
For the given estimator <span class="math inline">\(T\)</span> and the true parameter value <span class="math inline">\(\theta\)</span>,
the <span class="math inline">\(\operatorname{MSE}\)</span> can be expressed as follows:</p><p><span class="math display">\[\operatorname{MSE}(T) = \operatorname{E}[(T-\theta)^2]
\]</span></p><p>In numerical simulations, the <span class="math inline">\(\operatorname{MSE}\)</span> can&rsquo;t be used as a robust metric
because its breakdown point is zero
(a corruption of a single measurement leads to a corrupted result).
Typically, it&rsquo;s not a problem for light-tailed distributions.
Unfortunately, in the heavy-tailed case,
the <span class="math inline">\(\operatorname{MSE}\)</span> becomes an unreliable and unreproducible metric
because it can be easily spoiled by a single outlier.</p><p>I suggest an alternative way to compare statistical estimators.
Instead of using non-robust <span class="math inline">\(\operatorname{MSE}\)</span>,
we can use robust quantile estimations of the absolute error distribution.
In this post, I want to share numerical simulations
that show a problem of irreproducible <span class="math inline">\(\operatorname{MSE}\)</span> values
and how they can be replaced by reproducible quantile values.</p><p>We are going to compare four quantile estimators:</p><ul><li><code>hf7</code>: the traditional quantile estimator (also known as the Hyndman-Fan Type 7, see <a href=#Hyndman1996>[Hyndman1996]</a>)</li><li><code>hd</code>: the Harrell-Davis quantile estimator (see <a href=#Harrell1982>[Harrell1982]</a>)</li><li><code>sv1</code>: the first <a href=https://aakinshin.net/posts/sfakianakis-verginis-quantile-estimator/>Sfakianakis-Verginis quantile estimator</a>
(see <a href=#Sfakianakis2008>[Sfakianakis2008]</a>)</li><li><code>no</code>: the <a href=https://aakinshin.net/posts/navruz-ozdemir-quantile-estimator/>Navruz-Ã–zdemir quantile estimator</a>
(see <a href=#Navruz2020>[Navruz2020]</a>)</li></ul><p>With these estimators, we are going to estimate the median of the following distributions:</p><ul><li>The standard uniform distribution <span class="math inline">\(\mathcal{U}(0, 1)\)</span> <em>(light-tailed)</em></li><li>The standard normal distribution <span class="math inline">\(\mathcal{N}(0, 1)\)</span> <em>(light-tailed)</em></li><li>The pareto distribution <span class="math inline">\(\textrm{Pareto}(x_m = 1, \alpha = 1)\)</span> <em>(heavy-tailed)</em></li></ul><p>In each experiment, we generate 20'000 random samples,
each sample contains exactly 3 elements.
For each sample, we estimate the median using the current estimator.
Next, we build the distribution of absolute errors between the obtained median estimations and the true median value.
For each absolute error distribution, we estimate all the quantile values and draw corresponding plots.</p><h3 id=uniform-distribution>Uniform distribution</h3><div class=row><div class=mx-auto><a href=/posts/robust-statistical-efficiency/img/uniform3-seed1-light.png target=_blank class=imgldlink alt=uniform3-seed1><picture>
<source theme=dark srcset=/posts/robust-statistical-efficiency/img/uniform3-seed1-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/robust-statistical-efficiency/img/uniform3-seed1-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/robust-statistical-efficiency/img/uniform3-seed1-light.png></picture></a></div></div><br><div class=highlight><pre class=chroma><code class=language-js data-lang=js> <span class=nx>estimator</span>      <span class=nx>mse</span>      <span class=nx>p25</span>     <span class=nx>p50</span>     <span class=nx>p75</span>     <span class=nx>p90</span>     <span class=nx>p95</span>     <span class=nx>p99</span>
       <span class=nx>hf7</span> <span class=mf>0.049761</span> <span class=mf>0.082785</span> <span class=mf>0.17217</span> <span class=mf>0.27775</span> <span class=mf>0.36512</span> <span class=mf>0.40580</span> <span class=mf>0.45873</span>
        <span class=nx>hd</span> <span class=mf>0.030902</span> <span class=mf>0.062728</span> <span class=mf>0.12931</span> <span class=mf>0.21104</span> <span class=mf>0.28773</span> <span class=mf>0.33363</span> <span class=mf>0.40441</span>
       <span class=nx>sv1</span> <span class=mf>0.031096</span> <span class=mf>0.062015</span> <span class=mf>0.12936</span> <span class=mf>0.21394</span> <span class=mf>0.28739</span> <span class=mf>0.33340</span> <span class=mf>0.40215</span>
        <span class=nx>no</span> <span class=mf>0.030811</span> <span class=mf>0.061727</span> <span class=mf>0.13005</span> <span class=mf>0.21173</span> <span class=mf>0.28704</span> <span class=mf>0.33156</span> <span class=mf>0.40228</span>
</code></pre></div><p>In the case of standard uniform distribution, both the <span class="math inline">\(\operatorname{MSE}\)</span> and the absolute error quantile values
provide consistent results.
According to the simulations, <code>hd</code>/<code>sv1</code>/<code>no</code> perform much better than <code>hf7</code>.
Meanwhile, we don&rsquo;t see a noticeable difference between <code>hd</code>, <code>sv1</code>, and <code>no</code>.</p><h3 id=normal-distribution>Normal distribution</h3><div class=row><div class=mx-auto><a href=/posts/robust-statistical-efficiency/img/normal3-seed1-light.png target=_blank class=imgldlink alt=normal3-seed1><picture>
<source theme=dark srcset=/posts/robust-statistical-efficiency/img/normal3-seed1-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/robust-statistical-efficiency/img/normal3-seed1-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/robust-statistical-efficiency/img/normal3-seed1-light.png></picture></a></div></div><br><div class=highlight><pre class=chroma><code class=language-js data-lang=js> <span class=nx>estimator</span>     <span class=nx>mse</span>     <span class=nx>p25</span>     <span class=nx>p50</span>     <span class=nx>p75</span>     <span class=nx>p90</span>    <span class=nx>p95</span>    <span class=nx>p99</span>
       <span class=nx>hf7</span> <span class=mf>0.45162</span> <span class=mf>0.21470</span> <span class=mf>0.44859</span> <span class=mf>0.77262</span> <span class=mf>1.10815</span> <span class=mf>1.3174</span> <span class=mf>1.7413</span>
        <span class=nx>hd</span> <span class=mf>0.33698</span> <span class=mf>0.18662</span> <span class=mf>0.38851</span> <span class=mf>0.66673</span> <span class=mf>0.96248</span> <span class=mf>1.1328</span> <span class=mf>1.4903</span>
       <span class=nx>sv1</span> <span class=mf>0.34164</span> <span class=mf>0.18439</span> <span class=mf>0.39484</span> <span class=mf>0.67337</span> <span class=mf>0.96364</span> <span class=mf>1.1482</span> <span class=mf>1.4905</span>
        <span class=nx>no</span> <span class=mf>0.34263</span> <span class=mf>0.18713</span> <span class=mf>0.39773</span> <span class=mf>0.67639</span> <span class=mf>0.95694</span> <span class=mf>1.1420</span> <span class=mf>1.5073</span>
</code></pre></div><p>In the case of the standard normal distribution, we have a similar picture:
the absolute error quantile values give the same overview of the quantile estimator efficiency
as the <span class="math inline">\(\operatorname{MSE}\)</span>.</p><h3 id=pareto-distribution-attempt-1>Pareto distribution, attempt #1</h3><p>It&rsquo;s time to check a heavy-tailed distribution!</p><div class=row><div class=mx-auto><a href=/posts/robust-statistical-efficiency/img/pareto3-seed1-light.png target=_blank class=imgldlink alt=pareto3-seed1><picture>
<source theme=dark srcset=/posts/robust-statistical-efficiency/img/pareto3-seed1-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/robust-statistical-efficiency/img/pareto3-seed1-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/robust-statistical-efficiency/img/pareto3-seed1-light.png></picture></a></div></div><br><div class=highlight><pre class=chroma><code class=language-js data-lang=js> <span class=nx>estimator</span>        <span class=nx>mse</span>     <span class=nx>p25</span>     <span class=nx>p50</span>    <span class=nx>p75</span>    <span class=nx>p90</span>    <span class=nx>p95</span>    <span class=nx>p99</span>
       <span class=nx>hf7</span>     <span class=mf>31.978</span> <span class=mf>0.32446</span> <span class=mf>0.63152</span> <span class=mf>1.0811</span> <span class=mf>3.0858</span>  <span class=mf>5.293</span> <span class=mf>14.905</span>
        <span class=nx>hd</span>   <span class=mf>2640.998</span> <span class=mf>0.37870</span> <span class=mf>0.83140</span> <span class=mf>2.9100</span> <span class=mf>8.5205</span> <span class=mf>16.756</span> <span class=mf>77.500</span>
       <span class=nx>sv1</span>   <span class=mf>9322.438</span> <span class=mf>0.37274</span> <span class=mf>0.82331</span> <span class=mf>2.9271</span> <span class=mf>8.2836</span> <span class=mf>16.796</span> <span class=mf>75.108</span>
        <span class=nx>no</span> <span class=mf>128130.912</span> <span class=mf>0.36925</span> <span class=mf>0.83511</span> <span class=mf>3.0203</span> <span class=mf>8.4807</span> <span class=mf>17.054</span> <span class=mf>84.659</span>
</code></pre></div><p>From the plot, we can see that <code>hd</code>/<code>sv1</code>/<code>no</code> perform the same way (worse than <code>hf7</code>):
there is no noticeable difference between them.
However, if we build an overview based on the <span class="math inline">\(\operatorname{MSE}\)</span> values, we get another conclusion.
Let&rsquo;s estimate the relative efficiency of <code>hd</code>, <code>sv1</code>, and <code>no</code> using <code>hf7</code> as the baseline estimator:</p><p><span class="math display">\[e(T_{\operatorname{HD}}) \approx \frac{31.978}{2640.998} \approx 0.0121
\]</span></p><p><span class="math display">\[e(T_{\operatorname{SV1}}) \approx \frac{31.978}{9322.438} \approx 0.0034
\]</span></p><p><span class="math display">\[e(T_{\operatorname{NO}}) \approx \frac{31.978}{128130.912} \approx 0.00025
\]</span></p><p>According to the <span class="math inline">\(\operatorname{MSE}\)</span> values, <code>hd</code> is 3.5 times better than <code>sv1</code> and 48.5 times better than <code>no</code>!</p><h3 id=pareto-distribution-attempt-2>Pareto distribution, attempt #2</h3><p>Now let&rsquo;s repeat the previous experiment with another set of random samples.</p><div class=row><div class=mx-auto><a href=/posts/robust-statistical-efficiency/img/pareto3-seed2-light.png target=_blank class=imgldlink alt=pareto3-seed2><picture>
<source theme=dark srcset=/posts/robust-statistical-efficiency/img/pareto3-seed2-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/robust-statistical-efficiency/img/pareto3-seed2-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/robust-statistical-efficiency/img/pareto3-seed2-light.png></picture></a></div></div><br><div class=highlight><pre class=chroma><code class=language-js data-lang=js> <span class=nx>estimator</span>        <span class=nx>mse</span>     <span class=nx>p25</span>     <span class=nx>p50</span>    <span class=nx>p75</span>    <span class=nx>p90</span>     <span class=nx>p95</span>    <span class=nx>p99</span>
       <span class=nx>hf7</span>     <span class=mf>27.384</span> <span class=mf>0.32309</span> <span class=mf>0.63282</span> <span class=mf>1.0515</span> <span class=mf>3.1039</span>  <span class=mf>5.5155</span> <span class=mf>15.703</span>
        <span class=nx>hd</span> <span class=mf>811526.384</span> <span class=mf>0.38036</span> <span class=mf>0.84433</span> <span class=mf>3.0360</span> <span class=mf>8.6536</span> <span class=mf>17.0931</span> <span class=mf>85.511</span>
       <span class=nx>sv1</span> <span class=mf>718886.400</span> <span class=mf>0.38023</span> <span class=mf>0.82743</span> <span class=mf>2.9420</span> <span class=mf>8.4412</span> <span class=mf>16.0745</span> <span class=mf>71.577</span>
        <span class=nx>no</span>  <span class=mf>14857.025</span> <span class=mf>0.37242</span> <span class=mf>0.81987</span> <span class=mf>2.9058</span> <span class=mf>8.4988</span> <span class=mf>17.0583</span> <span class=mf>77.767</span>
</code></pre></div><p>If we look at the absolute error quantile values, the second attempt is pretty similar to the first attempt.
Of course, the numbers are not identical, but the difference is negligible.
Such repeatability is impressive in the case of heavy-tailed distributions.</p><p>However, if we look at the <span class="math inline">\(\operatorname{MSE}\)</span> values, we can see that they are not so repeatable.
Here are the relative efficiency values of <code>hd</code>, <code>sv1</code>, and <code>no</code> against <code>hf7</code> in the second simulation:</p><p><span class="math display">\[e(T_{\operatorname{HD}}) \approx \frac{27.384}{811526.38} \approx 0.000034
\]</span></p><p><span class="math display">\[e(T_{\operatorname{SV1}}) \approx \frac{27.384}{718886.400} \approx 0.000038
\]</span></p><p><span class="math display">\[e(T_{\operatorname{NO}}) \approx \frac{27.384}{14857.025} \approx 0.0018432
\]</span></p><p>Now the winner is <code>no</code>: it&rsquo;s 54 times better than <code>hd</code> and 48 times better than <code>sv1</code>.</p><h3 id=pareto-distribution-attempt-3>Pareto distribution, attempt #3</h3><p>Let&rsquo;s do the same experiment one more time.</p><div class=row><div class=mx-auto><a href=/posts/robust-statistical-efficiency/img/pareto3-seed3-light.png target=_blank class=imgldlink alt=pareto3-seed3><picture>
<source theme=dark srcset=/posts/robust-statistical-efficiency/img/pareto3-seed3-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/robust-statistical-efficiency/img/pareto3-seed3-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/robust-statistical-efficiency/img/pareto3-seed3-light.png></picture></a></div></div><br><div class=highlight><pre class=chroma><code class=language-js data-lang=js> <span class=nx>estimator</span>       <span class=nx>mse</span>     <span class=nx>p25</span>     <span class=nx>p50</span>    <span class=nx>p75</span>    <span class=nx>p90</span>    <span class=nx>p95</span>    <span class=nx>p99</span>
       <span class=nx>hf7</span>     <span class=mf>30.42</span> <span class=mf>0.32526</span> <span class=mf>0.63699</span> <span class=mf>1.0355</span> <span class=mf>3.0922</span>  <span class=mf>5.328</span> <span class=mf>14.707</span>
        <span class=nx>hd</span> <span class=mf>571078.71</span> <span class=mf>0.37972</span> <span class=mf>0.82261</span> <span class=mf>2.9377</span> <span class=mf>8.4516</span> <span class=mf>16.400</span> <span class=mf>75.704</span>
       <span class=nx>sv1</span> <span class=mf>129449.18</span> <span class=mf>0.37659</span> <span class=mf>0.82254</span> <span class=mf>2.8794</span> <span class=mf>8.2823</span> <span class=mf>16.356</span> <span class=mf>84.715</span>
        <span class=nx>no</span>   <span class=mf>4729.29</span> <span class=mf>0.38240</span> <span class=mf>0.83073</span> <span class=mf>2.9837</span> <span class=mf>8.3501</span> <span class=mf>16.606</span> <span class=mf>74.399</span>
</code></pre></div><p>Here are the updated <span class="math inline">\(\operatorname{MSE}\)</span>-based relative efficiency values of <code>hd</code>, <code>sv1</code>, and <code>no</code> against <code>hf7</code>:</p><p><span class="math display">\[e(T_{\operatorname{HD}}) \approx \frac{30.42}{571078.71} \approx 0.000053
\]</span></p><p><span class="math display">\[e(T_{\operatorname{SV1}}) \approx \frac{30.42}{129449.18} \approx 0.000235
\]</span></p><p><span class="math display">\[e(T_{\operatorname{NO}}) \approx \frac{30.42}{4729.29} \approx 0.0064323
\]</span></p><p>The winner is still <code>no</code>, but we have other relationships with two other estimators:
it&rsquo;s 120 times better than <code>hd</code> and 27 times better than <code>sv1</code>.</p><p>Here are the aggregated values of the relative efficiency from all three experiments:</p><div class=highlight><pre class=chroma><code class=language-js data-lang=js><span class=nx>Attempt</span>    <span class=mi>1</span>        <span class=mi>2</span>          <span class=mi>3</span>
<span class=nx>HD</span>      <span class=mf>0.0121</span>   <span class=mf>0.000034</span>   <span class=mf>0.000053</span>
<span class=nx>SV1</span>     <span class=mf>0.0034</span>   <span class=mf>0.000038</span>   <span class=mf>0.000235</span>
<span class=nx>NO</span>      <span class=mf>0.0002</span>   <span class=mf>0.001843</span>   <span class=mf>0.006432</span>
</code></pre></div><p>Here we can expect to observe similar values for all three estimators in all experiments.
However, the actual values differ not only between estimators but also between experiments.
Such an irreproducibility makes the <span class="math inline">\(\operatorname{MSE}\)</span> useless for quantile estimator comparison
in the case of heavy-tailed distributions.</p><h3 id=conclusion>Conclusion</h3><p>The &ldquo;classic&rdquo; <span class="math inline">\(\operatorname{MSE}\)</span>-based statistical efficiency estimation
may be an impractical way to compare estimators
in the case of heavy-tailed distributions because this metric is not robust.
Its breakdown point is zero, which means that a single outlier may completely distort the final value.</p><p>Instead of it, we can estimate quantiles of the absolute error distributions.
This approach provides a more reproducible way to compare the actual efficiency of different estimators.</p><h3 id=references>References</h3><ul><li><b id=Harrell1982>[Harrell1982]</b><br>Harrell, F.E. and Davis, C.E., 1982. A new distribution-free quantile estimator.
<em>Biometrika</em>, 69(3), pp.635-640.<br><a href=https://doi.org/10.2307/2335999>https://doi.org/10.2307/2335999</a></li><li><b id=Hyndman1996>[Hyndman1996]</b><br>Hyndman, R. J. and Fan, Y. 1996. Sample quantiles in statistical packages, <em>American Statistician</em> 50, 361â€“365.<br><a href=https://doi.org/10.2307/2684934>https://doi.org/10.2307/2684934</a></li><li><b id=Sfakianakis2008>[Sfakianakis2008]</b><br>Sfakianakis, Michael E., and Dimitris G. Verginis. &ldquo;A new family of nonparametric quantile estimators.&rdquo;
Communications in Statisticsâ€”Simulation and ComputationÂ® 37, no. 2 (2008): 337-345.<br><a href=https://doi.org/10.1080/03610910701790491>https://doi.org/10.1080/03610910701790491</a></li><li><b id=Navruz2020>[Navruz2020]</b><br>Navruz, GÃ¶zde, and A. FÄ±rat Ã–zdemir. &ldquo;A new quantile estimator with weights based on a subsampling approach.&rdquo;
British Journal of Mathematical and Statistical Psychology 73, no. 3 (2020): 506-521.<br><a href=https://doi.org/10.1111/bmsp.12198>https://doi.org/10.1111/bmsp.12198</a></li></ul><br><br><div class=row><div class="mx-auto share-block"><div class=share-title>Share:</div><div class=share-button><a href="https://www.reddit.com/submit?url=https%3a%2f%2faakinshin.net%2fposts%2frobust-statistical-efficiency%2f&title=Robust%20alternative%20to%20statistical%20efficiency" target=_blank title="Share on Reddit"><i class="fab fa-reddit fa-2x"></i></a></div><div class=share-button><a href="https://twitter.com/intent/tweet?text=Robust%20alternative%20to%20statistical%20efficiency&url=https%3a%2f%2faakinshin.net%2fposts%2frobust-statistical-efficiency%2f&via=andrey_akinshin&related=andrey_akinshin" rel=nofollow target=_blank title="Share on Twitter"><i class="fab fa-twitter fa-2x"></i></a></div><div class=share-button><a href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2faakinshin.net%2fposts%2frobust-statistical-efficiency%2f" target=_blank title="Share on HackerNews"><i class="fab fa-hacker-news fa-2x"></i></a></div><div class=share-button><a href="https://getpocket.com/save?url=https%3a%2f%2faakinshin.net%2fposts%2frobust-statistical-efficiency%2f&title=Robust%20alternative%20to%20statistical%20efficiency" target=_blank title="Add to Pocket"><i class="fab fa-get-pocket fa-2x"></i></a></div></div></div></div><hr></div></div></main></div><footer class=blog-footer><div class=container><p>&copy; 2013&mdash;2022 Andrey Akinshin
|
<a href=https://github.com/AndreyAkinshin><i class="fab fa-github" title=GitHub></i></a><a href=https://twitter.com/andrey_akinshin><i class="fab fa-twitter" title=Twitter></i></a><a href=https://aakinshin.net/posts/index.xml><i class="fas fa-rss" title=RSS></i></a>|
<a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></p></div></footer><script src=https://aakinshin.net/js/theme-after.min.082780cb948cc57eabbc0d80172a7a5347d5572b599938b4c9876dfd7978b424.js></script><script src=/js/popper.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/anchor.min.js></script><script src=https://aakinshin.net/js/custom.min.11932490dde776463ed165b345838c701accc0cfdedf2e0868f13415f41f0872.js></script><script>window.MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],processEscapes:true,processEnvironments:true,},options:{skipHtmlTags:['script','noscript','style','textarea','pre'],ignoreHtmlClass:'tex2jax_ignore',processHtmlClass:'tex2jax_process'}};</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></body></html>