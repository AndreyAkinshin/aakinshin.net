<!doctype html><html lang=en class=h-100><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.74.3"><meta name=author content="Andrey Akinshin"><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content="Statistics,Effect size,MAD,Harrell-Davis,R,perfolizer"><title>Nonparametric Cohen's d-consistent effect size | Andrey Akinshin</title><meta name=description content="The effect size is a common way to describe a difference between two distributions. When these distributions are normal, one of the most popular approaches..."><link href=/css/lumen-bootstrap.min.css theme=light rel=stylesheet type=text/css media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link href=/css/slate-bootstrap.min.css theme=dark rel=stylesheet type=text/css media="(prefers-color-scheme: dark)"><link href=/css/syntax-light.css theme=light rel=stylesheet type=text/css media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link href=/css/syntax-dark.css theme=dark rel=stylesheet type=text/css media="(prefers-color-scheme: dark)"><script src=https://aakinshin.net/js/theme-before.min.26d61b7027fe55e642f0001cef94cb75b567d721086492aab6b4e32d9ee7811d.js></script><script type=module src=https://aakinshin.net/js/dark-mode-toggle.min.882998740b9c4c24677576b997bde5a487246e2e3bd72128a0e922eaa59db029.mjs></script><link href=https://aakinshin.net/css/fontawesome-all.min.50da8736f05b35aac9691de67fe993cbe01b7d88fcf0cb682c3a8f39933fe4a3.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/about.min.2a76db7cc14055b3bafacc363f453917ab54a818a7db2a0a9b2409c0f6bf07c5.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/blog.min.fe41ce51781393cea2f6a8fd3567674242dd6203d0a0b62f852fb257e992a236.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZVB6MXSX32"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','G-ZVB6MXSX32');</script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-41419012-5"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-41419012-5');</script><script type=text/javascript>(function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym");ym(28700916,"init",{clickmap:true,trackLinks:true,accurateTrackBounce:true});</script><noscript><div><img src=https://mc.yandex.ru/watch/28700916 style=position:absolute;left:-9999px alt></div></noscript><script src=/js/jquery-3.3.1.slim.min.js></script></head><body><div class=bg-primary><div class="container bg-primary"><nav class="navbar navbar-expand-sm navbar-dark bg-primary"><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link id=nav-link-blog href=https://aakinshin.net/><i class="fas fa-home" title=Home style=color:#fff></i></a></li><li class=nav-item><a class=nav-link id=nav-link-posts href=https://aakinshin.net/posts/>Posts</a></li><li class=nav-item><a class=nav-link id=nav-link-about href=https://aakinshin.net/about/>About</a></li><li class=nav-item><a class=nav-link id=nav-link-pdnb href=https://aakinshin.net/prodotnetbenchmarking/>Pro .NET Benchmarking</a></li></ul><ul class="navbar-nav ml-auto"><li class=nav-item><dark-mode-toggle permanent=true></dark-mode-toggle></li></ul></nav></div></div><div class=container><main id=main><div class=blog-main><div class=blog-post><h1 class=blog-post-title id=post-title>Nonparametric Cohen's d-consistent effect size</h1><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2020-06-25>June 25, 2020</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/effect-size/ class="badge badge-info">Effect size</a>
<a href=https://aakinshin.net/tags/mad/ class="badge badge-info">MAD</a>
<a href=https://aakinshin.net/tags/harrell-davis/ class="badge badge-info">Harrell-Davis</a>
<a href=https://aakinshin.net/tags/r/ class="badge badge-info">R</a>
<a href=https://aakinshin.net/tags/perfolizer/ class="badge badge-info">perfolizer</a></span><br><br><p>The effect size is a common way to describe a difference between two distributions.
When these distributions are normal, one of the most popular approaches to express the effect size is <a href="https://en.wikipedia.org/wiki/Effect_size#Cohen's_d">Cohen&rsquo;s d</a>.
Unfortunately, it doesn&rsquo;t work great for non-normal distributions.</p><p>In this post, I will show a robust Cohen&rsquo;s d-consistent effect size formula for nonparametric distributions.</p><div class=row><div class=mx-auto><a href=/posts/nonparametric-effect-size/img/blackboard.png target=_blank alt=blackboard><img class="mx-auto d-block img-fluid" width=800 src=/posts/nonparametric-effect-size/img/blackboard.png></a></div></div><br><h3 id=cohens-d>Cohen&rsquo;s d</h3><p>Let&rsquo;s start with the basics.
For two samples <span class="math inline">\(X = \{ X_1, X_2, \ldots, X_{n_X} \}\)</span> and <span class="math inline">\(Y = \{ Y_1, Y_2, \ldots, Y_{n_Y} \}\)</span>, the <em>Cohen&rsquo;s d</em> is defined as follows (<a href=#Cohen1988>[Cohen1988]</a>):</p><p><span class="math display">\[d = \frac{\overline{Y}-\overline{X}}{s}
\]</span></p><p>where <span class="math inline">\(s\)</span> is the <a href=https://en.wikipedia.org/wiki/Pooled_standard_deviation>pooled standard deviation</a>:</p><p><span class="math display">\[s = \sqrt{\frac{(n_X - 1) s^2_X + (n_Y - 1) s^2_Y}{n_X + n_Y - 2}}.
\]</span></p><p>Our goal is to build a robust effect size formula that works the same way for normal distributions,
but also is applicable for nonparametric distributions.</p><h3 id=existing-nonparametric-effect-size-measures>Existing nonparametric effect size measures</h3><p>There are some existing nonparametric effect size measures, but most of them are clamped (they have fixed lower and upper bounds):</p><ul><li>Cliff&rsquo;s Delta (<a href=#Cliff1993>[Cliff1993]</a>): <span class="math inline">\([-1; 1]\)</span></li><li>Vargha-Delaney A (<a href=#Vargha2000>[Vargha2000]</a>): <span class="math inline">\([0; 1]\)</span></li><li>Wilcox&rsquo;s Q (<a href=#Wilcox2019>[Wilcox2019]</a>): <span class="math inline">\([0; 1]\)</span></li></ul><p>Let&rsquo;s consider the two following cases of nonoverlapped distribution pairs:</p><p><span class="math display">\[X^{(1)} \in [0; 5] \quad \textrm{vs.} \quad Y^{(1)} \in [10; 20]
\]</span></p><p>and</p><p><span class="math display">\[X^{(2)} \in [0; 5] \quad \textrm{vs.} \quad Y^{(2)} \in [50; 100].
\]</span></p><p>In both cases, all of the above measures have extreme values.
Thus, they don&rsquo;t help to distinguish these cases.
Meanwhile, the effect for <span class="math inline">\(X^{(2)} \; \textrm{vs.} \; Y^{(2)}\)</span> is much larger than the effect for <span class="math inline">\(X^{(1)} \; \textrm{vs.} \; Y^{(1)}\)</span>.
It would be nice to have an effect size measure that highlights this difference.</p><h3 id=quantiles-and-the-shift-function>Quantiles and the shift function</h3><p>When we compare two nonparametric distributions, it&rsquo;s a good idea to track differences for all quantile values.
We can do it via the <a href=/posts/shift-and-ratio-functions/>shift function</a> (<a href=#Doksum1974>[Doksum1974]</a>, <a href=#Doksum1976>[Doksum1976]</a>):</p><div class=row><div class=mx-auto><a href=/posts/nonparametric-effect-size/img/compare4-light.png target=_blank class=imgldlink alt=compare4><picture>
<source theme=dark srcset=/posts/nonparametric-effect-size/img/compare4-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/nonparametric-effect-size/img/compare4-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/nonparametric-effect-size/img/compare4-light.png></picture></a></div></div><br><p>It shows the absolute shift for each quantile.
The robustness of the shift function can be improved with the help of <em>the Harrell-Davis quantile estimator</em> (<a href=#Harrell1982>[Harrell1982]</a>).</p><p>Unfortunately, the raw shift function can&rsquo;t be used as the effect size because it heavily depends on the distribution dispersion.
Without it, we can&rsquo;t say if the shift values are large or small.
So, we need a way to normalize it.</p><h3 id=mad-normalization>MAD normalization</h3><p>My favorite measure of the statistical dispersion is <em>the median absolute deviation (MAD)</em>:</p><p><span class="math display">\[\mathcal{MAD}_X = C \cdot \textrm{median}(|X_i - \textrm{median}(X)|), \quad
\mathcal{MAD}_Y = C \cdot \textrm{median}(|Y_i - \textrm{median}(Y)|).
\]</span></p><p>For the normally distributed values, there is a well-known relationship between the standard deviation and the median absolute deviation:</p><p><span class="math display">\[s_X \approx 1.4826 \cdot \textrm{median}(|X_i - \textrm{median}(X)|).
\]</span></p><p>Thus, we can use <span class="math inline">\(C = 1.4826\)</span> (which is also known as <em>the consistency constant</em>) to make <span class="math inline">\(\mathcal{MAD}\)</span> a consistent estimator for the standard deviation estimation.</p><p>By analogy with the pooled standard deviation, we can introduce <em>the pooled median absolute deviation</em>:</p><p><span class="math display">\[\mathcal{PMAD}_{XY} = \sqrt{\frac{(n_X - 1) \mathcal{MAD}^2_X + (n_Y - 1) \mathcal{MAD}^2_Y}{n_X + n_Y - 2}}.
\]</span></p><p>As usual, we can use the Harrell-Davis quantile estimator to improve the robustness of this metric.</p><h3 id=a-quantile-specific-effect-size>A quantile-specific effect size</h3><p>Now we are ready to write down the effect size for the given quantile <span class="math inline">\(p\)</span>.
Let&rsquo;s call it <span class="math inline">\(\gamma_p\)</span> (just because a lot of other good letters like
<a href="https://en.wikipedia.org/wiki/Effect_size#Cohen's_d">d</a>,
<a href="https://en.wikipedia.org/wiki/Effect_size#Glass'_%CE%94">Δ</a>,
<a href="https://en.wikipedia.org/wiki/Effect_size#Hedges'_g">g</a>,
<a href=https://en.wikipedia.org/wiki/Effect_size#%CE%A8,_root-mean-square_standardized_effect>Ψ</a>,
<a href="https://en.wikipedia.org/wiki/Effect_size#Cohen's_%C6%922">f</a>,
<a href="https://en.wikipedia.org/wiki/Effect_size#Cohen's_q">q</a>,
<a href="https://en.wikipedia.org/wiki/Effect_size#Cohen's_w">w</a>,
<a href="https://en.wikipedia.org/wiki/Effect_size#Cohen's_h">h</a>
are already occupied):</p><p><span class="math display">\[\gamma_p = \frac{Q_p(Y) - Q_p(X)}{\mathcal{PMAD}_{XY}}
\]</span></p><p>where <span class="math inline">\(Q_p\)</span> is the <span class="math inline">\(p^{\textrm{th}}\)</span> quantile of the given sample.</p><p>For the normal distribution, the Cohen&rsquo;s d equals to <span class="math inline">\(\gamma_{0.5}\)</span>:</p><p><span class="math display">\[d = \frac{\overline{Y}-\overline{X}}{s} \approx \frac{Q_{0.5}(Y) - Q_{0.5}(X)}{\mathcal{PMAD}_{XY}} = \gamma_{0.5}.
\]</span></p><h3 id=condensation>Condensation</h3><p>It&rsquo;s nice to have the effect size value for each specific quantile.
However, it would be more convenient to have a single number (or a few numbers) that express the difference.
Let&rsquo;s introduce a set of the <span class="math inline">\(\gamma_p\)</span> values for an interval:</p><p><span class="math display">\[\tilde{\gamma}_p = \{ \gamma_t | t \in [p; 1 - p] \}.
\]</span></p><p>The shift function may be unstable around 0 and 1.
Thus, it makes sense to drop these values and operate with the middle of the shift function.
In practice, <span class="math inline">\(\tilde{\gamma}_{0.2}\)</span> or <span class="math inline">\(\tilde{\gamma}_{0.3}\)</span> work pretty well.
For the given <span class="math inline">\(\tilde{\gamma}_p\)</span>, we can calculate the minimum and maximum values for this function across all quantiles:</p><p><span class="math display">\[\min (\tilde{\gamma}_p) = \min_{t \in [p; 1 - p] } \gamma_t, \quad
\max (\tilde{\gamma}_p) = \max_{t \in [p; 1 - p] } \gamma_t.
\]</span></p><p>Finally, we can define a range of <span class="math inline">\(\tilde{\gamma}_p\)</span>:</p><p><span class="math display">\[\textrm{range}(\tilde{\gamma}_p) = [\min (\tilde{\gamma}_p); \max (\tilde{\gamma}_p)].
\]</span></p><p>When the range is narrow, we can replace <span class="math inline">\(\tilde{\gamma}_p\)</span> by the minimum of the maximum value (or the average of these values).
In practice, it will be a good way to describe the difference between two distributions using a single number.</p><p>When the range is wide, we can&rsquo;t condensate <span class="math inline">\(\tilde{\gamma}_p\)</span> to a single number
because the relationship between these distributions is too complex.
In this case, it&rsquo;s recommended to look at the plot of <span class="math inline">\(\tilde{\gamma}_p\)</span> (or just work with the range).</p><h3 id=reference-implementation>Reference implementation</h3><p>If you use R, here is the function that you can use in your scripts:</p><div class=highlight><pre class=chroma><code class=language-R data-lang=R><span class=nf>library</span><span class=p>(</span><span class=n>Hmisc</span><span class=p>)</span>

<span class=n>pooled</span> <span class=o>&lt;-</span> <span class=nf>function</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>FUN</span><span class=p>)</span> <span class=p>{</span>
  <span class=n>nx</span> <span class=o>&lt;-</span> <span class=nf>length</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
  <span class=n>ny</span> <span class=o>&lt;-</span> <span class=nf>length</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
  <span class=nf>sqrt</span><span class=p>(((</span><span class=n>nx</span> <span class=o>-</span> <span class=m>1</span><span class=p>)</span> <span class=o>*</span> <span class=nf>FUN</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=n>^</span> <span class=m>2</span> <span class=o>+</span> <span class=p>(</span><span class=n>ny</span> <span class=o>-</span> <span class=m>1</span><span class=p>)</span> <span class=o>*</span> <span class=nf>FUN</span><span class=p>(</span><span class=n>y</span><span class=p>)</span> <span class=n>^</span> <span class=m>2</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=n>nx</span> <span class=o>+</span> <span class=n>ny</span> <span class=o>-</span> <span class=m>2</span><span class=p>))</span>
<span class=p>}</span>
<span class=n>hdmedian</span> <span class=o>&lt;-</span> <span class=nf>function</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=nf>as.numeric</span><span class=p>(</span><span class=nf>hdquantile</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=m>0.5</span><span class=p>))</span>
<span class=n>hdmad</span> <span class=o>&lt;-</span> <span class=nf>function</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=m>1.4826</span> <span class=o>*</span> <span class=nf>hdmedian</span><span class=p>(</span><span class=nf>abs</span><span class=p>(</span><span class=n>x</span> <span class=o>-</span> <span class=nf>hdmedian</span><span class=p>(</span><span class=n>x</span><span class=p>)))</span>
<span class=n>phdmad</span> <span class=o>&lt;-</span> <span class=nf>function</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span> <span class=nf>pooled</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>hdmad</span><span class=p>)</span>
<span class=n>gammaEffectSize</span> <span class=o>&lt;-</span> <span class=nf>function</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span>
  <span class=nf>as.numeric</span><span class=p>((</span><span class=nf>hdquantile</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=n>prob</span><span class=p>)</span> <span class=o>-</span> <span class=nf>hdquantile</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>prob</span><span class=p>))</span> <span class=o>/</span> <span class=nf>phdmad</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>))</span>
</code></pre></div><p>If you use C#, you can take an implementation from
the latest nightly version (0.3.0-nightly.33+) of <a href=https://github.com/AndreyAkinshin/perfolizer>Perfolizer</a>
(you need <code>GammaEffectSize.CalcValue</code>).</p><h3 id=conclusion>Conclusion</h3><p>In this post, we built a new formula for the effect size:</p><p><span class="math display">\[\gamma_p = \frac{Q_p(Y) - Q_p(X)}{\mathcal{PMAD}_{XY}}, \quad
\tilde{\gamma}_p = \{ \gamma_t | t \in [p; 1 - p] \}.
\]</span></p><p>It provides the effect size for each quantile, but it can also be condensed to a range or a single number.
It has the following advantages:</p><ul><li>It&rsquo;s robust (the robustness can be improved using the Harrell-Davis quantile estimator).</li><li>It&rsquo;s applicable for nonparametric distributions.</li><li>It&rsquo;s consistent with the Cohen&rsquo;s d for normal distributions.</li><li>It&rsquo;s not clamped, and it allows comparing large effect sizes for nonoverlapped distribution pairs.</li></ul><p>I use this approach to compare distributions of software performance measurements
(they are often right-skewed and heavily-tailed) in <a href=https://www.jetbrains.com/rider/>Rider</a>.
For my use cases, it works well and provides a good measure of the effect size.
I hope it can be useful in many other applications.
If you decide to try it, I will be happy to hear feedback about your experience.</p><h3 id=references>References</h3><ul><li><b id=Cohen1988>[Cohen1988]</b><br>Cohen, Jacob. (1988).
Statistical Power Analysis for the Behavioral Sciences.
New York, NY: Routledge Academic</li><li><b id=Cliff1993>[Cliff1993]</b><br>Cliff, Norman.
&ldquo;Dominance statistics: Ordinal analyses to answer ordinal questions.&rdquo;
<em>Psychological bulletin</em> 114, no. 3 (1993): 494.<br><a href=https://doi.org/10.1037/0033-2909.114.3.494>https://doi.org/10.1037/0033-2909.114.3.494</a></li><li><b id=Vargha2000>[Vargha2000]</b><br>Vargha A., and Delaney, H. D.
&ldquo;A critique and improvement of the CL common language effect size statistics of McGraw and Wong.&rdquo;
<em>Journal of Educational and Behavioral Statistics</em>, 25(2):101-132, 2000<br><a href=https://doi.org/10.3102/10769986025002101>https://doi.org/10.3102/10769986025002101</a></li><li><b id=Wilcox2019>[Wilcox2019]</b><br>Wilcox, Rand.
&ldquo;A Robust Nonparametric Measure of Effect Size Based on an Analog of Cohen&rsquo;s d, Plus Inferences About the Median of the Typical Difference.&rdquo;
<em>Journal of Modern Applied Statistical Methods</em> 17, no. 2 (2019): 1.</li><li><b id=Doksum1974>[Doksum1974]</b><br>Doksum, Kjell.
&ldquo;Empirical probability plots and statistical inference for nonlinear models in the two-sample case.&rdquo;
<em>The annals of statistics</em> (1974): 267-277.<br><a href=https://doi.org/10.1214/aos/1176342662>https://doi.org/10.1214/aos/1176342662</a></li><li><b id=Doksum1976>[Doksum1976]</b><br>Doksum, Kjell A., and Gerald L. Sievers.
&ldquo;Plotting with confidence: Graphical comparisons of two populations.&rdquo;
<em>Biometrika</em>, 63, no. 3 (1976): 421-434.<br><a href=https://doi.org/10.2307/2335720>https://doi.org/10.2307/2335720</a></li><li><b id=Harrell1982>[Harrell1982]</b><br>Harrell, F.E. and Davis, C.E., 1982.
&ldquo;A new distribution-free quantile estimator.&rdquo;
<em>Biometrika</em>, 69(3), pp.635-640.<br><a href=https://pdfs.semanticscholar.org/1a48/9bb74293753023c5bb6bff8e41e8fe68060f.pdf>https://pdfs.semanticscholar.org/1a48/9bb74293753023c5bb6bff8e41e8fe68060f.pdf</a></li></ul><br><br><div class=row><div class="mx-auto share-block"><div class=share-title>Share:</div><div class=share-button><a href="https://www.reddit.com/submit?url=https%3a%2f%2faakinshin.net%2fposts%2fnonparametric-effect-size%2f&title=Nonparametric%20Cohen%27s%20d-consistent%20effect%20size" target=_blank title="Share on Reddit"><i class="fab fa-reddit fa-2x"></i></a></div><div class=share-button><a href="https://twitter.com/intent/tweet?text=Nonparametric%20Cohen%27s%20d-consistent%20effect%20size&url=https%3a%2f%2faakinshin.net%2fposts%2fnonparametric-effect-size%2f&via=andrey_akinshin&related=andrey_akinshin" rel=nofollow target=_blank title="Share on Twitter"><i class="fab fa-twitter fa-2x"></i></a></div><div class=share-button><a href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2faakinshin.net%2fposts%2fnonparametric-effect-size%2f" target=_blank title="Share on HackerNews"><i class="fab fa-hacker-news fa-2x"></i></a></div><div class=share-button><a href="https://facebook.com/sharer.php?u=https%3a%2f%2faakinshin.net%2fposts%2fnonparametric-effect-size%2f" rel=nofollow target=_blank title="Share on Facebook"><i class="fab fa-facebook fa-2x"></i></a></div><div class=share-button><a href="http://vk.com/share.php?url=https%3a%2f%2faakinshin.net%2fposts%2fnonparametric-effect-size%2f" target=_blank title="Share on VKontakte"><i class="fab fa-vk fa-2x"></i></a></div><div class=share-button><a href="https://getpocket.com/save?url=https%3a%2f%2faakinshin.net%2fposts%2fnonparametric-effect-size%2f&title=Nonparametric%20Cohen%27s%20d-consistent%20effect%20size" target=_blank title="Add to Pocket"><i class="fab fa-get-pocket fa-2x"></i></a></div></div></div></div><hr></div></div></main></div><footer class=blog-footer><div class=container><p>&copy; 2013–2020 Andrey Akinshin
|
<a href=https://github.com/AndreyAkinshin><i class="fab fa-github" title=GitHub style=color:#fff></i></a><a href=https://twitter.com/andrey_akinshin><i class="fab fa-twitter" title=Twitter style=color:#fff></i></a><a href=https://aakinshin.net/posts/index.xml><i class="fas fa-rss" title=RSS style=color:#fff></i></a>|
<a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></p></div></footer><script src=https://aakinshin.net/js/theme-after.min.082780cb948cc57eabbc0d80172a7a5347d5572b599938b4c9876dfd7978b424.js></script><script src=/js/popper.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/anchor.min.js></script><script src=https://aakinshin.net/js/custom.min.11932490dde776463ed165b345838c701accc0cfdedf2e0868f13415f41f0872.js></script><script>window.MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],processEscapes:true,processEnvironments:true,},options:{skipHtmlTags:['script','noscript','style','textarea','pre'],ignoreHtmlClass:'tex2jax_ignore',processHtmlClass:'tex2jax_process'}};</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></body></html>