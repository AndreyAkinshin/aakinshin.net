<!doctype html><html lang=en class=h-100><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.103.0-DEV"><meta name=author content="Andrey Akinshin"><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content="Mathematics,Statistics,Research,Density estimation,Discrete distributions,Ties,Jittering"><title>How to build a smooth density estimation for a discrete sample using jittering | Andrey Akinshin</title><meta name=description content="A simple technique that removes ties from samples without noticeable changes in density"><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><link href=https://aakinshin.net/sass/bootstrap-light.min.css theme=light rel=stylesheet type=text/css media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link href=https://aakinshin.net/sass/bootstrap-dark.min.css theme=dark rel=stylesheet type=text/css media="(prefers-color-scheme: dark)"><script src=https://aakinshin.net/js/theme-before.min.d7f6578e23ad3f0c33c589f9bcb34f995b45121f1f3ce888869c86b26826c845.js></script>
<script type=module src=https://aakinshin.net/js/dark-mode-toggle.min.9e68d431432744c07a43381a8a833ffe0921cc0e006d84ad97f0b0d43c5cd82d.mjs></script>
<link href=https://aakinshin.net/css/main.min.d3894e60e337fa8d9f2c81dcda5dcb9144502462aaabed3c6bad2fcf178a8410.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"></head><body class="d-flex flex-column min-vh-100"><div class=bg-primary><div class="container bg-primary"><nav class="navbar navbar-expand-sm navbar-dark bg-primary"><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link id=nav-link-blog href=https://aakinshin.net/><svg class="fai"><use xlink:href="/img/fa/all.svg#house-chimney"/></svg></a></li><li class=nav-item><a class=nav-link id=nav-link-posts href=https://aakinshin.net/posts/>Posts</a></li><li class=nav-item><a class=nav-link id=nav-link-about href=https://aakinshin.net/about/>About</a></li></ul><ul class="navbar-nav ms-auto"><li class=nav-item><dark-mode-toggle permanent=true></dark-mode-toggle></li></ul></nav></div></div><div class=container><main id=main><div class=blog-main><div class="blog-post table-sm"><h1 class=blog-post-title id=post-title>How to build a smooth density estimation for a discrete sample using jittering</h1><span class=blog-post-meta><svg class="fai"><use xlink:href="/img/fa/all.svg#calendar-days"/></svg><time datetime=2021-04-20>April 20, 2021</time>
&nbsp;&nbsp;<svg class="fai"><use xlink:href="/img/fa/all.svg#tag"/></svg>
<a href=https://aakinshin.net/tags/mathematics/ class="badge badge-info">Mathematics</a>
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research/ class="badge badge-info">Research</a>
<a href=https://aakinshin.net/tags/density-estimation/ class="badge badge-info">Density estimation</a>
<a href=https://aakinshin.net/tags/discrete-distributions/ class="badge badge-info">Discrete distributions</a>
<a href=https://aakinshin.net/tags/ties/ class="badge badge-info">Ties</a>
<a href=https://aakinshin.net/tags/jittering/ class="badge badge-info">Jittering</a></span><br><br><p>Let&rsquo;s say you have a sample with tied values.
If you draw a kernel density estimation (KDE) for such a sample,
you may get a serrated pattern like this:</p><div class=row><div class=mx-auto><a href=/posts/discrete-sample-jittering/img/intro-light.png target=_blank class=imgldlink alt=intro><picture><source theme=dark srcset=/posts/discrete-sample-jittering/img/intro-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/discrete-sample-jittering/img/intro-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/discrete-sample-jittering/img/intro-light.png></picture></a></div></div><br><p>KDE requires samples from continuous distributions
while tied values arise in discrete or mixture distributions.
Even if the original distribution is continuous,
you may observe artificial sample discretization due to a limited resolution of the measuring tool.
This effect may lead to distorted density plots like in the above picture.</p><p>The problem could be solved using a nice technique called <em>jittering</em>.
In the simplest case, jittering just adds random noise to each measurement.
Such a trick removes all ties from the sample and allows building a smooth density estimation.</p><p>However, there are many different ways to apply jittering.
The trickiest question here is how to choose proper noise values.
In this post, I want to share one of my favorite jittering approaches.
It generates a non-randomized noise pattern with a low risk of noticeable sample corruption.</p><h3 id=the-problem>The problem</h3><p>Let me show a small real-life example that illustrates the problem.
Imagine you collect some duration measurements, most of which are between 0 and 100 milliseconds.
You don&rsquo;t need excellent accuracy, so it&rsquo;s OK to round all observations to integer values.
Despite the continuous nature of time, you come up with a discrete sample.
If the sample size is &ldquo;not-so-big,&rdquo; the corresponding kernel density estimation may look pretty smooth:</p><div class=row><div class=mx-auto><a href=/posts/discrete-sample-jittering/img/problem1-light.png target=_blank class=imgldlink alt=problem1><picture><source theme=dark srcset=/posts/discrete-sample-jittering/img/problem1-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/discrete-sample-jittering/img/problem1-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/discrete-sample-jittering/img/problem1-light.png></picture></a></div></div><br><p>However, if you continue to collect more measurements,
the KDE &ldquo;will be able to guess&rdquo; that the non-integer values are not allowed in this sample.
Thus, the density between observed integer measurements should be zero.
It gives us the serrated pattern:</p><div class=row><div class=mx-auto><a href=/posts/discrete-sample-jittering/img/problem2-light.png target=_blank class=imgldlink alt=problem2><picture><source theme=dark srcset=/posts/discrete-sample-jittering/img/problem2-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/discrete-sample-jittering/img/problem2-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/discrete-sample-jittering/img/problem2-light.png></picture></a></div></div><br><p>You can also find a more detailed discussion about this problem in my <a href=https://aakinshin.net/posts/kde-discrete/>previous post</a>.</p><h3 id=random-jittering>Random jittering</h3><p>One of the easiest ways to resolve the problem is to add random noise to each sample element.
In simple cases, you can use the normal distribution to generate noise values.
If we apply this simple trick to the sample from the first picture,
it will instantly make the KDE plot smooth:</p><div class=row><div class=mx-auto><a href=/posts/discrete-sample-jittering/img/comparison-light.png target=_blank class=imgldlink alt=comparison><picture><source theme=dark srcset=/posts/discrete-sample-jittering/img/comparison-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/discrete-sample-jittering/img/comparison-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/discrete-sample-jittering/img/comparison-light.png></picture></a></div></div><br><p>If you are interested in a formal definition of the jittering kernel density estimator or a literature overview,
it&rsquo;s recommended to read <a href=#Nagler2018>[Nagler2018]</a>.</p><h3 id=my-noise-pattern-preferences>My noise pattern preferences</h3><p>There are many different ways to introduce a noise pattern.
The normal or uniform distributions may be reasonable choices for simple single-shot experiments.
Note that you would need to tweak parameters for a while to get a reasonable density estimation in some cases.
Jittering is always a trade-off between two states:</p><ul><li>The noise is too small (the serrated pattern is not fixed, jittering had no effect)</li><li>The noise is too large (density estimation is inaccurate because the sample is corrupted)</li></ul><p>If we want to find a proper balance between these states, we should define requirements for the noise pattern
that improve our chances to get a nice density estimation.
I didn&rsquo;t find any bulletproof guidance on how to build a good noise distribution.
So, I came up with my own list of rules that I use during jittering to form the noise pattern:</p><ul><li><strong>Use stable noise pattern instead of random values</strong><br>One of the main goals of the density estimation is to discover the true distribution nature
based on a set of random measurements.
This goal is about <em>removing</em> the randomness, not <em>increasing</em> it.
Whenever it&rsquo;s possible, I prefer to avoid using additional random values.
It&rsquo;s better to define a fixed noise pattern in advance based on the configuration of the tied values.</li><li><strong>Modify only tied values</strong><br>One may experience a temptation to add noise to each sample element.
This approach is quite simple to implement because there is no need to actually detect ties.
However, the primary intention of jittering is to only eliminate ties from the sample.
What the point of modifying non-tied values?
It would just reduce the accuracy of the final density estimation.
I prefer to detect all groups of tied values and don&rsquo;t touch the other values.</li><li><strong>Maintain noise range within discretization step</strong><br>It&rsquo;s important to pay attention to the minimum and maximum noise values.
In the case of extreme noise values (which may happen if you generate noise based on the normal distribution),
one may corrupt the sample and reduce the reliability of the density estimation.
It&rsquo;s better to detect the discretization step and ensure that all noise values fit within a narrow band.
In the simplest case, we could define the discretization step as the minimum positive difference
between consequent order statistics.
In more complicated cases, the discretization step could be defined adaptively based on neighbor values.</li><li><strong>Preserve sample range</strong><br>If jittering spoils the minimum and the maximum value of the sample, it may introduce problems.
Let&rsquo;s say we work with the
<a href=https://aakinshin.net/posts/kde-discrete/#pdf-and-mixed-distributions>rectified Gaussian distribution</a>.
In this case, we probably have a lot of tied values that equal exactly zero.
If we add negative noise to some of the tied values, we will get negative sample values.
It will be a violation of the sample invariant for the rectified Gaussian distribution.
To avoid such a situation, it&rsquo;s better to preserve the minimum and the maximum value.</li><li><strong>Ensure high density near the original value</strong><br>Without jittering, the density estimation should probably use
<a href=https://en.wikipedia.org/wiki/Dirac_delta_function>the Dirac delta function</a> to express tied values.
With a smoother approximation, it should look like a sharp peak.
Sometimes, this peak is explained not by artificial discretization but by other distribution features.
For the rectified Gaussian distribution, the location of this peak is exactly zero.
If we add non-negative random noise to the tied zero values, in this case,
we may introduce a bias for this peak.
For example, the biased peak location may become 0.2 instead of 0.0, which distorts the density shape.
Whenever it&rsquo;s possible, I prefer preserving the peak location.</li></ul><p>Now let me show an example of such noise patterns that satisfy all of the above requirements.</p><h3 id=noise-pattern-example>Noise pattern example</h3><p>We are going to introduce an independent noise pattern for each group of tied values.
Let&rsquo;s say our sample contains <span class="math inline">\(k\)</span> tied values that equal <span class="math inline">\(x^*\)</span>.
Let <span class="math inline">\(l\)</span> be the number of sample values lower than <span class="math inline">\(x^*\)</span>, and <span class="math inline">\(r\)</span> be the number of sample values higher than <span class="math inline">\(x^*\)</span>.
For the given <span class="math inline">\(l\)</span> and <span class="math inline">\(r\)</span>,
we could define a beta distribution <span class="math inline">\(\textrm{Beta}(\alpha, \beta)\)</span> with the following <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>:</p><p><span class="math display">\[\alpha = \frac{9l+r}{l+r}, \quad \beta = \frac{l+9r}{l+r}.
\]</span></p><p>This distributions satisfy the following properties:</p><ul><li><span class="math inline">\(\alpha + \beta = 10\)</span></li><li>The mode of this distribution is always <span class="math inline">\(l / (l + r)\)</span>.</li></ul><p>Here are examples of the corresponding density plots:</p><div class=row><div class=mx-auto><a href=/posts/discrete-sample-jittering/img/noise-patterns-light.png target=_blank class=imgldlink alt=noise-patterns><picture><source theme=dark srcset=/posts/discrete-sample-jittering/img/noise-patterns-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/discrete-sample-jittering/img/noise-patterns-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/discrete-sample-jittering/img/noise-patterns-light.png></picture></a></div></div><br><p>Now let&rsquo;s define <span class="math inline">\(k\)</span> uniformly distributed numbers <span class="math inline">\(p_i\)</span> on <span class="math inline">\([0;1]\)</span>:</p><p><span class="math display">\[p_i = i / (k + 1), \quad i = 1, \ldots, k.
\]</span></p><p>Let <span class="math inline">\(p_0\)</span> be equal to <span class="math inline">\(p_i\)</span> that is nearest to the mode value <span class="math inline">\(l / (l + r)\)</span>.
If <span class="math inline">\(Q(p)\)</span> is the quantile function of <span class="math inline">\(\textrm{Beta}(\alpha, \beta)\)</span>,
we could introduce the following noise vector:</p><p><span class="math display">\[\xi_i = Q(p_i) - Q(p_0), \quad i = 1, \ldots, k.
\]</span></p><p>Now we could rescale the noise vector according to the discretization step and define jittered values <span class="math inline">\(\hat{x}_i\)</span>:</p><p><span class="math display">\[\hat{x}_i = x^* + s \cdot \xi_i
\]</span></p><p>where <span class="math inline">\(s\)</span> is the scale constant.
Based on my local experiments, I assume that <span class="math inline">\(s = 1.5\)</span> is usually enough to get a smooth approximation.</p><p>The above equation may look confusing, but they satisfy the requirements from the previous section.
Let me show a few examples (for this table, <span class="math inline">\(s = 1.0\)</span>):</p><table><thead><tr><th align=right><span class="math inline">\(k\)</span></th><th align=right><span class="math inline">\(l\)</span></th><th align=right><span class="math inline">\(r\)</span></th><th align=right><span class="math inline">\(\xi_i\)</span></th></tr></thead><tbody><tr><td align=right><span class="math inline">\(1\)</span></td><td align=right><span class="math inline">\(1\)</span></td><td align=right><span class="math inline">\(1\)</span></td><td align=right><span class="math inline">\(\{ 0.000 \} \)</span></td></tr><tr><td align=right><span class="math inline">\(3\)</span></td><td align=right><span class="math inline">\(1\)</span></td><td align=right><span class="math inline">\(1\)</span></td><td align=right><span class="math inline">\(\{ -0.108,\; 0.000,\; 0.108 \} \)</span></td></tr><tr><td align=right><span class="math inline">\(5\)</span></td><td align=right><span class="math inline">\(1\)</span></td><td align=right><span class="math inline">\(1\)</span></td><td align=right><span class="math inline">\(\{ -0.153,\; -0.069,\; 0.000,\; 0.069,\; 0.153 \} \)</span></td></tr><tr><td align=right><span class="math inline">\(4\)</span></td><td align=right><span class="math inline">\(5\)</span></td><td align=right><span class="math inline">\(0\)</span></td><td align=right><span class="math inline">\(\{-0.139,\; -0.072,\; -0.031,\; 0.000 \} \)</span></td></tr><tr><td align=right><span class="math inline">\(4\)</span></td><td align=right><span class="math inline">\(0\)</span></td><td align=right><span class="math inline">\(5\)</span></td><td align=right><span class="math inline">\(\{0.000,\; 0.031,\; 0.072,\; 0.139 \} \)</span></td></tr></tbody></table><p>Thus, the suggested approach
preserves the sample range,
provides small bias,
and returns consistent non-randomized values.
In addition, one of the noise vector components is always zero (which is a lovely property for manual sample exploration).
The noise range can be controlled via the scale constant <span class="math inline">\(s\)</span>.</p><p>Let&rsquo;s look at a few examples.
Here is two kernel density estimations (normal kernel, Sheather & Jones bandwidth selector)
for a sample of size 1000 from the binomial distribution <span class="math inline">\(\textrm{B}(n = 30, p = 0.2)\)</span>
without and with jittering (<span class="math inline">\(s = 1.5\)</span>):</p><div class=row><div class=mx-auto><a href=/posts/discrete-sample-jittering/img/jittering-demo1-light.png target=_blank class=imgldlink alt=jittering-demo1><picture><source theme=dark srcset=/posts/discrete-sample-jittering/img/jittering-demo1-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/discrete-sample-jittering/img/jittering-demo1-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/discrete-sample-jittering/img/jittering-demo1-light.png></picture></a></div></div><br><p>As you can see, the jittered version is much smoother.
The suggested approach works nicely with multimodal distribution as well.
Here is another two KDEs for a mixture of
a sample of size 1000 from <span class="math inline">\(\textrm{B}(n = 20, p = 0.2)\)</span> and
a sample of size 1000 from <span class="math inline">\(\textrm{B}(n = 20, p = 0.8)\)</span>:</p><div class=row><div class=mx-auto><a href=/posts/discrete-sample-jittering/img/jittering-demo2-light.png target=_blank class=imgldlink alt=jittering-demo2><picture><source theme=dark srcset=/posts/discrete-sample-jittering/img/jittering-demo2-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/discrete-sample-jittering/img/jittering-demo2-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/discrete-sample-jittering/img/jittering-demo2-light.png></picture></a></div></div><br><h3 id=conclusion>Conclusion</h3><p>Jittering is an excellent technique that allows getting smooth density estimations for discrete samples.
In this post, I described an example of a non-randomized noise pattern with a low risk of noticeable sample corruption.</p><h3 id=references>References</h3><ul><li><b id=Nagler2018>[Nagler2018]</b><br>Nagler, Thomas.
&ldquo;A generic approach to nonparametric function estimation with mixed data.&rdquo;
Statistics & Probability Letters 137 (2018): 326-330.<br><a href=https://doi.org/10.1016/j.spl.2018.02.040>https://doi.org/10.1016/j.spl.2018.02.040</a><br><a href=https://arxiv.org/pdf/1704.07457.pdf>https://arxiv.org/pdf/1704.07457.pdf</a></li></ul><br><br><div class=row><div class="justify-content-center share-block"><div class=share-title>Share:</div><div class=share-button><a href="https://www.reddit.com/submit?url=https%3a%2f%2faakinshin.net%2fposts%2fdiscrete-sample-jittering%2f&title=How%20to%20build%20a%20smooth%20density%20estimation%20for%20a%20discrete%20sample%20using%20jittering" target=_blank title="Share on Reddit"><svg class="fai"><use xlink:href="/img/fa/all.svg#reddit"/></svg></a></div><div class=share-button><a href="https://twitter.com/intent/tweet?text=How%20to%20build%20a%20smooth%20density%20estimation%20for%20a%20discrete%20sample%20using%20jittering&url=https%3a%2f%2faakinshin.net%2fposts%2fdiscrete-sample-jittering%2f&via=andrey_akinshin&related=andrey_akinshin" rel=nofollow target=_blank title="Share on Twitter"><svg class="fai"><use xlink:href="/img/fa/all.svg#twitter"/></svg></a></div><div class=share-button><a href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2faakinshin.net%2fposts%2fdiscrete-sample-jittering%2f" target=_blank title="Share on HackerNews"><svg class="fai"><use xlink:href="/img/fa/all.svg#hacker-news"/></svg></a></div><div class=share-button><a href="https://getpocket.com/save?url=https%3a%2f%2faakinshin.net%2fposts%2fdiscrete-sample-jittering%2f&title=How%20to%20build%20a%20smooth%20density%20estimation%20for%20a%20discrete%20sample%20using%20jittering" target=_blank title="Add to Pocket"><svg class="fai"><use xlink:href="/img/fa/all.svg#get-pocket"/></svg></a></div></div></div></div><hr></div></div></main></div><footer class="blog-footer mt-auto"><div class=container><p>&copy; 2013&mdash;2022 Andrey Akinshin
|
<a href=https://github.com/AndreyAkinshin><svg class="fai"><title>GitHub</title><use xlink:href="/img/fa/all.svg#github"/></svg></a><a href=https://twitter.com/andrey_akinshin><svg class="fai"><title>Twitter</title><use xlink:href="/img/fa/all.svg#twitter"/></svg></a><a href=https://aakinshin.net/posts/index.xml><svg class="fai"><title>RSS</title><use xlink:href="/img/fa/all.svg#rss"/></svg></a>|
<a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></p></div></footer><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.2.0/dist/js/bootstrap.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.3.1/anchor.min.js integrity="sha512-zPB79j2C+3sFS9zcA3vg/z6bVKzJVEyu9pY5w89akQRys76zpAT2t6S3wZKla3QQ14O5l/Yt0RUQ/DHXx82Y5g==" crossorigin=anonymous referrerpolicy=no-referrer></script>
<script src=https://aakinshin.net/js/theme-after.min.29520a8e1176193da7ea4e6cb56cf9b3e634b867c9979234d8dafb5ab61dd494.js></script>
<script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></body></html>