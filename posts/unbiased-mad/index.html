<!doctype html><html lang=en class=h-100><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.74.3"><meta name=author content="Andrey Akinshin"><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content="Statistics,Quantile,MAD"><title>Unbiased median absolute deviation | Andrey Akinshin</title><meta name=description content="The finite-sample bias-correction factors for the median absolute deviation which make it a consistent estimator for the standard deviation"><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><link href=/css/lumen-bootstrap.min.css theme=light rel=stylesheet type=text/css media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link href=/css/slate-bootstrap.min.css theme=dark rel=stylesheet type=text/css media="(prefers-color-scheme: dark)"><link href=/css/syntax-light.css theme=light rel=stylesheet type=text/css media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link href=/css/syntax-dark.css theme=dark rel=stylesheet type=text/css media="(prefers-color-scheme: dark)"><script src=https://aakinshin.net/js/theme-before.min.26d61b7027fe55e642f0001cef94cb75b567d721086492aab6b4e32d9ee7811d.js></script><script type=module src=https://aakinshin.net/js/dark-mode-toggle.min.882998740b9c4c24677576b997bde5a487246e2e3bd72128a0e922eaa59db029.mjs></script><link href=https://aakinshin.net/css/fontawesome-all.min.50da8736f05b35aac9691de67fe993cbe01b7d88fcf0cb682c3a8f39933fe4a3.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/about.min.2a76db7cc14055b3bafacc363f453917ab54a818a7db2a0a9b2409c0f6bf07c5.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/blog.min.ae812fc71daf5160d927febda5a991cee6c361345e3f685d3736931ed7537986.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZVB6MXSX32"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','G-ZVB6MXSX32');</script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-41419012-5"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-41419012-5');</script><script type=text/javascript>(function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym");ym(28700916,"init",{clickmap:true,trackLinks:true,accurateTrackBounce:true});</script><noscript><div><img src=https://mc.yandex.ru/watch/28700916 style=position:absolute;left:-9999px alt></div></noscript><script src=/js/jquery-3.3.1.slim.min.js></script></head><body><div class=bg-primary><div class="container bg-primary"><nav class="navbar navbar-expand-sm navbar-dark bg-primary"><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link id=nav-link-blog href=https://aakinshin.net/><i class="fas fa-home" title=Home style=color:#fff></i></a></li><li class=nav-item><a class=nav-link id=nav-link-posts href=https://aakinshin.net/posts/>Posts</a></li><li class=nav-item><a class=nav-link id=nav-link-about href=https://aakinshin.net/about/>About</a></li><li class=nav-item><a class=nav-link id=nav-link-pdnb href=https://aakinshin.net/prodotnetbenchmarking/>Pro .NET Benchmarking</a></li></ul><ul class="navbar-nav ml-auto"><li class=nav-item><dark-mode-toggle permanent=true></dark-mode-toggle></li></ul></nav></div></div><div class=container><main id=main><div class=blog-main><div class="blog-post table-sm"><h1 class=blog-post-title id=post-title>Unbiased median absolute deviation</h1><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-02-09>February 9, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/quantile/ class="badge badge-info">Quantile</a>
<a href=https://aakinshin.net/tags/mad/ class="badge badge-info">MAD</a></span><br><br><p>The <a href=https://en.wikipedia.org/wiki/Median_absolute_deviation>median absolute deviation</a> (<span class="math inline">\(\textrm{MAD}\)</span>)
is a robust measure of scale.
For distribution <span class="math inline">\(X\)</span>, it can be calculated as follows:</p><p><span class="math display">\[\textrm{MAD} = C \cdot \textrm{median}(|X - \textrm{median}(X)|)
\]</span></p><p>where <span class="math inline">\(C\)</span> is a constant scale factor.
This metric can be used as a robust alternative to the standard deviation.
If we want to use the <span class="math inline">\(\textrm{MAD}\)</span> as a <a href=https://en.wikipedia.org/wiki/Consistent_estimator>consistent estimator</a>
for the standard deviation under the normal distribution,
we should set</p><p><span class="math display">\[C = C_{\infty} = \dfrac{1}{\Phi^{-1}(3/4)} \approx 1.4826022185056.
\]</span></p><p>where <span class="math inline">\(\Phi^{-1}\)</span> is the quantile function of the standard normal distribution
(or the inverse of the cumulative distribution function).
If <span class="math inline">\(X\)</span> is the normal distribution, we get <span class="math inline">\(\textrm{MAD} = \sigma\)</span> where <span class="math inline">\(\sigma\)</span> is the standard deviation.</p><p>Not let&rsquo;s consider a sample <span class="math inline">\(x = \{ x_1, x_2, \ldots x_n \}\)</span>.
Let&rsquo;s denote the median absolute deviation for a sample of size <span class="math inline">\(n\)</span> as <span class="math inline">\(\textrm{MAD}_n\)</span>.
The corresponding equation looks similar to the definition of <span class="math inline">\(\textrm{MAD}\)</span> for a distribution:</p><p><span class="math display">\[\textrm{MAD}_n = C_n \cdot \textrm{median}(|x - \textrm{median}(x)|).
\]</span></p><p>Let&rsquo;s assume that <span class="math inline">\(\textrm{median}\)</span> is the straightforward definition of the median
(if <span class="math inline">\(n\)</span> is odd, the median is the middle element of the sorted sample,
if <span class="math inline">\(n\)</span> is even, the median is the arithmetic average of the two middle elements of the sorted sample).
We still can use <span class="math inline">\(C_n = C_{\infty}\)</span> for extremely large sample sizes.
However, for small <span class="math inline">\(n\)</span>, <span class="math inline">\(\textrm{MAD}_n\)</span> becomes a <a href=https://en.wikipedia.org/wiki/Bias_of_an_estimator>biased estimator</a>.
If we want to get an unbiased version, we should adjust the value of <span class="math inline">\(C_n\)</span>.</p><p>In this post, we look at the possible approaches and learn the way to get the exact value of <span class="math inline">\(C_n\)</span>
that makes <span class="math inline">\(\textrm{MAD}_n\)</span> unbiased estimator of the median absolute deviation for any <span class="math inline">\(n\)</span>.</p><h3 id=the-bias>The bias</h3><p>Let&rsquo;s briefly discuss the impact of the bias on our measurements.
To illustrate the problem, we take <span class="math inline">\(100,000\)</span> samples of size <span class="math inline">\(n = 5\)</span>
from the standard normal distribution and
calculate <span class="math inline">\(\textrm{MAD}_5\)</span> for each of them using <span class="math inline">\(C = 1\)</span>.
The obtained numbers form the following distribution:</p><div class=row><div class=mx-auto><a href=/posts/unbiased-mad/img/bias-light.png target=_blank class=imgldlink alt=bias><picture>
<source theme=dark srcset=/posts/unbiased-mad/img/bias-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/unbiased-mad/img/bias-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/unbiased-mad/img/bias-light.png></picture></a></div></div><br><p>If we try to use <span class="math inline">\(\textrm{MAD}_5\)</span> with <span class="math inline">\(C = 1\)</span> as a standard deviation estimator,
it would be a <em>biased estimator</em>.
Indeed, the standard deviation equals <span class="math inline">\(1\)</span> (the true value),
but the expected value of <span class="math inline">\(\textrm{MAD}_5\)</span> is about
<span class="math inline">\(E[\textrm{MAD}_5] \approx 0.5542\)</span>.
In order to make it unbiased, we should set <span class="math inline">\(C_5 = 1 / 0.5542 \approx 1.804\)</span>.
If we repeat the experiment with the modified scale factor, we get a modified version of our distribution:</p><div class=row><div class=mx-auto><a href=/posts/unbiased-mad/img/bias2-light.png target=_blank class=imgldlink alt=bias2><picture>
<source theme=dark srcset=/posts/unbiased-mad/img/bias2-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/unbiased-mad/img/bias2-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/unbiased-mad/img/bias2-light.png></picture></a></div></div><br><p>Now <span class="math inline">\(E[\textrm{MAD}_5] \approx 1\)</span> which makes <span class="math inline">\(\textrm{MAD}_5\)</span> <em>unbiased estimator</em>.</p><p>Note that <span class="math inline">\(C_5 = 1.804\)</span> differs from <span class="math inline">\(C_{\infty} \approx 1.4826\)</span> which is the proper scale factor for <span class="math inline">\(n \to \infty\)</span>.
Each sample size needs its own scale factor to make <span class="math inline">\(\textrm{MAD}_n\)</span> unbiased.
Let&rsquo;s review some papers and look at different approaches to find the optimal scale factor value.</p><h3 id=literature-overview>Literature overview</h3><p>One of the first mentions of the median absolute deviation can be found in <a href=#Hampel1974>[Hampel1974]</a>.
In this paper, Frank R Hampel introduced <span class="math inline">\(\textrm{MAD}\)</span> as a robust measure of scale
(attributed to Gauss).
I have found four papers that describe unbiased versions:
<a href=#Croux1992>[Croux1992]</a>, <a href=#Williams2011>[Williams2011]</a>, <a href=#Hayes2014>[Hayes2014]</a>, and <a href=#Park2020>[Park2020]</a>.
Let&rsquo;s briefly discuss approaches from these papers.</p><h4 id=the-croux-rousseeuw-approach>The Croux-Rousseeuw approach</h4><p>In <a href=#Croux1992>[Croux1992]</a>, Christophe Croux and Peter J. Rousseeuw
described an unbiased version of <span class="math inline">\(\textrm{MAD}\)</span>.
They suggested using the following equations:</p><p><span class="math display">\[C_n = \dfrac{b_n}{\Phi^{-1}(3/4)}.
\]</span></p><p>For <span class="math inline">\(n \leq 9\)</span>, the approximated values of <span class="math inline">\(b_n\)</span> were defined as follows:</p><table><thead><tr><th align=right>n</th><th align=right><span class="math inline">\(b_n\)</span></th></tr></thead><tbody><tr><td align=right>2</td><td align=right>1.196</td></tr><tr><td align=right>3</td><td align=right>1.495</td></tr><tr><td align=right>4</td><td align=right>1.363</td></tr><tr><td align=right>5</td><td align=right>1.206</td></tr><tr><td align=right>6</td><td align=right>1.200</td></tr><tr><td align=right>7</td><td align=right>1.140</td></tr><tr><td align=right>8</td><td align=right>1.129</td></tr><tr><td align=right>9</td><td align=right>1.107</td></tr></tbody></table><p>For <span class="math inline">\(n > 9\)</span>, they suggested to use the following equation:</p><p><span class="math display">\[b_n = \dfrac{n}{n-0.8}.
\]</span></p><h4 id=the-williams-approach>The Williams approach</h4><p>In <a href=#Williams2011>[Williams2011]</a>, Dennis C. Williams improved this approach.
Firstly, he provided updated <span class="math inline">\(b_n\)</span> values for small <span class="math inline">\(n\)</span>:</p><table><thead><tr><th align=right>n</th><th align=right><span class="math inline">\(b_n\)</span> by Croux</th><th align=right><span class="math inline">\(b_n\)</span> by Williams</th></tr></thead><tbody><tr><td align=right>2</td><td align=right>1.196</td><td align=right>1.197</td></tr><tr><td align=right>3</td><td align=right>1.495</td><td align=right>1.490</td></tr><tr><td align=right>4</td><td align=right>1.363</td><td align=right>1.360</td></tr><tr><td align=right>5</td><td align=right>1.206</td><td align=right>1.217</td></tr><tr><td align=right>6</td><td align=right>1.200</td><td align=right>1.189</td></tr><tr><td align=right>7</td><td align=right>1.140</td><td align=right>1.138</td></tr><tr><td align=right>8</td><td align=right>1.129</td><td align=right>1.127</td></tr><tr><td align=right>9</td><td align=right>1.107</td><td align=right>1.101</td></tr></tbody></table><p>Secondly, he also introduced a small correction for the general equation:</p><p><span class="math display">\[b_n = \dfrac{n}{n-0.801}.
\]</span></p><p>Also, he discussed another kind of approximation equation for such kind of bias-correction factors:</p><p><span class="math display">\[b_n \cong 1 + cn^{-d}.
\]</span></p><p>In his paper, he applied the above equation only for Shorth
(is the smallest interval that contains at least half of the data points),
but this approach can also be applied for other measures of scale.</p><h4 id=the-hayes-approach>The Hayes approach</h4><p>Next, in <a href=#Hayes2014>[Hayes2014]</a>, Kevin Hayes suggested another kind of prediction equation for <span class="math inline">\(n \geq 9\)</span>:</p><p><span class="math display">\[C_n = \dfrac{1}{\hat{a}_n}
\]</span></p><p>where</p><p><span class="math display">\[\hat{a}_n = \Phi^{-1}(3/4) \Bigg( 1 - \dfrac{\alpha}{n} - \dfrac{\beta}{n^2} \Bigg).
\]</span></p><p>Here are the suggested constants:</p><table><thead><tr><th align=right>n</th><th align=right><span class="math inline">\(\alpha\)</span></th><th align=right><span class="math inline">\(\beta\)</span></th></tr></thead><tbody><tr><td align=right>odd</td><td align=right>0.7635</td><td align=right>0.565</td></tr><tr><td align=right>even</td><td align=right>0.7612</td><td align=right>1.123</td></tr></tbody></table><h4 id=the-park-kim-wang-approach>The Park-Kim-Wang approach</h4><p>Finally, in <a href=#Park2020>[Park2020]</a>, Chanseok Park, Haewon Kim, and Min Wang aggregated all of the previous results.
They used the following form of the main equation:</p><p><span class="math display">\[C_n = \dfrac{1}{\Phi^{-1}(3/4) \cdot (1+A_n)}
\]</span></p><p>For <span class="math inline">\(n > 100\)</span>, they suggested to approaches.
The first one is based on <a href=#Hayes2014>[Hayes2014]</a> (the same equation for both odd and even <span class="math inline">\(n\)</span> values):</p><p><span class="math display">\[A_n = -\dfrac{0.76213}{n} - \dfrac{0.86413}{n^2}
\]</span></p><p>The second one is based on <a href=#Williams2011>[Williams2011]</a>:</p><p><span class="math display">\[A_n = -0.804168866 \cdot n^{-1.008922}
\]</span></p><p>Both approaches produce almost identical results, so it doesn&rsquo;t actually matter which one to use.</p><p>For <span class="math inline">\(2 \leq n \leq 100\)</span>, they suggested to use predefined constants:
(the below values are calculated based on Table A2 from <a href=#Park2020>[Park2020]</a>):</p><table><thead><tr><th align=right>n</th><th align=right><span class="math inline">\(C_n\)</span></th><th align=right>n</th><th align=right><span class="math inline">\(C_n\)</span></th></tr></thead><tbody><tr><td align=right>1</td><td align=right>NA</td><td align=right>51</td><td align=right>1.505611</td></tr><tr><td align=right>2</td><td align=right>1.772150</td><td align=right>52</td><td align=right>1.505172</td></tr><tr><td align=right>3</td><td align=right>2.204907</td><td align=right>53</td><td align=right>1.504575</td></tr><tr><td align=right>4</td><td align=right>2.016673</td><td align=right>54</td><td align=right>1.504417</td></tr><tr><td align=right>5</td><td align=right>1.803927</td><td align=right>55</td><td align=right>1.503713</td></tr><tr><td align=right>6</td><td align=right>1.763788</td><td align=right>56</td><td align=right>1.503604</td></tr><tr><td align=right>7</td><td align=right>1.686813</td><td align=right>57</td><td align=right>1.503095</td></tr><tr><td align=right>8</td><td align=right>1.671843</td><td align=right>58</td><td align=right>1.502864</td></tr><tr><td align=right>9</td><td align=right>1.632940</td><td align=right>59</td><td align=right>1.502253</td></tr><tr><td align=right>10</td><td align=right>1.624681</td><td align=right>60</td><td align=right>1.502085</td></tr><tr><td align=right>11</td><td align=right>1.601308</td><td align=right>61</td><td align=right>1.501611</td></tr><tr><td align=right>12</td><td align=right>1.596155</td><td align=right>62</td><td align=right>1.501460</td></tr><tr><td align=right>13</td><td align=right>1.580754</td><td align=right>63</td><td align=right>1.501019</td></tr><tr><td align=right>14</td><td align=right>1.577272</td><td align=right>64</td><td align=right>1.500841</td></tr><tr><td align=right>15</td><td align=right>1.566339</td><td align=right>65</td><td align=right>1.500331</td></tr><tr><td align=right>16</td><td align=right>1.563769</td><td align=right>66</td><td align=right>1.500343</td></tr><tr><td align=right>17</td><td align=right>1.555284</td><td align=right>67</td><td align=right>1.499877</td></tr><tr><td align=right>18</td><td align=right>1.553370</td><td align=right>68</td><td align=right>1.499772</td></tr><tr><td align=right>19</td><td align=right>1.547206</td><td align=right>69</td><td align=right>1.499291</td></tr><tr><td align=right>20</td><td align=right>1.545705</td><td align=right>70</td><td align=right>1.499216</td></tr><tr><td align=right>21</td><td align=right>1.540681</td><td align=right>71</td><td align=right>1.498922</td></tr><tr><td align=right>22</td><td align=right>1.539302</td><td align=right>72</td><td align=right>1.498838</td></tr><tr><td align=right>23</td><td align=right>1.535165</td><td align=right>73</td><td align=right>1.498491</td></tr><tr><td align=right>24</td><td align=right>1.534053</td><td align=right>74</td><td align=right>1.498399</td></tr><tr><td align=right>25</td><td align=right>1.530517</td><td align=right>75</td><td align=right>1.497917</td></tr><tr><td align=right>26</td><td align=right>1.529996</td><td align=right>76</td><td align=right>1.497901</td></tr><tr><td align=right>27</td><td align=right>1.526916</td><td align=right>77</td><td align=right>1.497489</td></tr><tr><td align=right>28</td><td align=right>1.526422</td><td align=right>78</td><td align=right>1.497544</td></tr><tr><td align=right>29</td><td align=right>1.523608</td><td align=right>79</td><td align=right>1.497248</td></tr><tr><td align=right>30</td><td align=right>1.523031</td><td align=right>80</td><td align=right>1.497185</td></tr><tr><td align=right>31</td><td align=right>1.520732</td><td align=right>81</td><td align=right>1.496797</td></tr><tr><td align=right>32</td><td align=right>1.520333</td><td align=right>82</td><td align=right>1.496779</td></tr><tr><td align=right>33</td><td align=right>1.518509</td><td align=right>83</td><td align=right>1.496428</td></tr><tr><td align=right>34</td><td align=right>1.517941</td><td align=right>84</td><td align=right>1.496501</td></tr><tr><td align=right>35</td><td align=right>1.516279</td><td align=right>85</td><td align=right>1.496295</td></tr><tr><td align=right>36</td><td align=right>1.516070</td><td align=right>86</td><td align=right>1.496089</td></tr><tr><td align=right>37</td><td align=right>1.514425</td><td align=right>87</td><td align=right>1.495794</td></tr><tr><td align=right>38</td><td align=right>1.513989</td><td align=right>88</td><td align=right>1.495796</td></tr><tr><td align=right>39</td><td align=right>1.512747</td><td align=right>89</td><td align=right>1.495557</td></tr><tr><td align=right>40</td><td align=right>1.512418</td><td align=right>90</td><td align=right>1.495420</td></tr><tr><td align=right>41</td><td align=right>1.511078</td><td align=right>91</td><td align=right>1.495270</td></tr><tr><td align=right>42</td><td align=right>1.511041</td><td align=right>92</td><td align=right>1.495141</td></tr><tr><td align=right>43</td><td align=right>1.509858</td><td align=right>93</td><td align=right>1.494944</td></tr><tr><td align=right>44</td><td align=right>1.509499</td><td align=right>94</td><td align=right>1.494958</td></tr><tr><td align=right>45</td><td align=right>1.508529</td><td align=right>95</td><td align=right>1.494706</td></tr><tr><td align=right>46</td><td align=right>1.508365</td><td align=right>96</td><td align=right>1.494665</td></tr><tr><td align=right>47</td><td align=right>1.507535</td><td align=right>97</td><td align=right>1.494379</td></tr><tr><td align=right>48</td><td align=right>1.507247</td><td align=right>98</td><td align=right>1.494331</td></tr><tr><td align=right>49</td><td align=right>1.506382</td><td align=right>99</td><td align=right>1.494113</td></tr><tr><td align=right>50</td><td align=right>1.506307</td><td align=right>100</td><td align=right>1.494199</td></tr></tbody></table><p>Here is the corresponding plot:</p><div class=row><div class=mx-auto><a href=/posts/unbiased-mad/img/factors-light.png target=_blank class=imgldlink alt=factors><picture>
<source theme=dark srcset=/posts/unbiased-mad/img/factors-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/unbiased-mad/img/factors-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/unbiased-mad/img/factors-light.png></picture></a></div></div><br><h3 id=conclusion>Conclusion</h3><p>Currently, my tool-of-choice is the approach from <a href=#Park2020>[Park2020]</a>].
I verified all the predefined constants and equations from the paper using numerical simulations.
I can confirm that the suggested approach produces
a reliable estimate of the unbiased median absolute deviation <span class="math inline">\(\textrm{MAD}_n\)</span>.</p><h3 id=references>References</h3><ul><li><b id=Hampel1974>[Hampel1974]</b><br>Hampel, Frank R. &ldquo;The influence curve and its role in robust estimation.&rdquo; Journal of the american statistical association 69, no. 346 (1974): 383-393.<br><a href=https://doi.org/10.2307/2285666>https://doi.org/10.2307/2285666</a></li><li><b id=Croux1992>[Croux1992]</b><br>Croux, Christophe, and Peter J. Rousseeuw. &ldquo;Time-efficient algorithms for two highly robust estimators of scale.&ldquo;In Computational statistics, pp. 411-428. Physica, Heidelberg, 1992.<br><a href=https://doi.org/10.1007/978-3-662-26811-7_58>https://doi.org/10.1007/978-3-662-26811-7_58</a></li><li><b id=Williams2011>[Williams2011]</b><br>Williams, Dennis C. &ldquo;Finite sample correction factors for several simple robust estimators of normal standard deviation.&rdquo; Journal of Statistical Computation and Simulation 81, no. 11 (2011): 1697-1702.<br><a href=https://doi.org/10.1080/00949655.2010.499516>https://doi.org/10.1080/00949655.2010.499516</a></li><li><b id=Hayes2014>[Hayes2014]</b><br>Hayes, Kevin. &ldquo;Finite-sample bias-correction factors for the median absolute deviation.&rdquo; Communications in Statistics-Simulation and Computation 43, no. 10 (2014): 2205-2212.<br><a href=https://doi.org/10.1080/03610918.2012.748913>https://doi.org/10.1080/03610918.2012.748913</a></li><li><b id=Park2020>[Park2020]</b><br>Park, Chanseok, Haewon Kim, and Min Wang. &ldquo;Investigation of finite-sample properties of robust location and scale estimators.&rdquo; Communications in Statistics-Simulation and Computation (2020): 1-27.<br><a href=https://doi.org/10.1080/03610918.2019.1699114>https://doi.org/10.1080/03610918.2019.1699114</a></li></ul><br><br><div class=row><div class="mx-auto share-block"><div class=share-title>Share:</div><div class=share-button><a href="https://www.reddit.com/submit?url=https%3a%2f%2faakinshin.net%2fposts%2funbiased-mad%2f&title=Unbiased%20median%20absolute%20deviation" target=_blank title="Share on Reddit"><i class="fab fa-reddit fa-2x"></i></a></div><div class=share-button><a href="https://twitter.com/intent/tweet?text=Unbiased%20median%20absolute%20deviation&url=https%3a%2f%2faakinshin.net%2fposts%2funbiased-mad%2f&via=andrey_akinshin&related=andrey_akinshin" rel=nofollow target=_blank title="Share on Twitter"><i class="fab fa-twitter fa-2x"></i></a></div><div class=share-button><a href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2faakinshin.net%2fposts%2funbiased-mad%2f" target=_blank title="Share on HackerNews"><i class="fab fa-hacker-news fa-2x"></i></a></div><div class=share-button><a href="https://facebook.com/sharer.php?u=https%3a%2f%2faakinshin.net%2fposts%2funbiased-mad%2f" rel=nofollow target=_blank title="Share on Facebook"><i class="fab fa-facebook fa-2x"></i></a></div><div class=share-button><a href="http://vk.com/share.php?url=https%3a%2f%2faakinshin.net%2fposts%2funbiased-mad%2f" target=_blank title="Share on VKontakte"><i class="fab fa-vk fa-2x"></i></a></div><div class=share-button><a href="https://getpocket.com/save?url=https%3a%2f%2faakinshin.net%2fposts%2funbiased-mad%2f&title=Unbiased%20median%20absolute%20deviation" target=_blank title="Add to Pocket"><i class="fab fa-get-pocket fa-2x"></i></a></div></div></div></div><hr></div></div></main></div><footer class=blog-footer><div class=container><p>&copy; 2013–2021 Andrey Akinshin
|
<a href=https://github.com/AndreyAkinshin><i class="fab fa-github" title=GitHub></i></a><a href=https://twitter.com/andrey_akinshin><i class="fab fa-twitter" title=Twitter></i></a><a href=https://aakinshin.net/posts/index.xml><i class="fas fa-rss" title=RSS></i></a>|
<a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></p></div></footer><script src=https://aakinshin.net/js/theme-after.min.082780cb948cc57eabbc0d80172a7a5347d5572b599938b4c9876dfd7978b424.js></script><script src=/js/popper.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/anchor.min.js></script><script src=https://aakinshin.net/js/custom.min.11932490dde776463ed165b345838c701accc0cfdedf2e0868f13415f41f0872.js></script><script>window.MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],processEscapes:true,processEnvironments:true,},options:{skipHtmlTags:['script','noscript','style','textarea','pre'],ignoreHtmlClass:'tex2jax_ignore',processHtmlClass:'tex2jax_process'}};</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></body></html>