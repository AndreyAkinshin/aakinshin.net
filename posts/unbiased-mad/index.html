<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.123.7"><meta name=author content='Andrey Akinshin'><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content='Mathematics,Statistics,Research,Quantile,Median Absolute Deviation,Research: Unbiased median absolute deviation'><title>Unbiased median absolute deviation | Andrey Akinshin</title>
<meta name=description content="The finite-sample bias-correction factors for the median absolute deviation which make it a consistent estimator for the standard deviation"><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><script>localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?document.documentElement.classList.add("dark"):document.documentElement.classList.remove("dark")</script><link href=https://aakinshin.net/css/main.min.d6826f88345af20c0769a313557ec1355465a3091b1f9869b936f2504c4dfe26.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"></head><body class="flex flex-col min-h-screen"><nav><div class="container flex flex-wrap items-center justify-between mx-auto max-w-6xl h-12 px-2 xs:px-6"><div class="flex items-center justify-start justify-self-start"><div class="flex nav-item h-12 w-12 items-center justify-center"><a class=text-white href=https://aakinshin.net/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#house-chimney"/></svg></a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/posts/>Posts</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/research/>Research</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/library/>Library</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/about/>About</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/search/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#magnifying-glass"/></svg></a></div></div><button id=theme-toggle type=button title="Alt+Click to match OS color theme" class="nav-item p-3 content-center justify-self-end"><svg id="theme-toggle-dark-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001.0 1010.586 10.586z"/></svg><svg id="theme-toggle-light-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M10 2a1 1 0 011 1v1A1 1 0 119 4V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707A1 1 0 1113.536 5.05l.707-.707a1 1 0 011.414.0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707A1 1 0 004.343 5.757l.707.707zm1.414 8.486-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z" fill-rule="evenodd" clip-rule="evenodd"/></svg></button></div></nav><div class="main container mx-auto max-w-6xl px-6 flex-grow"><div class=main-post><h1 class=blog-post-title id=post-title>Unbiased median absolute deviation</h1><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg>
<time datetime=2021-02-09>February 9, 2021</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#statistics"/></svg>
Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/>Research
</a><a class=label-link href=https://aakinshin.net/tags/quantile/>Quantile
</a><a class=label-link href=https://aakinshin.net/tags/mad/>Median Absolute Deviation
</a><a class=label-link href=https://aakinshin.net/tags/research-unbiased-mad/>Research: Unbiased median absolute deviation</a></div></div><br><div class="main-content mb-3 px-2 py-1 rounded border text-alert-text-l border-alert-frame-l dark:text-alert-text-d dark:border-alert-frame-d">Update: this blog post is a part of research that aimed to build an unbiased median absolute deviation estimator based on various quantile estimators. A <a href=/posts/preprint-mad-factors/>preprint with final results</a> is available on arXiv: <a href=https://arxiv.org/abs/2207.12005>arXiv:2207.12005 [stat.ME]</a>. Some information in this blog post can be obsolete: please, use the preprint as the primary reference.</div><div class=main-content><p>The <a href=https://en.wikipedia.org/wiki/Median_absolute_deviation>median absolute deviation</a> ($\textrm{MAD}$)
is a robust measure of scale.
For distribution $X$, it can be calculated as follows:</p>$$
\textrm{MAD} = C \cdot \textrm{median}(|X - \textrm{median}(X)|)
$$<p>where $C$ is a constant scale factor.
This metric can be used as a robust alternative to the standard deviation.
If we want to use the $\textrm{MAD}$ as a <a href=https://en.wikipedia.org/wiki/Consistent_estimator>consistent estimator</a>
for the standard deviation under the normal distribution,
we should set</p>$$
C = C_{\infty} = \dfrac{1}{\Phi^{-1}(3/4)} \approx 1.4826022185056.
$$<p>where $\Phi^{-1}$ is the quantile function of the standard normal distribution
(or the inverse of the cumulative distribution function).
If $X$ is the normal distribution, we get $\textrm{MAD} = \sigma$ where $\sigma$ is the standard deviation.</p><p>Now let&rsquo;s consider a sample $x = \{ x_1, x_2, \ldots x_n \}$.
Let&rsquo;s denote the median absolute deviation for a sample of size $n$ as $\textrm{MAD}_n$.
The corresponding equation looks similar to the definition of $\textrm{MAD}$ for a distribution:</p>$$
\textrm{MAD}_n = C_n \cdot \textrm{median}(|x - \textrm{median}(x)|).
$$<p>Let&rsquo;s assume that $\textrm{median}$ is the straightforward definition of the median
(if $n$ is odd, the median is the middle element of the sorted sample,
if $n$ is even, the median is the arithmetic average of the two middle elements of the sorted sample).
We still can use $C_n = C_{\infty}$ for extremely large sample sizes.
However, for small $n$, $\textrm{MAD}_n$ becomes a <a href=https://en.wikipedia.org/wiki/Bias_of_an_estimator>biased estimator</a>.
If we want to get an unbiased version, we should adjust the value of $C_n$.</p><p>In this post, we look at the possible approaches and learn the way to get the exact value of $C_n$
that makes $\textrm{MAD}_n$ unbiased estimator of the median absolute deviation for any $n$.</p><h3 id=the-bias>The bias</h3><p>Let&rsquo;s briefly discuss the impact of the bias on our measurements.
To illustrate the problem, we take $100\,000$ samples of size $n = 5$
from the standard normal distribution and
calculate $\textrm{MAD}_5$ for each of them using $C = 1$.
The obtained numbers form the following distribution:</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/unbiased-mad/img/bias-light.png target=_blank alt=bias><img src=/posts/unbiased-mad/img/bias-light.png width=800>
</a><a class="img-dark hidden" href=/posts/unbiased-mad/img/bias-dark.png target=_blank alt=bias><img src=/posts/unbiased-mad/img/bias-dark.png width=800></a></div><p>If we try to use $\textrm{MAD}_5$ with $C = 1$ as a standard deviation estimator,
it would be a <em>biased estimator</em>.
Indeed, the standard deviation equals $1$ (the true value),
but the expected value of $\textrm{MAD}_5$ is about
$E[\textrm{MAD}_5] \approx 0.5542$.
In order to make it unbiased, we should set $C_5 = 1 / 0.5542 \approx 1.804$.
If we repeat the experiment with the modified scale factor, we get a modified version of our distribution:</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/unbiased-mad/img/bias2-light.png target=_blank alt=bias2><img src=/posts/unbiased-mad/img/bias2-light.png width=800>
</a><a class="img-dark hidden" href=/posts/unbiased-mad/img/bias2-dark.png target=_blank alt=bias2><img src=/posts/unbiased-mad/img/bias2-dark.png width=800></a></div><p>Now $E[\textrm{MAD}_5] \approx 1$ which makes $\textrm{MAD}_5$ <em>unbiased estimator</em>.</p><p>Note that $C_5 = 1.804$ differs from $C_{\infty} \approx 1.4826$ which is the proper scale factor for $n \to \infty$.
Each sample size needs its own scale factor to make $\textrm{MAD}_n$ unbiased.
Let&rsquo;s review some papers and look at different approaches to find the optimal scale factor value.</p><h3 id=literature-overview>Literature overview</h3><p>One of the first mentions of the median absolute deviation can be found in <a href=https://aakinshin.net/library/papers/hampel1974/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>hampel1974</a>.
In this paper, Frank R Hampel introduced $\textrm{MAD}$ as a robust measure of scale
(attributed to Gauss).
I have found four papers that describe unbiased versions:
<a href=https://aakinshin.net/library/papers/croux1992/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>croux1992</a>, <a href=https://aakinshin.net/library/papers/williams2011/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>williams2011</a>, <a href=https://aakinshin.net/library/papers/hayes2014/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>hayes2014</a>, and <a href=https://aakinshin.net/library/papers/park2020/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>park2020</a>.
Let&rsquo;s briefly discuss approaches from these papers.</p><h4 id=the-croux-rousseeuw-approach>The Croux-Rousseeuw approach</h4><p>In <a href=https://aakinshin.net/library/papers/croux1992/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>croux1992</a>, Christophe Croux and Peter J. Rousseeuw
described an unbiased version of $\textrm{MAD}$.
They suggested using the following equations:</p>$$
C_n = \dfrac{b_n}{\Phi^{-1}(3/4)}.
$$<p>For $n \leq 9$, the approximated values of $b_n$ were defined as follows:</p><table><thead><tr><th align=right>n</th><th align=right>$b_n$</th></tr></thead><tbody><tr><td align=right>2</td><td align=right>1.196</td></tr><tr><td align=right>3</td><td align=right>1.495</td></tr><tr><td align=right>4</td><td align=right>1.363</td></tr><tr><td align=right>5</td><td align=right>1.206</td></tr><tr><td align=right>6</td><td align=right>1.200</td></tr><tr><td align=right>7</td><td align=right>1.140</td></tr><tr><td align=right>8</td><td align=right>1.129</td></tr><tr><td align=right>9</td><td align=right>1.107</td></tr></tbody></table><p>For $n > 9$, they suggested to use the following equation:</p>$$
b_n = \dfrac{n}{n-0.8}.
$$<h4 id=the-williams-approach>The Williams approach</h4><p>In <a href=https://aakinshin.net/library/papers/williams2011/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>williams2011</a>, Dennis C. Williams improved this approach.
Firstly, he provided updated $b_n$ values for small $n$:</p><table><thead><tr><th align=right>n</th><th align=right>$b_n$ by Croux</th><th align=right>$b_n$ by Williams</th></tr></thead><tbody><tr><td align=right>2</td><td align=right>1.196</td><td align=right>1.197</td></tr><tr><td align=right>3</td><td align=right>1.495</td><td align=right>1.490</td></tr><tr><td align=right>4</td><td align=right>1.363</td><td align=right>1.360</td></tr><tr><td align=right>5</td><td align=right>1.206</td><td align=right>1.217</td></tr><tr><td align=right>6</td><td align=right>1.200</td><td align=right>1.189</td></tr><tr><td align=right>7</td><td align=right>1.140</td><td align=right>1.138</td></tr><tr><td align=right>8</td><td align=right>1.129</td><td align=right>1.127</td></tr><tr><td align=right>9</td><td align=right>1.107</td><td align=right>1.101</td></tr></tbody></table><p>Secondly, he also introduced a small correction for the general equation:</p>$$
b_n = \dfrac{n}{n-0.801}.
$$<p>Also, he discussed another kind of approximation equation for such kind of bias-correction factors:</p>$$
b_n \cong 1 + cn^{-d}.
$$<p>In his paper, he applied the above equation only to <em>Shorth</em>
(which is the smallest interval that contains at least half of the data points),
but this approach can also be applied to other measures of scale.</p><h4 id=the-hayes-approach>The Hayes approach</h4><p>Next, in <a href=https://aakinshin.net/library/papers/hayes2014/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>hayes2014</a>, Kevin Hayes suggested another kind of prediction equation for $n \geq 9$:</p>$$
C_n = \dfrac{1}{\hat{a}_n}
$$<p>where</p>$$
\hat{a}_n = \Phi^{-1}(3/4) \Bigg( 1 - \dfrac{\alpha}{n} - \dfrac{\beta}{n^2} \Bigg).
$$<p>Here are the suggested constants:</p><table><thead><tr><th align=right>n</th><th align=right>$\alpha$</th><th align=right>$\beta$</th></tr></thead><tbody><tr><td align=right>odd</td><td align=right>0.7635</td><td align=right>0.565</td></tr><tr><td align=right>even</td><td align=right>0.7612</td><td align=right>1.123</td></tr></tbody></table><h4 id=the-park-kim-wang-approach>The Park-Kim-Wang approach</h4><p>Finally, in <a href=https://aakinshin.net/library/papers/park2020/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>park2020</a>, Chanseok Park, Haewon Kim, and Min Wang aggregated all of the previous results.
They used the following form of the main equation:</p>$$
C_n = \dfrac{1}{\Phi^{-1}(3/4) \cdot (1+A_n)}
$$<p>For $n > 100$, they suggested two approaches.
The first one is based on <a href=https://aakinshin.net/library/papers/hayes2014/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>hayes2014</a> (the same equation for both odd and even $n$ values):</p>$$
A_n = -\dfrac{0.76213}{n} - \dfrac{0.86413}{n^2}
$$<p>The second one is based on <a href=https://aakinshin.net/library/papers/williams2011/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>williams2011</a>:</p>$$
A_n = -0.804168866 \cdot n^{-1.008922}
$$<p>Both approaches produce almost identical results, so it doesn&rsquo;t actually matter which one to use.</p><p>For $2 \leq n \leq 100$, they suggested to use predefined constants:
(the below values are based on Table A2 from <a href=https://aakinshin.net/library/papers/park2020/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>park2020</a>):</p><table><thead><tr><th align=right>n</th><th align=right>$C_n$</th><th align=right>n</th><th align=right>$C_n$</th></tr></thead><tbody><tr><td align=right>1</td><td align=right>NA</td><td align=right>51</td><td align=right>1.505611</td></tr><tr><td align=right>2</td><td align=right>1.772150</td><td align=right>52</td><td align=right>1.505172</td></tr><tr><td align=right>3</td><td align=right>2.204907</td><td align=right>53</td><td align=right>1.504575</td></tr><tr><td align=right>4</td><td align=right>2.016673</td><td align=right>54</td><td align=right>1.504417</td></tr><tr><td align=right>5</td><td align=right>1.803927</td><td align=right>55</td><td align=right>1.503713</td></tr><tr><td align=right>6</td><td align=right>1.763788</td><td align=right>56</td><td align=right>1.503604</td></tr><tr><td align=right>7</td><td align=right>1.686813</td><td align=right>57</td><td align=right>1.503095</td></tr><tr><td align=right>8</td><td align=right>1.671843</td><td align=right>58</td><td align=right>1.502864</td></tr><tr><td align=right>9</td><td align=right>1.632940</td><td align=right>59</td><td align=right>1.502253</td></tr><tr><td align=right>10</td><td align=right>1.624681</td><td align=right>60</td><td align=right>1.502085</td></tr><tr><td align=right>11</td><td align=right>1.601308</td><td align=right>61</td><td align=right>1.501611</td></tr><tr><td align=right>12</td><td align=right>1.596155</td><td align=right>62</td><td align=right>1.501460</td></tr><tr><td align=right>13</td><td align=right>1.580754</td><td align=right>63</td><td align=right>1.501019</td></tr><tr><td align=right>14</td><td align=right>1.577272</td><td align=right>64</td><td align=right>1.500841</td></tr><tr><td align=right>15</td><td align=right>1.566339</td><td align=right>65</td><td align=right>1.500331</td></tr><tr><td align=right>16</td><td align=right>1.563769</td><td align=right>66</td><td align=right>1.500343</td></tr><tr><td align=right>17</td><td align=right>1.555284</td><td align=right>67</td><td align=right>1.499877</td></tr><tr><td align=right>18</td><td align=right>1.553370</td><td align=right>68</td><td align=right>1.499772</td></tr><tr><td align=right>19</td><td align=right>1.547206</td><td align=right>69</td><td align=right>1.499291</td></tr><tr><td align=right>20</td><td align=right>1.545705</td><td align=right>70</td><td align=right>1.499216</td></tr><tr><td align=right>21</td><td align=right>1.540681</td><td align=right>71</td><td align=right>1.498922</td></tr><tr><td align=right>22</td><td align=right>1.539302</td><td align=right>72</td><td align=right>1.498838</td></tr><tr><td align=right>23</td><td align=right>1.535165</td><td align=right>73</td><td align=right>1.498491</td></tr><tr><td align=right>24</td><td align=right>1.534053</td><td align=right>74</td><td align=right>1.498399</td></tr><tr><td align=right>25</td><td align=right>1.530517</td><td align=right>75</td><td align=right>1.497917</td></tr><tr><td align=right>26</td><td align=right>1.529996</td><td align=right>76</td><td align=right>1.497901</td></tr><tr><td align=right>27</td><td align=right>1.526916</td><td align=right>77</td><td align=right>1.497489</td></tr><tr><td align=right>28</td><td align=right>1.526422</td><td align=right>78</td><td align=right>1.497544</td></tr><tr><td align=right>29</td><td align=right>1.523608</td><td align=right>79</td><td align=right>1.497248</td></tr><tr><td align=right>30</td><td align=right>1.523031</td><td align=right>80</td><td align=right>1.497185</td></tr><tr><td align=right>31</td><td align=right>1.520732</td><td align=right>81</td><td align=right>1.496797</td></tr><tr><td align=right>32</td><td align=right>1.520333</td><td align=right>82</td><td align=right>1.496779</td></tr><tr><td align=right>33</td><td align=right>1.518509</td><td align=right>83</td><td align=right>1.496428</td></tr><tr><td align=right>34</td><td align=right>1.517941</td><td align=right>84</td><td align=right>1.496501</td></tr><tr><td align=right>35</td><td align=right>1.516279</td><td align=right>85</td><td align=right>1.496295</td></tr><tr><td align=right>36</td><td align=right>1.516070</td><td align=right>86</td><td align=right>1.496089</td></tr><tr><td align=right>37</td><td align=right>1.514425</td><td align=right>87</td><td align=right>1.495794</td></tr><tr><td align=right>38</td><td align=right>1.513989</td><td align=right>88</td><td align=right>1.495796</td></tr><tr><td align=right>39</td><td align=right>1.512747</td><td align=right>89</td><td align=right>1.495557</td></tr><tr><td align=right>40</td><td align=right>1.512418</td><td align=right>90</td><td align=right>1.495420</td></tr><tr><td align=right>41</td><td align=right>1.511078</td><td align=right>91</td><td align=right>1.495270</td></tr><tr><td align=right>42</td><td align=right>1.511041</td><td align=right>92</td><td align=right>1.495141</td></tr><tr><td align=right>43</td><td align=right>1.509858</td><td align=right>93</td><td align=right>1.494944</td></tr><tr><td align=right>44</td><td align=right>1.509499</td><td align=right>94</td><td align=right>1.494958</td></tr><tr><td align=right>45</td><td align=right>1.508529</td><td align=right>95</td><td align=right>1.494706</td></tr><tr><td align=right>46</td><td align=right>1.508365</td><td align=right>96</td><td align=right>1.494665</td></tr><tr><td align=right>47</td><td align=right>1.507535</td><td align=right>97</td><td align=right>1.494379</td></tr><tr><td align=right>48</td><td align=right>1.507247</td><td align=right>98</td><td align=right>1.494331</td></tr><tr><td align=right>49</td><td align=right>1.506382</td><td align=right>99</td><td align=right>1.494113</td></tr><tr><td align=right>50</td><td align=right>1.506307</td><td align=right>100</td><td align=right>1.494199</td></tr></tbody></table><p>Here is the corresponding plot:</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/unbiased-mad/img/factors-light.png target=_blank alt=factors><img src=/posts/unbiased-mad/img/factors-light.png width=800>
</a><a class="img-dark hidden" href=/posts/unbiased-mad/img/factors-dark.png target=_blank alt=factors><img src=/posts/unbiased-mad/img/factors-dark.png width=800></a></div><h3 id=conclusion>Conclusion</h3><p>Currently, my tool-of-choice is the approach from <a href=https://aakinshin.net/library/papers/park2020/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>park2020</a>].
I verified all the predefined constants and equations from the paper using numerical simulations.
I can confirm that the suggested approach produces
a reliable estimate of the unbiased median absolute deviation $\textrm{MAD}_n$.</p><h3 id=references>References</h3><ul><li><b id=Hampel1974>[Hampel1974]</b><br>Hampel, Frank R. &ldquo;The influence curve and its role in robust estimation.&rdquo; Journal of the american statistical association 69, no. 346 (1974): 383-393.<br><a href=https://doi.org/10.2307/2285666>https://doi.org/10.2307/2285666</a></li><li><b id=Croux1992>[Croux1992]</b><br>Croux, Christophe, and Peter J. Rousseeuw. &ldquo;Time-efficient algorithms for two highly robust estimators of scale.&ldquo;In Computational statistics, pp. 411-428. Physica, Heidelberg, 1992.<br><a href=https://doi.org/10.1007/978-3-662-26811-7_58>https://doi.org/10.1007/978-3-662-26811-7_58</a></li><li><b id=Williams2011>[Williams2011]</b><br>Williams, Dennis C. &ldquo;Finite sample correction factors for several simple robust estimators of normal standard deviation.&rdquo; Journal of Statistical Computation and Simulation 81, no. 11 (2011): 1697-1702.<br><a href=https://doi.org/10.1080/00949655.2010.499516>https://doi.org/10.1080/00949655.2010.499516</a></li><li><b id=Hayes2014>[Hayes2014]</b><br>Hayes, Kevin. &ldquo;Finite-sample bias-correction factors for the median absolute deviation.&rdquo; Communications in Statistics-Simulation and Computation 43, no. 10 (2014): 2205-2212.<br><a href=https://doi.org/10.1080/03610918.2012.748913>https://doi.org/10.1080/03610918.2012.748913</a></li><li><b id=Park2020>[Park2020]</b><br>Park, Chanseok, Haewon Kim, and Min Wang. &ldquo;Investigation of finite-sample properties of robust location and scale estimators.&rdquo; Communications in Statistics-Simulation and Computation (2020): 1-27.<br><a href=https://doi.org/10.1080/03610918.2019.1699114>https://doi.org/10.1080/03610918.2019.1699114</a></li></ul></div><hr><h3 id=references>References (5)</h3><ol><li><a href=https://aakinshin.net/library/papers/ title="Library / papers"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>
</a><a href=https://aakinshin.net/library/papers/croux1992/>Time-Efficient Algorithms for Two Highly Robust Estimators of Scale
</a>(1992)
by
<a href=https://aakinshin.net/library/authors/christophe-croux/>Christophe Croux</a>
et al.
<span class=label title=Backlinks:2><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>2</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/library/papers/ title="Library / papers"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>
</a><a href=https://aakinshin.net/library/papers/hampel1974/>The Influence Curve and Its Role in Robust Estimation
</a>(1974)
by
<a href=https://aakinshin.net/library/authors/frank-r-hampel/>Frank R Hampel</a>
<span class=label title=Backlinks:1><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>1</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/library/papers/ title="Library / papers"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>
</a><a href=https://aakinshin.net/library/papers/hayes2014/>Finite-Sample Bias-Correction Factors for the Median Absolute Deviation
</a>(2014)
by
<a href=https://aakinshin.net/library/authors/kevin-hayes/>Kevin Hayes</a>
<span class=label title=Backlinks:2><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>2</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/library/papers/ title="Library / papers"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>
</a><a href=https://aakinshin.net/library/papers/park2020/>Investigation of finite-sample Properties of Robust Location and Scale Estimators
</a>(2020)
by
<a href=https://aakinshin.net/library/authors/chanseok-park/>Chanseok Park</a>
et al.
<span class=label title=Backlinks:6><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>6</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/library/papers/ title="Library / papers"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#paper"/></svg>
</a><a href=https://aakinshin.net/library/papers/williams2011/>Finite Sample Correction Factors for Several Simple Robust Estimators of Normal Standard Deviation
</a>(2011)
by
<a href=https://aakinshin.net/library/authors/dennis-c-williams/>Dennis C Williams</a>
<span class=label title=Backlinks:1><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>1</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li></ol><h3 id=backlinks>Backlinks (7)</h3><ol><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/dispersion-exponential-smoothing/>Dispersion exponential smoothing
</a>(2021-05-11)
<span class=label title=References:4><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>4</span>
<span class=label title=Backlinks:3><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>3</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/gamma-es-mnzqad/>Gamma effect size powered by the middle non-zero quantile absolute deviation
</a>(2022-02-22)
<span class=label title=References:7><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>7</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/mnzqad/>Middle non-zero quantile absolute deviation
</a>(2022-02-15)
<span class=label title=References:4><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>4</span>
<span class=label title=Backlinks:4><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>4</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/nonparametric-effect-size2/>Customization of the nonparametric Cohen's d-consistent effect size
</a>(2021-06-08)
<span class=label title=References:16><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>16</span>
<span class=label title=Backlinks:3><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>3</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/unbiased-mad-hd/>Unbiased median absolute deviation based on the Harrell-Davis quantile estimator
</a>(2021-02-16)
<span class=label title=References:4><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>4</span>
<span class=label title=Backlinks:5><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>5</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/unbiased-mad-n2/>Unbiased median absolute deviation for n=2
</a>(2022-04-26)
<span class=label title=References:3><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>3</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li><li><a href=https://aakinshin.net/posts/ title="Library / posts"><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>
</a><a href=https://aakinshin.net/posts/unbiased-mad-thd/>Unbiased median absolute deviation based on the trimmed Harrell-Davis quantile estimator
</a>(2022-02-08)
<span class=label title=References:4><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#reference"/></svg>4</span>
<span class=label title=Backlinks:2><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#backlink"/></svg>2</span>
<a href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><title>Mathematics</title><use xlink:href="/img/fa/all.svg#math"/></svg>
</a><a href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><title>Statistics</title><use xlink:href="/img/fa/all.svg#statistics"/></svg></a></li></ol></div></div><script>var themeToggleDarkIcon=document.getElementById("theme-toggle-dark-icon"),themeToggleBtn,themeToggleLightIcon=document.getElementById("theme-toggle-light-icon");const imagesDark=document.querySelectorAll(".img-dark"),imagesLight=document.querySelectorAll(".img-light");localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?(themeToggleLightIcon.classList.remove("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")})):(themeToggleDarkIcon.classList.remove("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}));function toggleTheme(e){e?(document.documentElement.classList.add("dark"),themeToggleLightIcon.classList.remove("hidden"),themeToggleDarkIcon.classList.add("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")}),imagesLight.forEach(e=>{e.classList.add("hidden")})):(document.documentElement.classList.remove("dark"),themeToggleDarkIcon.classList.remove("hidden"),themeToggleLightIcon.classList.add("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}),imagesDark.forEach(e=>{e.classList.add("hidden")}))}themeToggleBtn=document.getElementById("theme-toggle"),themeToggleBtn.addEventListener("click",function(){themeToggleDarkIcon.classList.toggle("hidden"),themeToggleLightIcon.classList.toggle("hidden"),imagesLight.forEach(e=>{e.classList.toggle("hidden")}),imagesDark.forEach(e=>{e.classList.toggle("hidden")}),event.altKey?(localStorage.removeItem("color-theme"),toggleTheme(window.matchMedia("(prefers-color-scheme: dark)").matches)):localStorage.getItem("color-theme")?localStorage.getItem("color-theme")==="light"?(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark")):(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):document.documentElement.classList.contains("dark")?(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark"))}),window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",e=>{if(localStorage.getItem("color-theme")===null){const t=e.matches?"dark":"light";toggleTheme(t==="dark")}})</script><footer class="z-20 p-4 md:p-6 mt-3 w-full border-t border-gray-200 shadow flex items-center justify-center dark:border-gray-600 bg-white dark:bg-zinc-800"><span class="dark:text-gray-400 text-center">© 2013—2024 <span class=whitespace-nowrap>Andrey Akinshin</span></span><ul class="flex flex-wrap items-center px-4 mb-1"><li><a href=https://github.com/AndreyAkinshin><svg class="fai fai-link w-5 h-5"><title>GitHub</title><use xlink:href="/img/fa/all.svg#github"/></svg></a></li><li><a href=https://twitter.com/andrey_akinshin><svg class="fai fai-link w-5 h-5"><title>Twitter</title><use xlink:href="/img/fa/all.svg#twitter"/></svg></a></li><li><a href=https://aakinshin.net/posts/index.xml><svg class="fai fai-link w-5 h-5"><title>RSS</title><use xlink:href="/img/fa/all.svg#rss"/></svg></a></li></ul><div class=main-content><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></div></footer><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+=" has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script></body></html>