<!doctype html><html lang=en class=h-100><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.103.0-DEV"><meta name=author content="Andrey Akinshin"><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content="Mathematics,Statistics,Research,Quantile,Effect Size,Research: Gamma Effect Size"><title>A single outlier could completely distort your Cohen's d value | Andrey Akinshin</title><meta name=description content="Comparison of classic Cohen's d and its non-parametric alternative on distributions with high outliers"><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><link href=https://aakinshin.net/sass/bootstrap-light.min.css theme=light rel=stylesheet type=text/css media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link href=https://aakinshin.net/sass/bootstrap-dark.min.css theme=dark rel=stylesheet type=text/css media="(prefers-color-scheme: dark)"><script src=https://aakinshin.net/js/theme-before.min.d7f6578e23ad3f0c33c589f9bcb34f995b45121f1f3ce888869c86b26826c845.js></script>
<script type=module src=https://aakinshin.net/js/dark-mode-toggle.min.9e68d431432744c07a43381a8a833ffe0921cc0e006d84ad97f0b0d43c5cd82d.mjs></script>
<link href=https://aakinshin.net/css/fontawesome-all.min.178e95bba6ea2e9a90838cd646658f4bf6667a6ceaa057cb587bf7e6eb8412d3.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/about.min.60773ab7266ecc6e9625306f57c0a82a219b011dc3ea2d83763d1ecdf11c86d2.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/blog.min.7e186db80d8c431d196b3e0718afb0636b82a269a8c92521c11a55267a24fc27.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"><script src=/js/jquery-3.3.1.slim.min.js></script></head><body class="d-flex flex-column min-vh-100"><div class=bg-primary><div class="container bg-primary"><nav class="navbar navbar-expand-sm navbar-dark bg-primary"><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link id=nav-link-blog href=https://aakinshin.net/><i class="fas fa-home" title=Home style=color:#fff></i></a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-expanded=false>Blog</a><ul class="dropdown-menu bg-primary"><li><a class=dropdown-item href=https://aakinshin.net/posts/>All Posts</a></li><li><a class=dropdown-item href=https://aakinshin.net/tags/statistics/>Posts about Statistics</a></li><li></li><a class=dropdown-item href=https://aakinshin.net/tags/>All Tags</a></li></ul></li><li class=nav-item><a class=nav-link id=nav-link-about href=https://aakinshin.net/about/>About</a></li></ul><ul class="navbar-nav ms-auto"><li class=nav-item><dark-mode-toggle permanent=true></dark-mode-toggle></li></ul></nav></div></div><div class=container><main id=main><div class=blog-main><div class="blog-post table-sm"><h1 class=blog-post-title id=post-title>A single outlier could completely distort your Cohen's d value</h1><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-01-26>January 26, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>
&nbsp;
<a href=https://aakinshin.net/tags/mathematics/ class="badge badge-info">Mathematics</a>
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research/ class="badge badge-info">Research</a>
<a href=https://aakinshin.net/tags/quantile/ class="badge badge-info">Quantile</a>
<a href=https://aakinshin.net/tags/effect-size/ class="badge badge-info">Effect Size</a>
<a href=https://aakinshin.net/tags/research-gamma-es/ class="badge badge-info">Research: Gamma Effect Size</a></span><br><br><p><a href="https://en.wikipedia.org/wiki/Effect_size#Cohen's_d">Cohen&rsquo;s d</a> is a popular way to estimate
the <a href=https://en.wikipedia.org/wiki/Effect_size>effect size</a> between two samples.
It works excellent for perfectly normal distributions.
Usually, people think that slight deviations from normality
shouldn&rsquo;t produce a noticeable impact on the result.
Unfortunately, it&rsquo;s not always true.
In fact, a single outlier value can completely distort the result even in large samples.</p><p>In this post, I will present some illustrations for this problem and will show how to fix it.</p><h3 id=cohens-d>Cohen&rsquo;s d</h3><p>First of all, let&rsquo;s recall the definition of Cohen&rsquo;s d.
For two samples <span class="math inline">\(x = \{ x_1, x_2, \ldots, x_n \}\)</span> and <span class="math inline">\(y = \{ y_1, y_2, \ldots, y_n \}\)</span>,
the <em>Cohen&rsquo;s d</em> is defined as follows (<a href=#Cohen1988>[Cohen1988]</a>):</p><p><span class="math display">\[d_{xy} = \frac{\overline{y}-\overline{x}}{s_{xy}}
\]</span></p><p>where <span class="math inline">\(s_{xy}\)</span> is the <a href=https://en.wikipedia.org/wiki/Pooled_standard_deviation>pooled standard deviation</a>:</p><p><span class="math display">\[s_{xy} = \sqrt{\frac{(n_x - 1) s^2_x + (n_y - 1) s^2_y}{n_x + n_y - 2}}.
\]</span></p><p>There is a rule of thumb that is widely used to interpret Cohen&rsquo;s d value:</p><table><thead><tr><th>d</th><th>Effect</th></tr></thead><tbody><tr><td>0.2</td><td>Small</td></tr><tr><td>0.5</td><td>Medium</td></tr><tr><td>0.8</td><td>Large</td></tr></tbody></table><p>E.g., if <span class="math inline">\(d_{xy} < 0.2\)</span>, we can say that the difference between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> is small.
If <span class="math inline">\(d_{xy} > 0.8\)</span>, the difference is large</p><h3 id=the-problem>The problem</h3><p>Now we are going to discuss a simple example that demonstrates the effect of a single outlier.
Let&rsquo;s consider the two following small samples:</p><p><span class="math display">\[x = \{ -1.4,\; -1,\; -0.2,\; 0,\; 0.2,\; 1,\; 1.4 \} \quad \big( \overline{x} = 0,\; s_x = 1 \big),
\]</span></p><p><span class="math display">\[y = \{ -0.4,\; 0,\; 0.8,\; 1,\; 1.2,\; 2,\; 2.4 \} \quad \big( \overline{y} = 0,\; s_y = 1 \big).
\]</span></p><p>Thus, the Cohen&rsquo;s d equals <span class="math inline">\(1\)</span>:</p><p><span class="math display">\[d_{xy} = \frac{\overline{y}-\overline{x}}{s_{xy}} = \frac{1 - 0}{1} = 1.
\]</span></p><p>We can see that <span class="math inline">\(d_{xy}\)</span> describes a large effect (because it&rsquo;s larger than 0.8 which is the large effect threshold).</p><p>Now let&rsquo;s replace the last element of <span class="math inline">\(y\)</span> with a high outlier and build a new sample <span class="math inline">\(z\)</span>:</p><p><span class="math display">\[z = \{ -0.4,\; 0,\; 0.8,\; 1,\; 1.2,\; 2,\; 100 \} \quad \big( \overline{z} \approx 14.08,\; s_{z} \approx 37.89 \big).
\]</span></p><p>Since the mean value has been significantly increased
(<span class="math inline">\(\overline{z} \approx 14.08 \gg \overline{y} = 0\)</span>),
we could expect that the Cohen&rsquo;s d value should be increased as well.
However, we observe an opposite situation because of the increased pooled standard deviation:</p><p><span class="math display">\[s_{xz} = \sqrt{\frac{(n_x - 1) s^2_x + (n_z - 1) s^2_z}{n_x + n_z - 2}} =
\sqrt{\frac{6\cdot 1^2 + 6\cdot 37.89^2}{12}} \approx 26.8.
\]</span></p><p><span class="math display">\[d_{xz} = \frac{\overline{z}-\overline{x}}{s_{xz}} \approx
\frac{14.08}{26.8} \approx 0.53.
\]</span></p><p>As we can see, this outlier spoiled our conclusion.
Now, the Cohen&rsquo;s d equals 0.53 (medium effect) instead of 1.0 (large effect).
Technically, the result is correct (because the standard deviation of <span class="math inline">\(z\)</span> is huge),
but it doesn&rsquo;t properly describe the actual difference between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</p><p>Here you could say that the size of the considered samples is too small,
it&rsquo;s not enough to get a reasonable Cohen&rsquo;s d value.
OK, let&rsquo;s see what kind of situation we get on larger samples.</p><h3 id=numerical-simulations>Numerical simulations</h3><p>Let&rsquo;s conduct the following simulation:</p><ul><li>Generate random sample <span class="math inline">\(x = \{x_1, \ldots, x_n \}\)</span> from <span class="math inline">\(\mathcal{N}(0, 1^2)\)</span>.</li><li>Generate random sample <span class="math inline">\(y = \{y_1, \ldots, y_n \}\)</span> from <span class="math inline">\(\mathcal{N}(1, 1^2)\)</span>
and replace <span class="math inline">\(y_n\)</span> with <span class="math inline">\(y_n = 100\)</span>.</li><li>Calculate the Cohen&rsquo;s d value between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</li><li>Repeat steps previous three steps 1000 times.</li><li>Build a distribution based on 1000 collected Cohen&rsquo;s d values.</li></ul><p>Below you can see corresponding density plots (KDE, normal kernel, Sheather & Jones)
for <span class="math inline">\(n = 50\)</span>, <span class="math inline">\(n = 500\)</span>, and <span class="math inline">\(n = 1000\)</span>.</p><div class=row><div class=mx-auto><a href=/posts/cohend-and-outliers/img/cohen-light.png target=_blank class=imgldlink alt=cohen><picture><source theme=dark srcset=/posts/cohend-and-outliers/img/cohen-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/cohend-and-outliers/img/cohen-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/cohend-and-outliers/img/cohen-light.png></picture></a></div></div><br><p>In these simulation, we got the following results:</p><ul><li><span class="math inline">\(n=50\)</span>: all Cohen&rsquo;s d values are inside <span class="math inline">\([0.23; 0.37]\)</span></li><li><span class="math inline">\(n=500\)</span>: all Cohen&rsquo;s d values are inside <span class="math inline">\([0.30; 0.43]\)</span></li><li><span class="math inline">\(n=1000\)</span>: all Cohen&rsquo;s d values are inside <span class="math inline">\([0.39; 0.51]\)</span></li></ul><p>As you can see, instead of the expected large effect (<span class="math inline">\(d = 1\)</span>),
we constantly get small or medium effect (<span class="math inline">\(d < 0.52\)</span>).
Even when <span class="math inline">\(n = 1000\)</span>, a single extreme number could completely distort the result.</p><p>So, how to solve this problem?</p><h3 id=the-solution>The solution</h3><p>In one of the previous posts, I <a href=https://aakinshin.net/posts/nonparametric-effect-size/>described</a>
a nonparametric effect size estimator which is consistent with Cohen&rsquo;s d.
Here is a quick definition:</p><div class=row><div class=mx-auto><a href=/posts/cohend-and-outliers/img/blackboard.png target=_blank alt=blackboard><img class="mx-auto d-block img-fluid" width=800 src=/posts/cohend-and-outliers/img/blackboard.png></a></div></div><br><p>The effect size <span class="math inline">\(\gamma_p\)</span> can be estimated as follows:</p><p><span class="math display">\[\gamma_p = \frac{Q_p(y) - Q_p(x)}{\mathcal{PMAD}_{xy}},
\]</span></p><p>where <span class="math inline">\(\mathcal{PMAD}_{xy}\)</span> is the pooled median absolute deviation:</p><p><span class="math display">\[\mathcal{PMAD}_{xy} = \sqrt{\frac{(n_y - 1) \mathcal{MAD}^2_y + (n_y - 1) \mathcal{MAD}^2_y}{n_x + n_y - 2}}.
\]</span></p><p>In this post, we are going to apply it only for the median (we need only <span class="math inline">\(\gamma_{0.5}\)</span>).
In order to improve the accuracy, we use the Harrell-Davis quantile estimator (<a href=#Harrell1982>[Harrell1982]</a>)
to estimate the median (<span class="math inline">\(Q_{0.5}\)</span>) and the median absolute deviation (<span class="math inline">\(\mathcal{MAD}_x\)</span>, <span class="math inline">\(\mathcal{MAD}_y\)</span>).
The consistency constant <span class="math inline">\(C\)</span> for <span class="math inline">\(\mathcal{MAD}\)</span> equals <span class="math inline">\(1.4826\)</span>, which makes <span class="math inline">\(\mathcal{MAD}\)</span> a consistent estimator for the standard deviation estimation.</p><p>Thus, in the case of the normal distribution, <span class="math inline">\(\gamma_p\)</span> could be used as a good approximation of the Cohen&rsquo;s d.
In this case of non-normal distribution, it provides a robust and stable alternative to the Cohen&rsquo;s d.</p><p>Let&rsquo;s repeat the above simulation with outliers and build corresponding density plots for <span class="math inline">\(\gamma_{0.5}\)</span>:</p><div class=row><div class=mx-auto><a href=/posts/cohend-and-outliers/img/cohen-vs-gamma-light.png target=_blank class=imgldlink alt=cohen-vs-gamma><picture><source theme=dark srcset=/posts/cohend-and-outliers/img/cohen-vs-gamma-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/cohend-and-outliers/img/cohen-vs-gamma-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/cohend-and-outliers/img/cohen-vs-gamma-light.png></picture></a></div></div><br><p>As you can see, a single outlier couldn&rsquo;t spoil the <span class="math inline">\(\gamma_{0.5}\)</span> values.
The obtained effect size values are normally distributed around <span class="math inline">\(1.0\)</span>, which is the true effect size value.</p><h3 id=conclusion>Conclusion</h3><p>The <span class="math inline">\(\gamma_p\)</span> effect size is a good alternative for Cohen&rsquo;s d.
For the normal distributions, it works similar to Cohen&rsquo;s d.
<span class="math inline">\(\gamma_p\)</span> based on two robust metrics
(the Harrell-Davis powered medians and median absolution deviations)
instead of non-robust metrics in the original Cohen&rsquo;s d equation
(the mean and the standard deviation).
Thus <span class="math inline">\(\gamma_p\)</span> is also robust and works well even when we observe deviations from normality.
In the case of non-normal distributions, it allows comparing individual quantiles instead of focusing only on the central tendency like the mean or the median.</p><h3 id=references>References</h3><ul><li><b id=Cohen1988>[Cohen1988]</b><br>Cohen, Jacob. (1988).
Statistical Power Analysis for the Behavioral Sciences.
New York, NY: Routledge Academic</li><li><b id=Harrell1982>[Harrell1982]</b><br>Harrell, F.E. and Davis, C.E., 1982.
&ldquo;A new distribution-free quantile estimator.&rdquo;
<em>Biometrika</em>, 69(3), pp.635-640.<br><a href=https://pdfs.semanticscholar.org/1a48/9bb74293753023c5bb6bff8e41e8fe68060f.pdf>https://pdfs.semanticscholar.org/1a48/9bb74293753023c5bb6bff8e41e8fe68060f.pdf</a></li></ul><br><br><div class=row><div class="justify-content-center share-block"><div class=share-title>Share:</div><div class=share-button><a href="https://www.reddit.com/submit?url=https%3a%2f%2faakinshin.net%2fposts%2fcohend-and-outliers%2f&title=A%20single%20outlier%20could%20completely%20distort%20your%20Cohen%27s%20d%20value" target=_blank title="Share on Reddit"><i class="fab fa-reddit fa-2x"></i></a></div><div class=share-button><a href="https://twitter.com/intent/tweet?text=A%20single%20outlier%20could%20completely%20distort%20your%20Cohen%27s%20d%20value&url=https%3a%2f%2faakinshin.net%2fposts%2fcohend-and-outliers%2f&via=andrey_akinshin&related=andrey_akinshin" rel=nofollow target=_blank title="Share on Twitter"><i class="fab fa-twitter fa-2x"></i></a></div><div class=share-button><a href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2faakinshin.net%2fposts%2fcohend-and-outliers%2f" target=_blank title="Share on HackerNews"><i class="fab fa-hacker-news fa-2x"></i></a></div><div class=share-button><a href="https://getpocket.com/save?url=https%3a%2f%2faakinshin.net%2fposts%2fcohend-and-outliers%2f&title=A%20single%20outlier%20could%20completely%20distort%20your%20Cohen%27s%20d%20value" target=_blank title="Add to Pocket"><i class="fab fa-get-pocket fa-2x"></i></a></div></div></div></div><hr></div></div></main></div><footer class="blog-footer mt-auto"><div class=container><p>&copy; 2013&mdash;2022 Andrey Akinshin
|
<a href=https://github.com/AndreyAkinshin><i class="fab fa-github" title=GitHub></i></a>
<a href=https://twitter.com/andrey_akinshin><i class="fab fa-twitter" title=Twitter></i></a>
<a href=https://aakinshin.net/posts/index.xml><i class="fas fa-rss" title=RSS></i></a>
|
<a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></p></div></footer><script src=https://aakinshin.net/js/theme-after.min.c26550621ac13c2221d7f6f5e6fe862345d3919723c50d730893e3e4856ecf35.js></script>
<script src=/js/bootstrap.bundle.min.js></script>
<script src=/js/anchor.min.js></script>
<script src=https://aakinshin.net/js/custom.min.f6e5d13fe39f305056cc743ee4cb8d117c1aba26176e58c82c79a480d02fe4b7.js></script>
<script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></body></html>