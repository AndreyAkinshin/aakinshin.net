<!doctype html><html lang=en class=h-100><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.103.0-DEV"><meta name=author content="Andrey Akinshin"><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content="Mathematics,Statistics,Research,Quantile,Winsorizing,Harrell-Davis quantile estimator,Research: Building trimmed Harrell-Davis quantile estimator"><title>Winsorized modification of the Harrell-Davis quantile estimator | Andrey Akinshin</title><meta name=description content="A modified version of the Harrell-Davis quantile estimator with better robustness"><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><link href=https://aakinshin.net/sass/bootstrap-light.min.css theme=light rel=stylesheet type=text/css media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link href=https://aakinshin.net/sass/bootstrap-dark.min.css theme=dark rel=stylesheet type=text/css media="(prefers-color-scheme: dark)"><script src=https://aakinshin.net/js/theme-before.min.d7f6578e23ad3f0c33c589f9bcb34f995b45121f1f3ce888869c86b26826c845.js></script>
<script type=module src=https://aakinshin.net/js/dark-mode-toggle.min.9e68d431432744c07a43381a8a833ffe0921cc0e006d84ad97f0b0d43c5cd82d.mjs></script>
<link href=https://aakinshin.net/css/fontawesome-all.min.178e95bba6ea2e9a90838cd646658f4bf6667a6ceaa057cb587bf7e6eb8412d3.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/about.min.2a76db7cc14055b3bafacc363f453917ab54a818a7db2a0a9b2409c0f6bf07c5.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/blog.min.7e186db80d8c431d196b3e0718afb0636b82a269a8c92521c11a55267a24fc27.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZVB6MXSX32"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-ZVB6MXSX32")</script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-41419012-5"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","UA-41419012-5")</script><script type=text/javascript>(function(e,t,n,s,o,i,a){e[o]=e[o]||function(){(e[o].a=e[o].a||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym"),ym(28700916,"init",{clickmap:!0,trackLinks:!0,accurateTrackBounce:!0})</script><noscript><div><img src=https://mc.yandex.ru/watch/28700916 style=position:absolute;left:-9999px alt></div></noscript><script src=/js/jquery-3.3.1.slim.min.js></script></head><body><div class=bg-primary><div class="container bg-primary"><nav class="navbar navbar-expand-sm navbar-dark bg-primary"><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link id=nav-link-blog href=https://aakinshin.net/><i class="fas fa-home" title=Home style=color:#fff></i></a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-expanded=false>Blog</a><ul class="dropdown-menu bg-primary"><li><a class=dropdown-item href=https://aakinshin.net/posts/>All Posts</a></li><li><a class=dropdown-item href=https://aakinshin.net/tags/statistics/>Posts about Statistics</a></li><li></li><a class=dropdown-item href=https://aakinshin.net/tags/>All Tags</a></li></ul></li><li class=nav-item><a class=nav-link id=nav-link-about href=https://aakinshin.net/about/>About</a></li></ul><ul class="navbar-nav ms-auto"><li class=nav-item><dark-mode-toggle permanent=true></dark-mode-toggle></li></ul></nav></div></div><div class=container><main id=main><div class=blog-main><div class="blog-post table-sm"><h1 class=blog-post-title id=post-title>Winsorized modification of the Harrell-Davis quantile estimator</h1><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-03-02>March 2, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>
&nbsp;
<a href=https://aakinshin.net/tags/mathematics/ class="badge badge-info">Mathematics</a>
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research/ class="badge badge-info">Research</a>
<a href=https://aakinshin.net/tags/quantile/ class="badge badge-info">Quantile</a>
<a href=https://aakinshin.net/tags/winsorizing/ class="badge badge-info">Winsorizing</a>
<a href=https://aakinshin.net/tags/harrell-davis-quantile-estimator/ class="badge badge-info">Harrell-Davis quantile estimator</a>
<a href=https://aakinshin.net/tags/research-thdqe/ class="badge badge-info">Research: Building trimmed Harrell-Davis quantile estimator</a></span><br><br><strong>Update: this blog post is a part of research that aimed to build a statistically efficient and robust quantile estimator. A <a href=/posts/pub-thdqe/>paper with final results</a> is available in <em>Communications in Statistics - Simulation and Computation</em> (DOI: <a href=https://www.tandfonline.com/doi/abs/10.1080/03610918.2022.2050396>10.1080/03610918.2022.2050396</a>). A preprint is available on arXiv: <a href=https://arxiv.org/abs/2111.11776>arXiv:2111.11776 [stat.ME]</a>. Some information in this blog post can be obsolete: please, use the official paper as the primary reference.</strong><br><br><p>The Harrell-Davis quantile estimator is one of my favorite quantile estimators
because of its <a href=https://en.wikipedia.org/wiki/Efficiency_(statistics)>efficiency</a>.
It has a small mean square error which allows getting accurate estimations.
However, it has a severe drawback: it&rsquo;s not robust.
Indeed, since the estimator includes all sample elements with positive weights,
its <a href=https://en.wikipedia.org/wiki/Robust_statistics#Breakdown_point>breakdown point</a> is zero.</p><p>In this post, I want to suggest modifications of the Harrell-Davis quantile estimator
which increases its <em>robustness</em> keeping almost the same level of <em>efficiency</em>.</p><h3 id=robustness>Robustness</h3><p>One of the essential properties of
a statistical <a href=https://en.wikipedia.org/wiki/Estimator>estimator</a> is <em>robustness</em>.
It describes the resistance abilities of the estimator against outliers.
Robustness can be expressed using the <em>breakdown point</em>.
The breakdown point is the proportion of invalid measurements that the estimator can handle.
In other words, it&rsquo;s the maximum number of sample elements
that we could replace by arbitrarily large values
without making the estimator value also arbitrarily large.
Let&rsquo;s look at a few examples.</p><p>Consider sample <span class="math inline">\(x = \{ 1, 2, 3, 4, 5, 6, 7 \}\)</span>.
The mean value of <span class="math inline">\(x\)</span> is <span class="math inline">\(4\)</span>.
Imagine that we replace one of the sample elements with <span class="math inline">\(\infty\)</span>.
Now the sample look like this: <span class="math inline">\(x = \{ 1, 2, 3, 4, 5, 6, \infty \}\)</span>.
The updated mean value is also <span class="math inline">\(\infty\)</span>.
It&rsquo;s enough to corrupt a single element in the sample to make the mean also corrupted.
The breakdown point of the mean is zero.
Thus, the mean is not a robust metric.</p><p>The sample median of <span class="math inline">\(x = \{ 1, 2, 3, 4, 5, 6, 7 \}\)</span> is also <span class="math inline">\(4\)</span>.
However, if we replace a single sample element with <span class="math inline">\(\infty\)</span> it doesn&rsquo;t make the sample median value also <span class="math inline">\(\infty\)</span>.
In fact, we can safely replace three elements of this sample and get <span class="math inline">\(x = \{ 1, 2, 3, 4, \infty, \infty, \infty \}\)</span>.
The sample median is still meaningful.
It could be changed to another element from the original sample, but it will not become arbitrarily large.
Thereby, we can corrupt three elements from the given seven-element sample without corrupting the sample median value.
The breakdown point is <span class="math inline">\(3/7\approx 43\%\)</span>.
Asymptotically, the breakdown point of the sample median is <span class="math inline">\(0.5\)</span> which is
the maximum possible breakdown point value.
Thus, the median is a robust metric.</p><h3 id=efficiency>Efficiency</h3><p>Another important estimator property is <em>efficiency</em>.
It describes the estimator accuracy.</p><p>Consider the straightforward way to calculate the sample median for a sample of size <span class="math inline">\(n\)</span>:</p><ul><li>If <span class="math inline">\(n\)</span> is odd, the median is the middle element of the sorted sample</li><li>If <span class="math inline">\(n\)</span> is even, the median is the arithmetic average of the two middle elements of the sorted sample</li></ul><p>This rule gives us the median value of the sample, but it doesn&rsquo;t provide an accurate estimation of the population median.
Meanwhile, there are other quantile estimators that have better accuracy.
One of my favorite options is the Harrell-Davis quantile estimator (see <a href=#Harrell1982>[Harrell1982]</a>).
Here is the estimation for <span class="math inline">\(p^\textrm{th}\)</span> quantile:</p><p><span class="math display">\[q_p = \sum_{i=1}^{n} W_{i} \cdot x_{(i)}, \quad
W_{i} = I_{i/n}(a, b) - I_{(i-1)/n}(a, b), \quad
a = p(n+1),\; b = (1-p)(n+1)
\]</span></p><p>where
<span class="math inline">\(I_t(a, b)\)</span> denotes the <a href=https://en.wikipedia.org/wiki/Beta_function#Incomplete_beta_function>regularized incomplete beta function</a>,
<span class="math inline">\(x_{(i)}\)</span> is the <span class="math inline">\(i^\textrm{th}\)</span> <a href=https://en.wikipedia.org/wiki/Order_statistic>order statistic</a>.
This estimator has higher efficiency than the sample median.
It means that it has a smaller variance and smaller mean squared error.</p><p>However, the Harrell-Davis quantile estimator has a serious drawback: it&rsquo;s not robust.
Indeed, since its value is a linear combination of all order statistics,
it&rsquo;s enough to corrupt a single sample element to spoil the estimation.
Thus, its breakdown point is zero.</p><p>So, how should we estimate the median?
The sample median gives a robust but not-so-efficient estimation.
The Harrell-Davis quantile estimator gives efficient but not robust estimation.</p><p>I&rsquo;m going to suggest an approach that improves the robustness of the Harrell-Davis quantile estimator
keeping a decent level of efficiency.
But first, we should briefly discuss trimmed and winsorized means.</p><h3 id=trimmed-and-winsorized-mean>Trimmed and winsorized mean</h3><p>The <a href=https://en.wikipedia.org/wiki/Truncated_mean>trimmed mean</a> (or truncated mean) is an attempt
to improve the mean robustness.
The idea is simple:
we should sort all values in the sample,
drop the first k values and the last k values,
and calculate the mean of the middle elements.
Let&rsquo;s say we have a sample with 8 elements:</p><p><span class="math display">\[x = \{x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8\}.
\]</span></p><p>If we assume that <span class="math inline">\(x\)</span> is already sorted, and we want to calculated the 25% trimmed mean,
we should drop the first 25% and the last 25% of the values:</p><p><span class="math display">\[x_{\textrm{trimmed}} = \{x_3, x_4, x_5, x_6\}.
\]</span></p><p>Next, we should calculate the mean of the middle elements:</p><p><span class="math display">\[\overline{x_{\textrm{trimmed}}} = \dfrac{x_3 + x_4 + x_5 + x_6}{4}.
\]</span></p><p>We can also consider a similar technique called <a href=https://en.wikipedia.org/wiki/Winsorizing>winsorization</a>.
Instead of dropping extreme values, we could replace them with the minimum and maximum elements among the remaining values.
Thus, if we 25% winsorize the above sample, we get</p><p><span class="math display">\[x_{\textrm{winsorized}} = \{x_3, x_3, x_3, x_4, x_5, x_6, x_6, x_6\}.
\]</span></p><p>Using the winsorized sample, we could calculate the <a href=https://en.wikipedia.org/wiki/Winsorized_mean>winsorized mean</a>:</p><p><span class="math display">\[\overline{x_{\textrm{winsorized}}} = \dfrac{x_3 + x_3 + x_3 + x_4 + x_5 + x_6 + x_6 + x_6}{4}.
\]</span></p><p>The breakdown point of p% trimmed mean and p% winsorized mean is p% (the proportion of dropped/replaced element on each tail).
This makes these metrics more robust than the classic mean.</p><h3 id=winsorized-harrell-davis-quantile-estimator>Winsorized Harrell-Davis quantile estimator</h3><p>Let&rsquo;s go back to the Harrell-Davis quantile estimator.
It estimates the <span class="math inline">\(p^\textrm{th}\)</span> quantile as a weighted sum of order statistics:</p><p><span class="math display">\[q_p = \sum_{i=1}^{n} W_{i} \cdot x_{(i)}
\]</span></p><p>The weights <span class="math inline">\(W_i\)</span> can be calculated as segment areas of Beta distribution density plot with <span class="math inline">\(a = p(n+1)\)</span> and <span class="math inline">\(b = (1-p)(n+1)\)</span>.
For example, <span class="math inline">\(n = 10, p = 0.5\)</span> (estimating the median for 10-elements sample) gives the following plot:</p><div class=row><div class=mx-auto><a href=/posts/winsorized-hdqe/img/beta1-light.png target=_blank class=imgldlink alt=beta1><picture><source theme=dark srcset=/posts/winsorized-hdqe/img/beta1-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/winsorized-hdqe/img/beta1-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/winsorized-hdqe/img/beta1-light.png></picture></a></div></div><br><p>Here are the values of corresponding weights <span class="math inline">\(W_i\)</span>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cs data-lang=cs><span class=line><span class=cl><span class=n>W</span><span class=p>[</span><span class=m>1</span><span class=p>]</span> <span class=p>=</span> <span class=n>W</span><span class=p>[</span><span class=m>10</span><span class=p>]</span> <span class=p>=</span> <span class=m>0.0005124147</span>
</span></span><span class=line><span class=cl><span class=n>W</span><span class=p>[</span><span class=m>2</span><span class=p>]</span> <span class=p>=</span> <span class=n>W</span><span class=p>[</span><span class=m>9</span><span class=p>]</span>  <span class=p>=</span> <span class=m>0.0145729829</span>
</span></span><span class=line><span class=cl><span class=n>W</span><span class=p>[</span><span class=m>3</span><span class=p>]</span> <span class=p>=</span> <span class=n>W</span><span class=p>[</span><span class=m>8</span><span class=p>]</span>  <span class=p>=</span> <span class=m>0.0727403902</span>
</span></span><span class=line><span class=cl><span class=n>W</span><span class=p>[</span><span class=m>4</span><span class=p>]</span> <span class=p>=</span> <span class=n>W</span><span class=p>[</span><span class=m>7</span><span class=p>]</span>  <span class=p>=</span> <span class=m>0.1683691116</span>
</span></span><span class=line><span class=cl><span class=n>W</span><span class=p>[</span><span class=m>5</span><span class=p>]</span> <span class=p>=</span> <span class=n>W</span><span class=p>[</span><span class=m>6</span><span class=p>]</span>  <span class=p>=</span> <span class=m>0.2438051006</span>
</span></span></code></pre></div><p>As we can see, weights of <span class="math inline">\(x_{(1)}\)</span> and <span class="math inline">\(x_{(10)}\)</span> are <span class="math inline">\(W_1 = W_{10} = 0.0005124147\)</span>.
In most cases, they don&rsquo;t produce a noticeable impact on the result (their total weight is about <span class="math inline">\(0.1\%\)</span>).
However, in the case of extremely large outliers, they can completely distort the final estimation.
Let&rsquo;s consider the following sample:</p><p><span class="math display">\[x = \{ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 \}
\]</span></p><p>The sample median is <span class="math inline">\(5.5\)</span>.
The Harrell-Davis quantile estimator dives the same estimation: <span class="math inline">\(q_{0.5} = 5.5\)</span>.
Now let&rsquo;s replace the last element of this sample by <span class="math inline">\(10^6\)</span>:</p><p><span class="math display">\[x = \{ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10^6 \}
\]</span></p><p>Now, the Harrell-Davis estimation is <span class="math inline">\(q_{0.5} = 517.9096\)</span> which is probably too far from the actual median value.
We have this problem because the Harrell-Davis quantile estimator is not robust; its breakdown point is zero.</p><p>Let&rsquo;s look again at the tail elements <span class="math inline">\(x_{(1)}\)</span> and <span class="math inline">\(x_{(10)}\)</span>.
They are almost useless in situations without outliers and
they are destructive in situations with outliers.
What the point of using these values at all?
What if we winsorize them?</p><p>However, we couldn&rsquo;t just update the p% of values in each tail.
Firstly, if we winsorize values with the big weight, we noticeably reduce the estimator efficiency.
Secondly, if we estimate arbitrary quantile (not the median), the tail values may have the highest weight
and definitely should not be dropped.</p><p>I suggest a simple heuristic.
We should find the 99% highest density interval of the considered beta distribution.
All segments outside this interval should be winsorized.
Thus, we keep values that form 99% of the final result (keeping almost the same level of efficiency)
and protect ourselves against outliers (improving robustness).
In the below table, you can find values of breakdown points and the numbers of winsorized elements
for different sample sizes.</p><table><thead><tr><th>n</th><th>winsorized</th><th>breakdown</th></tr></thead><tbody><tr><td>2</td><td>0</td><td>0.0000</td></tr><tr><td>3</td><td>0</td><td>0.0000</td></tr><tr><td>4</td><td>0</td><td>0.0000</td></tr><tr><td>5</td><td>0</td><td>0.0000</td></tr><tr><td>6</td><td>0</td><td>0.0000</td></tr><tr><td>7</td><td>0</td><td>0.0000</td></tr><tr><td>8</td><td>2</td><td>0.1250</td></tr><tr><td>9</td><td>2</td><td>0.1111</td></tr><tr><td>10</td><td>2</td><td>0.1000</td></tr><tr><td>11</td><td>2</td><td>0.0909</td></tr><tr><td>12</td><td>4</td><td>0.1667</td></tr><tr><td>13</td><td>4</td><td>0.1538</td></tr><tr><td>14</td><td>4</td><td>0.1429</td></tr><tr><td>15</td><td>6</td><td>0.2000</td></tr><tr><td>16</td><td>6</td><td>0.1875</td></tr><tr><td>17</td><td>6</td><td>0.1765</td></tr><tr><td>18</td><td>8</td><td>0.2222</td></tr><tr><td>19</td><td>8</td><td>0.2105</td></tr><tr><td>20</td><td>8</td><td>0.2000</td></tr><tr><td>21</td><td>10</td><td>0.2381</td></tr><tr><td>22</td><td>10</td><td>0.2273</td></tr><tr><td>23</td><td>10</td><td>0.2174</td></tr><tr><td>24</td><td>12</td><td>0.2500</td></tr><tr><td>25</td><td>12</td><td>0.2400</td></tr><tr><td>26</td><td>12</td><td>0.2308</td></tr><tr><td>27</td><td>14</td><td>0.2593</td></tr><tr><td>28</td><td>14</td><td>0.2500</td></tr><tr><td>29</td><td>14</td><td>0.2414</td></tr><tr><td>30</td><td>16</td><td>0.2667</td></tr><tr><td>31</td><td>16</td><td>0.2581</td></tr><tr><td>32</td><td>18</td><td>0.2812</td></tr><tr><td>33</td><td>18</td><td>0.2727</td></tr><tr><td>34</td><td>18</td><td>0.2647</td></tr><tr><td>35</td><td>20</td><td>0.2857</td></tr><tr><td>36</td><td>20</td><td>0.2778</td></tr><tr><td>37</td><td>22</td><td>0.2973</td></tr><tr><td>38</td><td>22</td><td>0.2895</td></tr><tr><td>39</td><td>22</td><td>0.2821</td></tr><tr><td>40</td><td>24</td><td>0.3000</td></tr><tr><td>41</td><td>24</td><td>0.2927</td></tr><tr><td>42</td><td>26</td><td>0.3095</td></tr><tr><td>43</td><td>26</td><td>0.3023</td></tr><tr><td>44</td><td>26</td><td>0.2955</td></tr><tr><td>45</td><td>28</td><td>0.3111</td></tr><tr><td>46</td><td>28</td><td>0.3043</td></tr><tr><td>47</td><td>30</td><td>0.3191</td></tr><tr><td>48</td><td>30</td><td>0.3125</td></tr><tr><td>49</td><td>30</td><td>0.3061</td></tr><tr><td>50</td><td>32</td><td>0.3200</td></tr><tr><td>100</td><td>74</td><td>0.3700</td></tr><tr><td>500</td><td>442</td><td>0.4420</td></tr><tr><td>1000</td><td>918</td><td>0.4590</td></tr><tr><td>10000</td><td>9742</td><td>0.4871</td></tr><tr><td>100000</td><td>99184</td><td>0.4959</td></tr></tbody></table><h3 id=winsorized-maritz-jarrett-method>Winsorized Maritz-Jarrett method</h3><p>The Maritz-Jarrett method (see <a href=#Maritz1979>[Maritz1979]</a>) allows estimating quantile confidence intervals.
It works great with the Harrell-Davis quantile estimator because it reuses weights <span class="math inline">\(W_i\)</span>.
Let&rsquo;s define <span class="math inline">\(k^\textrm{th}\)</span> moment of the <span class="math inline">\(p^\textrm{th}\)</span> quantile as follows:</p><p><span class="math display">\[C_k = \sum_{i=1}^n W_{i} \cdot x_{(i)}^k.
\]</span></p><p>Next, we could express the standard error of the <span class="math inline">\(p^\textrm{th}\)</span> quantile via the first and the seconds moments:</p><p><span class="math display">\[s_{q_p} = \sqrt{C_2 - C_1^2}
\]</span></p><p>It&rsquo;s easy to see that winsorization could be applied here as well.</p><h3 id=reference-implementation>Reference implementation</h3><p>The C# reference implementation can be found in
the latest nightly version (0.3.0-nightly.89+) of <a href=https://github.com/AndreyAkinshin/perfolizer>Perfolizer</a>
(you need <code>WinsorizedHarrellDavisQuantileEstimator</code>).</p><h3 id=conclusion>Conclusion</h3><p>The winsorized modifications of the Harrell-Davis quantile estimator has the same level of efficiency as the original estimator,
but it&rsquo;s more robust.
It protects the estimated value from extreme outliers.
The asymptotic breakdown point of the suggested estimator is <span class="math inline">\(0.5\)</span>.
Also, the winsorized version can be calculated much faster because it doesn&rsquo;t require so many values of the regularized incomplete beta function.</p><h3 id=references>References</h3><ul><li><b id=Harrell1982>[Harrell1982]</b><br>Harrell, F.E. and Davis, C.E., 1982. A new distribution-free quantile estimator.
<em>Biometrika</em>, 69(3), pp.635-640.<br><a href=https://doi.org/10.2307/2335999>https://doi.org/10.2307/2335999</a></li><li><b id=Maritz1979>[Maritz1979]</b><br>Maritz, J. S., and R. G. Jarrett. 1978.
“A Note on Estimating the Variance of the Sample Median.”
Journal of the American Statistical Association 73 (361): 194–196.<br><a href=https://doi.org/10.1080/01621459.1978.10480027>https://doi.org/10.1080/01621459.1978.10480027</a></li></ul><br><br><div class=row><div class="justify-content-center share-block"><div class=share-title>Share:</div><div class=share-button><a href="https://www.reddit.com/submit?url=https%3a%2f%2faakinshin.net%2fposts%2fwinsorized-hdqe%2f&title=Winsorized%20modification%20of%20the%20Harrell-Davis%20quantile%20estimator" target=_blank title="Share on Reddit"><i class="fab fa-reddit fa-2x"></i></a></div><div class=share-button><a href="https://twitter.com/intent/tweet?text=Winsorized%20modification%20of%20the%20Harrell-Davis%20quantile%20estimator&url=https%3a%2f%2faakinshin.net%2fposts%2fwinsorized-hdqe%2f&via=andrey_akinshin&related=andrey_akinshin" rel=nofollow target=_blank title="Share on Twitter"><i class="fab fa-twitter fa-2x"></i></a></div><div class=share-button><a href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2faakinshin.net%2fposts%2fwinsorized-hdqe%2f" target=_blank title="Share on HackerNews"><i class="fab fa-hacker-news fa-2x"></i></a></div><div class=share-button><a href="https://getpocket.com/save?url=https%3a%2f%2faakinshin.net%2fposts%2fwinsorized-hdqe%2f&title=Winsorized%20modification%20of%20the%20Harrell-Davis%20quantile%20estimator" target=_blank title="Add to Pocket"><i class="fab fa-get-pocket fa-2x"></i></a></div></div></div></div><hr></div></div></main></div><footer class=blog-footer><div class=container><p>&copy; 2013&mdash;2022 Andrey Akinshin
|
<a href=https://github.com/AndreyAkinshin><i class="fab fa-github" title=GitHub></i></a>
<a href=https://twitter.com/andrey_akinshin><i class="fab fa-twitter" title=Twitter></i></a>
<a href=https://aakinshin.net/posts/index.xml><i class="fas fa-rss" title=RSS></i></a>
|
<a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></p></div></footer><script src=https://aakinshin.net/js/theme-after.min.c26550621ac13c2221d7f6f5e6fe862345d3919723c50d730893e3e4856ecf35.js></script>
<script src=/js/bootstrap.bundle.min.js></script>
<script src=/js/anchor.min.js></script>
<script src=https://aakinshin.net/js/custom.min.f6e5d13fe39f305056cc743ee4cb8d117c1aba26176e58c82c79a480d02fe4b7.js></script>
<script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></body></html>