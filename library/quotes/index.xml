<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Quotes on Andrey Akinshin</title><link>https://aakinshin.net/library/quotes/</link><description>Recent content in Quotes on Andrey Akinshin</description><generator>Hugo -- gohugo.io</generator><language>en</language><atom:link href="https://aakinshin.net/library/quotes/index.xml" rel="self" type="application/rss+xml"/><item><title>50 Percent Below Average</title><link>https://aakinshin.net/library/quotes/714b462f-fe06-4644-a1fe-b067d6832d63/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/714b462f-fe06-4644-a1fe-b067d6832d63/</guid><description>And then they get into Harvard, walk confidently into that Hogwarts-like freshman dining hall on the first day of college, and have a terrible realization: 50 percent of them are suddenly below average. I like to tell my advisees: If my calculations are correct, 99 percent of Harvard students do not graduate in the top 1 percent. They don’t find that joke very funny.</description></item><item><title>A Cumulative Evidence Base in Psychology</title><link>https://aakinshin.net/library/quotes/7a99a4bd-15fa-4520-9bf6-dacdea581298/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/7a99a4bd-15fa-4520-9bf6-dacdea581298/</guid><description>Scrutiny of the details of previous work’s measures is necessary to both inform how we should interpret existing findings and to increase measures’ future reuse potential. Transparency about the fine grain details of our measures allows others to reuse them with fidelity, and allows for the fidelity of measures to be checked between studies. These aspects of transparency and their scientific benefits have yet to be tapped by our field. If we want to build a cumulative evidence base in psychology, we need to standardise our measures and protocols. Psychologists need to stop remixing and recycling, and start reusing (measures, not toothbrushes).</description></item><item><title>A jingle-jangle of Labels</title><link>https://aakinshin.net/library/quotes/9b23bf30-c334-4f03-b399-a336fe8fe1cb/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/9b23bf30-c334-4f03-b399-a336fe8fe1cb/</guid><description>A jingle-jangle of labels
Some measures actually quantify different things, but share similar labels (or even identical ones: In APA PsycTests, no less than 19 different tests go by “theory of planned behavior ques- tionnaire”, 15 by “job satisfaction scale”, and 11 by “self-efficacy scale”). Other measures quantify the same thing as existing measures but under a different label. Known as the Jingle and Jangle fallacies, these are common and well-documented threats to the replicability and validity of psychological research, e.g. in studies on emotion . They involve a nominal fallacy: that a measure’s name tells you about its contents or what it measures.
Undisclosed flexibility
Even when authors profess using the same measure of the same construct, all is not yet well because disclosed and undisclosed measurement flexibility, i.e. changes to a measure with known or unknown psychometric consequences, is common. Dropping, adding, and altering items in self-report scales, aggregating total scores in various ways in laboratory tasks, or varying stimuli and trial durations all occur while researchers not only refer to the same construct, but actually to the same nominal instrument. Even when all decisions are disclosed, only a methodological literature review will reveal that many studies used, for instance, unique aggregation algorithms, scoring strategies, or items, often with unknown psychometric consequences.</description></item><item><title>Absence of Evidence is Not Evidence of Absence</title><link>https://aakinshin.net/library/quotes/0881be0d-6149-4d55-8561-87ddbfe9d453/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/0881be0d-6149-4d55-8561-87ddbfe9d453/</guid><description>Absence of Evidence is Not Evidence of Absence</description></item><item><title>Achieving a Goal Only Changes Your Life for the Moment</title><link>https://aakinshin.net/library/quotes/518d1a6e-4059-43e4-b2a5-dc50c6aaa08b/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/518d1a6e-4059-43e4-b2a5-dc50c6aaa08b/</guid><description>Achieving a goal only changes your life for the moment.</description></item><item><title>Addressing False Positives in Self-Report Surveys</title><link>https://aakinshin.net/library/quotes/6c23bac3-f06b-4234-8b0d-eb4c29388360/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/6c23bac3-f06b-4234-8b0d-eb4c29388360/</guid><description>Self-report surveys of rare events easily lead to huge overestimates of the true incidence of such events, particularly if the event in question has some potential social desirability. Researchers who claim that such survey incidence data are accurate must show how they have eliminated the enormous problem of false positives.</description></item><item><title>Addressing Pseudoreplication in Experimental Studies</title><link>https://aakinshin.net/library/quotes/4c2a9774-48bc-42db-a035-c416e710ed01/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/4c2a9774-48bc-42db-a035-c416e710ed01/</guid><description>We believe that good investigators who are aware of the issue will find that eliminating pseudoreplication from their experiments is a relatively straightforward matter. The problems of pseudoreplication that we typically encounter in published studies are easily solvable, and we see no reason that reviewers and editors should accept studies that fail to eliminate pseudoreplication. We certainly do not believe that absence of pseudoreplication should be the sole, or even the main, criterion for evaluating experiments. Rather, we see the absence of pseudoreplication as representing a minimum requirement that should be met before the merits of an experiment are evaluated.</description></item><item><title>Aliases of Syphilis</title><link>https://aakinshin.net/library/quotes/e4208f1d-e3a2-49fb-9600-84a036f22697/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/e4208f1d-e3a2-49fb-9600-84a036f22697/</guid><description>The body’s largest organ is the skin. Before modern medicine, one of the worst imaginable skin diseases was syphilis, which would start as itchy boils and then eat its way into the bones until it exposed the skeleton. The microbe that caused this disgusting sight and unbearable pain had different names in different places. In Russia it was called the Polish disease. In Poland it was the German disease; in Germany, the French disease; and in France, the Italian disease. The Italians blamed back, calling it the French disease.</description></item><item><title>All Animals Are Equal</title><link>https://aakinshin.net/library/quotes/f3bdc79d-f452-4403-859f-996838998b12/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/f3bdc79d-f452-4403-859f-996838998b12/</guid><description>All animals are equal, but some animals are more equal than others.</description></item><item><title>An Enormous Threat</title><link>https://aakinshin.net/library/quotes/d5b1dc5f-2f56-41fa-ac2a-a4bcd86e4aa4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/d5b1dc5f-2f56-41fa-ac2a-a4bcd86e4aa4/</guid><description>Hence, (a) the lack of strong empirical or procedural norms in measurement, (b) the lack of transparency in reporting, and (c) the lack of common referents (i.e., test norms) in measurement are an enormous threat to meaningful evidence cumulation and research synthesis.</description></item><item><title>Analysis of Variance in Genetic Associations and Health Care Interventions</title><link>https://aakinshin.net/library/quotes/c84cec6e-c9dd-4ea2-b87f-516d09824fbf/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/c84cec6e-c9dd-4ea2-b87f-516d09824fbf/</guid><description>The maximal between-study variance was more likely to be recorded early in the 44 eligible meta-analyses of genetic associations than in the 37 meta-analyses of health care interventions (P = .013). At the time of the first heterogeneity assessment, the most favorable-ever result in support of a specific association was more likely to appear than the least favorable-ever result (22 vs. 10, P = .017); the opposite was seen at the second heterogeneity assessment (15 vs. 5, P = .031). Such a sequence of extreme opposite results was not seen in the clinical trials meta-analyses. The estimated between-study variance decreased over time in genetic association studies (P = .010), but not in clinical trials (P = .30).</description></item><item><title>Analytically Calculating Power Can Be Difﬁcult or Downright Impossible</title><link>https://aakinshin.net/library/quotes/ff049ff8-818f-4005-a0df-a2104d3c4fb5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/ff049ff8-818f-4005-a0df-a2104d3c4fb5/</guid><description>Math is another possible explanation for why power calculations are so uncommon: analytically calculating power can be difﬁcult or downright impossible. Techniques for calculating power are not frequently taught in intro statistics courses. And some commercially available statistical software does not come with power calculation functions. It is possible to avoid hairy mathematics by simply simulating thousands of artiﬁcial datasets with the effect size you expect and running your statistical tests on the simulated data. The power is simply the fraction of datasets for which you obtain a statistically signiﬁcant result. But this approach requires programming experience, and simulating realistic data can be tricky.</description></item><item><title>Any Series of Real Observations Does Not Actually Follow a Normal Curve</title><link>https://aakinshin.net/library/quotes/0d2cd179-ce5c-4fa0-a31e-c0e1c7d8189e/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/0d2cd179-ce5c-4fa0-a31e-c0e1c7d8189e/</guid><description>For we may assume that it is practically certain that any series of real observations does not actually follow a normal curve with absolute exactitude in all respects, and no matter how small the discrepancy between the normal curve and the true curve of observations, the chi-square P will be small if the sample has a sufficientlylarge numberof observationsin it.</description></item><item><title>Balancing Realism and Purity</title><link>https://aakinshin.net/library/quotes/c940f25b-3f02-40ea-8f2c-8934efe03226/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/c940f25b-3f02-40ea-8f2c-8934efe03226/</guid><description>It is difficult to give an objective assessment of the validity of a statistical analysis. Rather like medicine, statistics is an art, and there is rarely a unique correct approach. Rather judgement is necessary to select one of a number of possible analyses, each with their own advantages and limitations. In my review I encountered many analyses which I would have tackled differently, but where in my judgement the analysis as presented was perfectly acceptable. In writing this article I have attempted to confine my criticisms to points where I believe that the vast majority of statisticians would agree that the approach adopted was not acceptable, and indeed many statisticians would probably take a harder line than I have. My statistical philosophy leans towards being a realist rather than a purist, and my research interests lie in the area of how to obtain the least biased results possible in areas where perhaps for ethical or practical reasons randomization is not possible, or where missing data abound.</description></item><item><title>Beauty is a Dynamic Event</title><link>https://aakinshin.net/library/quotes/b9cf8096-6f2a-4f2a-bade-e41f1c62abc5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/b9cf8096-6f2a-4f2a-bade-e41f1c62abc5/</guid><description>Wabi-sabi suggests that beauty is a dynamic event that occurs between you and something else.</description></item><item><title>Being Bored</title><link>https://aakinshin.net/library/quotes/a108d728-7af8-4698-82d2-09ec1ffdf807/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/a108d728-7af8-4698-82d2-09ec1ffdf807/</guid><description>Answer this question honestly: When was the last time you were bored?
Really think about it. Can you remember?
Chances are it was a long time ago, maybe before welcoming devices into your life.
Never in human history have we divided our attention among so many things. In the moment this can feel like a benefit — we always have something to do—but the disadvantage is that distracting devices have basically eliminated boredom from our lives.</description></item><item><title>Bimodal Human Height</title><link>https://aakinshin.net/library/quotes/6f60ee1b-8d38-451e-a356-e94f4970f9b7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/6f60ee1b-8d38-451e-a356-e94f4970f9b7/</guid><description>Although the separate distributions of his male and female students are approximately normal, the histogram of men and women together is clearly bimodal.</description></item><item><title>Binary Thinking</title><link>https://aakinshin.net/library/quotes/43b23270-4b95-47af-826b-07c64cedc182/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/43b23270-4b95-47af-826b-07c64cedc182/</guid><description>I think this is because human beings have a strong dramatic instinct toward binary thinking, a basic urge to divide things into two distinct groups, with nothing but an empty gap in between. We love to dichotomize. Good versus bad. Heroes versus villains. My country versus the rest. Dividing the world into two distinct sides is simple and intuitive, and also dramatic because it implies conflict, and we do it without thinking, all the time.</description></item><item><title>Black and White Medical Conclusions</title><link>https://aakinshin.net/library/quotes/61d2c118-762a-4f38-8710-231759813a08/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/61d2c118-762a-4f38-8710-231759813a08/</guid><description>It appears that medical authors feel the need to make black and white conclusions when their data almost never allows for such dichotomous statements. This is particularly true when comparing results to similar studies with largely overlapping CIs. Virtually all of the conclusion confusion discussed in this paper can be linked to slavish adherence to an arbitrary threshold for statistical significance. Even if the threshold is reasonable, it still cannot be used to make dichotomous conclusions.</description></item><item><title>Challenges and Pitfalls in Spatial Data Mapping</title><link>https://aakinshin.net/library/quotes/454084e3-99c3-415b-8a06-25a8b5318e21/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/454084e3-99c3-415b-8a06-25a8b5318e21/</guid><description>Mapping raw data can lead to spurious spatial features. For example, regions can appear highly variable because of small sample sizes in spatial sub-units (as in the radon example) or small populations (as in the cancer example), and these apparently variable regions contain a disproportionate number of very high (or low) observed parameter values. Mapping posterior means leads to the reverse problems: areas that appear too uniform because of small sample sizes or populations.</description></item><item><title>Change Your Counterfact</title><link>https://aakinshin.net/library/quotes/f2a7e52c-6911-4131-90e5-eb4f267f2982/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/f2a7e52c-6911-4131-90e5-eb4f267f2982/</guid><description>Change your counterfact
Consider the following scenario I have presented to business leaders in countries around the globe, always to the same effect. Imagine for a moment that you walk into a bank. There are 50 other people in the bank. A robber walks in and fires his weapon once. You are shot in the right arm. Now if you were honestly describing this event to your friends and coworkers the next day, do you describe it as lucky or unlucky?</description></item><item><title>China 1960</title><link>https://aakinshin.net/library/quotes/65382f75-9f20-49b0-a7ed-0b1b59a6504a/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/65382f75-9f20-49b0-a7ed-0b1b59a6504a/</guid><description>There’s a dip in the global life expectancy curve in 1960 because 15 to 40 million people—nobody knows the exact number—starved to death that year in China, in what was probably the world’s largest ever man-made famine. The Chinese harvest in 1960 was smaller than planned because of a bad season combined with poor governmental advice about how to grow crops more effectively. The local governments didn’t want to show bad results, so they took all the food and sent it to the central government. There was no food left. One year later the shocked inspectors were delivering eyewitness reports of cannibalism and dead bodies along roads. The government denied that its central planning had failed, and the catastrophe was kept secret by the Chinese government for 36 years. It wasn’t described in English to the outside world until 1996. (Think about it. Could any government keep the death of 15 million people a global secret today?)</description></item><item><title>Common Sense is Not Common Action</title><link>https://aakinshin.net/library/quotes/a299d717-eba8-4845-868c-315c4ea2c11f/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/a299d717-eba8-4845-868c-315c4ea2c11f/</guid><description>Common sense is not common action.
Would you be surprised if I told you that cigarettes are not a great source of vitamin C? Or that watching hours of reality television will not dramatically raise your IQ? Probably not. Similarly, we all know that we should exercise, sleep eight hours, eat healthier, and be kind to others. But does this common knowledge make doing these things any easier?</description></item><item><title>Compute Many Estimates</title><link>https://aakinshin.net/library/quotes/25bb3307-d976-4e25-9f49-671e0c787608/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/25bb3307-d976-4e25-9f49-671e0c787608/</guid><description>Compute many (30 or 60?) estimates</description></item><item><title>Conclusions on Journal Impact Factor</title><link>https://aakinshin.net/library/quotes/2526af27-e9d4-4a82-a5d3-e95b8af58146/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/2526af27-e9d4-4a82-a5d3-e95b8af58146/</guid><description> While at this point it seems impossible to quantify the relative contributions of the different factors influencing the reliability of scientific publications, the current empirical literature on the effects of journal rank provides evidence supporting the following four conclusions:
Journal rank is a weak to moderate predictor of utility and perceived importance; Journal rank is a moderate to strong predictor of both intentional and unintentional scientific unreliability Journal rank is expensive, delays science and frustrates researchers; Journal rank as established by IF violates even the most basic scientific standards, but predicts subjective judgments of journal quality.</description></item><item><title>Confidence Intervals</title><link>https://aakinshin.net/library/quotes/8a403d69-3240-4581-9710-cde46af21603/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/8a403d69-3240-4581-9710-cde46af21603/</guid><description>We have argued that the excessive use of hypothesis testing at the expense of more informative approaches to data interpretation is an unsatisfactory way of assessing and presenting statistical findings from medical studies. We prefer the use of confidence intervals, which present the results directly on the scale of data measurement. We have also suggested a notation for confidence intervals which is intended to force clarity of meaning. Confidence intervals, which also have a link to the outcome of hypothesis tests, should become the standard method for presenting the statistical results of major findings.</description></item><item><title>Convenient p=0.05</title><link>https://aakinshin.net/library/quotes/9306030d-dc0f-42cd-ae4f-8c77d9dbd656/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/9306030d-dc0f-42cd-ae4f-8c77d9dbd656/</guid><description>The value for which P = 0.05, or 1 in 20, is 1'96 or nearly 2; it is convenient to take this point as a limit in judging whether a deviation is to be considered significant or not. Deviations exceeding twice the standard deviation are thus formally regarded as significant.</description></item><item><title>Correction for Universal non-normality</title><link>https://aakinshin.net/library/quotes/34328b30-684a-46df-a1fe-deb669aebda7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/34328b30-684a-46df-a1fe-deb669aebda7/</guid><description>It may be asked if testing for normality and, when necessary, correction for universal non-normality is worth the trouble. To answer this question it is desirable to have regard to the logical position of the statistician, concerned with drawing inferences from samples whose characteristic approach may be defined as reductio ad paene absurdum: if an event is highly improbable it must be regarded for practical purposes as impossible.</description></item><item><title>Correspondence Between Confidence Intervals and Hypothesis Tests</title><link>https://aakinshin.net/library/quotes/426c7b3f-1b39-443c-9f6f-25dfaa973005/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/426c7b3f-1b39-443c-9f6f-25dfaa973005/</guid><description>Although for quantitative data and means there is a direct correspondence between the confidence interval approach and a t test ofthe null hypothesis at the associated level of statistical significance, this is not exactly so for qualitative data and proportions. The reason is related to the use of different estimates of the standard error for the usual tests of the null hypothesis from those given here for constructing confidence intervals. The lack of direct correspondence is small and should not result in changes of interpretation. In addition, more accurate confidence intervals can sometimes be obtained by using estimates of the standard error of the sample statistic at the confidence limits themselves-such as derived by Cornfield for relative risks.</description></item><item><title>Counterintuitiveness of Significance Testing</title><link>https://aakinshin.net/library/quotes/87d5d946-bcbf-4c7d-921f-d7d2f680a5d4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/87d5d946-bcbf-4c7d-921f-d7d2f680a5d4/</guid><description>This is a counterintuitive feature of significance testing: if you want to prove that your drug works, you do so by showing the data is inconsistent with the drug not working.</description></item><item><title>Creative Minds</title><link>https://aakinshin.net/library/quotes/43d87c58-07d4-4ea2-b5d1-a3465cff61b5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/43d87c58-07d4-4ea2-b5d1-a3465cff61b5/</guid><description>In a New York Times column on the topic, David Brooks summarizes this reality more bluntly: “[Great creative minds] think like artists but work like accountants.</description></item><item><title>Critique of McClintock's Study of Human Menstrual Cycles</title><link>https://aakinshin.net/library/quotes/79121729-78ab-4ef3-a3da-409b3596273c/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/79121729-78ab-4ef3-a3da-409b3596273c/</guid><description>McClintock’s study of human menstrual cycles went something like this:
Find groups of women who live together in close contactfor instance, college students in dormitories. Every month or so, ask each woman when her last menstrual period began and to list the other women with whom she spent the most time. Use these lists to split the women into groups that tend to spend time together. For each group of women, see how far the average woman’s period start date deviates from the average. Small deviations would mean the women’s cycles were aligned, all starting at around the same time. Then the researchers tested whether the deviations decreased over time, which would indicate that the women were synchronizing. To do this, they checked the mean deviation at ﬁve different points throughout the study, testing whether the deviation decreased more than could be expected by chance.
Unfortunately, the statistical test they used assumed that if there was no synchronization, the deviations would randomly increase and decrease from one period to another. But imagine two women in the study who start with aligned cycles. One has an average gap of 28 days between periods and the other a gap of roughly 30 days. Their cycles will diverge consistently over the course of the study, starting two days apart, then four days, and so on, with only a bit of random variation because periods are not perfectly timed. Similarly, two women can start the study not aligned but gradually align.
For comparison, if you’ve ever been stuck in traffic, you’ve probably seen how two turn signals blinking at different rates will gradually synchronize and then go out of phase again. If you’re stuck at the intersection long enough, you’ll see this happen multiple times. But to the best of my knowledge, there are no turn signal pheromones.</description></item><item><title>Data as Absolutely Key</title><link>https://aakinshin.net/library/quotes/6f1ebbc7-462f-4828-ba2b-c1fdb7348aef/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/6f1ebbc7-462f-4828-ba2b-c1fdb7348aef/</guid><description>It was data — the data showing that suspected cases were doubling every three weeks—that made me realize how big the Ebola crisis was. It was also data — the data showing that confirmed cases were now falling—that showed me that what was being done to fight it was working. Data was absolutely key. And because it will be key in the future too, when there is another outbreak somewhere, it is crucial to protect its credibility and the credibility of those who produce it. Data must be used to tell the truth, not to call to action, no matter how noble the intentions.</description></item><item><title>DDoSing</title><link>https://aakinshin.net/library/quotes/73903faf-c1d8-42db-8bb0-5add7a9f8ea4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/73903faf-c1d8-42db-8bb0-5add7a9f8ea4/</guid><description>Too many notifications made us want to check them less. Too many social interactions made us want to post online less frequently. Too many emails made us not want to answer. We were, effectively, DDoSing one another</description></item><item><title>Decline of Power in Psychology (1962..1984)</title><link>https://aakinshin.net/library/quotes/9eaab253-ea71-4eb4-add2-fc061c448725/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/9eaab253-ea71-4eb4-add2-fc061c448725/</guid><description>The long-term impact of studies of statistical power is investigated using J. Cohen&amp;rsquo;s (1962) pioneering work as an example. We argue that the impact is nil; the power of studies in the same journal that Cohen reviewed (now the Journal of Abnormal Psychology) has not increased over the past 24 years. In 1960 the median power (i.e., the probability that a significant result will be obtained if there is a true effect) was .46 for a medium size effect, whereas in 1984 it was only .37. The decline of power is a result of alpha-adjusted procedures. Low power seems to go unnoticed: only 2 out of 64 experiments mentioned power, and it was never estimated. Nonsignificance was generally interpreted as confirmation of the null hypothesis (if this was the research hypothesis), although the median power was as low as .25 in these cases.</description></item><item><title>Dichotomization of 2 Continuous Independent Variables</title><link>https://aakinshin.net/library/quotes/ac013725-23bd-4d83-b98c-4b791a382e70/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/ac013725-23bd-4d83-b98c-4b791a382e70/</guid><description>Despite pleas from methodologists, researchers often continue to dichotomize continuous predictor variables. The primary argument against this practice has been that it underestimates the strength of relationships and reduces statistical power. Although this argument is correct for relationships involving a single predictor, a different problem can arise when multiple predictors are involved. Specifically, dichotomizing 2 continuous independent variables can lead to false statistical significance. As a result, the typical justification for using a median split as long as results continue to be statistically significant is invalid, because such results may in fact be spurious. Thus, researchers who dichotomize multiple continuous predictor variables not only may lose power to detect true predictor-criterion relationships in some situations but also may dramatically increase the probability of Type I errors in other situations.</description></item><item><title>Dichotomization Should Be Avoided in Most Cases</title><link>https://aakinshin.net/library/quotes/8cb30d74-c4bb-470b-b52f-eab706477a22/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/8cb30d74-c4bb-470b-b52f-eab706477a22/</guid><description>The knowledge of losing information from dichotomizing a continuous outcome is nothing new. However, many previous writings report on the optimal choice of cut points, which depends upon the parameters we wish to estimate. If we are lucky, the chosen cut point is near the optimal point, but the consequences of dichotomizing become more dire as we deviate from the optimal point. We focus our study on the evaluation of losses caused by dichotomization given cut points. While the analysis of dichotomized outcomes may be easier, there are no benefits to this approach when the true outcomes can be observed and the ‘working’ model is flexible enough to describe the population at hand. Thus, dichotomization should be avoided in most cases. Only when we wish to estimate a CDF value, our working model poorly approximates reality, and our sample size is large will the biasedness of model-based estimators overpower the improvement in variance. In this case, the dichotomized estimator may lead to better results, but further study-specific consideration is needed. We also want to emphasize that while analysis should be done using actual outcomes, some aspects of this analysis can be reported on a dichotomized scale.</description></item><item><title>Distractions and Writing</title><link>https://aakinshin.net/library/quotes/ab635111-aa09-4ef5-a3af-57090d0cc091/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/ab635111-aa09-4ef5-a3af-57090d0cc091/</guid><description>While I’m writing, I’m less likely to enter into the state of reading hypnosis where I’m pantomiming the act of reading while my mind is actually elsewhere</description></item><item><title>Distractions Notebook</title><link>https://aakinshin.net/library/quotes/e9307a00-5ad2-4a97-9ac2-7957fe04f868/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/e9307a00-5ad2-4a97-9ac2-7957fe04f868/</guid><description>Whenever I have to focus, I adopt the two tactics mentioned above — and I also bring a pen and a notepad with me. In the notepad I write every distraction that makes its way into my mind—things I need to follow up on, tasks I can’t forget, new ideas, and so on.
Maintaining a distractions list as you read will capture the important things that float to the surface of your consciousness. Writing them down to make sure they don’t slip through the cracks will let you refocus on the task at hand.</description></item><item><title>Distributions Are Never Normal</title><link>https://aakinshin.net/library/quotes/8c71defc-488a-4b1e-a360-f0b37f77de12/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/8c71defc-488a-4b1e-a360-f0b37f77de12/</guid><description>To begin, distributions are never normal. For some this seems obvious, hardly worth mentioning, but an aphorism given by Cramér (1946) and attributed to the mathematician Poincaré remains relevant: “Everyone believes in the [normal] law of errors, the experimenters because they think it is a mathematical theorem, the mathematicians because they think it is an experimental fact.”</description></item><item><title>Eager-Beaver Researchers</title><link>https://aakinshin.net/library/quotes/5a3b8f36-edc5-4e56-bd51-d6fe8c1e0fee/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/5a3b8f36-edc5-4e56-bd51-d6fe8c1e0fee/</guid><description>Meanwhile our eager-beaver researcher, undismayed by logic-of-science considerations and relying blissfully on the “exactitude” of modem statistical hypothesis-testing, has produced a long publication list and been promoted to a full professorship. In terms of his contribution to the enduring body of psychological knowledge, he has done hardly anything. His true position is that of a potent-but-sterile intellectual rake, who leaves in his merry path a long train of ravished maidens but no viable scientific offspring.
First, I found this quote in the paper itself, next rediscovered it in Statistics Done Wrong.</description></item><item><title>Early Stopping of Rcts</title><link>https://aakinshin.net/library/quotes/7c744647-3299-4d41-b73f-85556e2d6e91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/7c744647-3299-4d41-b73f-85556e2d6e91/</guid><description>RCTs stopped early for benefit are becoming more common, often fail to adequately report relevant information about the decision to stop early, and show implausibly large treatment effects, particularly when the number of events is small. These findings suggest clinicians should view the results of such trials with skepticism.</description></item><item><title>Easy to Publish</title><link>https://aakinshin.net/library/quotes/9ef2c0c7-a5da-4d76-8169-2d2d97aae36a/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/9ef2c0c7-a5da-4d76-8169-2d2d97aae36a/</guid><description>Our job as scientists is to discover truths about the world. We generate hypotheses, collect data, and examine whether or not the data are consistent with those hypotheses. Although we aspire to always be accurate, errors are inevitable. Perhaps the most costly error is a false positive, the incorrect rejection of a null hypothesis. First, once they appear in the literature, false positives are particularly persistent. Because null results have many possible causes, failures to replicate previous findings are never conclusive. Furthermore, because it is uncommon for prestigious journals to publish null findings or exact replications, researchers have little incentive to even attempt them. Second, false positives waste resources: They inspire investment in fruitless research programs and can lead to ineffective policy changes. Finally, a field known for publishing false positives risks losing its credibility. In this article, we show that despite the nominal endorsement of a maximum false-positive rate of 5% (i.e., p ≤ .05), current standards for disclosing details of data collection and analyses make false positives vastly more likely. In fact, it is unacceptably easy to publish “statistically significant” evidence consistent with any hypothesis.
(Emphasis is mine.)</description></item><item><title>Efficiency Loss of Dichotomization</title><link>https://aakinshin.net/library/quotes/834262d6-ba81-46ea-a08a-952fafecc22c/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/834262d6-ba81-46ea-a08a-952fafecc22c/</guid><description>Dichotomization is the transformation of a continuous outcome (response) to a binary outcome. This approach, while somewhat common, is harmful from the viewpoint of statistical estimation and hypothesis testing. We show that this leads to loss of information, which can be large. For normally distributed data, this loss in terms of Fisher’s information is at least $1-2/\pi$ (or 36%). In other words, 100 continuous observations are statistically equivalent to 158 dichotomized observations. The amount of information lost depends greatly on the prior choice of cut points, with the optimal cut point depending upon the unknown parameters. The loss of information leads to loss of power or conversely a sample size increase to maintain power. Only in certain cases, for instance, in estimating a value of the cumulative distribution function and when the assumed model is very different from the true model, can the use of dichotomized outcomes be considered a reasonable approach.</description></item><item><title>Efficient Algorithms as Prime Concerns</title><link>https://aakinshin.net/library/quotes/2172a5e0-fc35-4bc9-852f-3b2d3a898fe8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/2172a5e0-fc35-4bc9-852f-3b2d3a898fe8/</guid><description>From the viewpoint of applied computational complexity, statistics is a gold mine, for it provides a rich and extensive source of unalyzed algorithms and computational procedures. For the statistician, however, the search for efficient algorithms has not been of prime concerns for several reasons: First, the design of fast algorithms is a new and developing art. Second, until recently, the cost of obtaining data has been far greater than the cost of analyzing it. Now, hoever, speech and image processing provide information to statistical analysis programs rapidly and cheaply, so that fast analysis is of considerable important. Third, statisticians are properly concerned with the significance and effectiveness of the tests they perform, rather than with their cost. The result has been that the analysis of statistical algorithms remains largely ignored.</description></item><item><title>Egotism is Inevitable</title><link>https://aakinshin.net/library/quotes/ede52fa8-4ad3-4289-8bb8-ee6196d70ab6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/ede52fa8-4ad3-4289-8bb8-ee6196d70ab6/</guid><description>Some egotism of this sort is inevitable, and I do not feel that it really needs justification. Good work is not done by ‘humble’ men. It is one of the first duties of a professor, for example, in any subject, to exaggerate a little both the importance of his subject and his own importance in it. A man who is always asking ‘Is what I do worth while?’ and ‘Am I the right person to do it?’ will always be ineffective himself and a discouragement to others. He must shut his eyes a little and think a little more of his subject and himself than they deserve. This is not too difficult: it is harder not to make his subject and himself ridiculous by shutting his eyes too tightly.</description></item><item><title>Embarrassignly Large Confidence Intervals</title><link>https://aakinshin.net/library/quotes/a2e73f66-cacd-4065-94d2-b541952903ab/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/a2e73f66-cacd-4065-94d2-b541952903ab/</guid><description>&amp;ldquo;Everyone knows&amp;rdquo; that confidence intervals contain all the information to be found in significance tests and much more. They not only reveal the status of the trivial nil hypothesis but also about the status of non-nil null hypotheses and thus help remind researchers about the possible operation of the crud factor. Yet they are rarely to be found in the literature. I suspect that the main reason they are not reported is that they are so embarrassingly large!</description></item><item><title>Equivalence Testing and FDA Regulations</title><link>https://aakinshin.net/library/quotes/39e9af59-2697-45ca-bbf6-989c68d91e21/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/39e9af59-2697-45ca-bbf6-989c68d91e21/</guid><description>From a “historical” perspective (the first journal article on an equivalence test appeared as late as in the sixties of the twentieth century), the interest of statistical researchers in equivalence assessment was almost exclusively triggered by the introduction of special approval regulations for so-called generic drugs by the Food and Drug Administration (FDA) of the U.S. as well as the drug regulation authorities of many other industrial countries. Essentially, these regulations provide that the positive result of a test, which enables one to demonstrate with the data obtained from a so-called comparative bioavailability trial the equivalence of the new generic version of a drug to the primary manufacturer’s formulation, shall be accepted as a sufficient condition for approval of the generic formulation to the market. The overwhelming practi- cal importance of the entailed problems of bioequivalence assessment (drugs whose equivalence with respect to the measured bioavailabilities can be taken for granted, are termed “bioequivalent” in clinical pharmacology literature), arises mainly out of quantity: Nowadays, at least half of the prescription drug units sold in the leading industrial countries are generic drugs that have been approved to be marketed on the basis of some bioequivalence trial.</description></item><item><title>Equivalence vs. Noninferiority</title><link>https://aakinshin.net/library/quotes/10d3f239-933e-4eef-9f89-4f2e2c6e643e/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/10d3f239-933e-4eef-9f89-4f2e2c6e643e/</guid><description>When referring to specific problems and procedures, equivalence per se will always used in the strict, two-sided sense of the term. Noninferiority problems will be either called that way or, alternatively, addressed as one-sided equivalence problems.</description></item><item><title>Established Before Improved</title><link>https://aakinshin.net/library/quotes/b50e64cf-b22d-4b30-b562-1aa6cd9e032e/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/b50e64cf-b22d-4b30-b562-1aa6cd9e032e/</guid><description>The truth is, a habit must be established before it can be improved.</description></item><item><title>Evaluating the Reliability of Highly Cited Clinical Research Studies</title><link>https://aakinshin.net/library/quotes/3862f143-7b54-472a-b201-83407f62ac6c/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/3862f143-7b54-472a-b201-83407f62ac6c/</guid><description>Of 49 highly cited original clinical research studies, 45 claimed that the intervention was effective. Of these, 7 (16%) were contradicted by subsequent studies, 7 others (16%) had found effects that were stronger than those of subsequent studies, 20 (44%) were replicated, and 11 (24%) remained largely unchallenged. Five of 6 highlycited nonrandomized studies had been contradicted or had found stronger effects vs 9 of 39 randomized controlled trials (P=.008). Among randomized trials, studies with contradicted or stronger effects were smaller (P=.009) than replicated or unchallenged studies although there was no statistically significant difference in their early or overall citation impact. Matched control studies did not have a significantly different share of refuted results than highly cited studies, but they included more studies with “negative” results.</description></item><item><title>Every Habit is Context Dependent</title><link>https://aakinshin.net/library/quotes/6a9e517b-d8cb-434e-8f3e-ca1624f628a6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/6a9e517b-d8cb-434e-8f3e-ca1624f628a6/</guid><description>Every habit is context dependent.</description></item><item><title>Evidence-Based Rationality</title><link>https://aakinshin.net/library/quotes/aaf3096e-4db0-4a9b-a8ed-4ac409d58ab1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/aaf3096e-4db0-4a9b-a8ed-4ac409d58ab1/</guid><description>Ask yourself, “What kind of evidence would convince me to change my mind?” If the answer is “no evidence could ever change my mind about vaccination,” then you are putting yourself outside evidence-based rationality, outside the very critical thinking that first brought you to this point.</description></item><item><title>Falsifiability and Reality</title><link>https://aakinshin.net/library/quotes/a755755a-4bf6-4dc8-81ba-b1d76438eb62/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/a755755a-4bf6-4dc8-81ba-b1d76438eb62/</guid><description>In so far as a scientific statement speaks about reality, it must be falsifiable: and in so far as it is not falsifiable, it does not speak about reality.</description></item><item><title>Five Percieved Probability Values</title><link>https://aakinshin.net/library/quotes/68b00b34-b893-406a-963c-6775b11a9147/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/68b00b34-b893-406a-963c-6775b11a9147/</guid><description>There are only five probabilities the average human can handle: 99 percent, one percent, 100 percent, zero, and 50-50. That’s it.
Source: https://twitter.com/ProbFact/status/1559569468979908608</description></item><item><title>Forget about goals, Focus on Systems Instead</title><link>https://aakinshin.net/library/quotes/dd90e7dd-eec5-42d5-b3be-b97abe4a5d1f/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/dd90e7dd-eec5-42d5-b3be-b97abe4a5d1f/</guid><description>Forget about goals, focus on systems instead</description></item><item><title>Go Big or Go Home</title><link>https://aakinshin.net/library/quotes/ee7e09a3-3dd0-42ae-b953-b066ecab6daa/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/ee7e09a3-3dd0-42ae-b953-b066ecab6daa/</guid><description>Applying go big or go home to everything you do is a recipe for self-criticism and disappointment. We already know that the Motivation Monkey loves to help us make big moves, then slips away from us when the going gets tough. And doing big things can be painful. We often push ourselves beyond our physical, emotional, or mental capabilities. And while we might be able to keep up this effort for a while, humans don’t do things that are painful for very long. As you can imagine, this isn’t a good recipe for creating successful habits.</description></item><item><title>Goal Planning</title><link>https://aakinshin.net/library/quotes/7146fe49-6fe2-4848-9091-85f3d71181ac/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/7146fe49-6fe2-4848-9091-85f3d71181ac/</guid><description>The human mind is remarkably persistent in its pursuits, often even disturbingly so. Intrusive thoughts remind people of their unfulfilled goals, including to the point of interfering with other tasks. The present results, however, suggest an alternative possibility.
By planning for their goals, people can better manage their multiple pursuits. It has been well documented that specific plans increase success (Gollwitzer, 1999), doing so in part by making goal pursuit more automatic. Once a detailed plan has been made, one no longer has to think about the goal to execute it (Brandsta¨tter et al., 2001). Apparently, a plan reduces the amount of thoughts and attention that are typically recruited in service of an unfulfilled goal. Thoughts of an incomplete goal will not interfere with current concerns so long as a plan has been made to see the goal through later on.</description></item><item><title>Goals Restrict Your Happiness</title><link>https://aakinshin.net/library/quotes/09ced642-84e0-4542-81cb-53d4b0892a01/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/09ced642-84e0-4542-81cb-53d4b0892a01/</guid><description>Goals restrict your happiness.</description></item><item><title>Goodhart’s Law</title><link>https://aakinshin.net/library/quotes/7fbaf43d-ba09-4bb9-a1fb-be44d5c85e60/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/7fbaf43d-ba09-4bb9-a1fb-be44d5c85e60/</guid><description>This pitfall is evident in many areas of life. We focus on working long hours instead of getting meaningful work done. We care more about getting ten thousand steps than we do about being healthy. We teach for standardized tests instead of emphasizing learning, curiosity, and critical thinking. In short, we optimize for what we measure. When we choose the wrong measurement, we get the wrong behavior. This is sometimes referred to as Goodhart’s Law. Named after the economist Charles Goodhart, the principle states, “When a measure becomes a target, it ceases to be a good measure.” Measurement is only useful when it guides you and adds context to a larger picture, not when it consumes you. Each number is simply one piece of feedback in the overall system. In our data-driven world, we tend to overvalue numbers and undervalue anything ephemeral, soft, and difficult to quantify. We mistakenly think the factors we can measure are the only factors that exist. But just because you can measure something doesn’t mean it’s the most important thing. And just because you can’t measure something doesn’t mean it’s not important at all.</description></item><item><title>Grain Size and Sorting of Sediments</title><link>https://aakinshin.net/library/quotes/c8f7700c-3dae-4b39-ab68-71fd0df31b80/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/c8f7700c-3dae-4b39-ab68-71fd0df31b80/</guid><description>Two of the most discussed yet most poorly understood topics in this day of quantitative geology are the concepts of grain size and sorting of sediments. Countless values have veen published by research workers, recorded in innumerable theses, and secreted in oil company files: yet the meaning of all these figures and their ultimate geological significance (if any) are still quite obscure. One can hardly read a month&amp;rsquo;s publications without enountering plots of sorting versus size or distance; countour maps showing values of grain size parameters; or statemenets of the alleged increase of sorting with sediment transport. Despite all this effort, few of these papers attempt to explain why or how the parameters are varying. If this vagueness is true of fairly simple ideas such as mean size or sorting, the situation with regard to more complex parameters like skewness or kurtosis is even worse. Little attempt has been made to relate these measures to the mode of deposition or to environmental characteristcs and most published papers simply tabulate these values without any evident attempt to understand or interpret them. One begins to wonder if all these length computations are not wasted effort — do they show us anything of real value, or are they merely a deceptively impressive shell of figures surrounding a vacumm of geologic meaning?</description></item><item><title>Guidelines for Reviewers</title><link>https://aakinshin.net/library/quotes/1d8a5c7b-087b-4a6e-b60e-f144dd8a0f0b/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/1d8a5c7b-087b-4a6e-b60e-f144dd8a0f0b/</guid><description>We propose the following four guidelines for reviewers.
Reviewers should ensure that authors follow the requirements. Review teams are the gatekeepers of the scientific community, and they should encourage authors not only to rule out alternative explanations, but also to more convincingly demonstrate that their findings are not due to chance alone. This means prioritizing transparency over tidiness; if a wonderful study is partially marred by a peculiar exclusion or an inconsistent condition, those imperfections should be retained. If reviewers require authors to follow these requirements, they will. Reviewers should be more tolerant of imperfections in results. One reason researchers exploit researcher degrees of freedom is the unreasonable expectation we often impose as reviewers for every data pattern to be (significantly) as predicted. Underpowered studies with perfect results are the ones that should invite extra scrutiny. Reviewers should require authors to demonstrate that their results do not hinge on arbitrary analytic decisions. Even if authors follow all of our guidelines, they will necessarily still face arbitrary decisions. For example, should they subtract the baseline measure of the dependent variable from the final result or should they use the baseline measure as a covariate? When there is no obviously correct way to answer questions like this, the reviewer should ask for alternatives. For example, reviewer reports might include questions such as, “Do the results also hold if the baseline measure is instead used as a covariate?” Similarly, reviewers should ensure that arbitrary decisions are used consistently across studies (e.g., “Do the results hold for Study 3 if gender is entered as a covariate, as was done in Study 2?”).5 If a result holds only for one arbitrary specification, then everyone involved has learned a great deal about the robustness (or lack thereof) of the effect. If justifications of data collection or analysis are not compelling, reviewers should require the authors to conduct an exact replication.</description></item><item><title>How Far He Could Go</title><link>https://aakinshin.net/library/quotes/230a62ed-ccf0-4f30-a1ca-292854936685/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/230a62ed-ccf0-4f30-a1ca-292854936685/</guid><description>His goal wasn’t to reach some predetermined extreme but to see how far he could go.</description></item><item><title>How Long Does It Take to Build a New habit?</title><link>https://aakinshin.net/library/quotes/b865e647-651e-4f8e-ace2-064b2f75ba3d/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/b865e647-651e-4f8e-ace2-064b2f75ba3d/</guid><description>One of the most common questions I hear is, “How long does it take to build a new habit?” But what people really should be asking is, “How many does it take to form a new habit?” That is, how many repetitions are required to make a habit automatic?
There is nothing magical about time passing with regard to habit formation. It doesn’t matter if it’s been twenty-one days or thirty days or three hundred days. What matters is the rate at which you perform the behavior. You could do something twice in thirty days, or two hundred times. It’s the frequency that makes the difference. Your current habits have been internalized over the course of hundreds, if not thousands, of repetitions. New habits require the same level of frequency. You need to string together enough successful attempts until the behavior is firmly embedded in your mind and you cross the Habit Line.</description></item><item><title>How to Lie with Smoking Statistics</title><link>https://aakinshin.net/library/quotes/c7d9734a-45b7-4537-a692-93abb79a4e25/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/c7d9734a-45b7-4537-a692-93abb79a4e25/</guid><description>Attempting to capitalize on Huff’s respected status, the tobacco industry commissioned him to testify before Congress and then to write a book, tentatively titled &amp;lsquo;How to Lie with Smoking Statistics&amp;rsquo;, covering the many statistical and logical errors alleged to be found in the surgeon general’s report. Huff completed a manuscript, for which he was paid more than $9,000 > (roughly $60,000 in 2014 dollars) by tobacco companies and which was positively reviewed by University of Chicago statistician (and paid tobacco industry consultant) K.A. Brownlee. Although it was never published, it’s likely that Huff’s friendly, accessible style would have made a strong impression on the public, providing talking points for watercooler arguments.
Read more: reinhart2014.</description></item><item><title>Hunter is Affected by Strong Noise</title><link>https://aakinshin.net/library/quotes/a4192cbd-ee25-4d65-a58c-b300885d098a/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/a4192cbd-ee25-4d65-a58c-b300885d098a/</guid><description>One of the teams using Hunter was afflicted with frequent change point messages via the Slack bot. After investigating these change points they discovered that the performance of the application hadn’t changed, rather the change in benchmark results was caused by unstable hardware performance in a private data center. Changes of +- 10% for the median latency were typical.
While Hunter can detect statistically significant changes in time series data, it is still not impervious to data that contains wildly fluctuating points such as that produced by running benchmarks on untuned hardware.</description></item><item><title>Ill-Defined and well-defined Problems</title><link>https://aakinshin.net/library/quotes/fdecbf50-a5d0-4999-87bf-8e7357542223/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/fdecbf50-a5d0-4999-87bf-8e7357542223/</guid><description>At the one extreme are &amp;ldquo;well-defined&amp;rdquo; problems, at the other are &amp;ldquo;ill-defined&amp;quot;problems. Well-defined problems (like the chemical composition of the lunar samples) are amenableto solution in that they can be clearly posed and hence solved by relatively clear-cut, standard, analytic tech- niques; they are &amp;ldquo;consensible&amp;rdquo;(Ziman, 1968) ifnthat a relatively wide degree of consensus can be obtained regardingthe &amp;ldquo;natureof the problem;&amp;rdquo; in short, they are easily formulated. Ill-defined problems (like the origin of the moon) are almost defiantly elusive; they seem to defy a common &amp;ldquo;consensible&amp;rdquo; formulation (Mitroff and Betz, 1972). Beause of their widespreadconsensiblenature, well-defined problems seem independent of the personality of their formulators; they appearto be impersonal. Ill-defined problems, on the other hand, appearto be the intensely personal creations of their creators. Whereas the conventional norms of science are dominant for well-structured problems, the counter-norms proposed here appear to be dominant for ill-structured problems.</description></item><item><title>Illusions in Our Brains</title><link>https://aakinshin.net/library/quotes/2e3a822e-99a9-4393-bc0a-46b3627158fb/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/2e3a822e-99a9-4393-bc0a-46b3627158fb/</guid><description>My glasses have a custom lens to correct for my personal sight problem. But when I look at this optical illusion, I still misinterpret what I see, just like everyone else. This is because illusions don’t happen in our eyes, they happen in our brains. They are systematic misinterpretations, unrelated to individual sight problems.</description></item><item><title>Incorrect Conclusions</title><link>https://aakinshin.net/library/quotes/6a109ebe-d385-4150-a1b8-ddc1c81e46b3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/6a109ebe-d385-4150-a1b8-ddc1c81e46b3/</guid><description>Unfortunately, some in the scientific community have derived incorrect conclusions from this experience. It has been widely but incorrectly reported that the TOMS team missed the discovery of the ozone hole since “they rejected the data and discovered it only after the publication of Farman et al. 1985 paper” (see Seinfeld &amp;amp; Pandis 1998, page 189, for a typical example). In fact when the South Pole Dobson data from October 1984 became available to the TOMS team in late 1984, well before the publication of Farman et al. paper, there was no doubt on the validity of satellite total ozone retrievals. (Ironically, October 1983 total ozone values initially reported by the S. Pole station showed normal ozone values that were much larger than that being reported by TOMS. These data were later withdrawn by the station.) The correct conclusion that should be derived from this experience is that remote sensing techniques, such as those used by nadir-viewing satellites, depend critically on information generated by in-situ techniques because of their dependence on prior information. When the retrievals are pushed beyond the limits set by prior information the data become suspect. To report such data without proper validation is scientifically irresponsible. The TOMS team followed the correct approach even though it caused several months delay in reporting the data to the scientific community.</description></item><item><title>Incorrect Statistical Procedures in Neuroscience</title><link>https://aakinshin.net/library/quotes/4e6b0a2d-9a6c-4b97-9c15-b7009ef063a5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/4e6b0a2d-9a6c-4b97-9c15-b7009ef063a5/</guid><description>In theory, a comparison of two experimental effects requires a statistical test on their difference. In practice, this comparison is often based on an incorrect procedure involving two separate tests in which researchers conclude that effects differ when one effect is significant (P &amp;lt; 0.05) but the other is not (P &amp;gt; 0.05). We reviewed 513 behavioral, systems and cognitive neuroscience articles in five top-ranking journals (Science, Nature, Nature Neuroscience, Neuron and The Journal of Neuroscience) and found that 78 used the correct procedure and 79 used the incorrect procedure. An additional analysis suggests that incorrect analyses of interactions are even more common in cellular and molecular neuroscience.</description></item><item><title>Investigating the Probability of Rejecting Null Hypotheses in Abnormal-Social Research</title><link>https://aakinshin.net/library/quotes/fcecf1bc-d282-46ec-b32a-86dc4b053695/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/fcecf1bc-d282-46ec-b32a-86dc4b053695/</guid><description>The results indicate that the investigators contributing to Volume 61 of the Journal of Abnormal and Social Psychology had, on the average, a relatively (or even absolutely) poor chance of rejecting their major null hypotheses, unless the effect they sought was large. This surprising (and discouraging) finding needs some further consideration to be seen in full perspective.
First, it may be noted that with few exceptions, the 70 studies did have significant results. This may then suggest that perhaps the definitions of size of effect were too severe, or perhaps, accepting the definitions, one might seek to conclude that the investigators were operating under circumstances wherein the effects were actually large, hence their success. Perhaps, then, research in the abnormal-social area is not as &amp;ldquo;weak&amp;rdquo; as the above results suggest. But this argument rests on the implicit assumption that the research which is published is representative of the research undertaken in this area. It seems obvious that investigators are less likely to submit for publication unsuccessful than successful research, to say nothing of a similar editorial bias in accepting research for publication. Consider this paradigm: 100 investigations are undertaken in which, in fact, there is actually a medium population effect. From the above findings, about SO get positive results and are likely to come to publication; the other SO fail to reject their (assumed false) null hypotheses and are unlikely to come to publication. Thus, the general success of the articles in the volume under review does not successfully argue for their antecedent probabilities of success being any higher than the results of the analysis suggest, or, equivalently, that the criteria for size of effect used were overly stringent.&amp;quot;</description></item><item><title>Jittering as a Statistical Irony</title><link>https://aakinshin.net/library/quotes/f1bd2864-ab15-4888-af78-83b48d0a4cb5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/f1bd2864-ab15-4888-af78-83b48d0a4cb5/</guid><description>The act of jittering (adding random noise to data) is a statistical irony: statisticians spend most of their day trying &amp;ldquo;remove&amp;rdquo; noise from data, but jittering puts noise back in!</description></item><item><title>Joint P and E Usage</title><link>https://aakinshin.net/library/quotes/80ed236b-ff1e-4214-9995-6e5f12948167/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/80ed236b-ff1e-4214-9995-6e5f12948167/</guid><description>Consider the P value and the E value jointly; if the P value is small and the E value is substantial, then a real effect is obtained.</description></item><item><title>Journal’s Impact Factor and Overestimation of Effect Sizes</title><link>https://aakinshin.net/library/quotes/544f89c6-188a-488a-a13a-585caf62ef81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/544f89c6-188a-488a-a13a-585caf62ef81/</guid><description>Some evidence suggests a correlation between a journal’s impact factor (a rough measure of its prominence and importance) and the factor by which its studies overestimate effect sizes. Studies that produce less “exciting” results are closer to the truth but less interesting to a major journal editor.</description></item><item><title>Learning from Outliers</title><link>https://aakinshin.net/library/quotes/103ff452-2341-44a3-8891-202422abfb08/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/103ff452-2341-44a3-8891-202422abfb08/</guid><description>Conventional psychology consciously ignores outliers because they don’t fit the pattern. I’ve sought to do the opposite: Instead of deleting these outliers, I want to learn from them.</description></item><item><title>Lifeline</title><link>https://aakinshin.net/library/quotes/f2892ab3-3c83-42f2-8ee3-6088a9972325/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/f2892ab3-3c83-42f2-8ee3-6088a9972325/</guid><description>I watched my own brain nearly succumb to this trap when I was researching this chapter. I generally love reading psychology books at coffee shops and then talking about their ideas with my colleagues and students. My brain considers that “fun” and “playtime.” But because I had a deadline for finishing this book and I needed to read those studies for research, suddenly my mindset changed. Reading psychology books was now “work,” and my brain attempted to avoid what I normally love. Tasks I once completed quickly and joyfully now made me feel as though I were wading through mental molasses.
I realized it was time to move the fulcrum. I thought about how I was defining the task mentally (menial labor) and consciously changed it (to reading for enrichment). I also changed the language I used to describe the activity to other people. After telling a few friends I was at Starbucks reading for pleasure, I started to realize that in fact I was. Altering my conception of the time constraints also proved helpful. Tal Ben-Shahar has pointed out that the term “deadline” is about as negative as you can get. How true! He likes to use the term “lifeline” instead. For me, the renewed enthusiasm for my work came when I ignored the constraint entirely and thought only of the intrinsic value I derived from the activity itself, instead of simply when it was “due.” It also helped to stop focusing on how I would “use” the material I was reading later on. When we reconnect ourselves with the pleasure of the “means,” as opposed to only focusing on the “ends,” we adopt a mindset more conducive not only to enjoyment, but to better results. (I’m pleased to report that I did in fact turn my manuscript in on time, in case you’re wondering.</description></item><item><title>List of Boring Activities</title><link>https://aakinshin.net/library/quotes/6a21ae71-b0a9-4105-aa4e-cd447fabcc05/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/6a21ae71-b0a9-4105-aa4e-cd447fabcc05/</guid><description> During a monthlong experiment I intentionally made myself bored for an hour a day. In that period I shut off all distractions and spent my time and attention on an excruciatingly boring task, based on the thirty weirdest ideas suggested by my website readers:
Reading the iTunes terms and conditions Staringattheceiling Watching C-SPAN 3 Waiting on hold with Air Canada’s baggage claim department Watching C-SPAN 2 Watching my turtle, Edward, swim back and forth in her tank Staringataslowlyrotatingfanblade Painting a tiny canvas with one color Watchingpaintdry Looking out my office window Removing and counting the seeds on a strawberry with a pair of tweezers 12.Watching grass grow Staring out a train window Watching an online chess tournament Watching one cloud in the sky Waiting at the hospital Watching a dripping faucet Ironing every piece of clothing I own Counting the 0s in the first 10,000 digits of pi Watching my girlfriend read Making dots on a sheet of paper Eating alone in a restaurant, without a book or phone Reading Wikipedia articles about rope Watching a clock Watching every file transfer from my computer to an external hard drive (and back) Peeling exactly five potatoes Watching a pot boil Attending a church service in Latin Watching C-SPAN Moving small rocks from one place to another, repeatedly</description></item><item><title>List of Good Things</title><link>https://aakinshin.net/library/quotes/e83baeac-9871-4843-967a-42e4c579543d/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/e83baeac-9871-4843-967a-42e4c579543d/</guid><description>Just as it takes days of concentrated practice to master a video game, training your brain to notice more opportunities takes practice focusing on the positive. The best way to kick-start this is to start making a daily list of the good things in your job, your career, and your life. It may sound hokey, or ridiculously simple—and indeed the activity itself is simple—but over a decade of empirical studies has proven the profound effect it has on the way our brains are wired. When you write down a list of “three good things” that happened that day, your brain will be forced to scan the last 24 hours for potential positives—things that brought small or large laughs, feelings of accomplishment at work, a strengthened connection with family, a glimmer of hope for the future. In just five minutes a day, this trains the brain to become more skilled at noticing and focusing on possibilities for personal and professional growth, and seizing opportunities to act on them. At the same time, because we can only focus on so much at once, our brains push out those small annoyances and frustrations that used to loom large into the background, even out of our visual field entirely.</description></item><item><title>Locking Future Behavior</title><link>https://aakinshin.net/library/quotes/9bbb685d-186c-4b56-918e-002011dfff3a/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/9bbb685d-186c-4b56-918e-002011dfff3a/</guid><description> A commitment device is a choice you make in the present that controls your actions in the future. It is a way to lock in future behavior, bind you to good habits, and restrict you from bad ones. When Victor Hugo shut his clothes away so he could focus on writing, he was creating a commitment device.
See also:
The Victor Hugo working naked story: myth or fact?</description></item><item><title>Look Elsewhere Effect in Physics</title><link>https://aakinshin.net/library/quotes/ce332bef-224c-42b5-8235-9a412e36de23/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/ce332bef-224c-42b5-8235-9a412e36de23/</guid><description>When searching for a new resonance somewhere in a possible mass range, the significance of observing a local excess of events must take into account the probability of observing such an excess anywhere in the range. This is the so called “look elsewhere effect”. The effect can be quantified in terms of a trial factor, which is the ratio between the probability of observing the excess at some fixed mass point, to the probability of observing it anywhere in the range.</description></item><item><title>Low Statistical Power</title><link>https://aakinshin.net/library/quotes/982229dc-9c49-4800-8039-c08ca40858e3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/982229dc-9c49-4800-8039-c08ca40858e3/</guid><description>Objective. To describe the pattern over time in the level of statistical power and the reporting of sample size calculations in published randomized controlled trials (RCTs) with negative results.
Design. Ourstudy was a descriptive survey. Power to detect 25% and 50% relative differences was calculated for the subset of trials with negative results in which a simple two-group parallel design was used. Criteria were developed both to classify trial results as positive or negative and to identify the primary outcomes. Power calculations were based on results from the primary outcomes reported in the trials.
Population. We reviewed all 383 RCTs published in JAMA, Lancet, and the New England Journal of Medicine in 1975, 1980, 1985, and 1990.
Results. Twenty-sevenpercent of the 383 RCTs (n=102) were classified as having negative results. The number of published RCTs more than doubled from 1975 to 1990, with the proportion of trials with negative results remaining fairly stable. Of the simple two-group parallel design trials having negative results with dichotomous or continuous primary outcomes (n=70), only 16% and 36% had sufficient statistical power (80%) to detect a 25% or 50% relative difference, respectively. These percentages did not consistently increase overtime. Overall, only 32% of the trials with negative results reported sample size calculations, but the percentage doing so has improved over time from 0% in 1975 to 43% in 1990. Only 20 of the 102 reports made any statement related to the clinical significance of the observed differences.
Conclusions. Most trials with negative results did not have large enough sample sizes to detect a 25% or a 50% relative difference. This result has not changed over time. Few trials discussed whether the observed differences were clinically important. There are important reasons to change this practice. The reporting of statistical power and sample size also needs to be improved.</description></item><item><title>Making the Study Positive</title><link>https://aakinshin.net/library/quotes/613be7e4-c3fd-405a-be24-1874a4c93a26/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/613be7e4-c3fd-405a-be24-1874a4c93a26/</guid><description>Believing there is a difference between groups, a well-intentioned clinician researcher addresses unexpected values. We tested how much removal, remeasurement, or reclassification of patients would be needed in most cases to turn an otherwise-neutral study positive. Remeasurement of 19 patients out of 200 per group was required to make most studies positive. Removal was more powerful: just 9 out of 200 was enough. Reclassification was most powerful, with 5 out of 200 enough. The larger the study, the smaller the proportion of patients needing to be manipulated to make the study positive: the percentages needed to be remeasured, removed, or reclassified fell from 45%, 20%, and 10% respectively for a 20 patient-per-group study, to 4%, 2%, and 1% for an 800 patient-per-group study. Dot-plots, but not bar-charts, make the perhaps-inadvertent manipulations visible.</description></item><item><title>Material Significance</title><link>https://aakinshin.net/library/quotes/fb35e80b-410b-456e-9cbd-c167d9f31062/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/fb35e80b-410b-456e-9cbd-c167d9f31062/</guid><description>It seems to us that this difficulty can be avoided by making a clear distinction, in the formulation of the problem, between &amp;ldquo;statistical significance&amp;rdquo; and what might be called &amp;ldquo;material significance&amp;rdquo;.</description></item><item><title>Misunderstanding of Confidence Intervals and Standard Error Bars</title><link>https://aakinshin.net/library/quotes/22a80e19-4456-4510-8a14-7415b537a7da/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/22a80e19-4456-4510-8a14-7415b537a7da/</guid><description>Little is known about researchers’ understanding of confidence intervals (CIs) and standard error (SE) bars. Authors of journal articles in psychology, behavioral neuroscience, and medicine were invited to visit a Web site where they adjusted a figure until they judged 2 means, with error bars, to be just statistically significantly different (p &amp;lt; .05). Results from 473 respondents suggest that many leading researchers have severe misconceptions about how error bars relate to statistical significance, do not adequately distinguish CIs and SE bars, and do not appreciate the importance of whether the 2 means are independent or come from a repeated measures design. Better guidelines for researchers and less ambiguous graphical conventions are needed before the advantages of CIs for research communication can be realized.</description></item><item><title>Monte Carlo Methods</title><link>https://aakinshin.net/library/quotes/cdce4d2e-fb19-44fb-997f-4d1981e471a2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/cdce4d2e-fb19-44fb-997f-4d1981e471a2/</guid><description>Monte Carlo is an extremely bad method; it should only be used when all alternative methods are worse.</description></item><item><title>Most People Can Do Nothing Well</title><link>https://aakinshin.net/library/quotes/dd819038-b910-43ed-877b-2cf845d840bb/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/dd819038-b910-43ed-877b-2cf845d840bb/</guid><description>It is quite true that most people can do nothing well. If so, it matters very little what career they choose, and there is really nothing more to say about it.</description></item><item><title>Multi-Tasking and Attention</title><link>https://aakinshin.net/library/quotes/39d2895b-46a3-47ea-89e1-18852cdace52/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/39d2895b-46a3-47ea-89e1-18852cdace52/</guid><description>Multi-tasking (i.e. doing several things simultaneously) has often been considered in terms of what people &amp;ldquo;do&amp;rdquo; and not necessarily in terms of what people &amp;ldquo;think about&amp;rdquo; or how they allocate their attention among their tasks. The present research suggests that even when people are behaviorally focused on one task and are not multi-tasking, their minds may not be com- pletely focused on the task at hand. In other words, multi-tasking may not only be due to competing simultaneous demands, like receiving an email or a text message during a meeting, but may also be a function of how the mind operates in a context where people must manage multiple tasks, activities or responsibilities at the same time.</description></item><item><title>My Intellectual Superiority</title><link>https://aakinshin.net/library/quotes/74f82fe8-c5b2-42c3-ac0b-fb969d32d39e/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/74f82fe8-c5b2-42c3-ac0b-fb969d32d39e/</guid><description>I was aware of my intellectual superiority by age six or earlier.</description></item><item><title>Natural Population is Ever Exactly Normal</title><link>https://aakinshin.net/library/quotes/8c0aba63-5274-4e0c-9ff5-a564a8765962/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/8c0aba63-5274-4e0c-9ff5-a564a8765962/</guid><description>For example, we may formulate the hypothesis that a population is normally distributed, but we realize that no natural population is ever exactly normal. We would want to reject normality only if the departure of the actual distribution from the normal form were great enough to be material for our investigation.</description></item><item><title>Neyman-Pearson vs. Fisher</title><link>https://aakinshin.net/library/quotes/e9011bc6-0eaf-4e76-8090-0331bd513617/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/e9011bc6-0eaf-4e76-8090-0331bd513617/</guid><description>It is not generally appreciated that the p value, as conceived by R. A. Fisher, is not compatible with the Neyman-Pearson hypothesis test in which it has become embedded. The p value was meant to be a flexible inferential measure, whereas the hypothesis test was a rule for behavior, not inference. The combination of the two methods has led to a reinterpretation of the p value simultaneously as an &amp;ldquo;observed error rate&amp;rdquo; and as a measure of evidence. Both of these interpretations are problematic, and their combination has obscured the important differences between Neyman and Fisher on the nature of the scientific method and inhibited our understanding of the philosophic implications of the basic methods in use today. An analysis using another method promoted by Fisher, mathematical likelihood, shows that the p value substantially overstates the evidence against the null hypothesis. Likelihood makes clearer the distinction between error rates and inferential evidence and is a quantitative tool for expressing evidential strength that is more appropriate for the purposes of epidemiology than the p value.</description></item><item><title>Neyman–pearson vs. Fisher</title><link>https://aakinshin.net/library/quotes/510b2ea5-0e1c-4aa9-8e13-28240daf157a/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/510b2ea5-0e1c-4aa9-8e13-28240daf157a/</guid><description>Confusion surrounding the reporting and interpretation of results of classical statistical tests is widespread among applied researchers, most of whom erroneously believe that such tests are prescribed by a single coherent theory of statistical inference. This is not the case: Classical statistical testing is an anonymous hybrid of the competing and frequently contradictory approaches formulated by R. A. Fisher on the one hand, and Jerzy Neyman and Egon Pearson on the other. In particular, there is a widespread failure to appreciate the incompatibility of Fisher’s evidential p value with the Type I error rate, α, of Neyman–Pearson statistical orthodoxy. The distinction between evidence (p’s) and error (α ’s) is not trivial. Instead, it reflects the fundamental differences between Fisher’s ideas on significance testing and inductive inference, and Neyman–Pearson’s views on hypothesis testing and inductive behavior. The emphasis of the article is to expose this incompatibility, but we also briefly note a possible reconciliation.</description></item><item><title>NHST</title><link>https://aakinshin.net/library/quotes/0dff54f2-c974-483a-a6b6-81eb944d4882/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/0dff54f2-c974-483a-a6b6-81eb944d4882/</guid><description>What&amp;rsquo;s wrong with NHST? Well, among many other things, it does not tell us what we want to know, and we so much want to know what we want to know that, out of desperation, we nevertheless believe that it does!</description></item><item><title>NHST</title><link>https://aakinshin.net/library/quotes/f75b2f1f-b183-45f5-a015-f0cf16344a19/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/f75b2f1f-b183-45f5-a015-f0cf16344a19/</guid><description>We are inclined to think that as far as a particular hypothesis is concerned, no test based upon the theory of probability can by itself provide any valuable evidence of the truth or falsehood of that hypothesis.
But we may look at the purpose of tests from another view-point. Without hoping to know whether each separate hypothesis is true or false, we may search for rules to govern our behaviour with regard to them, in following which we insure that, in the long run of experience, we shall not be too often wrong.</description></item><item><title>No Benefit of n−3 Fatty Acids on Reducing the Risk of Death from Cardiovascular Causes</title><link>https://aakinshin.net/library/quotes/0f384174-3c23-405e-9d51-d85c98e713d6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/0f384174-3c23-405e-9d51-d85c98e713d6/</guid><description>In summary, we conducted a randomized trial of n−3 fatty acids in a large population of patients with multiple cardiovascular risk factors but no history of myocardial infarction. The trial incorporated systematic efforts to optimize medical therapies and control cardiovascular risk factors. On the basis of the results, we conclude that there was no significant benefit of n−3 fatty acids in reducing the risk of death from cardiovascular causes or hospital admission for cardiovascular causes.</description></item><item><title>No Black and White Balls</title><link>https://aakinshin.net/library/quotes/ff0b2c37-5936-46d9-99ff-a9cc47b3ed64/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/ff0b2c37-5936-46d9-99ff-a9cc47b3ed64/</guid><description>I have a considerable interest in mathematical statistics, but very little competency in it. You will not hear anything about cards or black and white balls from me. I shall speak as a practitioner who has frequently applied the test to real observations, made seriously for the solution of concrete scientific problems.</description></item><item><title>Noise and Real Effects</title><link>https://aakinshin.net/library/quotes/ca6fb0ae-cfb4-406b-b47d-603f05d13cd6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/ca6fb0ae-cfb4-406b-b47d-603f05d13cd6/</guid><description>A statistically insignificant difference could be nothing but noise, or it could represent a real effect that can be pinned down only with more data.</description></item><item><title>Non-Correct Statement</title><link>https://aakinshin.net/library/quotes/3f621733-8cca-4baf-8f19-c9f1a4701dac/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/3f621733-8cca-4baf-8f19-c9f1a4701dac/</guid><description>This myth was the result of a statement made by one of my colleagues in reply to a question during an interview on the science program NOVA in which he was asked why NASA did not discover the ozone hole first. He was not directly involved in ozone processing at that time and his answer was not correct.</description></item><item><title>Normal Subjects</title><link>https://aakinshin.net/library/quotes/ca964333-044c-4fec-8d89-145921696525/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/ca964333-044c-4fec-8d89-145921696525/</guid><description>Normal or approximately normal subjects are less useful objects of research than their pathological counterparts.</description></item><item><title>Normality is a Myth</title><link>https://aakinshin.net/library/quotes/3ebdf436-7f2c-4840-8680-1fe2c1a9496a/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/3ebdf436-7f2c-4840-8680-1fe2c1a9496a/</guid><description>Normality is a myth; there never was, and never will be, a normal distribution.</description></item><item><title>Occult Effects</title><link>https://aakinshin.net/library/quotes/a2c994b2-6063-4a15-b7a4-0d14f4ea5eee/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/a2c994b2-6063-4a15-b7a4-0d14f4ea5eee/</guid><description>Every experimental physicist knows those surprising and inexplicable apparent ‘effects’ which in his laboratory can perhaps even be reproduced for some time, but which finally disappear without trace. Of course, no physicist would say in such a case that he had made a scientific discovery (though he might try to rearrange his experiments so as to make the effect reproducible). Indeed the scientifically significant physical effect may be defined as that which can be regularly reproduced by anyone who carries out the appropriate experiment in the way prescribed. No serious physicist would offer for publication, as a scientific discovery, any such ‘occult effect’, as I propose to call it — one for whose reproduction he could give no instructions. The ‘discovery’ would be only too soon rejected as chimerical, simply because attempts to test it would lead to negative results. (It follows that any controversy over the question whether events which are in principle unrepeatable and unique ever do occur cannot be decided by science: it would be a metaphysical controversy.)</description></item><item><title>On College Professors</title><link>https://aakinshin.net/library/quotes/08bf0dd4-ae92-4925-9a95-4dbcf2079634/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/08bf0dd4-ae92-4925-9a95-4dbcf2079634/</guid><description>While I have mellowed with age and become more tolerant of other people’s frailties (as I hope they are of mine), I must confess that I have never fully recovered from the shock of realizing that one can become a college professor and not be able to think straight.</description></item><item><title>On the Triumph of Mediocrity in Business</title><link>https://aakinshin.net/library/quotes/44145d2a-d5dc-41ea-8376-174d942ed091/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/44145d2a-d5dc-41ea-8376-174d942ed091/</guid><description>A final, famous example dates back to 1933, when the field of mathematical statistics was in its infancy. Horace Secrist, a statistics professor at Northwestern University, published The Triumph of Mediocrity in Business, which argued that unusually successful businesses tend to become less successful and unsuccessful businesses tend to become more successful: proof that businesses trend toward mediocrity. This was not a statistical artifact, he argued, but a result of competitive market forces. Secrist supported his argument with reams of data and numerous charts and graphs and even cited some of Galton’s work in regression to the mean. Evidently, Secrist did not understand Galton’s point.</description></item><item><title>P Values Like Mosquitos</title><link>https://aakinshin.net/library/quotes/5b71be63-c543-4d94-8c3a-aafff77ca666/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/5b71be63-c543-4d94-8c3a-aafff77ca666/</guid><description>Perhaps p values are like mosquitos. They have an evolutionary niche somewhere and no amount of scratching, swatting, or spraying will dislodge them</description></item><item><title>P-Value Beyond Any Usual Limit of Significance</title><link>https://aakinshin.net/library/quotes/7d8010cb-c8b9-4878-801f-c267f591282d/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/7d8010cb-c8b9-4878-801f-c267f591282d/</guid><description>I believe that an observant statistician who has had any considerable experience with applying the chi-square test repeatedly will agree with my statement that, as a matterof observation, when the numbersin the data are quite large, the P&amp;rsquo;s tend to come out small. Having observed this, and on reflection, I make the following dogmatic statement, referring for illustration to the normal curve: &amp;ldquo;If the normal curve is fitted to a body of data representingany real observations whatever of quantitiesin the physical world, hen if the number of observationsis extremely large - for instance, on the order of 200,000-the chi-square P will be small beyond any usual limit of significance.&amp;rdquo;</description></item><item><title>Pareto vs. Gaussian</title><link>https://aakinshin.net/library/quotes/8051c319-407d-4298-a6ac-d264553f545f/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/8051c319-407d-4298-a6ac-d264553f545f/</guid><description>This means that large values are much more likely to occur under a Pareto distribution than under a Gaussian or Exponential distribution. For example, you are much more likely to meet someone who’s income is 10 times the average than someone whose height is ten times the average.</description></item><item><title>Passive Learning vs. Active Practice</title><link>https://aakinshin.net/library/quotes/72bc8b1a-cf43-41bf-9d25-78d6312f22da/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/72bc8b1a-cf43-41bf-9d25-78d6312f22da/</guid><description>Passive learning creates knowledge. Active practice creates skill.</description></item><item><title>People You Meet</title><link>https://aakinshin.net/library/quotes/d4fe8282-aebc-4abc-ba8b-e19bb83c98f7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/d4fe8282-aebc-4abc-ba8b-e19bb83c98f7/</guid><description>Statistically speaking, most of the people you meet will be fair to middling stupid.</description></item><item><title>Plot and Eye</title><link>https://aakinshin.net/library/quotes/5277cbcc-0a1a-4094-8dab-5360a6876aa6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/5277cbcc-0a1a-4094-8dab-5360a6876aa6/</guid><description>It may well be true that &amp;ldquo;plot and eye&amp;rdquo; is the most diverse channel to the human mind. Not that it transmits more bits per second, but rather that it will transmit a greater variety of messages on unexpected topics easily and rapidly. There really seems to be no substitute for &amp;ldquo;looking at the data.&amp;rdquo;</description></item><item><title>Pointing-And-Calling</title><link>https://aakinshin.net/library/quotes/1f1da997-a042-4ff9-aa30-64c5cfa85f63/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/1f1da997-a042-4ff9-aa30-64c5cfa85f63/</guid><description>Pointing-and-Calling raises your level of awareness from a nonconscious habit to a more conscious level by verbalizing your actions.</description></item><item><title>Post Mortem Examination</title><link>https://aakinshin.net/library/quotes/e361cd8b-796d-4edd-8b8a-1f5325c9801c/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/e361cd8b-796d-4edd-8b8a-1f5325c9801c/</guid><description>To consult the statistician after an experiment is fnished is often merely to ask him to conduct a post mortem examination. He can perhaps say what the experiment died of.</description></item><item><title>Pseudoreplication in Experimental Studies</title><link>https://aakinshin.net/library/quotes/c5d9190f-aaaa-4d7b-96f6-84186076c145/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/c5d9190f-aaaa-4d7b-96f6-84186076c145/</guid><description>Pseudoreplication is defined as the use of inferential statistics to test for treatment effects with data from experiments where either treatments are not replicated (though samples may be) or replicates are not statistically independent. In ANOVA terminology, it is the testing for treatment effects with an error term inappropriate to the hypothesis being considered. Scrutiny of 176 experimental studies published between 1960 and the present revealed that pseudoreplication occurred in 27% of them, or 48% of all such studies that applied inferential statistics. The incidence of pseudoreplication is especially high in studies of marine benthos and small mammals.</description></item><item><title>Pseudoreplication in Neuroscience Research:</title><link>https://aakinshin.net/library/quotes/e9ebe56a-db58-4982-9d18-d15926814ecc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/e9ebe56a-db58-4982-9d18-d15926814ecc/</guid><description>Of the nineteen papers published in the August 2008 issue of Nature Neuroscience, seventeen papers (89%) used inferential statistics; of these, only three (18%) had sufficient information to assess whether there was pseudoreplication. Of these three, two appeared to have pseudoreplication. Of the fourteen papers that used inferential statistics but did not provide sufficient information, five (36%) were suspected of having pseudoreplication, but it was not possible to determine for certain.</description></item><item><title>Public Statements</title><link>https://aakinshin.net/library/quotes/48dc66e4-407a-4dc7-a408-218194500f76/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/48dc66e4-407a-4dc7-a408-218194500f76/</guid><description>If you make neutral statements, nobody really listens to you. You have to stick your neck out. The statements you make in public are actually stronger than you believe in. You have to get people to remember that you represent a point of view even if for you it&amp;rsquo;s just a possibility.</description></item><item><title>Putting the Knowledge to Use</title><link>https://aakinshin.net/library/quotes/e97131d7-630a-4928-a457-c54d846172a4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/e97131d7-630a-4928-a457-c54d846172a4/</guid><description>He isn’t focused on simply soaking up knowledge. He is committed to putting that knowledge to use.</description></item><item><title>Questionable Practices</title><link>https://aakinshin.net/library/quotes/a40b9984-ae39-4f04-821b-42f8fabf5719/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/a40b9984-ae39-4f04-821b-42f8fabf5719/</guid><description>Cases of clear scientific misconduct have received significant media attention recently, but less flagrantly questionable research practices may be more prevalent and, ultimately, more damaging to the academic enterprise. Using an anonymous elicitation format supplemented by incentives for honest reporting, we surveyed over 2,000 psychologists about their involvement in questionable research practices. The impact of truth-telling incentives on self-admissions of questionable research practices was positive, and this impact was greater for practices that respondents judged to be less defensible. Combining three different estimation methods, we found that the percentage of respondents who have engaged in questionable practices was surprisingly high. This finding suggests that some questionable practices may constitute the prevailing research norm.</description></item><item><title>Recognizing Fallacies</title><link>https://aakinshin.net/library/quotes/46d1d9c2-9ed0-46da-848a-eb2685fce777/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/46d1d9c2-9ed0-46da-848a-eb2685fce777/</guid><description>It was excusable to make a mistake, although if you made too many egregious ones you would not be well accepted; but the unpardonable sin was to refuse to recognize that you had committed a fallacy, formal or material, when it was pointed out. A close second major sin would be to keep committing the same fallacy over and over again and having to be reminded of it.</description></item><item><title>Recommendations on Presenting of Statistical Results in Medical Literature</title><link>https://aakinshin.net/library/quotes/10d26f39-ca23-4d67-8a99-baa4b9c0211f/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/10d26f39-ca23-4d67-8a99-baa4b9c0211f/</guid><description>We encourage authors to avoid statements like “X has no effect on mortality” as they are likely to be both untrue and misleading. This is especially true as results get “close” to being statistically significant. Results should speak for themselves. For that to happen, readers (clinicians and science reporters) need to understand the language of statistics and approach authors’ conclusions with a critical eye. We are not trying to say that the reader should not review the abstract but when authors’ conclusions differ from others, readers must examine and compare the actual results. In fact, all but one of the meta-analyses provided point estimates and CIs in the abstracts. This facilitates quick comparisons to other studies reported to be “completely different,” and to determine if the CIs demonstrate clinically important differences. The problem lies in the authors’ conclusions, which often have little to do with their results but rather what they want the results to show. We encourage journal editors to challenge authors’ conclusions, particularly when they argue they have found something unique or different than other researchers but the difference is based solely on tiny variations in CIs or p-value (statistically significant or not).
We are not suggesting the elimination of statistical testing or statistical significance, but rather that all people (authors, publishers, regulators etc.) who write about medical interventions use common sense and good judgment when presenting results that differ from others and not be so beholden to the “magical” statistical significance level of 0.05. We urge them to consider the degree to which the results of the “differing” study overlap with their own, the true difference in the point estimates and range of possible effects, where the preponderance of the effect lies and how clinicians might apply the evidence.
It appears that readers of the papers discussed here would be better served by reviewing the actual results than reading the authors’ conclusions.</description></item><item><title>Requirements for Authors</title><link>https://aakinshin.net/library/quotes/2915ea66-476d-46bc-a79a-43ebe0c730e2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/2915ea66-476d-46bc-a79a-43ebe0c730e2/</guid><description>We propose the following six requirements for authors.
Authors must decide the rule for terminating data collection before data collection begins and report this rule in the article. Following this requirement may mean reporting the outcome of power calculations or disclosing arbitrary rules, such as “we decided to collect 100 observations” or “we decided to collect as many observations as we could before the end of the semester.” The rule itself is secondary, but it must be determined ex ante and be reported. Authors must collect at least 20 observations per cell or else provide a compelling cost-of-data-collection justification. This requirement offers extra protection for the first requirement. Samples smaller than 20 per cell are simply not powerful enough to detect most effects, and so there is usually no good reason to decide in advance to collect such a small number of observations. Smaller samples, it follows, are much more likely to reflect interim data analysis and a flexible termination rule. In addition, as Figure 1 shows, larger minimum sample sizes can lessen the impact of violating Requirement 1. Authors must list all variables collected in a study. This requirement prevents researchers from reporting only a convenient subset of the many measures that were collected, allowing readers and reviewers to easily identify possible researcher degrees of freedom. Because authors are required to just list those variables rather than describe them in detail, this requirement increases the length of an article by only a few words per otherwise shrouded variable. We encourage authors to begin the list with “only,” to assure readers that the list is exhaustive (e.g., “participants reported only their age and gender”). Authors must report all experimental conditions, including failed manipulations. This requirement prevents authors from selectively choosing only to report the condition comparisons that yield results that are consistent with their hypothesis.</description></item><item><title>Right Thing in Each Moment</title><link>https://aakinshin.net/library/quotes/8975c9e5-f082-484e-bd2c-3d8f3ecfd4bd/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/8975c9e5-f082-484e-bd2c-3d8f3ecfd4bd/</guid><description>If our plan today is to write three thousand words, rock a presentation with our leadership team, and catch up on our email, and we successfully accomplish all of those, we were perfectly productive. Likewise, if we intend to have a relaxing day and manage to do absolutely nothing, we’re again perfectly productive. Being busy doesn’t make us productive. It doesn’t matter how busy we are if that busyness doesn’t lead us to accomplish anything of importance. Productivity is not about cramming more into our days but about doing the right thing in each moment.</description></item><item><title>Risk Reduction in Truncated Rcts</title><link>https://aakinshin.net/library/quotes/cfcf0003-6df7-4c36-a140-1297e5f8954f/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/cfcf0003-6df7-4c36-a140-1297e5f8954f/</guid><description>Nontruncated RCTs with no evidence of benefit &amp;hellip; would on average be associated with a 29% relative risk reduction in truncated RCTs addressing the same question.</description></item><item><title>Rules of Smaple Size Planning</title><link>https://aakinshin.net/library/quotes/63edb163-442a-4336-a5c4-fc51eb0e94e7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/63edb163-442a-4336-a5c4-fc51eb0e94e7/</guid><description> Sample size planning is important to enhance cumulative knowledge in the discipline as well as for the individual researcher. Sample size planning can be based on a goal of achieving adequate statistical power, or accurate parameter estimates, or both. Researchers are actively involved in developing methods for sample size planning, especially for complex designs and analyses. Sample sizes necessary to achieve accurate parameter estimates will often be larger than sample sizes necessary to detect even a small effect. Sample sizes necessary to obtain accurate parameter estimates or power to detect small effects may often require resources prohibitive to the individual researcher, thus suggesting the desirability of study registries accompanied by meta-analytic methods.</description></item><item><title>Same Data, Different Results</title><link>https://aakinshin.net/library/quotes/6e3a83e1-2574-4f7f-a436-579ec133c468/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/6e3a83e1-2574-4f7f-a436-579ec133c468/</guid><description>Most published reports of clinical studies begin with an abstract – likely the first and perhaps only thing many clinicians, the media and patients will read. Within that abstract, authors/investigators typically provide a brief summary of the results and a 1–2 sentence conclusion. At times, the conclusion of one study will be different, even diametrically opposed, to another despite the authors looking at similar data. In these cases, readers may assume that these individual authors somehow found dramatically different results. While these reported differences may be true some of the time, radically diverse conclusions and ensuing controversies may simply be due to tiny differences in confidence intervals combined with an over-reliance and misunderstanding of a “statistically significant difference.” Unfortunately, this misunderstanding can lead to therapeutic uncertainty for front-line clinicians when in fact the overall data on a particular issue is remarkably consistent.</description></item><item><title>Scientific Method</title><link>https://aakinshin.net/library/quotes/cd4d7cb3-1f80-4fa7-be94-9cb8181e7851/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/cd4d7cb3-1f80-4fa7-be94-9cb8181e7851/</guid><description>The originators of the statistical frameworks that underlie modern epidemiologic studies recognized that their methods could not be interpreted properly without an understanding of their philosophical underpinnings. Neyman held that inductive reasoning was an illusion and that the only meaningful parameters of importance in an experiment were constraints on the number of statistical &amp;ldquo;errors&amp;rdquo; we would make, defined before an experiment. Fisher rejected mechanistic approaches to inference, believing in a more flexible, inductive approach to science. One of Fisher&amp;rsquo;s developments, mathematical likelihood, fit into such an approach. The p value, which Fisher wanted used in a similar manner, invited misinterpretation because it occupied a peculiar middle ground. Because of its resemblance to the pretrial a error, it was absorbed into the hypothesis test framework. This created two illusions: that an &amp;ldquo;error rate&amp;rdquo; could be measured after an experiment and that this posttrial &amp;ldquo;error rate&amp;rdquo; could be regarded as a measure of inductive evidence. Even though Fisher, Neyman, and many others have recognized these as fallacies, their perpetuation has been encouraged by the manner in which we use the p value today. One consequence is that we overestimate the evidence for associations, particularly with p values in the range of 0.001-0.05, creating misleading impressions of their plausibility. Another result is that we minimize the importance of judgment in inference, because its role is unclear when postexperiment evidential strength is thought to be measurable with preexperiment &amp;ldquo;error-rates.&amp;rdquo; Many experienced epidemiologists have tried to correct these problems by offering guidelines about how p values should be used. We may be more effective if, in the spirts of Fisher and Neyman, we instead focus on clarifying what p values mean, and on what we mean by the &amp;ldquo;scientific method.&amp;rdquo;</description></item><item><title>Several Men Have Concerned Themselves</title><link>https://aakinshin.net/library/quotes/ab816cd5-6722-46ef-a222-dba966ecc619/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/ab816cd5-6722-46ef-a222-dba966ecc619/</guid><description>Several men have concerned themselves extensively with the transformation of frequency distributions, for instance, Edgeworth, Hapteyn, Arne Fisher, and H. L. Reitz. The first three of these men have been concerned with transformations as a means of extending the scope of the normal distribution and Gram-Charlier system as a method of description. Reitz has been more interested in the properties of the transformed distributions.</description></item><item><title>Sir. Ronald Fisher</title><link>https://aakinshin.net/library/quotes/01015429-2154-45e1-b36d-9e11757643ca/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/01015429-2154-45e1-b36d-9e11757643ca/</guid><description>You may say, “But, Meehl, R. A. Fisher was a genius, and we all know how valuable his stuff has been in agronomy. Why shouldn’t it work for soft psychology?” Well, I am not intimidated by Fisher’s genius, because my complaint is not in the field of mathematical statistics, and as regards inductive logic and philosophy of science, it is well-known that Sir Ronald permitted himself a great deal of dogmatism. I remember my amazement when the late Rudolf Carnap said to me, the first time I met him, “But, of course, on this subject Fisher is just mistaken: surely you must know that.” My statistician friends tell me that it is not clear just how useful the significance test has been in biological science either, but I set that aside as beyond my competence to discuss.</description></item><item><title>Smart Plan</title><link>https://aakinshin.net/library/quotes/74d4fd50-ed01-4990-8f18-3cde44d72d11/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/74d4fd50-ed01-4990-8f18-3cde44d72d11/</guid><description>I cannot afford to allow a large deadline to creep up on me, or a morning to be wasted on something trivial, because I didn’t take a moment to craft a smart plan.</description></item><item><title>Smoking and Anxiety</title><link>https://aakinshin.net/library/quotes/02bb7e52-c9a1-480a-a94d-02ff036b9147/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/02bb7e52-c9a1-480a-a94d-02ff036b9147/</guid><description>Showing pictures of blackened lungs to smokers leads to higher levels of anxiety, which drives many people to reach for a cigarette.</description></item><item><title>Somerville</title><link>https://aakinshin.net/library/quotes/93bcdd88-24e2-4a2e-995c-7fe64496deed/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/93bcdd88-24e2-4a2e-995c-7fe64496deed/</guid><description>However remarkable this is, I’m more interested in the kind of focus that Somerville seemed to possess. How can one in an environment such as hers, with constant distractions, little social support, and continuous obligations, manage to focus long enough not only to learn an impressive breadth of subjects, but to such depths that the French mathematician Siméon Poisson once remarked that “there were not twenty men in France who could read [her] book”?</description></item><item><title>Spherical Horse Moving Through a Vacuum</title><link>https://aakinshin.net/library/quotes/345b1b6e-c75a-4164-9999-c9519f1a309c/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/345b1b6e-c75a-4164-9999-c9519f1a309c/</guid><description>A multimillionaire offered a prize for predicting the outcome of a horse race to a stockbreeder, a geneticist, and a physicist. The stockbreeder said there were too many variables, the geneticist could not make a prediction about any particular horse, but the physicist claimed the prize, saying he could make the prediction to many decimal places—provided it were a perfectly spherical horse moving through a vacuum.</description></item><item><title>Sphygmomanometer</title><link>https://aakinshin.net/library/quotes/a2525cc5-5f08-47f3-a5af-da84d9e94d9b/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/a2525cc5-5f08-47f3-a5af-da84d9e94d9b/</guid><description> Or perhaps I’m worried that my sphygmomanometers are not perfectly calibrated, so I measure with a different one each day.
I just wanted an excuse to use the word sphygmomanometer.</description></item><item><title>Statistical Literacy Training for obstetrics-gynecology Residents</title><link>https://aakinshin.net/library/quotes/58d4e333-4344-4fef-be8a-61e319433780/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/58d4e333-4344-4fef-be8a-61e319433780/</guid><description>Methods In 2011 we surveyed US obstetrics-gynecology residents participating in the Council for Resident Education in Obstetrics and Gynecology In-Training Examination about their statistical literacy and statistical literacy training.
Results Our response rate was 95% (4713 of 4961). About two-thirds (2980 of 4713) of the residents rated their statistical literacy training as adequate. Female respondents were more likely to rate their statistical literacy training poorly, with 25% (897 of 3575) indicating inadequate literacy compared with 17% (141 of 806) of the male respondents (P &amp;lt; .001). Respondents performed poorly on 2 statistical literacy questions, with only 26% (1222 of 4713) correctly answering a positive predictive value question and 42% (1989 of 4173) correctly defining a P value. A total of 51% (2391 of 4713) of respondents reported receiving statistical literacy training through a journal club, 29% (1359 of 4713) said they had informal training, 15% (711 of 4713) said that they had statistical literacy training as part of a course, and 11% (527 of 4713) said that they had no training.</description></item><item><title>Statistical Misleadingness of Error Bars</title><link>https://aakinshin.net/library/quotes/e42a2cde-94ae-44f9-b9bf-3f2c1eee39c9/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/e42a2cde-94ae-44f9-b9bf-3f2c1eee39c9/</guid><description>Climate studies often involve comparisons between estimates of some parameter derived from different observed and/or model-generated datasets. It is common practice to present estimates of two or more statistical quantities with error bars about each representing a confidence interval. If the error bars do not overlap, it is presumed that there is a statistically significant difference between them. In general, such a procedure is not valid and usually results in declaring statistical significance too infrequently. Simple examples that demonstrate the nature of this pitfall, along with some formulations, are presented. It is recommended that practitioners use standard hypothesis testing techniques that have been derived from statistical theory rather than the ad hoc approach involving error bars.</description></item><item><title>Statistical Practices in high-impact Journals</title><link>https://aakinshin.net/library/quotes/8120cd40-f648-47d8-ac65-45509e4262af/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/8120cd40-f648-47d8-ac65-45509e4262af/</guid><description>What are the statistical practices of articles published in journals with a high impact factor? Are there differences compared with articles published in journals with a somewhat lower impact factor that have adopted editorial policies to reduce the impact of limitations of Null Hypothesis Significance Testing? To investigate these questions, the current study analyzed all articles related to psychological, neuropsychological and medical issues, published in 2011 in four journals with high impact factors: Science, Nature, The New England Journal of Medicine and The Lancet, and three journals with relatively lower impact factors: Neuropsychology, Journal of Experimental Psychology-Applied and the American Journal of Public Health. Results show that Null Hypothesis Significance Testing without any use of confidence intervals, effect size, prospective power and model estimation, is the prevalent statistical practice used in articles published in Nature, 89%, followed by articles published in Science, 42%.</description></item><item><title>Statistical Reforms</title><link>https://aakinshin.net/library/quotes/efcae53d-3220-4ef9-9a3d-2d2925a667c2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/efcae53d-3220-4ef9-9a3d-2d2925a667c2/</guid><description>In recent years there have been many advocates for statistical reform, and naturally there is disagreement among them on the best method to address these problems. Some insist that p values, which I will show are frequently misleading and confusing, should be abandoned altogether; others advocate a “new statistics” based on confidence intervals. Still others suggest a switch to new Bayesian methods that give more-interpretable results, while others believe statistics as it’s currently taught is just fine but used poorly.</description></item><item><title>Swaying an Entire Study</title><link>https://aakinshin.net/library/quotes/c81a5510-8273-4df8-aaef-aeadc928b20f/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/c81a5510-8273-4df8-aaef-aeadc928b20f/</guid><description>In medical practice, clinically unexpected measurements might be quite properly handled by the remeasurement, removal, or reclassification of patients. If these habits are not prevented during clinical research, how much of each is needed to sway an entire study?</description></item><item><title>Tentative Exploratory Findings</title><link>https://aakinshin.net/library/quotes/976fa15f-840e-4f3c-a764-76f2fc7dd657/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/976fa15f-840e-4f3c-a764-76f2fc7dd657/</guid><description>But aimlessly exploring data means a lot of opportunities for false positives and truth inflation. If in your explorations you find an interesting correlation, the standard procedure is to collect a new dataset and test the hypothesis again. Testing an independent dataset will filter out false positives and leave any legitimate discoveries standing. (Of course, you’ll need to ensure your test dataset is sufficiently powered to replicate your findings.) And so exploratory findings should be considered tentative until confirmed.
If you don’t collect a new dataset or your new dataset is strongly related to the old one, truth inflation will come back to bite you in the butt.</description></item><item><title>Tetris Effect</title><link>https://aakinshin.net/library/quotes/8b85f2d8-bfc1-4f5c-83b5-cddc1cf928e5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/8b85f2d8-bfc1-4f5c-83b5-cddc1cf928e5/</guid><description>Everyone knows someone stuck in some version of the Tetris Effect — someone who is unable to break a pattern of thinking or behaving.</description></item><item><title>The 3% Usage of Power Analysis</title><link>https://aakinshin.net/library/quotes/b6157da6-8408-4226-a073-c1a0ac73fdb4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/b6157da6-8408-4226-a073-c1a0ac73fdb4/</guid><description>Over-reliance on significance testing has been heavily criticized in psychology. Therefore the American Psychological Association recommended supplementing the p value with additional elements such as effect sizes, confidence intervals, and considering statistical power seriously. This article elaborates the conclusions that can be drawn when these measures accompany the p value. An analysis of over 30 summary papers (including over 6,000 articles) reveals that, if at all, only effect sizes are reported in addition to p’s (38%). Only every 10th article provides a confidence interval and statistical power is reported in only 3% of articles.</description></item><item><title>The Any-Benefit Approach</title><link>https://aakinshin.net/library/quotes/20e7444a-fe38-4d7b-bd83-52e3461f2373/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/20e7444a-fe38-4d7b-bd83-52e3461f2373/</guid><description>The Any-Benefit Approach to Network Tool Selection: You’re justified in using a network tool if you can identify any possible benefit to its use, or anything you might possibly miss out on if you don’t use it.</description></item><item><title>The Bimodal Philosophy</title><link>https://aakinshin.net/library/quotes/43591ac0-19fb-4661-8607-74abc59c61af/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/43591ac0-19fb-4661-8607-74abc59c61af/</guid><description>Jung’s approach is what I call the bimodal philosophy of deep work. This philosophy asks that you divide your time, dedicating some clearly defined stretches to deep pursuits and leaving the rest open to everything else.</description></item><item><title>The Delicate Balance</title><link>https://aakinshin.net/library/quotes/cfbf691e-a44c-4403-842e-f846be39bf38/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/cfbf691e-a44c-4403-842e-f846be39bf38/</guid><description>Wabi-sabi is exactly about the delicate balance between the pleasure we get from things and the pleasure we get from freedom from things.</description></item><item><title>The dipsy-doodle</title><link>https://aakinshin.net/library/quotes/e7194b0a-bece-4058-8687-cb7b6d077289/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/e7194b0a-bece-4058-8687-cb7b6d077289/</guid><description>Schunn and his colleagues were interested in how scientists deal with unexpected results, or anomalies. In one study, he videotaped two astronomers interacting over a new set of data concerning the formation of ring galaxies. Schunn found that these researchers noticed anomalies as much as expected results, but paid more attention to the anomalies. The researchers developed hypotheses about the anomalies and elaborated on them visually, whereas they used theory to elaborate on expected results. When the two astronomers discussed the anomalies, they used terms like ‘the funky thing’ and ‘the dipsy-doodle’, staying at a perceptual rather than a theoretical level. Schunn’s astronomers were working neither in the hypothesis nor experimental space; instead, they were working in a space of possible visualizations dependent on their domain-specific experience.</description></item><item><title>The Easiest Way</title><link>https://aakinshin.net/library/quotes/8b0d41dc-2b62-4023-81e9-48fa312b4d1a/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/8b0d41dc-2b62-4023-81e9-48fa312b4d1a/</guid><description>The easiest way to learn directly is to simply spend a lot of time doing the thing you want to become good at.</description></item><item><title>The Emotionally Disinterested Scientist is a Myth</title><link>https://aakinshin.net/library/quotes/1435d5e5-6200-4084-aeeb-28bf82b83377/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/1435d5e5-6200-4084-aeeb-28bf82b83377/</guid><description>The [emotionally] disinterested scientist is a myth. Even if there were such a being, he probably wouldn&amp;rsquo;t be worth much as a scientist. I still think you can be objective in spite of having strong interests and biases.</description></item><item><title>The Feynman Technique</title><link>https://aakinshin.net/library/quotes/708f6c4a-a63d-4473-b726-034b0cc5e139/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/708f6c4a-a63d-4473-b726-034b0cc5e139/</guid><description>I had a scheme, which I still use today when somebody is explaining something that I&amp;rsquo;m trying to understand: I keep making up examples.</description></item><item><title>The First Feynman's Principle</title><link>https://aakinshin.net/library/quotes/fb1f3887-c6eb-4bbe-9275-6cf0424e276f/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/fb1f3887-c6eb-4bbe-9275-6cf0424e276f/</guid><description>The first principle is that you must not fool yourself — and you are the easiest person to fool.</description></item><item><title>The Four Laws of Behavior Change</title><link>https://aakinshin.net/library/quotes/ae854979-0fa3-4dde-aed8-d702dd6ed114/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/ae854979-0fa3-4dde-aed8-d702dd6ed114/</guid><description>The Four Laws of Behavior Change are a simple set of rules we can use to build better habits. They are (1) make it obvious, (2) make it attractive, (3) make it easy, and (4) make it satisfying.</description></item><item><title>The Game of Science</title><link>https://aakinshin.net/library/quotes/14ae475c-edf6-46a8-9bd4-e49f792adb71/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/14ae475c-edf6-46a8-9bd4-e49f792adb71/</guid><description>The game of science is, in principle, without end. He who decides one day that scientific statements do not call for any further test, and that they can be regarded as finally verified, retires from the game.</description></item><item><title>The Goldilocks Rule</title><link>https://aakinshin.net/library/quotes/927cd615-0e2b-4ae8-bf49-06d473d2e74f/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/927cd615-0e2b-4ae8-bf49-06d473d2e74f/</guid><description>The Goldilocks Rule states that humans experience peak motivation when working on tasks that are right on the edge of their current abilities. Not too hard. Not too easy. Just right.</description></item><item><title>The Illusion of Attaining Improbability</title><link>https://aakinshin.net/library/quotes/7a038512-b3c5-496a-b7ac-e5c900fca23b/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/7a038512-b3c5-496a-b7ac-e5c900fca23b/</guid><description>One problem arises from a misapplication of deductive syllogistic reasoning. Falk and Greenbaum (in press) called this the &amp;ldquo;illusion of probabilistic proof by contradiction&amp;rdquo; or the &amp;ldquo;illusion of attaining improbability.&amp;rdquo; Gigerenzer (1993) called it the &amp;ldquo;permanent illusion&amp;rdquo; and the &amp;ldquo;Bayesian Id&amp;rsquo;s wishful thinking,&amp;rdquo; part of the &amp;ldquo;hybrid logic&amp;rdquo; of contemporary statistical inference—a mishmash of Fisher and Neyman-Pearson, with invalid Bayesian interpretation.</description></item><item><title>The Importance of Effect Magnitude Over Statistical Hypotheses</title><link>https://aakinshin.net/library/quotes/c6000a61-924a-47b7-805c-2fc024a131bb/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/c6000a61-924a-47b7-805c-2fc024a131bb/</guid><description>Instead of asking “how many more crashes?” and the authors chose to ask “are we sufficiently sure that the effect was not zero?” This substitution of questions led to all the subsequent entanglements. These can all be avoided by not testing statistical hypotheses when the research question is about the effect of some treatment; by returning to common sense and the mainstream of science and providing estimates of effect magnitude and its standard error instead.</description></item><item><title>The Importance of the Critical Attitude</title><link>https://aakinshin.net/library/quotes/b9b10859-3a7a-49d0-9a3a-cfb9d9a16c3c/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/b9b10859-3a7a-49d0-9a3a-cfb9d9a16c3c/</guid><description>I have italicized the words ‘rational discussion’ and ‘critically’ in order to stress that I equate the rational attitude and the critical attitude. The point is that, whenever we propose a solution to a problem, we ought to try as hard as we can to overthrow our solution, rather than defend it. Few of us, unfortunately, practise this precept; but other people, fortunately, will supply the criticism for us if we fail to supply it ourselves. Yet criticism will be fruitful only if we state our problem as clearly as we can and put our solution in a sufficiently definite form — a form in which it can be critically discussed.</description></item><item><title>The Inappropriateness of Significance Tests</title><link>https://aakinshin.net/library/quotes/441a516a-9f37-46bc-afb1-fd6165503b80/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/441a516a-9f37-46bc-afb1-fd6165503b80/</guid><description>All references to statistical hypothesis testing and statistical significance should be removed from the paper. I ask that you delete p values as well as comments about statistical significance. If you do not agree with my standards (concerning the inappropriateness of significance tests), you should feel free to argue the point, or simply ignore what you may consider to be my misguided view, by publishing elsewher.</description></item><item><title>The Indifference Zone</title><link>https://aakinshin.net/library/quotes/7c967475-c1b4-4610-8c28-3ccdfc458e95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/7c967475-c1b4-4610-8c28-3ccdfc458e95/</guid><description>Admittedly, finding a consensus on how to specify that indifference zone concretely is far from easy in the majority of applications. However, it is an indispensable step without which the testing problem the experimenter proposes would make no statistical sense at all.</description></item><item><title>The Influence of Journal Prestige on the Inflation of Effect Sizes in Small Trials</title><link>https://aakinshin.net/library/quotes/79991435-cde7-4963-8f62-2bf812a39fda/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/79991435-cde7-4963-8f62-2bf812a39fda/</guid><description>We found that small trials published in NEJM, JAMA and Lancet were more likely to display more favourable results for experimental interventions compared with trials in other publication venues. Inflated effect sizes were seen primarily for early small trials in these prominent journals. Therefore, the results of small trials with spectacular early promises for large treatment effects should be seen with great caution. Conversely, for large trials, effect estimates are likely to be more reliable. Small-study effects have been previously documented in the randomized trials literature. However, the results of our study provide further insight suggesting the possibility of a specific interaction with further exaggerated effects when the limited evidence from small trials appears in the most prestigious journals. Also, the inflation of effects in early randomized trials on particular interventions appears to be quite specific to these most prestigious journals. Some modest heterogeneity was seen in the two tertiles with higher events, but heterogeneity is difficult to determine in the tertile with lower events, because of the wide uncertainty in the ROR for single topics, when there is limited evidence.</description></item><item><title>The Journalist Philosophy</title><link>https://aakinshin.net/library/quotes/4cb21a24-b212-4685-9b29-8bc363cfcdd7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/4cb21a24-b212-4685-9b29-8bc363cfcdd7/</guid><description>I call this approach, in which you fit deep work wherever you can into your schedule, the journalist philosophy. This name is a nod to the fact that journalists, like Walter Isaacson, are trained to shift into a writing mode on a moment’s notice, as is required by the deadline-driven nature of their profession.</description></item><item><title>The Mad Scientist Who Will Destroy the World for Knowledge</title><link>https://aakinshin.net/library/quotes/e1007148-ba1e-4cd2-ba19-e6dde3b6cf09/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/e1007148-ba1e-4cd2-ba19-e6dde3b6cf09/</guid><description>The uninvolved, unemotional scientist is just as much a fiction as the mad scientist who will destroy the world for knowledge. Most of the scientists I know have theories and are looking for data to support them; they&amp;rsquo;re not sorting impersonally through the data looking for a theory to fit the data.</description></item><item><title>The Mother</title><link>https://aakinshin.net/library/quotes/93a73227-bcc9-4a25-9eb7-8a650dfa317e/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/93a73227-bcc9-4a25-9eb7-8a650dfa317e/</guid><description>My mother was affectionate, nurturant, praiseful, but somewhat seductive, which led to sexual problems for me as a young adult.</description></item><item><title>The Neuroscience of Low Statistical Power</title><link>https://aakinshin.net/library/quotes/76c951e9-c936-4b30-919f-d3d3fd7f7227/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/76c951e9-c936-4b30-919f-d3d3fd7f7227/</guid><description>A study with low statistical power has a reduced chance of detecting a true effect, but it is less well appreciated that low power also reduces the likelihood that a statistically significant result reflects a true effect. Here, we show that the average statistical power of studies in the neurosciences is very low. The consequences of this include overestimates of effect size and low reproducibility of results. There are also ethical dimensions to this problem, as unreliable research is inefficient and wasteful. Improving reproducibility in neuroscience is a key priority and requires attention to well-established but often ignored methodological principles.</description></item><item><title>The Null Field</title><link>https://aakinshin.net/library/quotes/f05e3cd0-fb35-4654-b121-421c58c5f5e4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/f05e3cd0-fb35-4654-b121-421c58c5f5e4/</guid><description>Let us suppose that in a research field there are no true findings at all to be discovered. History of science teaches us that scientific endeavor has often in the past wasted effort in fields with absolutely no yield of true scientific information, at least based on our current understanding. In such a “null field,” one would ideally expect all observed effect sizes to vary by chance around the null in the absence of bias. The extent that observed findings deviate from what is expected by chance alone would be simply a pure measure of the prevailing bias.</description></item><item><title>The Null Hypothesis is Always False</title><link>https://aakinshin.net/library/quotes/9d1c1cff-0bdb-4fd7-b146-da704a7caa82/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/9d1c1cff-0bdb-4fd7-b146-da704a7caa82/</guid><description>I believe is generally recognized by statisticians today and by thoughtful social scientists, the null hypothesis, taken literally, is always false.</description></item><item><title>The Null Hypothesis Ritual</title><link>https://aakinshin.net/library/quotes/af7c74d8-e8ac-4736-958a-ef3bd67c4385/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/af7c74d8-e8ac-4736-958a-ef3bd67c4385/</guid><description>After 4 decades of severe criticism, the ritual of null hypothesis significance testing — mechanical dichotomous decisions around a sacred .05 criterion — still persists.</description></item><item><title>The Overlap Method</title><link>https://aakinshin.net/library/quotes/eb3039e9-e45a-411d-ac91-4885d0049c0b/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/eb3039e9-e45a-411d-ac91-4885d0049c0b/</guid><description>The overlap method is simple, and it is convenient when lists or graphs of confidence intervals are presented. It can be useful as a quick and relatively rough method for exploratory data analysis. It should not be regarded as an optimal method for significance testing, however, given its conservatism and low power relative to the standard method in the common situation that we have considered. Thus, the overlap method should not be used for formal significance testing unless the data analyst is aware of its deficiencies and unless the information needed to carry out a more appropriate procedure is unavailable.</description></item><item><title>The Ozone Hole Discovery</title><link>https://aakinshin.net/library/quotes/5eb9df1d-003d-4921-9cde-ab8535f111b9/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/5eb9df1d-003d-4921-9cde-ab8535f111b9/</guid><description>The discovery of the ozone hole was announced in 1985 by a British team working on the ground with “conventional” instruments and examining its observations in detail. Only later, after reexamining the data transmitted by the TOMS instrument on NASA’s Nimbus 7 satellite, was it found that the hole had been forming for several years. Why had nobody noticed it? The reason was simple: the systems processing the TOMS data, designed in accordance with predictions derived from models, which in turn were established on the basis of what was thought to be “reasonable”, had rejected the very (“excessively”) low values observed above the Antarctic during the Southern spring. As far as the program was concerned, there must have been an operating defect in the instrument.</description></item><item><title>The P Value Fallacy</title><link>https://aakinshin.net/library/quotes/aeb58f62-484b-49a5-853c-8f72e49c82e3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/aeb58f62-484b-49a5-853c-8f72e49c82e3/</guid><description>An important problem exists in the interpretation of modern medical research data: Biological understanding and previous research play little formal role in the interpretation of quantitative results. This phenomenon is manifest in the discussion sections of research articles and ultimately can affect the reliability of conclusions. The standard statistical approach has created this situation by promoting the illusion that conclusions can be produced with certain “error rates,” without consideration of information from outside the experiment. This statistical approach, the key components of which are P values and hypothesis tests, is widely perceived as a mathematically coherent approach to inference. There is little appreciation in the medical community that the methodology is an amalgam of incompatible elements, whose utility for scientific inference has been the subject of intense debate among statisticians for almost 70 years. This article introduces some of the key elements of that debate and traces the appeal and adverse impact of this methodology to the P value fallacy, the mistaken idea that a single number can capture both the long-run outcomes of an experiment and the evidential meaning of a single result. This argument is made as a prelude to the suggestion that another measure of evidence should be used—the Bayes factor, which properly separates issues of long-run behavior from evidential strength and allows the integration of background knowledge with statistical findings.</description></item><item><title>The Parents</title><link>https://aakinshin.net/library/quotes/7f1e39a3-06fe-4662-b5d5-96fbb64cf984/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/7f1e39a3-06fe-4662-b5d5-96fbb64cf984/</guid><description>In 1931 my father, who had embezzled money to play the stock market, committed suicide. &amp;hellip; My mother began having frightening “heart attacks,” and life seemed precarious indeed. &amp;hellip; My mother isn’t going to die of heart failure, she’s a young widow with anxiety neurosis. I decided overnight to become a psychotherapist. &amp;hellip; At age sixteen I suffered a second object loss when my mother (who had remarried when I was fourteen) died of ether pneumonia after surgery for a brain tumor.</description></item><item><title>The Rhythmic Philosophy</title><link>https://aakinshin.net/library/quotes/13a6810a-fd4c-4dc3-9cdf-be6af83c32a7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/13a6810a-fd4c-4dc3-9cdf-be6af83c32a7/</guid><description>This chain method (as some now call it) soon became a hit among writers and fitness enthusiasts — communities that thrive on the ability to do hard things consistently. For our purposes, it provides a specific example of a general approach to integrating depth into your life: the rhythmic philosophy. This philosophy argues that the easiest way to consistently start deep work sessions is to transform them into a simple regular habit. The goal, in other words, is to generate a rhythm for this work that removes the need for you to invest energy in deciding if and when you’re going to go deep</description></item><item><title>The Riddle of the World</title><link>https://aakinshin.net/library/quotes/3e2b099c-520a-40a2-b99b-f11d4ddad259/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/3e2b099c-520a-40a2-b99b-f11d4ddad259/</guid><description>For myself, I am interested in science and in philosophy only because I want to learn something about the riddle of the world in which we live, and the riddle of man’s knowledge of that world. And I believe that only a revival of interest in these riddles can save the sciences and philosophy from narrow specialization and from an obscurantist faith in the expert’s special skill, and in his personal knowledge and authority; a faith that so well fits our ‘post-rationalist’ and ‘post-critical’ age, proudly dedicated to the destruction of the tradition of rational philosophy, and of rational thought itself.</description></item><item><title>The Score Takes Care of Itself</title><link>https://aakinshin.net/library/quotes/14483f0f-9730-45de-b98d-8b58f4786dd7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/14483f0f-9730-45de-b98d-8b58f4786dd7/</guid><description>In the words of three-time Super Bowl winner Bill Walsh, “The score takes care of itself.”</description></item><item><title>The Statistical Accessibility of Medical Papers</title><link>https://aakinshin.net/library/quotes/cca63eb6-34c7-451e-baaf-1c35e7c1d7d8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/cca63eb6-34c7-451e-baaf-1c35e7c1d7d8/</guid><description>Similarly, if a reader had knowledge of t-tests, contingency tables, nonparametric tests, epidemiologic statistics, Pearson’s correlation, simple linear regression, analysis of variance, transformations, and nonparametric correlation (topics typically included in introductory statistics courses), then 21 percent of the articles would be accessible.</description></item><item><title>The Toothbrush Problem</title><link>https://aakinshin.net/library/quotes/3e2e8840-784d-41ed-8c01-5a880bd614c2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/3e2e8840-784d-41ed-8c01-5a880bd614c2/</guid><description>Taxonomies and frameworks are like toothbrushes — no one wants to use anyone else’s.
The attribution of this quotation is ambiguous. A nice historical overview of the quote can be found in A useless history of the “Frameworks are Like Toothbrushes” quote. While gorman2001 is one of the first appearances of the quote, this metaphor was especially popularized in The Toothbrush Problem by Walter Mischel. Occasionally, it is used in other works (e.g., see elson2023).</description></item><item><title>The Wrong Question</title><link>https://aakinshin.net/library/quotes/7566960c-ae77-4add-9c00-b9865d8f1cac/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/7566960c-ae77-4add-9c00-b9865d8f1cac/</guid><description>Statisticians classically asked the wrong question — and were willing to answer with a lie, one that was often a downright lie. They asked &amp;ldquo;Are the effects of A and B different?&amp;rdquo; and they were willing to answer &amp;ldquo;no.&amp;rdquo;
All we know about the world teaches us that the effects of A and B are always difference — in some decimal place — for any A and B. Thus asking &amp;ldquo;Are the effects different?&amp;rdquo; is foolish.
What we should be answering first is &amp;ldquo;Can we tell the direction in which the effects of A differ from the effects of B?&amp;rdquo; In other words, can we be confident about the direction from A to B? Is it &amp;ldquo;up,&amp;rdquo; &amp;ldquo;down&amp;rdquo; or &amp;ldquo;uncertain&amp;rdquo;?
The third answer to this first question is that we are &amp;ldquo;uncertain about the direction&amp;rdquo; — it is not, and never should be, that we &amp;ldquo;accept the null hypothesis.&amp;rdquo;</description></item><item><title>Three Dangerous Statistical Equations</title><link>https://aakinshin.net/library/quotes/9d9f8cca-5477-4108-9b60-6520cd897505/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/9d9f8cca-5477-4108-9b60-6520cd897505/</guid><description>Supporting ignorance is not, however, the direction I wish to pursue—indeed it is quite the antithesis of my message. Instead I am interested in equations that unleash their danger not when we know about them, but rather when we do not. Kept close at hand, these equations allow us to understand things clearly, but their absence leaves us dangerously ignorant.
There are many plausible candidates, and I have identified three prime examples: Kelley&amp;rsquo;s equation, which indicates that the truth is estimated best when its observed value is regressed toward the mean of the group that it came from; the standard linear regression equation; and the equation that provides us with the standard deviation of the sampling distribution of the mean—what might be called de Moivre&amp;rsquo;s equation: $\sigma_{\bar{x}} = \sigma/\sqrt{n}$, where $\sigma_{\bar{x}}$ is the standard error of the mean, $s$ is the standard deviation of the sample and $n$ is the size of the sample. (Note the square root symbol, which will be a key to at least one of the misunderstandings of variation.) De Moivre&amp;rsquo;s equation was derived by the French mathematician Abraham de Moivre, who described it in his 1730 exploration of the binomial distribution, Miscellanea Analytica.</description></item><item><title>Three Doctors</title><link>https://aakinshin.net/library/quotes/7cc6c419-8556-40a5-b642-4c7ae9c6a3d9/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/7cc6c419-8556-40a5-b642-4c7ae9c6a3d9/</guid><description>Imagine three researchers in separate laboratories around the world who believe that patients in two groups differ in their values of a variable. Each researcher proclaims high clinical and research standards. Dr A is particularly fastidious, taking care to remeasure any initial measurements where they are inconsistent with the clinical picture. Dr B is especially scrupulous about bias in research and tries to prevent even a few patients who have other intercurrent diseases from distorting results. Dr C realises that unaided clinical judgement may be poor at classifying patients and that test results may be better guidance.</description></item><item><title>Trivial Understanding of Scientific Knowledge</title><link>https://aakinshin.net/library/quotes/89e4cdba-7dc3-451c-b249-399056c2bf7d/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/89e4cdba-7dc3-451c-b249-399056c2bf7d/</guid><description>If scientific knowledge were the product of uncommitted or weakly committed observers, its understanding would be trivial.</description></item><item><title>Truth Inflation</title><link>https://aakinshin.net/library/quotes/48424c6e-3e04-4281-87fd-2b2ca1ef057d/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/48424c6e-3e04-4281-87fd-2b2ca1ef057d/</guid><description>This effect, known as truth inflation, type M error (M for magnitude), or the winner’s curse, occurs in fields where many researchers conduct similar experiments and compete to publish the most “exciting” results: pharmacological trials, epidemiological studies, gene association studies (“gene A causes condition B”), and psychological studies often show symptoms, along with some of the most-cited papers in the medical literature.</description></item><item><title>Truth Inflation and Groundbreaking Effect Sizes in top-ranked Journals</title><link>https://aakinshin.net/library/quotes/3107d5e7-d81b-48f9-926e-591261332ef5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/3107d5e7-d81b-48f9-926e-591261332ef5/</guid><description>Consider also that top-ranked journals, such as Nature and Science, prefer to publish studies with groundbreaking results—meaning large effect sizes in novel fields with little prior research. This is a perfect combination for chronic truth inflation. Some evidence suggests a correlation between a journal’s impact factor (a rough measure of its prominence and importance) and the factor by which its studies overestimate effect sizes. Studies that produce less “exciting” results are closer to the truth but less interesting to a major journal editor. brembs2013 siontis2011</description></item><item><title>Twelve P-Value Misconceptions</title><link>https://aakinshin.net/library/quotes/ac262184-cdb6-46f8-b7ac-5107d66d8314/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/ac262184-cdb6-46f8-b7ac-5107d66d8314/</guid><description> Twelve P-Value Misconceptions:
If P =.05, the null hypothesis has only a 5% chance of being true. A nonsignificant difference (eg, P &amp;gt; .05) means there is no difference between groups. A statistically significant finding is clinically important. Studies with P values on opposite sides of .05 are conflicting. Studies with the same P value provide the same evidence against the null hypothesis. P = .05 means that we have observed data that would occur only 5% of the time under the null hypothesis. P = .05 and P &amp;lt;= .05 mean the same thing. P values are properly written as inequalities (eg, “P &amp;lt; .02” when P = .015) P = .05 means that if you reject the null hypothesis, the probability of a type I error is only 5%. With a P = .05 threshold for significance, the chance of a type I error will be 5%. You should use a one-sided P value when you don’t care about a result in one direction, or a difference in that direction is impossible. A scientific conclusion or treatment policy should be based on whether or not the P value is significant.</description></item><item><title>Type II Error Should Be as Essential a Requirement for Publication</title><link>https://aakinshin.net/library/quotes/c7ba1497-c183-41ab-9d9e-a4cffb4d2c84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/c7ba1497-c183-41ab-9d9e-a4cffb4d2c84/</guid><description>Failure to achieve statistical significance between interventions does not prove the absence of any difference. Proper planning of a clinical trial with attention to beta error and sample size determination allows the critical investigator to acknowledge the probability of a type II error and therefore the probability of detecting a clinically meaningful difference if one exists. The reader and clinician must be aware that negative trials may in fact be falsely negative, and should look for specific reporting of alpha, beta, and $\Delta_c$ error to provide the details of the reliability of such conclusions. Type II error should be as essential a requirement for publication, and as rigorously analyzed, as the traditional and far more common type I (alpha) error.</description></item><item><title>Type M and Type S Errors</title><link>https://aakinshin.net/library/quotes/8359ad42-cd60-4f97-b32a-1f81df61f486/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/8359ad42-cd60-4f97-b32a-1f81df61f486/</guid><description>This is a Type M (magnitude) error (Gelman and Tuerlinckx, 2000): the study is constructed in such a way that any statistically-significant finding will almost certainly be a huge overestimate of the true effect. In addition there will be Type S (sign) errors, in which the estimate will be in the opposite direction as the true effect.</description></item><item><title>Underpowered Negative Clinical Trials</title><link>https://aakinshin.net/library/quotes/10189519-eb48-41f5-a1ca-adac8092bf8e/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/10189519-eb48-41f5-a1ca-adac8092bf8e/</guid><description>Our survey of 423 negative clinical trials indicates that 55% of trials had too few participants to detect a medium effect size in favor of the experimental over the standard treatment arm for their primary end point with at least 80% statistical power. Although underpowered negative clinical trials have been widely reported in the general medical and subspecialty literature, there are few reports relating to trials evaluating treatment of cancer. A review of 22 negative randomized oncology trials published in major general medical or oncology journals during a 1-year period found that 16 trials (73%) lacked adequate statistical power to detect a 50% improvement in median survival in favor of the experimental arm.</description></item><item><title>Unimpressive Theories in Psychology</title><link>https://aakinshin.net/library/quotes/a877a820-1fcb-4944-99ad-5f888320ea8d/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/a877a820-1fcb-4944-99ad-5f888320ea8d/</guid><description>I consider it unnecessary to persuade you that most so-called “theories” in the soft areas of psychology (clinical, counseling, social, personality, community, and school psychology) are scientifically unimpressive and technologically worthless.</description></item><item><title>White Swans and Universal Statements</title><link>https://aakinshin.net/library/quotes/a6d7b386-604a-4b5d-afaf-cc570da1ec87/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/a6d7b386-604a-4b5d-afaf-cc570da1ec87/</guid><description>Now it is far from obvious, from a logical point of view, that we are justified in inferring universal statements from singular ones, no matter how numerous; for any conclusion drawn in this way may always turn out to be false: no matter how many instances of white swans we may have observed, this does not justify the conclusion that all swans are white.</description></item><item><title>Workaholic’s Curse</title><link>https://aakinshin.net/library/quotes/50832382-1a8c-4d05-b53a-20cb517a11d1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/50832382-1a8c-4d05-b53a-20cb517a11d1/</guid><description>Just as our view of work affects our real experience of it, so too does our view of leisure. If our mindset conceives of free time, hobby time, or family time as non-productive, then we will, in fact, make it a waste of time. For example, many of the business leaders and Harvard students I work with exhibit the telltale symptoms of the “workaholic’s curse.” They conceive of all the time spent away from actual work to be a hindrance to their productivity, so they squander it. As one CEO of a telecommunications company in Malaysia told me: “I wanted to be productive because that’s what makes me happy, so I tried to maximize the time I spent working. But, as I later realized, I had too narrowly defined what ‘being productive’ was. I started to feel guilty when I did anything that wasn’t work. Nothing else, not exercise or time with my wife or relaxation, was productive. So I never had time to recharge my batteries, which meant that, ironically, the more I worked, the more my productivity plummeted.”</description></item><item><title>You can't Randomly Cite 2,000-page-long Books</title><link>https://aakinshin.net/library/quotes/0584d8b1-376c-40ee-bbd5-958bdbbdfb01/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/0584d8b1-376c-40ee-bbd5-958bdbbdfb01/</guid><description>No, you can&amp;rsquo;t randomly cite 2,000-page-long books and hope nobody will read them.</description></item><item><title>Your Eyeball</title><link>https://aakinshin.net/library/quotes/36f7123e-0f36-4dc6-9699-12bcf8a85455/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/36f7123e-0f36-4dc6-9699-12bcf8a85455/</guid><description>Your eyeball is not a well-deﬁned statistical procedure.</description></item></channel></rss>