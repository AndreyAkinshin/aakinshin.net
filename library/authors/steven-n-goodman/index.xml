<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Steven N Goodman on Andrey Akinshin</title><link>https://aakinshin.net/library/authors/steven-n-goodman/</link><description>Recent content in Steven N Goodman on Andrey Akinshin</description><generator>Hugo -- gohugo.io</generator><language>en</language><atom:link href="https://aakinshin.net/library/authors/steven-n-goodman/index.xml" rel="self" type="application/rss+xml"/><item><title>Neyman-Pearson vs. Fisher</title><link>https://aakinshin.net/library/quotes/e9011bc6-0eaf-4e76-8090-0331bd513617/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/e9011bc6-0eaf-4e76-8090-0331bd513617/</guid><description>It is not generally appreciated that the p value, as conceived by R. A. Fisher, is not compatible with the Neyman-Pearson hypothesis test in which it has become embedded. The p value was meant to be a flexible inferential measure, whereas the hypothesis test was a rule for behavior, not inference. The combination of the two methods has led to a reinterpretation of the p value simultaneously as an &amp;ldquo;observed error rate&amp;rdquo; and as a measure of evidence. Both of these interpretations are problematic, and their combination has obscured the important differences between Neyman and Fisher on the nature of the scientific method and inhibited our understanding of the philosophic implications of the basic methods in use today. An analysis using another method promoted by Fisher, mathematical likelihood, shows that the p value substantially overstates the evidence against the null hypothesis. Likelihood makes clearer the distinction between error rates and inferential evidence and is a quantitative tool for expressing evidential strength that is more appropriate for the purposes of epidemiology than the p value.</description></item><item><title>P values, Hypothesis tests, and likelihood: Implications for Epidemiology of a Neglected Historical Debate</title><link>https://aakinshin.net/library/papers/goodman1993/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/goodman1993/</guid><description>Reference Steven N Goodman “P values, hypothesis tests, and likelihood: implications for epidemiology of a neglected historical debate” (1993) // American Journal of Epidemiology. Publisher: Oxford University Press. Vol. 137. No 5. Pp. 485–496. DOI: 10.1093/oxfordjournals.aje.a116700
Bib @Article{goodman1993, title = {P values, hypothesis tests, and likelihood: implications for epidemiology of a neglected historical debate}, author = {Goodman, Steven N}, journal = {American Journal of Epidemiology}, volume = {137}, number = {5}, pages = {485--496}, year = {1993}, publisher = {Oxford University Press}, doi = {10.1093/oxfordjournals.aje.a116700} }</description></item><item><title>Scientific Method</title><link>https://aakinshin.net/library/quotes/cd4d7cb3-1f80-4fa7-be94-9cb8181e7851/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/cd4d7cb3-1f80-4fa7-be94-9cb8181e7851/</guid><description>The originators of the statistical frameworks that underlie modern epidemiologic studies recognized that their methods could not be interpreted properly without an understanding of their philosophical underpinnings. Neyman held that inductive reasoning was an illusion and that the only meaningful parameters of importance in an experiment were constraints on the number of statistical &amp;ldquo;errors&amp;rdquo; we would make, defined before an experiment. Fisher rejected mechanistic approaches to inference, believing in a more flexible, inductive approach to science. One of Fisher&amp;rsquo;s developments, mathematical likelihood, fit into such an approach. The p value, which Fisher wanted used in a similar manner, invited misinterpretation because it occupied a peculiar middle ground. Because of its resemblance to the pretrial a error, it was absorbed into the hypothesis test framework. This created two illusions: that an &amp;ldquo;error rate&amp;rdquo; could be measured after an experiment and that this posttrial &amp;ldquo;error rate&amp;rdquo; could be regarded as a measure of inductive evidence. Even though Fisher, Neyman, and many others have recognized these as fallacies, their perpetuation has been encouraged by the manner in which we use the p value today. One consequence is that we overestimate the evidence for associations, particularly with p values in the range of 0.001-0.05, creating misleading impressions of their plausibility. Another result is that we minimize the importance of judgment in inference, because its role is unclear when postexperiment evidential strength is thought to be measurable with preexperiment &amp;ldquo;error-rates.&amp;rdquo; Many experienced epidemiologists have tried to correct these problems by offering guidelines about how p values should be used. We may be more effective if, in the spirts of Fisher and Neyman, we instead focus on clarifying what p values mean, and on what we mean by the &amp;ldquo;scientific method.&amp;rdquo;</description></item><item><title>Statistical tests, P values, Confidence intervals, and power: A Guide to Misinterpretations</title><link>https://aakinshin.net/library/papers/greenland2016/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/greenland2016/</guid><description>Reference Sander Greenland, Stephen J Senn, Kenneth J Rothman, John B Carlin, Charles Poole, Steven N Goodman, Douglas G Altman “Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations” (2016) // European Journal of Epidemiology. Vol. 31. No 4. Pp. 337–350. DOI: 10.1007/s10654-016-0149-3
Bib @Article{greenland2016, title = {Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations}, volume = {31}, issn = {0393-2990, 1573-7284}, shorttitle = {Statistical tests, P values, confidence intervals, and power}, url = {http://link.springer.com/10.1007/s10654-016-0149-3}, doi = {10.1007/s10654-016-0149-3}, language = {en}, number = {4}, urldate = {2020-01-08}, journal = {European Journal of Epidemiology}, author = {Greenland, Sander and Senn, Stephen J and Rothman, Kenneth J and Carlin, John B and Poole, Charles and Goodman, Steven N and Altman, Douglas G}, month = {apr}, year = {2016}, note = {ZSCC: 0000855}, pages = {337--350} }</description></item><item><title>The P Value Fallacy</title><link>https://aakinshin.net/library/quotes/aeb58f62-484b-49a5-853c-8f72e49c82e3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/aeb58f62-484b-49a5-853c-8f72e49c82e3/</guid><description>An important problem exists in the interpretation of modern medical research data: Biological understanding and previous research play little formal role in the interpretation of quantitative results. This phenomenon is manifest in the discussion sections of research articles and ultimately can affect the reliability of conclusions. The standard statistical approach has created this situation by promoting the illusion that conclusions can be produced with certain “error rates,” without consideration of information from outside the experiment. This statistical approach, the key components of which are P values and hypothesis tests, is widely perceived as a mathematically coherent approach to inference. There is little appreciation in the medical community that the methodology is an amalgam of incompatible elements, whose utility for scientific inference has been the subject of intense debate among statisticians for almost 70 years. This article introduces some of the key elements of that debate and traces the appeal and adverse impact of this methodology to the P value fallacy, the mistaken idea that a single number can capture both the long-run outcomes of an experiment and the evidential meaning of a single result. This argument is made as a prelude to the suggestion that another measure of evidence should be used—the Bayes factor, which properly separates issues of long-run behavior from evidential strength and allows the integration of background knowledge with statistical findings.</description></item><item><title>Toward evidence-based Medical statistics. 1: The P Value Fallacy</title><link>https://aakinshin.net/library/papers/goodman1999/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/goodman1999/</guid><description>Reference Steven N Goodman “Toward evidence-based medical statistics. 1: The P value fallacy” (1999) // Annals of internal medicine. Publisher: American College of Physicians. Vol. 130. No 12. Pp. 995–1004. DOI: 10.7326/0003-4819-130-12-199906150-00008
Bib @Article{goodman1999, title = {Toward evidence-based medical statistics. 1: The P value fallacy}, author = {Goodman, Steven N}, journal = {Annals of internal medicine}, volume = {130}, number = {12}, pages = {995--1004}, year = {1999}, doi = {10.7326/0003-4819-130-12-199906150-00008}, publisher = {American College of Physicians} }</description></item></channel></rss>