<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>John PA Ioannidis on Andrey Akinshin</title><link>https://aakinshin.net/library/authors/john-pa-ioannidis/</link><description>Recent content in John PA Ioannidis on Andrey Akinshin</description><generator>Hugo -- gohugo.io</generator><language>en</language><atom:link href="https://aakinshin.net/library/authors/john-pa-ioannidis/index.xml" rel="self" type="application/rss+xml"/><item><title>An Exploratory Test for an Excess of Significant Findings</title><link>https://aakinshin.net/library/papers/ioannidis2007/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/ioannidis2007/</guid><description>Reference John PA Ioannidis, Thomas A Trikalinos “An exploratory test for an excess of significant findings” (2007) // Clinical Trials. Publisher: SAGE Publications. Vol. 4. No 3. Pp. 245–253. DOI: 10.1177/1740774507079441
Bib @Article{ioannidis2007, title = {An exploratory test for an excess of significant findings}, volume = {4}, issn = {1740-7753}, url = {http://dx.doi.org/10.1177/1740774507079441}, doi = {10.1177/1740774507079441}, number = {3}, journal = {Clinical Trials}, publisher = {SAGE Publications}, author = {Ioannidis, John PA and Trikalinos, Thomas A}, year = {2007}, month = {jun}, pages = {245–253} }</description></item><item><title>Analysis of Variance in Genetic Associations and Health Care Interventions</title><link>https://aakinshin.net/library/quotes/c84cec6e-c9dd-4ea2-b87f-516d09824fbf/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/c84cec6e-c9dd-4ea2-b87f-516d09824fbf/</guid><description>The maximal between-study variance was more likely to be recorded early in the 44 eligible meta-analyses of genetic associations than in the 37 meta-analyses of health care interventions (P = .013). At the time of the first heterogeneity assessment, the most favorable-ever result in support of a specific association was more likely to appear than the least favorable-ever result (22 vs. 10, P = .017); the opposite was seen at the second heterogeneity assessment (15 vs. 5, P = .031). Such a sequence of extreme opposite results was not seen in the clinical trials meta-analyses. The estimated between-study variance decreased over time in genetic association studies (P = .010), but not in clinical trials (P = .30).</description></item><item><title>Contradicted and Initially Stronger Effects in Highly Cited Clinical Research</title><link>https://aakinshin.net/library/papers/ioannidis2005a/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/ioannidis2005a/</guid><description>Reference John PA Ioannidis “Contradicted and Initially Stronger Effects in Highly Cited Clinical Research” (2005) // JAMA. Publisher: American Medical Association (AMA). Vol. 294. No 2. Pp. 218. DOI: 10.1001/jama.294.2.218
Bib @Article{ioannidis2005a, title = {Contradicted and Initially Stronger Effects in Highly Cited Clinical Research}, volume = {294}, issn = {0098-7484}, url = {http://dx.doi.org/10.1001/jama.294.2.218}, doi = {10.1001/jama.294.2.218}, number = {2}, journal = {JAMA}, publisher = {American Medical Association (AMA)}, author = {Ioannidis, John PA}, year = {2005}, month = {jul}, pages = {218} }</description></item><item><title>Early Extreme Contradictory Estimates May Appear in Published research: The Proteus Phenomenon in Molecular Genetics Research and Randomized Trials</title><link>https://aakinshin.net/library/papers/ioannidis2005b/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/ioannidis2005b/</guid><description>Reference John PA Ioannidis, Thomas A Trikalinos “Early extreme contradictory estimates may appear in published research: The Proteus phenomenon in molecular genetics research and randomized trials” (2005) // Journal of Clinical Epidemiology. Publisher: Elsevier BV. Vol. 58. No 6. Pp. 543–549. DOI: 10.1016/j.jclinepi.2004.10.019
Bib @Article{ioannidis2005b, title = {Early extreme contradictory estimates may appear in published research: The Proteus phenomenon in molecular genetics research and randomized trials}, volume = {58}, issn = {0895-4356}, url = {http://dx.doi.org/10.1016/j.jclinepi.2004.10.019}, doi = {10.1016/j.jclinepi.2004.10.019}, number = {6}, journal = {Journal of Clinical Epidemiology}, publisher = {Elsevier BV}, author = {Ioannidis, John PA and Trikalinos, Thomas A}, year = {2005}, month = {jun}, pages = {543–549} }</description></item><item><title>Evaluating the Reliability of Highly Cited Clinical Research Studies</title><link>https://aakinshin.net/library/quotes/3862f143-7b54-472a-b201-83407f62ac6c/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/3862f143-7b54-472a-b201-83407f62ac6c/</guid><description>Of 49 highly cited original clinical research studies, 45 claimed that the intervention was effective. Of these, 7 (16%) were contradicted by subsequent studies, 7 others (16%) had found effects that were stronger than those of subsequent studies, 20 (44%) were replicated, and 11 (24%) remained largely unchallenged. Five of 6 highlycited nonrandomized studies had been contradicted or had found stronger effects vs 9 of 39 randomized controlled trials (P=.008). Among randomized trials, studies with contradicted or stronger effects were smaller (P=.009) than replicated or unchallenged studies although there was no statistically significant difference in their early or overall citation impact. Matched control studies did not have a significantly different share of refuted results than highly cited studies, but they included more studies with “negative” results.</description></item><item><title>Is Everything We Eat Associated with cancer? A Systematic Cookbook Review</title><link>https://aakinshin.net/library/papers/schoenfeld2013/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/schoenfeld2013/</guid><description>Reference Jonathan D Schoenfeld, John PA Ioannidis “Is everything we eat associated with cancer? A systematic cookbook review” (2013) // The American Journal of Clinical Nutrition. Publisher: Elsevier BV. Vol. 97. No 1. Pp. 127–134. DOI: 10.3945/ajcn.112.047142
Bib @Article{schoenfeld2013, title = {Is everything we eat associated with cancer? A systematic cookbook review}, volume = {97}, issn = {0002-9165}, url = {http://dx.doi.org/10.3945/ajcn.112.047142}, doi = {10.3945/ajcn.112.047142}, number = {1}, journal = {The American Journal of Clinical Nutrition}, publisher = {Elsevier BV}, author = {Schoenfeld, Jonathan D and Ioannidis, John PA}, year = {2013}, month = {jan}, pages = {127–134} }</description></item><item><title>Is Molecular Profiling Ready for Use in Clinical Decision Making?</title><link>https://aakinshin.net/library/papers/ioannidis2007a/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/ioannidis2007a/</guid><description>Reference John PA Ioannidis “Is Molecular Profiling Ready for Use in Clinical Decision Making?” (2007) // The Oncologist. Publisher: Oxford University Press (OUP). Vol. 12. No 3. Pp. 301–311. DOI: 10.1634/theoncologist.12-3-301
Abstract Molecular profiling, the classification of tissue or other specimens for diagnostic, prognostic, and predictive purposes based on multiple gene expression, is a technology that holds major promise for optimizing the management of patients with cancer. However, the use of these tests for clinical decision making presents many challenges to overcome. Assay development and data analysis in this field have been largely exploratory, and leave numerous possibilities for the introduction of bias. Standardization of profiles remains the exception. Classifier performance is usually overinterpreted by presenting the results as p-values or multiplicative effects (e.g., relative risks), while the absolute sensitivity and specificity of classification remain modest at best, especially when tested in large validation samples. Validation has often been done with suboptimal attention to methodology and protection from bias. The postulated classifier performance may be inflated compared to what these profiles can achieve. With the exception of breast cancer, we have little evidence about the incremental discrimination that molecular profiles can provide versus classic risk factors alone. Clinical trials have started to evaluate the utility of using molecular profiles for breast cancer management. Until we obtain data from these trials, the impact of these tests and the net benefit under real-life settings remain unknown. Optimal incorporation into clinical practice is not straightforward. Finally, cost-effectiveness is difficult to appreciate until these other challenges are addressed. Overall, molecular profiling is a fascinating and promising technology, but its incorporation into clinical decision making requires careful planning and robust evidence.
Bib @Article{ioannidis2007a, title = {Is Molecular Profiling Ready for Use in Clinical Decision Making?}, abstract = {Molecular profiling, the classification of tissue or other specimens for diagnostic, prognostic, and predictive purposes based on multiple gene expression, is a technology that holds major promise for optimizing the management of patients with cancer.</description></item><item><title>Magnitude of Effects in Clinical Trials Published in high-impact General Medical Journals</title><link>https://aakinshin.net/library/papers/siontis2011/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/siontis2011/</guid><description>Reference Konstantinos CM Siontis, Evangelos Evangelou, John PA Ioannidis “Magnitude of effects in clinical trials published in high-impact general medical journals” (2011) // International Journal of Epidemiology. Publisher: Oxford University Press (OUP). Vol. 40. No 5. Pp. 1280–1291. DOI: 10.1093/ije/dyr095
Bib @Article{siontis2011, title = {Magnitude of effects in clinical trials published in high-impact general medical journals}, volume = {40}, issn = {0300-5771}, url = {http://dx.doi.org/10.1093/ije/dyr095}, doi = {10.1093/ije/dyr095}, number = {5}, journal = {International Journal of Epidemiology}, publisher = {Oxford University Press (OUP)}, author = {Siontis, Konstantinos CM and Evangelou, Evangelos and Ioannidis, John PA}, year = {2011}, month = {sep}, pages = {1280–1291} }</description></item><item><title>The Influence of Journal Prestige on the Inflation of Effect Sizes in Small Trials</title><link>https://aakinshin.net/library/quotes/79991435-cde7-4963-8f62-2bf812a39fda/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/79991435-cde7-4963-8f62-2bf812a39fda/</guid><description>We found that small trials published in NEJM, JAMA and Lancet were more likely to display more favourable results for experimental interventions compared with trials in other publication venues. Inflated effect sizes were seen primarily for early small trials in these prominent journals. Therefore, the results of small trials with spectacular early promises for large treatment effects should be seen with great caution. Conversely, for large trials, effect estimates are likely to be more reliable. Small-study effects have been previously documented in the randomized trials literature. However, the results of our study provide further insight suggesting the possibility of a specific interaction with further exaggerated effects when the limited evidence from small trials appears in the most prestigious journals. Also, the inflation of effects in early randomized trials on particular interventions appears to be quite specific to these most prestigious journals. Some modest heterogeneity was seen in the two tertiles with higher events, but heterogeneity is difficult to determine in the tertile with lower events, because of the wide uncertainty in the ROR for single topics, when there is limited evidence.</description></item><item><title>The Null Field</title><link>https://aakinshin.net/library/quotes/f05e3cd0-fb35-4654-b121-421c58c5f5e4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/f05e3cd0-fb35-4654-b121-421c58c5f5e4/</guid><description>Let us suppose that in a research field there are no true findings at all to be discovered. History of science teaches us that scientific endeavor has often in the past wasted effort in fields with absolutely no yield of true scientific information, at least based on our current understanding. In such a “null field,” one would ideally expect all observed effect sizes to vary by chance around the null in the absence of bias. The extent that observed findings deviate from what is expected by chance alone would be simply a pure measure of the prevailing bias.</description></item><item><title>US Studies May Overestimate Effect Sizes in Softer Research</title><link>https://aakinshin.net/library/papers/fanelli2013/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/fanelli2013/</guid><description>Reference Daniele Fanelli, John PA Ioannidis “US studies may overestimate effect sizes in softer research” (2013) // Proceedings of the National Academy of Sciences. Publisher: National Acad Sciences. Vol. 110. No 37. Pp. 15031–15036. DOI: 10.1073/pnas.1302997110
Abstract Many biases affect scientific research, causing a waste of resources, posing a threat to human health, and hampering scientific progress. These problems are hypothesized to be worsened by lack of consensus on theories and methods, by selective publication processes, and by career systems too heavily oriented toward productivity, such as those adopted in the United States (US). Here, we extracted 1,174 primary outcomes appearing in 82 meta-analyses published in health-related biological and behavioral research sampled from the Web of Science categories Genetics &amp;amp; Heredity and Psychiatry and measured how individual results deviated from the overall summary effect size within their respective meta-analysis. We found that primary studies whose outcome included behavioral parameters were generally more likely to report extreme effects, and those with a corresponding author based in the US were more likely to deviate in the direction predicted by their experimental hypotheses, particularly when their outcome did not include additional biological parameters. Nonbehavioral studies showed no such &amp;ldquo;US effect&amp;rdquo; and were subject mainly to sampling variance and small-study effects, which were stronger for non-US countries. Although this latter finding could be interpreted as a publication bias against non-US authors, the US effect observed in behavioral research is unlikely to be generated by editorial biases. Behavioral studies have lower methodological consensus and higher noise, making US researchers potentially more likely to express an underlying propensity to report strong and significant findings.
Bib @Article{fanelli2013, title = {US studies may overestimate effect sizes in softer research}, author = {Fanelli, Daniele and Ioannidis, John PA}, journal = {Proceedings of the National Academy of Sciences}, abstract = {Many biases affect scientific research, causing a waste of resources, posing a threat to human health, and hampering scientific progress.</description></item><item><title>Why Most Discovered True Associations Are Inflated</title><link>https://aakinshin.net/library/papers/ioannidis2008/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/ioannidis2008/</guid><description>Disclaimer The debate on whether research findings are credible is out of the scope. Assumption: considered research findings are true. First example is based on the previous work of the author: ioannidis2007a. While the original study van2002 is based on 117 patients (98 initial + 19 confirmatory), the author highlights only 19 patients from the second trial (to show the small sample size in the pioneer work). On page 645, left column, third line from the bottom, the number 256 should be 461. The same correction should be made in the legend for Figure 2. Reference John PA Ioannidis “Why Most Discovered True Associations Are Inflated” (2008) // Epidemiology. Publisher: Ovid Technologies (Wolters Kluwer Health). Vol. 19. No 5. Pp. 640–648. DOI: 10.1097/ede.0b013e31818131e7
Abstract Newly discovered true (non-null) associations often have inflated effects compared with the true effect sizes. I discuss here the main reasons for this inflation. First, theoretical considerations prove that when true discovery is claimed based on crossing a threshold of statistical significance and the discovery study is underpowered, the observed effects are expected to be inflated. This has been demonstrated in various fields ranging from early stopped clinical trials to genome-wide associations. Second, flexible analyses coupled with selective reporting may inflate the published discovered effects. The vibration ratio (the ratio of the largest vs. smallest effect on the same association approached with different analytic choices) can be very large. Third, effects may be inflated at the stage of interpretation due to diverse conflicts of interest. Discovered effects are not always inflated, and under some circumstances may be deflated-for example, in the setting of late discovery of associations in sequentially accumulated overpowered evidence, in some types of misclassification from measurement error, and in conflicts causing reverse biases. Finally, I discuss potential approaches to this problem. These include being cautious about newly discovered effect sizes, considering some rational down-adjustment, using analytical methods that correct for the anticipated inflation, ignoring the magnitude of the effect (if not necessary), conducting large studies in the discovery phase, using strict protocols for analyses, pursuing complete and transparent reporting of all results, placing emphasis on replication, and being fair with interpretation of results.</description></item><item><title>Why Most Published Research Findings Are False</title><link>https://aakinshin.net/library/papers/ioannidis2005/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/ioannidis2005/</guid><description>Corollaries:
The smaller the studies conducted in a scientific field, the less likely the research findings are to be true. The smaller the effect sizes in a scientific field, the less likely the research findings are to be true. The greater the number and the lesser the selection of tested relationships in a scientific field, the less likely the research findings are to be true. The greater the flexibility in designs, definitions, outcomes, and analytical modes in a scientific field, the less likely the research findings are to be true. The greater the financial and other interests and prejudices in a scientific field, the less likely the research findings are to be true. How Can We Improve the Situation:
Better powered evidence. The totality of the evidence (including all false discoveries). Instead of chasing statistical significance, we should improve our understanding of the pre-study odds. Reference John PA Ioannidis “Why most published research findings are false” (2005) // PLoS medicine. Publisher: Public Library of Science. Vol. 2. No 8. Pp. e124. DOI: 10.1371/journal.pmed.0020124
Abstract There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance.</description></item></channel></rss>