---
title: Three Dangerous Statistical Equations
year: 2007
authors:
- Howard Wainer
tags:
- Mathematics
- Statistics
source: wainer2007
features:
- math
sourceTitle: The Most Dangerous Equation
hasNotes: false
---

> Supporting ignorance is not, however, the direction I wish to pursue—indeed it is quite the antithesis of my message.
> Instead I am interested in equations that unleash their danger not when we know about them, but rather when we do not.
> Kept close at hand, these equations allow us to understand things clearly,
>   but their absence leaves us dangerously ignorant.
>
> There are many plausible candidates, and I have identified three prime examples:
>   Kelley's equation, which indicates that the truth is estimated best when its observed value
>   is regressed toward the mean of the group that it came from;
>   the standard linear regression equation;
>   and the equation that provides us with the standard deviation of the sampling distribution
>   of the mean—what might be called de Moivre's equation: $\sigma_{\bar{x}} = \sigma/\sqrt{n}$,
>   where $\sigma_{\bar{x}}$ is the standard error of the mean, $s$ is the standard deviation of the sample
>   and $n$ is the size of the sample.
> (Note the square root symbol, which will be a key to at least one of the misunderstandings of variation.)
> De Moivre's equation was derived by the French mathematician Abraham de Moivre,
>   who described it in his 1730 exploration of the binomial distribution, Miscellanea Analytica.
