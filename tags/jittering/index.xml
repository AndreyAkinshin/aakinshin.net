<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Jittering on Andrey Akinshin</title><link>https://aakinshin.net/tags/jittering/</link><description>Recent content in Jittering on Andrey Akinshin</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Tue, 27 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://aakinshin.net/tags/jittering/index.xml" rel="self" type="application/rss+xml"/><item><title>Improving quantile-respectful density estimation for discrete distributions using jittering</title><link>https://aakinshin.net/posts/qrde-discrete/</link><pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/qrde-discrete/</guid><description>&lt;p>In my previous posts, I already discussed the &lt;a href="https://aakinshin.net/posts/kde-discrete/">problem&lt;/a> that arises
when we try to build kernel density estimation (KDE) for samples with ties.
We may get such samples in real life from discrete or mixed discrete/continuous distributions.
Even if the original distribution is continuous,
we may observe artificial sample discretization due to the limited resolution of the measuring tool.
Such discretization may lead to inaccurate density plots due to undersmoothing.
The problem can be resolved using a nice technique called &lt;em>jittering&lt;/em>.
I also discussed &lt;a href="https://aakinshin.net/posts/discrete-sample-jittering/">how to apply&lt;/a> jittering to get a smoother version of KDE.&lt;/p>
&lt;p>However, I&amp;rsquo;m not a huge fan of KDE because of two reasons.
The first one is the &lt;a href="https://aakinshin.net/posts/kde-bw/">problem of choosing a proper bandwidth value&lt;/a>.
With poorly chosen bandwidth, we can easily get oversmoothing or undersmoothing even without the discretization problem.
The second one is an inconsistency between the KDE-based probability density function and evaluated sample quantiles.
It could lead to inconsistent visualizations (e.g., KDE-based violin plots with non-KDE-based quantile values)
or it could introduce problems for algorithms that require density function and quantile values at the same time.
The inconsistency could be resolved using &lt;a href="https://aakinshin.net/posts/qrde-hd/">quantile-respectful density estimation&lt;/a> (QRDE).
This kind of estimation builds the density function which matches the evaluated sample quantiles.
To get a smooth QRDE, we also need a smooth quantile estimator like the Harrell-Davis quantile estimator.
The robustness and componential efficiency of this approach can be improved using
the &lt;a href="https://aakinshin.net/posts/winsorized-hdqe/">winsorized&lt;/a> and &lt;a href="https://aakinshin.net/posts/trimmed-hdqe/">trimmed&lt;/a>
modifications of the Harrell-Davis quantile estimator
(which also have a &lt;a href="https://aakinshin.net/posts/wthdqe-efficiency/">decent statistical efficiency level&lt;/a>).&lt;/p>
&lt;p>Unfortunately, the straightforward QRDE calculation is not always applicable for samples with ties
because it&amp;rsquo;s impossible to build an &amp;ldquo;honest&amp;rdquo; density function for discrete distributions
without using the Dirac delta function.
This is a severe problem for QRDE-based algorithms like the
&lt;a href="https://aakinshin.net/posts/lowland-multimodality-detection/">lowland multimodality detection algorithm&lt;/a>.
In this post, I will show how jittering could help to solve this problem and get a smooth QRDE on samples with ties.&lt;/p></description></item><item><title>How to build a smooth density estimation for a discrete sample using jittering</title><link>https://aakinshin.net/posts/discrete-sample-jittering/</link><pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/discrete-sample-jittering/</guid><description>&lt;p>Let&amp;rsquo;s say you have a sample with tied values.
If you draw a kernel density estimation (KDE) for such a sample,
you may get a serrated pattern like this:&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/discrete-sample-jittering/img/intro-light.png" target="_blank" alt="intro">
 &lt;img
 src="https://aakinshin.net/posts/discrete-sample-jittering/img/intro-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/discrete-sample-jittering/img/intro-dark.png" target="_blank" alt="intro">
 &lt;img
 src="https://aakinshin.net/posts/discrete-sample-jittering/img/intro-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>KDE requires samples from continuous distributions
while tied values arise in discrete or mixture distributions.
Even if the original distribution is continuous,
you may observe artificial sample discretization due to the limited resolution of the measuring tool.
This effect may lead to distorted density plots like in the above picture.&lt;/p>
&lt;p>The problem could be solved using a nice technique called &lt;em>jittering&lt;/em>.
In the simplest case, jittering just adds random noise to each measurement.
Such a trick removes all ties from the sample and allows building a smooth density estimation.&lt;/p>
&lt;p>However, there are many different ways to apply jittering.
The trickiest question here is how to choose proper noise values.
In this post, I want to share one of my favorite jittering approaches.
It generates a non-randomized noise pattern with a low risk of noticeable sample corruption.&lt;/p></description></item><item><title>A Generic Approach to Nonparametric Function Estimation with Mixed Data</title><link>https://aakinshin.net/library/papers/nagler2018/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/nagler2018/</guid><description>The paper contains a nice literature overview.
Reference Thomas Nagler “A generic approach to nonparametric function estimation with mixed data” (2018) // Statistics &amp;amp; Probability Letters. Publisher: Elsevier BV. Vol. 137. Pp. 326–330. DOI: 10.1016/j.spl.2018.02.040
Abstract Most nonparametric function estimators can only handle continuous data. We show that making discrete variables continuous by adding noise is justified under suitable conditions on the noise distribution. This principle is widely applicable, including density and regression function estimation.
Bib @Article{nagler2018, title = {A generic approach to nonparametric function estimation with mixed data}, abstract = {Most nonparametric function estimators can only handle continuous data. We show that making discrete variables continuous by adding noise is justified under suitable conditions on the noise distribution. This principle is widely applicable, including density and regression function estimation.}, volume = {137}, issn = {0167-7152}, doi = {10.1016/j.spl.2018.02.040}, arxiv = {1704.07457}, journal = {Statistics \&amp;amp; Probability Letters}, publisher = {Elsevier BV}, author = {Nagler, Thomas}, year = {2018}, month = {jun}, pages = {326–330} }</description></item><item><title>Asymptotic Analysis of the Jittering Kernel Density Estimator</title><link>https://aakinshin.net/library/papers/nagler2018a/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/nagler2018a/</guid><description>Reference Thomas Nagler “Asymptotic Analysis of the Jittering Kernel Density Estimator” (2018) // Mathematical Methods of Statistics. Publisher: Allerton Press. Vol. 27. No 1. Pp. 32–46. DOI: 10.3103/s1066530718010027
Abstract Jittering estimators are nonparametric function estimators for mixed data. They extend arbitrary estimators from the continuous setting by adding random noise to discrete variables. We give an in-depth analysis of the jittering kernel density estimator, which reveals several appealing properties. The estimator is strongly consistent, asymptotically normal, and unbiased for discrete variables. It converges at minimax-optimal rates, which are established as a by-product of our analysis. To understand the effect of adding noise, we further study its asymptotic efficiency and finite sample bias in the univariate discrete case. Simulations show that the estimator is competitive on finite samples. The analysis suggests that similar properties can be expected for other jittering estimators.
Bib @Article{nagler2018a, title = {Asymptotic Analysis of the Jittering Kernel Density Estimator}, abstract = {Jittering estimators are nonparametric function estimators for mixed data. They extend arbitrary estimators from the continuous setting by adding random noise to discrete variables. We give an in-depth analysis of the jittering kernel density estimator, which reveals several appealing properties. The estimator is strongly consistent, asymptotically normal, and unbiased for discrete variables. It converges at minimax-optimal rates, which are established as a by-product of our analysis. To understand the effect of adding noise, we further study its asymptotic efficiency and finite sample bias in the univariate discrete case. Simulations show that the estimator is competitive on finite samples. The analysis suggests that similar properties can be expected for other jittering estimators.}, volume = {27}, issn = {1934-8045}, doi = {10.3103/s1066530718010027}, arxiv = {1705.05431}, number = {1}, journal = {Mathematical Methods of Statistics}, publisher = {Allerton Press}, author = {Thomas Nagler}, year = {2018}, month = {jan}, pages = {32–46} }</description></item><item><title>Jittering as a Statistical Irony</title><link>https://aakinshin.net/library/quotes/f1bd2864-ab15-4888-af78-83b48d0a4cb5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/f1bd2864-ab15-4888-af78-83b48d0a4cb5/</guid><description>The act of jittering (adding random noise to data) is a statistical irony: statisticians spend most of their day trying &amp;ldquo;remove&amp;rdquo; noise from data, but jittering puts noise back in!</description></item><item><title>To Jitter or Not to jitter: That is the Question</title><link>https://aakinshin.net/library/web/a72c7e2c451cde590e23791d0dc63370/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/web/a72c7e2c451cde590e23791d0dc63370/</guid><description/></item></channel></rss>