<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Statistics on Andrey Akinshin</title><link>https://aakinshin.net/tags/statistics/</link><description>Recent content in Statistics on Andrey Akinshin</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Tue, 27 Feb 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://aakinshin.net/tags/statistics/index.xml" rel="self" type="application/rss+xml"/><item><title>The Effect Existence, Its Magnitude, and the Goals</title><link>https://aakinshin.net/posts/effect-magnitude-goals/</link><pubDate>Tue, 27 Feb 2024 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/effect-magnitude-goals/</guid><description>&lt;p>If you are curious if something impacts something else, the answer is probably &amp;ldquo;yes.&amp;rdquo;
Does that indicator depend on those factors?
Yes, it does.
If we change this thing, would it affect &amp;hellip;?
Yes, it would.
If a person takes this pill, could it cause a non-exactly-zero change in the body?
Yes, the presence of the pill is already a change that can always be detected with the right amount of effort.&lt;/p>
&lt;p>One may argue that in some cases (assuming the list of specific cases is presented), zero effect does exist.
For a moment, let us pretend that it is true.
Now, let us imagine a parallel universe, which is the same as ours but with the presence of the effect.
Unfortunately, the effect is so small that our tools are not sophisticated enough to detect it.
Imagine being put into one of these worlds, but you don&amp;rsquo;t know which one.
How do you determine the existence of the effect?
Of course, you can improve the resolution of the measurement tools via new scientific discoveries,
but with the current state of technology, the absence of the effect cannot be checked.
Therefore, it is always safer to assume that the effect exists, keeping in mind that it can be negligible.
Let us accept this assumption and continue if it is absolute truth.&lt;/p></description></item><item><title>Case study: a city social survey</title><link>https://aakinshin.net/posts/cs-social-survey/</link><pubDate>Tue, 20 Feb 2024 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/cs-social-survey/</guid><description>&lt;p>Imagine a city mayor considering a project offering to build parks in several neighborhoods.
It can be a good budget investment since it can potentially increase the happiness level of the citizens.
However, it is just a hypothesis: if parks do not impact happiness,
it is worth considering other city renovation projects.
It makes sense to perform a pilot experiment before spending the budget on all the parks.
The mayor is thinking about the following plan:
pick a random neighborhood,
survey the citizens to measure their happiness,
build a park,
survey the citizens again,
compare the survey results,
make a decision about the further parks in other neighborhoods.
Someone is needed to design the survey and draw the conclusion.&lt;/p>
&lt;p>Let us explore possible approaches to perform such a study.
These artificial examples are not guidelines
but rather simplified illustrations of possible mindsets presented as lists of thoughts.
In this demonstration, we mainly focus on the attitude to the research process rather than on the technical details.
All the examples are based on real stories.&lt;/p></description></item><item><title>Simplifying adjustments of confidence levels and practical significance thresholds</title><link>https://aakinshin.net/posts/adjust-confidence-levels-and-practical-significance/</link><pubDate>Tue, 13 Feb 2024 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/adjust-confidence-levels-and-practical-significance/</guid><description>&lt;p>Translation of the buisness goals to the actual parameters of the statistical procedure is a non-trivial task.
The degree of non-triviality increases if we should adjust several parameters at the same time.
In this post, we consider a problem of simultaneous choice
of the confidence level and the practical significance threshold.
We discuss possible pitfalls and how to simplify the adjusting procedure to avoid them.&lt;/p></description></item><item><title>Degrees of practical significance</title><link>https://aakinshin.net/posts/practical-significance-degrees/</link><pubDate>Tue, 06 Feb 2024 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/practical-significance-degrees/</guid><description>&lt;p>Let&amp;rsquo;s say we have two data samples, and we want to check if there is a difference between them.
If we are talking about any kind of difference, the answer is most probably yes.
It&amp;rsquo;s highly unlikely that two random samples are identical.
Even if they are, there are still chances that we observe such a situation by accident,
and there is a difference in the underlying distributions.
Therefore, the discussion about the existence of any kind of difference is not meaningful.&lt;/p>
&lt;p>To make more meaningful insights, researchers often talk about statistical significance.
The approach can also be misleading.
If the sample size is large enough, we are almost always able to detect even a neglectable difference
and obtain a statistically significant result for any pair of distributions.
On the other hand, a huge difference can be declared insignificant if the sample size is small.
While the concept is interesting and well-researched, it rarely matches the actual research goal.
I strongly believe that we should &lt;em>not&lt;/em> test for the nil hypothesis (checking if the true difference is &lt;em>exactly&lt;/em> zero).&lt;/p>
&lt;p>Here, we can switch from statistical significance to practical significance.
We are supposed to define a threshold (e.g., in terms of minimum effect size)
for the difference that is meaningful for the research.
This approach has more chances to be aligned with the research goals.
However, it is also not always satisfying enough.
We should keep in mind that hypothesis testing often arises in the context of decision-making problems.
In some cases, we can do exploration research in which we just want to have a better understanding of the world.
However, in most cases, we do not perform calculations just because we are curious;
we often want to make a decision based on the results.
And this is the most crucial moment.
It should always be the starting point in any research project.
First of all, we should clearly describe the possible decisions and their preconditions.
When we start doing that, we can discover that not all the practically significant outcomes are equally significant.
If different practically significant results may lead to different decisions,
we should define the proper classification in advance during the research design stage.
The dichotomy of &amp;ldquo;practically significant&amp;rdquo; vs. &amp;ldquo;not practically significant&amp;rdquo;
may conceal important problem aspects and lead to a wrong decision.&lt;/p>
&lt;p>In this post, I would like to discuss the degrees of practical significance and
show an example of how important it is for some problems.&lt;/p></description></item><item><title>Weighted Mann-Whitney U test, Part 3</title><link>https://aakinshin.net/posts/wmw3/</link><pubDate>Tue, 30 Jan 2024 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/wmw3/</guid><description>&lt;p>I continue building a weighted version of the Mann–Whitney $U$ test.
While &lt;a href="https://aakinshin.net/posts/wmw1/">previously suggested approach&lt;/a> feel promising,
I don&amp;rsquo;t like the usage of Bootstrap to obtain the $p$-value.
It is always better to have a deterministic and exact approach where it&amp;rsquo;s possible.
I still don&amp;rsquo;t know how to solve it in general case,
but it seems that I&amp;rsquo;ve obtained a reasonable solution for some specific cases.
The current version of the approach still has issues and
requires additional correction factors in some cases and additional improvements.
However, it passes my minimal requirements, so it is worth trying to continue developing this idea.
In this post, I share the description of the weighted approach and provide numerical examples.&lt;/p></description></item><item><title>Andreas Löffler's implementation of the exact p-values calculations for the Mann-Whitney U test</title><link>https://aakinshin.net/posts/mw-loeffler/</link><pubDate>Tue, 23 Jan 2024 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/mw-loeffler/</guid><description>&lt;p>Mann-Whitney is one of the most popular non-parametric statistical tests.
Unfortunately, most test implementations in statistical packages are far from perfect.
The exact p-value calculation is time-consuming and can be impractical for large samples.
Therefore, most implementations automatically switch to the asymptotic approximation, which can be quite inaccurate.
Indeed, the classic normal approximation could produce
&lt;a href="https://aakinshin.net/posts/r-mann-whitney-incorrect-p-value/">enormous&lt;/a>
&lt;a href="https://aakinshin.net/posts/python-mann-whitney-incorrect-p-value/">errors&lt;/a>.
Thanks to the &lt;a href="https://aakinshin.net/posts/mw-edgeworth2/">Edgeworth expansion&lt;/a>, the accuracy can be improved,
but it is still not always satisfactory enough.
I prefer using the exact p-value calculation whenever possible.&lt;/p>
&lt;p>The computational complexity of the exact p-value calculation using the classic recurrent equation
suggested by Mann and Whitney is $\mathcal{O}(n^2 m^2)$ in terms of time and memory.
It&amp;rsquo;s not a problem for small samples, but for medium-size samples,
it is slow, and it has an extremely huge memory footprint.
This gives us an unpleasant dilemma:
either we use the exact p-value calculation (which is extremely time and memory-consuming),
or we use the asymptotic approximation (which gives poor accuracy).&lt;/p>
&lt;p>Last week, I got acquainted with a brilliant algorithm for the exact p-value calculation
suggested by Andreas Löffler in 1982.
It&amp;rsquo;s much faster than the classic approach, and it requires only $\mathcal{O}(n+m)$ memory.&lt;/p></description></item><item><title>Eclectic statistics</title><link>https://aakinshin.net/posts/eclectic-statistics/</link><pubDate>Tue, 16 Jan 2024 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/eclectic-statistics/</guid><description>&lt;p>In the world of mathematical statistics, there is a constant confrontation between adepts of different paradigms.
This is a constant source of confusion for many researchers who struggle to pick out the proper approach to follow.
For example, how to choose between the frequentist and Bayesian approaches?
Since these paradigms may produce inconsistent results
(e.g., see &lt;a href="https://en.wikipedia.org/wiki/Lindley%27s_paradox">Lindley&amp;rsquo;s paradox&lt;/a>),
some choice has to be made.
The easiest way to conduct research is to pick a single paradigm and stick to it.
The right way to conduct research is to carefully think.&lt;/p></description></item><item><title>Change Point Detection and Recent Changes</title><link>https://aakinshin.net/posts/cpd-recent-changes/</link><pubDate>Tue, 09 Jan 2024 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/cpd-recent-changes/</guid><description>&lt;p>Change point detection (CPD) in time series analysis
is an essential tool for identifying significant shifts in data patterns.
These shifts, or &amp;ldquo;change points,&amp;rdquo; can signal critical transitions in various contexts.
While most CPD algorithms are adept at discovering historical change points,
their sensitivity in detecting recent changes can be limited,
often due to a key parameter: the minimum distance between sequential change points.
In this post, I share some speculations on how we can improve cpd analysis by combining two change point detectors.&lt;/p></description></item><item><title>Merging extended P² quantile estimators, Part 1</title><link>https://aakinshin.net/posts/merging-exp2-1/</link><pubDate>Tue, 02 Jan 2024 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/merging-exp2-1/</guid><description>&lt;p>&lt;a href="https://aakinshin.net/tags/research-p2qe/">P² quantile estimator&lt;/a> is a streaming quantile estimator
with $\mathcal{O}(1)$ memory footprint and an extremely fast update procedure.
Several days ago, I learned that it was &lt;a href="https://twitter.com/rickbrewPDN/status/1740233421673349544">adopted&lt;/a> for
the new Paint.NET GPU-based Median Sketch effect
(the description is &lt;a href="https://forums.getpaint.net/topic/124261-median-sketch-gpu/">here&lt;/a>).
While P² meets the basic problem requirement (streaming median approximation without storing all the values),
the algorithm performance is still not acceptable without additional adjustments.
A significant performance improvement &lt;a href="https://twitter.com/rickbrewPDN/status/1740422610545234153">can be obtained&lt;/a>
if we split the input stream, process each part separately with a separate P², and merge the results.
Unfortunately, the merging procedure is a tricky thing to implement.
I enjoy such challenges, so I decided to attempt to build such a merging approach.
In this post, I describe my first attempt.&lt;/p></description></item><item><title>Hodges-Lehmann ratio estimator vs. Bhattacharyya's scale ratio estimator</title><link>https://aakinshin.net/posts/hl-ratio-vs-bhattacharyya/</link><pubDate>Tue, 26 Dec 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/hl-ratio-vs-bhattacharyya/</guid><description>&lt;p>Previously, I &lt;a href="https://aakinshin.net/posts/hl-ratio/">discussed&lt;/a> an idea of a ratio estimator based on the Hodges-Lehmann estimator.
This idea looks so simple and natural that I was sure that it must have already been proposed and studied.
However, when I started to search for it, it turned out that it was not as easy as I expected.
Moreover, some papers attribute this idea to Bhattacharyya, which is not accurate.
In this post, we discuss the difference between these two approaches.&lt;/p></description></item><item><title>Finite-sample Gaussian efficiency: Shamos vs. Rousseeuw-Croux Qn scale estimators</title><link>https://aakinshin.net/posts/shamos-vs-qn/</link><pubDate>Tue, 19 Dec 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/shamos-vs-qn/</guid><description>&lt;p>&lt;a href="https://aakinshin.net/posts/qad-vs-rc/">Previously&lt;/a>, we compared the finite-sample Gaussian efficiency of
the &lt;a href="https://aakinshin.net/library/papers/rousseeuw1993/">Rousseeuw-Croux scale estimators&lt;/a> and the QAD estimator.
In this post, we compare the finite-sample Gaussian efficiency of the Shamos scale estimator
and the Rousseeuw-Croux $Q_n$ scale estimator.
This is a particularly interesting comparison.
In the famous &amp;ldquo;Alternatives to the Median Absolute Deviation&amp;rdquo; (1993) paper by Peter J. Rousseeuw and Christophe Croux,
the authors presented $Q_n$ as an improved version of the Shamos estimator.
Both estimators are based on the set of pairwise absolute differences between the elements of the sample.
The Shamos estimator takes the median of this set and, therefore,
has the asymptotic breakdown point of $\approx 29\%$
and the asymptotic Gaussian efficiency of $\approx 86\%$.
$Q_n$ takes the first quartile of this set and, therefore,
has the asymptotic breakdown point of $\approx 50\%$ (like the median)
and the asymptotic Gaussian efficiency of $\approx 82\%$.
It sounds like a good deal: we trade $4\%$ of the asymptotic Gaussian efficiency
for $21\%$ of the asymptotic breakdown point.
What could possibly stop us from using $Q_n$ everywhere instead of the Shamos estimator?&lt;/p>
&lt;p>Well, here is a trick.
The breakdown point of $29\%$ is actually a practically reasonable value.
If more than $29\%$ of the sample are outliers, we should probably consider them not as outliers but as a separate mode.
Such a situation should be handled by a multimodality detector and lead us to a different approach.
The usage of dispersion estimators in the case of multimodal distributions is potentially misleading.
When such a multimodality diagnostic scheme is used, there is no practical need for a higher breakdown point.&lt;/p>
&lt;p>Thus, the breakdown point of $50\%$ is not so impressive property of $Q_n$.
Meanwhile, the drop in Gaussian efficiency is not so enjoyable.
$4\%$ may sound like a negligible difference, but it is only the asymptotic value.
In real life, we typically tend to work with finite samples.
Let us explore the actual finite-sample Gaussian efficiency values of these estimators.&lt;/p></description></item><item><title>Two-pass change point detection for temporary interval condensation</title><link>https://aakinshin.net/posts/two-pass-cpd/</link><pubDate>Tue, 12 Dec 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/two-pass-cpd/</guid><description>&lt;p>When we choose a change point detection algorithm, the most important thing is to clearly understand
why we want to detect the change points.
The knowledge of the final business goals is essential.
In this post, I show a simple example of how a business requirement can be translated into algorithm adjustments.&lt;/p></description></item><item><title>Inconsistent violin plots</title><link>https://aakinshin.net/posts/inconsistent-violin-plots/</link><pubDate>Tue, 05 Dec 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/inconsistent-violin-plots/</guid><description>&lt;p>The usefulness and meaningfulness of the &lt;a href="https://en.wikipedia.org/wiki/Violin_plot">violin plots&lt;/a> are dubious
(e.g., see &lt;a href="https://youtu.be/_0QMKFzW9fw">this video&lt;/a> and the
&lt;a href="https://www.reddit.com/16z7stw">corresponding discussion&lt;/a>).
While this type of plot inherits issues of density plots (e.g., &lt;a href="https://aakinshin.net/posts/kde-bw/">the bandwidth selection problem&lt;/a>)
and box plots, it also introduces new problems.
One such problem is data inconsistency: default density plots and box plots are often incompatible with each other.
In this post, I show an example of this inconsistency.&lt;/p></description></item><item><title>Sporadic noise problem in change point detection</title><link>https://aakinshin.net/posts/sporadic-noise-problem/</link><pubDate>Tue, 28 Nov 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/sporadic-noise-problem/</guid><description>&lt;p>We consider a problem of change point detection at the end of a time series.
Let us say that we systematically monitor readings of an indicator,
and we want to react to noticeable changes in the measured values as fast as possible.
When there are no changes in the underlying distribution,
any alerts about detected change points should be considered false positives.
Typically, in such problems,
we consider the &lt;a href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">i.i.d.&lt;/a>
assumption that claims that in the absence of change points,
all the measurements are independent and identically distributed.
Such an assumption significantly simplifies the mathematical model,
but unfortunately, it is rarely fully satisfied in real life.
If we want to build a reliable change point detection system,
it is important to be aware of possible real-life artifacts that introduce deviations from the declared model.
In this problem, I discuss the problem of the sporadic noise.&lt;/p></description></item><item><title>Resistance to the low-density regions: the Hodges-Lehmann location estimator based on the Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/rldr-hlhd/</link><pubDate>Tue, 21 Nov 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/rldr-hlhd/</guid><description>&lt;p>Previously, I have discussed the topic of the &lt;a href="https://aakinshin.net/tags/research-rldr/">resistance to the low-density regions&lt;/a>
of various estimators including &lt;a href="https://aakinshin.net/posts/rldr-hl/">the Hodges-Lehmann location estimator&lt;/a> ($\operatorname{HL}$).
In general, $\operatorname{HL}$ is a great estimator with great statistical efficiency and a decent breakdown point.
Unfortunately, it has low resistance to the low-density regions around
$29^\textrm{th}$ and $71^\textrm{th}$ percentiles, which may cause troubles in the case of multimodal distributions.
I am trying to find a modification of $\operatorname{HL}$
that performs almost the same as the original $\operatorname{HL}$, but has increased resistance.
One of the ideas I had was using the Harrell-Davis quantile estimator
instead of the sample median to evaluate $\operatorname{HL}$.
Regrettably, this idea did not turn out to be successful:
such an estimator has a resistance function similar to the original $\operatorname{HL}$.
I believe that it is important to share negative results, and therefore this post contains a bunch of plots,
which illustrate results of relevant numerical simulations.&lt;/p></description></item><item><title>Median vs. Hodges-Lehmann: compare efficiency under heavy-tailedness</title><link>https://aakinshin.net/posts/robust-eff-median-hl/</link><pubDate>Tue, 14 Nov 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/robust-eff-median-hl/</guid><description>&lt;p>In the &lt;a href="https://aakinshin.net/posts/thoughts-robust-efficiency/">previous post&lt;/a>,
I shared some thoughts on how to evaluate the statistical efficiency of estimators under heavy-tailed distributions.
In this post, I apply described ideas to actually compare efficiency values of
the Mean, the Sample Median, and the Hodges-Lehmann location estimator
under various distributions.&lt;/p></description></item><item><title>Thoughts about robustness and efficiency</title><link>https://aakinshin.net/posts/thoughts-robust-efficiency/</link><pubDate>Tue, 07 Nov 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/thoughts-robust-efficiency/</guid><description>Statistical efficiency is an essential characteristic, which has to be taken into account when we choose between different estimators. When the underlying distribution is a normal one or at least light-tailed, evaluation of the statistical efficiency typically is not so hard. However, when the underlying distribution is a heavy-tailed one, problems appear. The statistical efficiency is usually expressed via the mean squared error or via variance, which are not robust. Therefore, heavy-tailedness may lead to distorted or even infinite efficiency, which is quite impractical.
So, how do we compare the efficiency of estimators under a heavy-tailed distribution?
Let&amp;rsquo;s say we want to compare the efficiency of the mean and the median distribution. Under the normal distribution (so-called Gaussian efficiency), this task is trivial: we build the sampling mean distribution and the sampling median distribution, estimate the variance for each of them, and then get the ratio of these variances. However, if we are interested in the median, we are probably expecting some outliers. Most of the significant real-life outliers come from the heavy-tailed distributions. Therefore, Gaussian efficiency is not the most interesting metric. It makes sense to evaluate the efficiency of the considered estimators under various heavy-tailed distributions. Unfortunately, the variance is not a robust measure and is too sensitive to tails: if the sampling distribution is also not normal or even heavy-tailed, the meaningfulness of the true variance value decreases. It seems reasonable to consider alternative robust measures of dispersion. Which one should we choose? Maybe Median Absolute Deviation (MAD)? Well, the asymptotic Gaussian efficiency of MAD is only ~37%. And here we have the same problem: should we trust the Gaussian efficiency under heavy-tailedness? Therefore, we should first evaluate the efficiency of dispersion estimators. But we can&amp;rsquo;t do it without a previously chosen dispersion estimator! And could we truly express the actual relative efficiency between two estimators under tricky asymmetric multimodal heavy-tailed distributions using a single number?</description></item><item><title>Finite-sample Gaussian efficiency: Quantile absolute deviation vs. Rousseeuw-Croux scale estimators</title><link>https://aakinshin.net/posts/qad-vs-rc/</link><pubDate>Tue, 31 Oct 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/qad-vs-rc/</guid><description>&lt;p>In this post, we discuss the finite-sample Gaussian efficiency of various robust dispersion estimators.
The classic standard deviation has the highest possible Gaussian efficiency of $100\%$,
but it is not robust: a single outlier can completely destroy the estimation.
A typical robust alternative to the standard deviation is the Median Absolute Deviation ($\operatorname{MAD}$).
While the $\operatorname{MAD}$ is highly robust (the breakdown point is $50\%$), it is not efficient:
its asymptotic Gaussian efficiency is only $37\%$.
Common alternative to the $\operatorname{MAD}$ is the Rousseeuw-Croux $S_n$ and $Q_n$ scale estimators
that provide higher efficiency, keeping the breakdown point of $50\%$.
In &lt;a href="https://aakinshin.net/posts/preprint-qad/">one of my recent preprints&lt;/a>,
I introduced the concept of the Quantile Absolute Deviation ($\operatorname{QAD}$)
and its specific cases:
the Standard Quantile Absolute Deviation ($\operatorname{SQAD}$) and
the Optimal Quantile Absolute Deviation ($\operatorname{OQAD}$).
Let us review the finite-sample and asymptotic values of the Gaussian efficiency for these estimators.&lt;/p></description></item><item><title>Mann-Whitney U test and heteroscedasticity</title><link>https://aakinshin.net/posts/mw-heteroscedasticity/</link><pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/mw-heteroscedasticity/</guid><description>&lt;p>Mann-Whitney U test is a good nonparametric test, which mostly targets changes in locations.
However, it doesn&amp;rsquo;t properly support all types of differences between the two distributions.
Specifically, it poorly handles changes in variance.
In this post, I briefly discuss its behavior in reaction to scaling a distribution without introducing location changes.&lt;/p></description></item><item><title>Exploring the power curve of the Ansari-Bradley test</title><link>https://aakinshin.net/posts/ansari-power/</link><pubDate>Tue, 17 Oct 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/ansari-power/</guid><description>&lt;p>The Ansari-Bradley test is a popular rank-based nonparametric test for a difference in scale/dispersion parameters.
In this post, we explore its power curve in a numerical simulation.&lt;/p></description></item><item><title>Exploring the power curve of the Lepage test</title><link>https://aakinshin.net/posts/lepage-power/</link><pubDate>Tue, 10 Oct 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/lepage-power/</guid><description>&lt;p>Previously, I already &lt;a href="https://aakinshin.net/posts/cucconi-power/">discussed the Cucconi test&lt;/a>.
In this post, I continue the topic of nonparametric tests and
check out the &lt;a href="https://en.wikipedia.org/wiki/Lepage_test">Lepage test&lt;/a>.&lt;/p></description></item><item><title>Weighted Hodges-Lehmann location estimator and mixture distributions</title><link>https://aakinshin.net/posts/whl-mixture/</link><pubDate>Tue, 03 Oct 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/whl-mixture/</guid><description>&lt;p>The classic non-weighted Hodges-Lehmann location estimator of a sample $\mathbf{x} = (x_1, x_2, \ldots, x_n)$
is defined as follows:&lt;/p>
$$
\operatorname{HL}(\mathbf{x}) =
 \underset{1 \leq i \leq j \leq n}{\operatorname{median}} \left(\frac{x_i + x_j}{2} \right),
$$
&lt;p>where $\operatorname{median}$ is the sample median.
&lt;a href="https://aakinshin.net/posts/whl/">Previously&lt;/a>, we have defined a weighted version of the Hodges-Lehmann location estimator as follows:&lt;/p>
$$
\operatorname{WHL}(\mathbf{x}, \mathbf{w}) =
 \underset{1 \leq i \leq j \leq n}{\operatorname{wmedian}} \left(\frac{x_i + x_j}{2},\; w_i \cdot w_j \right),
$$
&lt;p>where $\mathbf{w} = (w_1, w_2, \ldots, w_n)$ is the vector of weights,
$\operatorname{wmedian}$ is the &lt;a href="https://aakinshin.net/posts/preprint-wqe/">weighted median&lt;/a>.
For simplicity, in the scope of the current post,
Hyndman-Fan Type 7 quantile estimator is used as the base for the weighted median.&lt;/p>
&lt;p>In this post, we consider a numerical simulation in which we compare sampling distribution of
$\operatorname{HL}$ and $\operatorname{WHL}$ in a case of mixture distribution.&lt;/p></description></item><item><title>Carling’s Modification of the Tukey's fences</title><link>https://aakinshin.net/posts/carling-outlier-detector/</link><pubDate>Tue, 26 Sep 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/carling-outlier-detector/</guid><description>&lt;p>Let us consider the classic problem of outlier detection in one-dimensional sample.
One of the most popular approaches is Tukey&amp;rsquo;s fences, that defines the following range:&lt;/p>
$$
[Q_1 - k(Q_3 - Q_1);\; Q_3 + k(Q_3 - Q_1)],
$$
&lt;p>where $Q_1$ and $Q_3$ are the first and the third quartiles of the given sample.&lt;/p>
&lt;p>All the values outside the given range are classified as outliers.
The typical values of $k$ are $1.5$ for &amp;ldquo;usual outliers&amp;rdquo; and $3.0$ for &amp;ldquo;far out&amp;rdquo; outliers.
In the classic Tukey&amp;rsquo;s fences approach, $k$ is often a predefined constant.
However, there are alternative approaches that define $k$ dynamically based on the given sample.
One of the possible variations of Tukey&amp;rsquo;s fences is Carling&amp;rsquo;s modification that defines $k$ as follows:&lt;/p>
$$
k = \frac{17.63n - 23.64}{7.74n - 3.71},
$$
&lt;p>where $n$ is the sample size.&lt;/p>
&lt;p>In this post, we compare the classic Tukey&amp;rsquo;s fences with $k=1.5$ and $k=3.0$ against Carling&amp;rsquo;s modification.&lt;/p></description></item><item><title>Central limit theorem and log-normal distribution</title><link>https://aakinshin.net/posts/clt-lnorm/</link><pubDate>Tue, 19 Sep 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/clt-lnorm/</guid><description>&lt;p>It is inconvenient to work with samples from a distribution of unknown form.
Therefore, researchers often switch to considering the sample mean value and
hope that thanks to the &lt;a href="https://en.wikipedia.org/wiki/Central_limit_theorem">central limit theorem&lt;/a>,
the distribution of the sample means should be approximately normal.
They say that if we consider samples of size $n \geq 30$, we can expect practically acceptable convergence to normality
thanks to &lt;a href="https://en.wikipedia.org/wiki/Berry%E2%80%93Esseen_theorem">Berry–Esseen theorem&lt;/a>.
Indeed, this statement is almost valid for many real data sets.
However, we can actually expect the applicability of this approach only for light-tailed distributions.
In the case of heavy-tailed distributions, converging to normality is so slow,
that we cannot imply the normality assumption for the distribution of the sample means.
In this post, I provide an illustration of this effect using the log-normal distribution.&lt;/p></description></item><item><title>Hodges-Lehmann Gaussian efficiency: location shift vs. shift of locations</title><link>https://aakinshin.net/posts/hl-loc-shift-vs-shift-loc/</link><pubDate>Tue, 12 Sep 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/hl-loc-shift-vs-shift-loc/</guid><description>&lt;p>Let us consider two samples $\mathbf{x} = (x_1, x_2, \ldots, x_n)$ and $\mathbf{y} = (y_1, y_2, \ldots, y_m)$.
The one-sample Hodges-Lehman location estimator is defined as the median of the Walsh (pairwise) averages:&lt;/p>
$$
\operatorname{HL}(\mathbf{x}) =
 \underset{1 \leq i \leq j \leq n}{\operatorname{median}} \left(\frac{x_i + x_j}{2} \right),
\quad
\operatorname{HL}(\mathbf{y}) =
 \underset{1 \leq i \leq j \leq m}{\operatorname{median}} \left(\frac{y_i + y_j}{2} \right).
$$
&lt;p>For these two samples, we can also define the shift between these two estimations:&lt;/p>
$$
\Delta_{\operatorname{HL}}(\mathbf{x}, \mathbf{y}) = \operatorname{HL}(\mathbf{x}) - \operatorname{HL}(\mathbf{y}).
$$
&lt;p>The two-sample Hodges-Lehmann location shift estimator is defined as the median of pairwise differences:&lt;/p>
$$
\operatorname{HL}(\mathbf{x}, \mathbf{y}) =
 \underset{1 \leq i \leq n,\,\, 1 \leq j \leq m}{\operatorname{median}} \left(x_i - y_j \right).
$$
&lt;p>Previously, I already compared the location shift estimator with the difference of median estimators
(&lt;a href="https://aakinshin.net/posts/median-shift-vs-shift-median1/">1&lt;/a>, &lt;a href="https://aakinshin.net/posts/median-shift-vs-shift-median2/">2&lt;/a>).
In this post, I compare the difference between two location estimations and the shift estimations
in terms of Gaussian efficiency.
Before I started this study, I expected that $\operatorname{HL}$ should be more efficient
than $\Delta_{\operatorname{HL}}$.
Let us find out if my intuition is correct or not!&lt;/p></description></item><item><title>Thoughts on automatic statistical methods and broken assumptions</title><link>https://aakinshin.net/posts/thoughts-on-broken-assumptions/</link><pubDate>Tue, 05 Sep 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/thoughts-on-broken-assumptions/</guid><description>In the old times of applied statistics existence, all statistical experiments used to be performed by hand. In manual investigations, an investigator is responsible not only for interpreting the research results but also for the applicability validation of the used statistical approaches. Nowadays, more and more data processing is performed automatically on enormously huge data sets. Due to the extraordinary number of data samples, it is often almost impossible to verify each output individually using human eyes. Unfortunately, since we typically have no full control over the input data, we cannot guarantee certain assumptions that are required by classic statistical methods. These assumptions can be violated not only due to real-life phenomena we were not aware of during the experiment design stage, but also due to data corruption. In such corner cases, we may get misleading results, wrong automatic decisions, unacceptably high Type I/II error rates, or even a program crash because of a division by zero or another invalid operation. If we want to make an automatic analysis system reliable and trustworthy, the underlying mathematical procedures should correctly process malformed data.
The normality assumption is probably the most popular one. There are well-known methods of robust statistics that focus only on slight deviations from normality and the appearance of extreme outliers. However, it is only a violation of one specific consequence from the normality assumption: light-tailedness. In practice, this sub-assumption is often interpreted as &amp;ldquo;the probability of observing extremely large outliers is negligible.&amp;rdquo; Meanwhile, there are other implicit derived sub-assumptions: continuity (we do not expect tied values in the input samples), symmetry (we do not expect highly-skewed distributions), unimodality (we do not expect multiple modes), nondegeneracy (we do not expect all sample values to be equal), sample size sufficiency (we do not expect extremely small samples like single-element samples), and others.</description></item><item><title>Ratio estimator based on the Hodges-Lehmann approach</title><link>https://aakinshin.net/posts/hl-ratio/</link><pubDate>Tue, 29 Aug 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/hl-ratio/</guid><description>&lt;p>For two samples $\mathbf{x} = ( x_1, x_2, \ldots, x_n )$ and $\mathbf{y} = ( y_1, y_2, \ldots, y_m )$,
the Hodges-Lehmann location shift estimator is defined as follows:&lt;/p>
$$
\operatorname{HL}(\mathbf{x}, \mathbf{y}) =
 \underset{1 \leq i \leq n,\,\, 1 \leq j \leq m}{\operatorname{median}} \left(x_i - y_j \right).
$$
&lt;p>Now, let us consider the problem of estimating the ratio of the location measures instead of the shift between them.
While there are multiple approaches to providing such an estimation,
one of the options that can be considered is based on the Hodges-Lehmann ideas.&lt;/p></description></item><item><title>Weighted Mann-Whitney U test, Part 2</title><link>https://aakinshin.net/posts/wmw2/</link><pubDate>Tue, 22 Aug 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/wmw2/</guid><description>&lt;p>Previously, I &lt;a href="https://aakinshin.net/posts/wmw1/">suggested&lt;/a> a weighted version of the Mann–Whitney $U$ test.
The distribution of the weighted normalized $U_\circ^\star$ can be obtained via bootstrap.
However, it is always nice if we can come up with an exact solution for the statistic distribution or
at least provide reasonable approximations.
In this post, we start exploring this distribution.&lt;/p></description></item><item><title>Exploring the power curve of the Cucconi test</title><link>https://aakinshin.net/posts/cucconi-power/</link><pubDate>Tue, 15 Aug 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/cucconi-power/</guid><description>&lt;p>The &lt;a href="https://en.wikipedia.org/wiki/Cucconi_test">Cucconi test&lt;/a>
is a nonparametric two-sample test that compares both location and scale.
It is a classic example of the family of tests that
perform such a comparison simultaneously
instead of combining the results of a location test and a scale test.
Intuitively, such an approach should fit well unimodal distributions.
Moreover, it has the potential to outperform more generic nonparametric tests
that do not rely on the unimodality assumption.&lt;/p>
&lt;p>In this post, we briefly show the equations behind the Cucconi test and
present a power curve that compares it with the Student&amp;rsquo;s t-test and the Mann-Whitney U test under normality.&lt;/p></description></item><item><title>Parametric, Nonparametric, Robust, and Defensive statistics</title><link>https://aakinshin.net/posts/parametric-nonparametric-robust-defensive/</link><pubDate>Tue, 08 Aug 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/parametric-nonparametric-robust-defensive/</guid><description>&lt;p>Recently, I started writing about &lt;a href="https://aakinshin.net/tags/ds/">defensive statistics&lt;/a>.
The methodology allows having parametric assumptions,
but it adjusts statistical methods so that they continue working even in the case
of huge deviations from the declared assumptions.
This idea sounds quite similar to nonparametric and robust statistics.
In this post, I briefly explain the difference between different statistical methodologies.&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/parametric-nonparametric-robust-defensive/img/compare-light.png" target="_blank" alt="compare">
 &lt;img
 src="https://aakinshin.net/posts/parametric-nonparametric-robust-defensive/img/compare-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/parametric-nonparametric-robust-defensive/img/compare-dark.png" target="_blank" alt="compare">
 &lt;img
 src="https://aakinshin.net/posts/parametric-nonparametric-robust-defensive/img/compare-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div></description></item><item><title>Insidious implicit statistical assumptions</title><link>https://aakinshin.net/posts/insidious-assumptions/</link><pubDate>Tue, 01 Aug 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/insidious-assumptions/</guid><description>&lt;p>Recently, I was rereading &lt;a href="https://aakinshin.net/library/papers/hampel1986/">&lt;svg class="rating-icon">&lt;use xlink:href="https://aakinshin.net/img/fa/all.svg#paper">&lt;/use>&lt;/svg>hampel1986&lt;/a>
and I found this quote about the difference between robust and nonparametric statistics (page 9):&lt;/p>
&lt;blockquote>
&lt;p>Robust statistics considers the effects of only approximate fulfillment of assumptions,
while nonparametric statistics makes rather weak but nevertheless strict assumptions
(such as continuity of distribution or independence).&lt;/p>
&lt;/blockquote>
&lt;p>This statement may sound obvious.
Unfortunately, facts that are presumably obvious in general are not always so obvious at the moment.
When a researcher works with specific types of distributions for a long time,
the properties of these distributions may be transformed into implicit assumptions.
This implicitness can be pretty dangerous.
If an assumption is explicitly declared,
it can become a starting point for a discussion on how to handle violations of this assumption.
The implicit assumptions are hidden and
therefore conceal potential issues in cases when the collected data do not meet our expectations.&lt;/p>
&lt;p>A switch from parametric to nonparametric methods is sometimes perceived as a rejection of all assumptions.
Such a perception can be hazardous.
While the original parametric assumption is actually neglected,
many researchers continue to act like the implicit consequences of this assumption are still valid.&lt;/p>
&lt;p>Since normality is the most popular parametric assumption,
I would like to briefly discuss connected implicit assumptions
that are often perceived not as non-validated hypotheses, but as essential properties of the collected data.&lt;/p></description></item><item><title>Four main books on robust statistics</title><link>https://aakinshin.net/posts/robust-statistics-books/</link><pubDate>Tue, 25 Jul 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/robust-statistics-books/</guid><description>&lt;p>Robust statistics is a practical and pragmatic branch of statistics.
If you want to design reliable and trustworthy statistical procedures, the knowledge of robust statistics is essential.
Unfortunately, it&amp;rsquo;s a challenging topic to learn.&lt;/p>
&lt;p>In this post, I share my favorite books on robust statistics.
I cannot pick my favorite one: each book is good in its own way, and all of them complement each other.
I am returning to these books periodically to reinforce and expand my understanding of the topic.&lt;/p></description></item><item><title>Multimodal distributions and effect size</title><link>https://aakinshin.net/posts/multimodal-es/</link><pubDate>Tue, 18 Jul 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/multimodal-es/</guid><description>&lt;p>When we want to express the difference between two samples or distributions,
a popular measure family is the effect sizes based on differences between means (difference family).
When the normality assumption is satisfied, this approach works well thanks to classic measures of effect size
like Cohen&amp;rsquo;s d, Glass&amp;rsquo; Δ, or Hedges&amp;rsquo; g.
With slight deviations from normality, &lt;a href="https://aakinshin.net/posts/nonparametric-effect-size2/">robust alternatives&lt;/a> may be considered.
To build such a measure, it&amp;rsquo;s enough to upgrade classic measures by
replacing the sample mean with a robust measure of central tendency and
replacing the standard deviation with a robust measure of dispersion.
However, it might not be enough in the case of large deviations from normality.
In this post, I briefly discuss the problem of effect size evaluation in the context of multimodal distributions.&lt;/p></description></item><item><title>Unobvious limitations of R *signrank Wilcoxon Signed Rank functions</title><link>https://aakinshin.net/posts/signrank-limitations/</link><pubDate>Tue, 11 Jul 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/signrank-limitations/</guid><description>&lt;p>In R, we have functions to calculate the density, distribution function, and quantile function
of the Wilcoxon Signed Rank statistic distribution: &lt;code>dsignrank&lt;/code>, &lt;code>psignrank&lt;/code>, and &lt;code>qsignrank&lt;/code>.
All the functions use exact calculations of the target functions
(the R 4.3.1 implementation can be found &lt;a href="https://svn.r-project.org/R/tags/R-4-3-1/src/nmath/signrank.c">here&lt;/a>).
The exact approach works excellently for small sample sizes.
Unfortunately, for large sample sizes, it fails to provide the expected function values.
Out of the box, there are no alternative approximation solutions that could allow us to get reasonable results.
In this post, we investigate the limitations of these functions and
provide sample size thresholds after which we might get invalid results.&lt;/p></description></item><item><title>Weighted Mann-Whitney U test, Part 1</title><link>https://aakinshin.net/posts/wmw1/</link><pubDate>Tue, 04 Jul 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/wmw1/</guid><description>&lt;p>Previously, I have discussed how to build weighted versions of various statistical methods.
I have already covered weighted versions of
&lt;a href="https://aakinshin.net/posts/preprint-wqe/">various quantile estimators&lt;/a> and
&lt;a href="https://aakinshin.net/posts/whl/">the Hodges-Lehmann location estimator&lt;/a>.
Such methods can be useful in various tasks like the support of weighted mixture distributions or exponential smoothing.
In this post, I suggest a way to build a weighted version of the Mann-Whitney U test.&lt;/p></description></item><item><title>Joining modes of multimodal distributions</title><link>https://aakinshin.net/posts/joining-modes/</link><pubDate>Tue, 27 Jun 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/joining-modes/</guid><description>&lt;p>Multimodality of distributions is a severe issue in statistical analysis.
Comparing two multimodal distributions is a tricky challenge.
The degree of this challenge depends on the number of existing modes.
Switching from unimodal models to multimodal ones
can be a controversial decision, potentially causing more problems than solutions.
Hence, if we dare to increase the complexity of the considering models,
we should be sure that this is an essential necessity.
Even when we confidently detect a truly multimodal distribution,
a unimodal model could be an acceptable approximation if it is sufficiently close to the true distribution.
The simplicity of a unimodal model may make it preferable, even if it is less accurate.
Of course, the research goals should always be taken into account when the particular model choice is being made.&lt;/p></description></item><item><title>Understanding the pitfalls of preferring the median over the mean</title><link>https://aakinshin.net/posts/median-vs-mean/</link><pubDate>Tue, 20 Jun 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/median-vs-mean/</guid><description>&lt;p>A common task in mathematical statistics is to aggregate a set of numbers $\mathbf{x} = \{ x_1, x_2, \ldots, x_n \}$
to a single &amp;ldquo;average&amp;rdquo; value.
Such a value is usually called &lt;em>central tendency&lt;/em>.
There are multiple measures of central tendency.
The most popular one is the &lt;em>arithmetic average&lt;/em> or the &lt;em>mean&lt;/em>:&lt;/p>
$$
\overline{\mathbf{x}} = \left( x_1 + x_2 + \ldots + x_n \right) / n.
$$
&lt;p>The mean is so popular not only thanks to its simplicity but also
because it provides the best way to estimate the center of the perfect normal distribution.
Unfortunately, the mean is not a robust measure.
This means that a single extreme value $x_i$ may distort the mean estimation and
lead to a non-reproducible value that has nothing in common with the &amp;ldquo;expected&amp;rdquo; central tendency.
The actual real-life distributions are never normal.
They can be pretty close to the normal distribution, but only to a certain extent.
Even small deviations from normality may produce occasional extreme outliers,
which makes the mean an unreliable measure in the general case.&lt;/p>
&lt;p>When people discover the danger of the mean, they start looking for a more robust measure of the central tendency.
And the first obvious alternative is the sample median $\tilde{\mathbf{x}}$.
The classic sample median is easy to calculate.
First, you have to sort the sample.
If the sample size $n$ is odd, the median is the middle element in the sorted sample.
If $n$ is even, the median is the arithmetic average of the two middle elements in the sorted sample.
The median is extremely robust: it provides a reasonable estimate
even if almost half of the sample elements are corrupted.&lt;/p>
&lt;p>For symmetric distributions (including the normal one), the true values of the mean and the median are the same.
Once we discover the high robustness of the median, it may be tempting to always use the median instead of the mean.
The median is often perceived as &amp;ldquo;something like the mean but with high resistance to outliers.&amp;rdquo;
Indeed, what is the point of using the unreliable mean, if the median always provides a safer choice?
Should we make the median our default option for the central tendency?&lt;/p>
&lt;p>The answer is no.
You should beware of any default options in mathematical statistics.
All the measures are just tools, and each tool has its limitations and areas of applicability.
A mindless transition from the mean to the median, regardless of the underlying distribution, is not a smart move.
When we are picking a measure of central tendency to use,
the first step should be reviewing the research goals:
why do we need a measure of central tendency, and what are we going to do with the result?
It&amp;rsquo;s impossible to make a rational decision on the statistical methods used without a clear understanding of the goals.
Next, we should match the goals to the properties of available measures.&lt;/p>
&lt;p>There are multiple practical issues with the median,
but the most noticeable problem in practice is about its &lt;em>statistical efficiency&lt;/em>.
Understanding this problem reveals the price of advanced robustness of the median.
In this post, we discuss the concept of statistical efficiency,
estimate the statistical efficiency of the mean and the median under different distributions,
and consider the Hodges-Lehman estimator as a measure of central tendency
that provides a better trade-off between robustness and efficiency.&lt;/p></description></item><item><title>Introducing the defensive statistics</title><link>https://aakinshin.net/posts/defensive-statistics-intro/</link><pubDate>Tue, 13 Jun 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/defensive-statistics-intro/</guid><description>&lt;blockquote>
&lt;p>Normal or approximately normal subjects are less useful objects of research than their pathological counterparts.&lt;/p>
&lt;p>&amp;mdash; Sigmund Freud, &amp;ldquo;The Psychopathology of Everyday Life&amp;rdquo;&lt;/p>
&lt;/blockquote>
&lt;p>In the realm of software development, reliability is crucial.
This is especially true when creating systems
that automatically analyze performance measurements to maintain optimal application performance.
To achieve the desired level of reliability, we need a set of statistical approaches
that provide accurate and trustworthy results.
These approaches must work even when faced with varying input data sets and multiple violated assumptions,
including malformed and corrupted values.
In this blog post, I introduce &amp;ldquo;Defensive Statistics&amp;rdquo; as an appropriate methodology for tackling this challenge.&lt;/p></description></item><item><title>Edgeworth expansion for the Mann-Whitney U test, Part 2: increased accuracy</title><link>https://aakinshin.net/posts/mw-edgeworth2/</link><pubDate>Tue, 06 Jun 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/mw-edgeworth2/</guid><description>&lt;p>In the &lt;a href="https://aakinshin.net/posts/mw-edgeworth/">previous post&lt;/a>,
we showed how the Edgeworth expansion can improve the accuracy of obtained p-values in the Mann-Whitney U test.
However, we considered only the Edgeworth expansion to terms of order $1/m$.
In this post, we explore how to improve the accuracyk of this approach using
the Edgeworth expansion to terms of order $1/m^2$.&lt;/p></description></item><item><title>Edgeworth expansion for the Mann-Whitney U test</title><link>https://aakinshin.net/posts/mw-edgeworth/</link><pubDate>Tue, 30 May 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/mw-edgeworth/</guid><description>&lt;p>In &lt;a href="https://aakinshin.net/posts/r-mann-whitney-incorrect-p-value/">previous posts&lt;/a>,
I have shown a severe drawback of the classic Normal approximation for the Mann-Whitney U test:
under certain conditions, can lead to quite substantial p-value errors,
distorting the significance level of the test.&lt;/p>
&lt;p>In this post, we will explore the potential of the Edgeworth expansion
as a more accurate alternative for approximating the distribution of the Mann-Whitney U statistic.&lt;/p></description></item><item><title>Confusing tie correction in the classic Mann-Whitney U test implementation</title><link>https://aakinshin.net/posts/mw-confusing-tie-correction/</link><pubDate>Tue, 23 May 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/mw-confusing-tie-correction/</guid><description>&lt;p>In this post, we discuss the classic implementation of the Mann-Whitney U test for cases
in which the considered samples contain tied values.
This approach is used the same way in all the popular statistical packages.&lt;/p>
&lt;p>Unfortunately, in some situations, this approach produces confusing p-values, which may be surprising for researchers
who do not have a deep understanding of ties correction.
Moreover, some statistical textbooks argue against the validity of the default tie correction.
The controversialness and counterintuitiveness of this approach may become a severe issue which may lead
to incorrect experiment design and flawed result interpretation.
In order to prevent such problems, it is essential to clearly understand
the actual impact of tied observations on the true p-value and
the impact of tie correction on the approximated p-value estimation.
In this post, we discuss the tie correction for the Mann-Whitney U test
and review examples that illustrate potential problems.
We also provide examples of the Mann-Whitney U test implementations from popular statistical packages:
&lt;code>wilcox.test&lt;/code> from &lt;code>stats&lt;/code> (R),
&lt;code>mannwhitneyu&lt;/code> from &lt;code>SciPy&lt;/code> (Python), and
&lt;code>MannWhitneyUTest&lt;/code> from &lt;code>HypothesisTests&lt;/code> (Julia).
At the end of the post, we discuss how to avoid possible problems related to the tie correction.&lt;/p></description></item><item><title>Efficiency of the central tendency measures under the uniform distribution</title><link>https://aakinshin.net/posts/central-tendency-efficiency-uniform/</link><pubDate>Tue, 16 May 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/central-tendency-efficiency-uniform/</guid><description>&lt;p>Statistical efficiency is one of the primary ways to compare various estimators.
Since the normality assumption is often used, Gaussian efficiency (efficiency under the normality distribution)
is typically considered.
For example, the asymptotic Gaussian efficiency values of
the median and the Hodges-Lehmann location estimator (the pseudo-median)
are $\approx 64\%$ and $\approx 96\%$ respectively (assuming the baseline is the mean).&lt;/p>
&lt;p>But what if the underlying distribution is not normal, but uniform?
What would happen to the relative statistical efficiency values in this case?
Let&amp;rsquo;s find out!
In this post, we calculate
the relative efficiency of the median, the Hodges-Lehmann location estimator, and the midrange
to the mean under the uniform distribution (or under uniformity).&lt;/p></description></item><item><title>Unobvious problems of using the R's implementation of the Hodges-Lehmann estimator</title><link>https://aakinshin.net/posts/r-hodges-lehmann-problems/</link><pubDate>Tue, 09 May 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/r-hodges-lehmann-problems/</guid><description>&lt;p>The Hodges-Lehmann location estimator (also known as pseudo-median) is a robust, non-parametric statistic
used as a measure of the central tendency.
For a sample $\mathbf{x} = \{ x_1, x_2, \ldots, x_n \}$, it is defined as follows:&lt;/p>
$$
\operatorname{HL}(\mathbf{x}) =
 \underset{1 \leq i \leq j \leq n}{\operatorname{median}} \left(\frac{x_i + x_j}{2} \right).
$$
&lt;p>Essentially, it&amp;rsquo;s the median of the Walsh (pairwise) averages.&lt;/p>
&lt;p>For two samples $\mathbf{x} = \{ x_1, x_2, \ldots, x_n \}$ and $\mathbf{y} = \{ y_1, y_2, \ldots, y_m \}$,
we can also consider the Hodges-Lehmann location shift estimator:&lt;/p>
$$
\operatorname{HL}(\mathbf{x}, \mathbf{y}) =
 \underset{1 \leq i \leq n,\,\, 1 \leq j \leq m}{\operatorname{median}} \left(x_i - y_j \right).
$$
&lt;p>In R, both estimators are available via
the &lt;a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html">wilcox.test&lt;/a> function.
Here is a usage example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="line">&lt;span class="cl">&lt;span class="nf">set.seed&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="m">1729&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">x&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">rnorm&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="m">2000&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">5&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># A sample of size 2000 from the normal distribution N(5, 1)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">y&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">rnorm&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="m">2000&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">2&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># A sample of size 2000 from the normal distribution N(2, 1)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">wilcox.test&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">conf.int&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">TRUE&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="n">estimate&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># (pseudo)median&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 5.000984&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">wilcox.test&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">y&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">conf.int&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">TRUE&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="n">estimate&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># (pseudo)median&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 1.969096&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">wilcox.test&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">conf.int&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">TRUE&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="n">estimate&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># difference in location&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 3.031782&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In most cases, this function works fine.
However, there is an unobvious corner case, in which it returns wrong values.
In this post, we discuss the underlying problem and provide a correct implementation for the Hodges-Lehmann estimators.&lt;/p></description></item><item><title>When Python's Mann-Whitney U test returns extremely distorted p-values</title><link>https://aakinshin.net/posts/python-mann-whitney-incorrect-p-value/</link><pubDate>Tue, 02 May 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/python-mann-whitney-incorrect-p-value/</guid><description>&lt;p>In the &lt;a href="https://aakinshin.net/posts/r-mann-whitney-incorrect-p-value/">previous post&lt;/a>,
I have discussed a huge difference between p-values evaluated via the R implementation of
the &lt;a href="https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test">Mann-Whitney U test&lt;/a>
between the exact and asymptotic implementations.
This issue is not unique only to R, it is relevant for other statistical packages in other languages as well.
In this post, we review this problem in the Python package &lt;a href="https://scipy.org/">SciPy&lt;/a>.&lt;/p></description></item><item><title>When R's Mann-Whitney U test returns extremely distorted p-values</title><link>https://aakinshin.net/posts/r-mann-whitney-incorrect-p-value/</link><pubDate>Tue, 25 Apr 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/r-mann-whitney-incorrect-p-value/</guid><description>&lt;p>The &lt;a href="https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test">Mann–Whitney U test&lt;/a>
(also known as the Wilcoxon rank-sum test)
is one of the most popular nonparametric statistical tests.
In R, it can be accessed using
the &lt;a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html">wilcox.test&lt;/a> function,
which has been &lt;a href="https://github.com/wch/r-source/blob/tags/R-1-0/src/library/ctest/R/wilcox.test.R">available&lt;/a>
since R 1.0.0 (February 2000).
With its extensive adoption and long-standing presence in R,
the &lt;code>wilcox.test&lt;/code> function has become a trusted tool for many researchers.
But is it truly reliable, and to what extent can we rely on its accuracy by default?&lt;/p>
&lt;p>In my work,
I often encounter the task of comparing a large sample (e.g., of size 50+) with a small sample (e.g., of size 5).
In some cases, the ranges of these samples do not overlap with each other,
which is the extreme case of the Mann–Whitney U test: it gives the minimum possible p-value.
In &lt;a href="https://aakinshin.net/posts/mann-whitney-min-stat-level/">one of the previous posts&lt;/a>,
I presented the exact equation for such a p-value.
If we compare two samples of sizes $n$ and $m$,
the minimum p-value we can observe with the one-tailed Mann–Whitney U test is $1/C_{n+m}^n$.
For example, if $n=50$ and $m=5$, we get $1/C_{55}^5 \approx 0.0000002874587$.
Let&amp;rsquo;s check these calculations using R:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">wilcox.test&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="m">101&lt;/span>&lt;span class="o">:&lt;/span>&lt;span class="m">105&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">1&lt;/span>&lt;span class="o">:&lt;/span>&lt;span class="m">50&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">alternative&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;greater&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="n">p.value&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">[1]&lt;/span> &lt;span class="m">0.0001337028&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The obtained p-value is $\approx 0.0001337028$, which is $\approx 465$ times larger than we expected!
Have we discovered a critical bug in &lt;code>wilcox.test&lt;/code>?
Can we now trust this function?
Let&amp;rsquo;s find out!&lt;/p></description></item><item><title>Preprint announcement: 'Weighted quantile estimators'</title><link>https://aakinshin.net/posts/preprint-wqe/</link><pubDate>Tue, 18 Apr 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/preprint-wqe/</guid><description>&lt;p>I have just published a preprint of a paper &amp;lsquo;Weighted quantile estimators&amp;rsquo;.
It&amp;rsquo;s based on a series of my &lt;a href="https://aakinshin.net/tags/research-wqe/">research notes&lt;/a> that I have been writing since September 2020.&lt;/p>
&lt;p>The paper preprint is available on arXiv:
&lt;a href="https://arxiv.org/abs/2304.07265">arXiv:2304.07265 [stat.ME]&lt;/a>.
The paper source code is available on GitHub:
&lt;a href="https://github.com/AndreyAkinshin/paper-wqe">AndreyAkinshin/paper-wqe&lt;/a>.
You can cite it as follows:&lt;/p>
&lt;ul>
&lt;li>Andrey Akinshin (2023)
&amp;ldquo;Weighted quantile estimators&amp;rdquo;
&lt;a href="https://arxiv.org/abs/2304.07265">arXiv:2304.07265&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Abstract:&lt;/p>
&lt;blockquote>
&lt;p>In this paper, we consider a generic scheme that allows building weighted versions of various quantile estimators,
such as traditional quantile estimators based on linear interpolation of two order statistics,
the Harrell-Davis quantile estimator and its trimmed modification.
The obtained weighted quantile estimators are especially useful
in the problem of estimating a distribution at the tail of a time series using quantile exponential smoothing.
The presented approach can also be applied to other problems,
such as quantile estimation of weighted mixture distributions.&lt;/p>
&lt;/blockquote></description></item><item><title>Rethinking Type I/II error rates with power curves</title><link>https://aakinshin.net/posts/rethinking-type-i-ii-errors/</link><pubDate>Tue, 11 Apr 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/rethinking-type-i-ii-errors/</guid><description>&lt;p>When it comes to the analysis of a statistical significance test design,
many people tend to overfocus purely on the Type I error rate.
Those who are aware of the importance of power analysis
often stop at expressing the Type II error rate as a single number.
It is better than nothing, but such an approach always confuses me.&lt;/p>
&lt;p>Let us say that the declared Type II error rate is 20% (or the declared statistical power is 80%).
What does it actually mean?
If the sample size and the significance level (or any other significance criteria) are given,
the Type II error rate is a function of the effect size.
When we express the Type II error rate as a single number,
we always (implicitly or explicitly) assume the target effect size.
In most cases, it is an arbitrary number
that is somehow chosen to reflect our expectations of the &amp;ldquo;reasonable&amp;rdquo; effect size.
However, the actual Type II error rate and the corresponding statistical power
depend on the actual effect size that we do not know.
Some researchers estimate the Type II error rate / statistical power using the measured effect size,
but it does not make a lot of sense since
it does not provide new information in addition to the measured effect size or p-value.
In reality, we have high statistical power (low Type II error rate) for large effect sizes
and low statistical power (high Type II error rate) for small effect sizes.
Without the knowledge of the actual effect size (which we do not have),
the Type II error rate expressed as a single number mostly describes this arbitrarily chosen expected effect size,
rather than the actual properties of our statistical test.&lt;/p></description></item><item><title>Adaptation of continuous scale measures to discrete distributions</title><link>https://aakinshin.net/posts/scale-measure-for-discrete-case/</link><pubDate>Tue, 04 Apr 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/scale-measure-for-discrete-case/</guid><description>&lt;p>In statistics, it is often important to have a reliable measure of scale
since it is required for estimating many types of the effect size and for statistical tests.
If we work with continuous distributions,
there are plenty of available scale measures with various levels of statistical efficiency and robustness.
However, when distribution becomes discrete (e.g. because of the limited resolution of the measure tools),
classic measures of scale can collapse to zero due to tied values in collected samples.
This can be a severe problem in the analysis
since the scale measures are often used as denominators in various equations.
To make the calculations more reliable,
it is important to handle such situations somehow and ensure that the target scale measure never becomes zero.
In this post,
I discuss a simple approach to work around this problem and adapt any given measure of scale to the discrete case.&lt;/p></description></item><item><title>Weighted modification of the Hodges-Lehmann location estimator</title><link>https://aakinshin.net/posts/whl/</link><pubDate>Tue, 28 Mar 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/whl/</guid><description>&lt;p>The classic Hodges-Lehmann location estimator is a robust, non-parametric statistic
used as a measure of the central tendency.
For a sample $\mathbf{x} = \{ x_1, x_2, \ldots, x_n \}$, it is defined as follows:&lt;/p>
$$
\operatorname{HL}(\mathbf{x}) = \underset{1 \leq i &lt; j \leq n}{\operatorname{median}} \left(\frac{x_i + x_j}{2} \right).
$$
&lt;p>This estimator works great for non-weighted samples
(its asymptotic Gaussian efficiency is $\approx 96\%$, and its asymptotic breakdown point is $\approx 29\%$).
However, in real-world applications, data points may have varying importance or relevance.
For example, in finance, different stocks may have different market capitalizations,
which can impact the overall performance of an index.
In social science research, survey responses may be weighted
based on demographic representation to ensure that the final results are more generalizable.
In software performance measurements, the observations may be collected from different source code revisions,
some of which may be obsolete.
In these cases, the classic $\operatorname{HL}$-measure is not suitable, as it treats each data point equally.&lt;/p>
&lt;p>We can overcome this problem using weighted samples to obtain more accurate and meaningful central tendency estimates.
Unfortunately, there is no well-established definition of the weighted Hodges-Lehmann location estimator.
In this blog post, we introduce such a definition so that we can apply this estimator to weighted samples
keeping it compatible with the original version.&lt;/p></description></item><item><title>Performance stability of GitHub Actions</title><link>https://aakinshin.net/posts/github-actions-perf-stability/</link><pubDate>Tue, 21 Mar 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/github-actions-perf-stability/</guid><description>&lt;p>Nowadays, &lt;a href="https://github.com/features/actions">GitHub Actions&lt;/a> is one of the most popular free CI systems.
It&amp;rsquo;s quite convenient to use it to run unit and integration tests.
However, some developers try to use it to run benchmarks and performance tests.
Unfortunately, default GitHub Actions build agents do not provide
a consistent execution environment from the performance point of view.
Therefore, performance measurements from different builds can not be compared.
This makes it almost impossible to set up reliable performance tests based
on the default GitHub Actions build agent pool.&lt;/p>
&lt;p>So, it&amp;rsquo;s expected that the execution environments are not &lt;em>absolutely&lt;/em> identical.
But how bad is the situation?
What&amp;rsquo;s the maximum difference between performance measurements from different builds?
Is there a chance that we can play with thresholds and
utilize GitHub Actions to detect at least major performance degradations?
Let&amp;rsquo;s find out!&lt;/p></description></item><item><title>p-value distribution of the Brunner–Munzel test in the finite case</title><link>https://aakinshin.net/posts/brunner-munzel-pvalue-distribution/</link><pubDate>Tue, 14 Mar 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/brunner-munzel-pvalue-distribution/</guid><description>&lt;p>In our of the previous post, I explored the
&lt;a href="https://aakinshin.net/posts/mann-whitney-pvalue-distribution/">distribution of observed p-values for the Mann–Whitney U test&lt;/a>
in the finite case when the null hypothesis is true.
It is time to repeat the experiment for the Brunner–Munzel test.&lt;/p></description></item><item><title>Comparing statistical power of the Mann-Whitney U test and the Brunner-Munzel test</title><link>https://aakinshin.net/posts/power-mw-bm/</link><pubDate>Tue, 07 Mar 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/power-mw-bm/</guid><description>&lt;p>In this post, we perform a short numerical simulation to compare the statistical power
of the Mann-Whitney U test and the Brunner-Munzel test under normality
for various sample sizes and significance levels.&lt;/p></description></item><item><title>p-value distribution of the Mann–Whitney U test in the finite case</title><link>https://aakinshin.net/posts/mann-whitney-pvalue-distribution/</link><pubDate>Tue, 28 Feb 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/mann-whitney-pvalue-distribution/</guid><description>&lt;p>When we work with null hypothesis significance testing and the null hypothesis is true,
the distribution of observed p-value is asymptotically uniform.
However, the distribution shape is not always uniform in the finite case.
For example, when we work with rank-based tests like the Mann–Whitney U test,
the distribution of the p-values is discrete with a limited set of possible values.
This should be taken into account when we design a testing procedure for small samples
and choose the significance level.&lt;/p>
&lt;p>Previously, we already discussed the &lt;a href="https://aakinshin.net/posts/mann-whitney-min-stat-level/">minimum reasonable significance level&lt;/a>
of the Mann-Whitney U test for small samples.
In this post, we explore the full distribution of the p-values for this case.&lt;/p></description></item><item><title>Corner case of the Brunner–Munzel test</title><link>https://aakinshin.net/posts/brunner-munzel-corner-case/</link><pubDate>Tue, 21 Feb 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/brunner-munzel-corner-case/</guid><description>&lt;p>The Brunner–Munzel test is a nonparametric significance test,
which can be considered an alternative to the Mann–Whitney U test.
However, the Brunner–Munzel test has a corner case
that can cause some practical issues with applying this test to real data.
In this post, I briefly discuss the test itself and the corresponding corner case.&lt;/p></description></item><item><title>Examples of the Mann–Whitney U test misuse cases</title><link>https://aakinshin.net/posts/mann-whitney-misuse/</link><pubDate>Tue, 14 Feb 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/mann-whitney-misuse/</guid><description>&lt;p>The Mann–Whitney U test is one of the most popular nonparametric statistical tests.
Its alternative hypothesis claims that one distribution is stochastically greater than the other.
However, people often misuse this test and try to apply it to check
if two nonparametric distributions are not identical
or that there is a difference in distribution medians
(while there are no additional assumptions on the shapes of the distributions).
In this post, I show several cases in which the Mann–Whitney U test is not applicable
for comparing two distributions.&lt;/p></description></item><item><title>Types of finite-sample consistency with the standard deviation</title><link>https://aakinshin.net/posts/sd-consistency-types/</link><pubDate>Tue, 07 Feb 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/sd-consistency-types/</guid><description>&lt;p>Let us say we have a robust dispersion estimator $\operatorname{T}(X)$.
If it is asymptotically consistent with the standard deviation,
we can use such an estimator as a robust replacement for the standard deviation under normality.
Thanks to asymptotical consistency, we can use the estimator &amp;ldquo;as is&amp;rdquo; for large samples.
However, if the number of sample elements is small,
we typically need finite-sample bias-correction factors to make the estimator unbiased.
Here we should clearly understand what kind of consistency we need.&lt;/p>
&lt;p>There are various ways to estimate the standard deviation.
Let us consider a sample of random variables $X = \{ X_1, X_2, \ldots, X_n \}$.
The most popular equation of the standard deviation is given by&lt;/p>
$$
s(X) = \sqrt{\frac{1}{n - 1} \sum_{i=1}^n (X_i - \overline{X})^2}.
$$
&lt;p>Using this definition, we can get an unbiased estimator for the population variance: $\mathbb{E}[s^2(X)] = 1$.
However, it is a biased estimator for the population standard deviation: $\mathbb{E}[s(X)] \neq 1$.
To obtain to corresponding unbiased estimator, we should use $s(\mathbf{x}) \cdot c_4(n)$,
where $c_4(n)$ is a correction factor defined as follows:&lt;/p>
$$
c_4(n) = \sqrt{\frac{2}{n-1}} \cdot \frac{\Gamma\left(\frac{n}{2}\right)}{\Gamma\left(\frac{n-1}{2}\right)}.
$$
&lt;p>When we define finite-sample bias-correction factors for a robust standard deviation replacement,
we should choose which kind of consistency we need.
In this post, I briefly explore available options.&lt;/p></description></item><item><title>Nonparametric effect size: Cohen's d vs. Glass's delta</title><link>https://aakinshin.net/posts/gamma-es-cohen-glass/</link><pubDate>Tue, 24 Jan 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/gamma-es-cohen-glass/</guid><description>&lt;p>In the &lt;a href="https://aakinshin.net/tags/research-gamma-es/">previous posts&lt;/a>,
I discussed the idea of nonparametric effect size measures
consistent with Cohen&amp;rsquo;s d under normality.
However, Cohen&amp;rsquo;s d is not always the best effect size measure, even in the normal case.&lt;/p>
&lt;p>In this post, we briefly discuss a case study in which a nonparametric version of Glass&amp;rsquo;s delta is preferable
than the &lt;a href="https://aakinshin.net/posts/nonparametric-effect-size/">previously suggested&lt;/a> Cohen&amp;rsquo;s d-consistent measure.&lt;/p></description></item><item><title>Trinal statistical thresholds</title><link>https://aakinshin.net/posts/trinal-thresholds/</link><pubDate>Tue, 17 Jan 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/trinal-thresholds/</guid><description>&lt;p>When we design a test for practical significance, which compares two samples,
we should somehow express the threshold.
The most popular options are the shift, the ratio, and the effect size.
Unfortunately, if we have little information about the underlying distributions,
it&amp;rsquo;s hard to get a reliable test based only on a single threshold.
And it&amp;rsquo;s almost impossible to define a generic threshold that fits all situations.
After struggling with a lot of different thresholding approaches,
I came up with the idea of setting a trinal threshold
that includes three individual thresholds for the shift, the ratio, and the effect size.&lt;/p>
&lt;p>In this post, I show some examples in which a single threshold is not enough.&lt;/p></description></item><item><title>Trimmed Hodges-Lehmann location estimator, Part 2: Gaussian efficiency</title><link>https://aakinshin.net/posts/thl-ge/</link><pubDate>Tue, 10 Jan 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/thl-ge/</guid><description>&lt;p>In the &lt;a href="https://aakinshin.net/posts/thl-bp/">previous post&lt;/a>, we introduced
the trimmed Hodges-Lehman location estimator.
For a sample $\mathbf{x} = \{ x_1, x_2, \ldots, x_n \}$,
it is defined as follows:&lt;/p>
$$
\operatorname{THL}(\mathbf{x}, k) = \underset{k &lt; i &lt; j \leq n - k}{\operatorname{median}}\biggl(\frac{x_{(i)} + x_{(j)}}{2}\biggr).
$$
&lt;p>We also derived the exact expression for its asymptotic and finite-sample breakdown point values.
In this post, we explore its Gaussian efficiency.&lt;/p></description></item><item><title>Trimmed Hodges-Lehmann location estimator, Part 1: breakdown point</title><link>https://aakinshin.net/posts/thl-bp/</link><pubDate>Tue, 03 Jan 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/thl-bp/</guid><description>&lt;p>For a sample $\mathbf{x} = \{ x_1, x_2, \ldots, x_n \}$,
the Hodges-Lehmann location estimator is defined as follows:&lt;/p>
$$
\operatorname{HL}(\mathbf{x}) =
 \underset{i &lt; j}{\operatorname{median}}\biggl(\frac{x_i + x_j}{2}\biggr).
$$
&lt;p>Its asymptotic Gaussian efficiency is $\approx 96\%$,
while its asymptotic breakdown point is $\approx 29\%$.
This makes the Hodges-Lehmann location estimator a decent robust alternative to the mean.&lt;/p>
&lt;p>While the Gaussian efficiency is quite impressive (almost as efficient as the mean),
the breakdown point is not as great as in the case of the median (which has a breakdown point of $50\%$).
Could we change this trade-off a little bit and make this estimator more robust,
sacrificing a small portion of efficiency?
Yes, we can!&lt;/p>
&lt;p>In this post, I want to present the idea of the trimmed Hodges-Lehmann location estimator
and provide the exact equation for its breakdown point.&lt;/p></description></item><item><title>Median of the shifts vs. shift of the medians, Part 2: Gaussian efficiency</title><link>https://aakinshin.net/posts/median-shift-vs-shift-median2/</link><pubDate>Tue, 27 Dec 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/median-shift-vs-shift-median2/</guid><description>&lt;p>In the &lt;a href="https://aakinshin.net/posts/median-shift-vs-shift-median1/">previous post&lt;/a>,
we discussed the difference between shifts of the medians
and the Hodges-Lehmann location shift estimator.
In this post, we conduct a simple numerical simulation
to evaluate the Gaussian efficiency of these two estimators.&lt;/p></description></item><item><title>Median of the shifts vs. shift of the medians, Part 1</title><link>https://aakinshin.net/posts/median-shift-vs-shift-median1/</link><pubDate>Tue, 20 Dec 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/median-shift-vs-shift-median1/</guid><description>&lt;p>Let us say that we have two samples
$x = \{ x_1, x_2, \ldots, x_n \}$,
$y = \{ y_1, y_2, \ldots, y_m \}$,
and we want to estimate the shift of locations between them.
In the case of the normal distribution, this task is quite simple
and has a lot of straightforward solutions.
However, in the nonparametric case, the location shift is an ambiguous metric
which heavily depends on the chosen estimator.
In the context of this post, we consider two approaches that may look similar.
The first one is the &lt;strong>s&lt;/strong>hift of the &lt;strong>m&lt;/strong>edians:&lt;/p>
$$
\newcommand{\DSM}{\Delta_{\operatorname{SM}}}
\DSM = \operatorname{median}(y) - \operatorname{median}(x).
$$
&lt;p>The second one of the median of all pairwise shifts,
also known as the &lt;strong>H&lt;/strong>odges-&lt;strong>L&lt;/strong>ehmann location shift estimator:&lt;/p>
$$
\newcommand{\DHL}{\Delta_{\operatorname{HL}}}
\DHL = \operatorname{median}(y_j - x_i).
$$
&lt;p>In the case of the normal distributions, these estimators are consistent.
However, this post will show an example of multimodal distributions
that lead to opposite signs of $\DSM$ and $\DHL$.&lt;/p></description></item><item><title>Resistance to the low-density regions: the Hodges-Lehmann location estimator</title><link>https://aakinshin.net/posts/rldr-hl/</link><pubDate>Tue, 13 Dec 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/rldr-hl/</guid><description>&lt;p>In the previous posts, I discussed the concept of a resistance function
that shows the sensitivity of the given estimator to the low-density regions.
I already showed how this function behaves for &lt;a href="https://aakinshin.net/posts/rldr-mean-median/">the mean, the sample median&lt;/a>,
and &lt;a href="https://aakinshin.net/posts/rldr-hdmedian/">the Harrell-Davis median&lt;/a>.
In this post, I explore this function for the Hodges-Lehmann location estimator.&lt;/p></description></item><item><title>Kernel density estimation boundary correction: reflection (ggplot2 v3.4.0)</title><link>https://aakinshin.net/posts/kde-bc-reflection/</link><pubDate>Tue, 06 Dec 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/kde-bc-reflection/</guid><description>&lt;p>Kernel density estimation (KDE) is a popular way to approximate a distribution based on the given data.
However, it has several flaws.
One of the most significant flaws is that it extends the support of the distribution.
It is pretty unfortunate: even if we know the actual range of supported values,
KDE provides non-zero density values for the regions where no values exist.
It is obviously an inaccurate estimation.
The procedure of adjusting the KDE values according to the given boundaries is known as &lt;em>boundary correction&lt;/em>.
As usual, there are plenty of available boundary correction strategies.&lt;/p>
&lt;p>One such strategy was implemented in the
&lt;a href="https://www.tidyverse.org/blog/2022/11/ggplot2-3-4-0/#bounded-density-estimation">v3.4.0 update&lt;/a> of
&lt;a href="https://ggplot2.tidyverse.org/">ggplot2&lt;/a> (a popular R package for plotting)
thanks to &lt;a href="https://github.com/tidyverse/ggplot2/pull/4013/">pull request #4013&lt;/a>.
At the present moment, it supports a single boundary correction strategy called &lt;em>reflection&lt;/em>.
In this post, we discuss this approach and see how it works in practice.&lt;/p></description></item><item><title>Sheather &amp; Jones vs. unbiased cross-validation</title><link>https://aakinshin.net/posts/sj-vs-ucv/</link><pubDate>Tue, 29 Nov 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/sj-vs-ucv/</guid><description>&lt;p>In the post about &lt;a href="https://aakinshin.net/posts/kde-bw/">the importance of kernel density estimation bandwidth&lt;/a>,
I reviewed several bandwidth selectors and showed their impact on the KDE.
The classic selectors like Scott&amp;rsquo;s rule of thumb or Silverman&amp;rsquo;s rule of thumb are designed for the normal distribution
and perform purely in non-parametric cases.
One of the most significant caveats is that they can mask multimodality.
The same problem is also relevant to the biased cross-validation method.
Among all the bandwidth selectors
&lt;a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/bandwidth.html">available in R&lt;/a>,
only Sheather &amp;amp; Jones and unbiased cross-validation provide reliable results in the multimodal case.
However, I always advocate using the Sheather &amp;amp; Jones method rather than the unbiased cross-validation approach.&lt;/p>
&lt;p>In this post, I will show the drawbacks of the unbiased cross-validation method
and what kind of problems we can get if we use it as a KDE bandwidth selector.&lt;/p></description></item><item><title>Resistance to the low-density regions: the Harrell-Davis median</title><link>https://aakinshin.net/posts/rldr-hdmedian/</link><pubDate>Tue, 22 Nov 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/rldr-hdmedian/</guid><description>&lt;p>In the &lt;a href="https://aakinshin.net/posts/rldr-mean-median/">previous post&lt;/a>,
we defined the resistance function that show sensitivity of the given estimator
to the low-density regions.
We also showed the resistance function plots for the mean and the sample median.
In this post, we explore corresponding plots for the Harrell-Davis median.&lt;/p></description></item><item><title>Resistance to the low-density regions: the mean and the median</title><link>https://aakinshin.net/posts/rldr-mean-median/</link><pubDate>Tue, 15 Nov 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/rldr-mean-median/</guid><description>&lt;p>When we discuss resistant statistics, we typically assume resistance to extreme values.
However, extreme values are not the only problem source
that can violate usual assumptions about expected metric distribution.
The low-density regions which often arise in multimodal distributions
can also corrupt the results of the statistical analysis.
In this post, I discuss this problem and introduce a measure of resistance to low-density regions.&lt;/p></description></item><item><title>Finite-sample Gaussian efficiency of the trimmed Harrell-Davis median estimator</title><link>https://aakinshin.net/posts/thd-ge/</link><pubDate>Tue, 08 Nov 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/thd-ge/</guid><description>&lt;p>In the &lt;a href="https://aakinshin.net/posts/hd-ge/">previous post&lt;/a>,
we obtained the finite-sample Gaussian efficiency values
of the sample median and the Harrell-Davis median.
In this post, we extended these results
and get the finite-sample Gaussian efficiency values
of the &lt;a href="https://aakinshin.net/posts/pub-thdqe/">trimmed Harrell-Davis median estimator based on the highest density interval of the width $1/\sqrt{n}$&lt;/a>.&lt;/p></description></item><item><title>Finite-sample Gaussian efficiency of the Harrell-Davis median estimator</title><link>https://aakinshin.net/posts/hd-ge/</link><pubDate>Tue, 01 Nov 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/hd-ge/</guid><description>&lt;p>In this post, we explore finite-sample and asymptotic Gaussian efficiency values
of the sample median and the Harrell-Davis median.&lt;/p></description></item><item><title>Weighted quantile estimation for a weighted mixture distribution</title><link>https://aakinshin.net/posts/wqe-mixture/</link><pubDate>Tue, 25 Oct 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/wqe-mixture/</guid><description>&lt;p>Let $\mathbf{x} = \{ x_1, x_2, \ldots, x_n \}$ be a sample of size $n$.
We assign non-negative weight coefficients $w_i$ with a positive sum for all sample elements:&lt;/p>
$$
\mathbf{w} = \{ w_1, w_2, \ldots, w_n \}, \quad w_i \geq 0, \quad \sum_{i=1}^{n} w_i > 0.
$$
&lt;p>For simplification, we also consider normalized (standardized) weights $\overline{\mathbf{w}}$:&lt;/p>
$$
\overline{\mathbf{w}} = \{ \overline{w}_1, \overline{w}_2, \ldots, \overline{w}_n \}, \quad
 \overline{w}_i = \frac{w_i}{\sum_{i=1}^{n} w_i}.
$$
&lt;p>In the non-weighted case, we can consider a quantile estimator $\operatorname{Q}(\mathbf{x}, p)$
that estimates the $p^\textrm{th}$ quantile of the underlying distribution.
We want to build a weighted quantile estimator $\operatorname{Q}(\mathbf{x}, \mathbf{w}, p)$
so that we can estimate the quantiles of a weighed sample.&lt;/p>
&lt;p>In this post, we consider a specific problem of estimating quantiles of a weighted mixture distribution.&lt;/p></description></item><item><title>Preprint announcement: 'Finite-sample Rousseeuw-Croux scale estimators'</title><link>https://aakinshin.net/posts/preprint-frc/</link><pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/preprint-frc/</guid><description>&lt;p>Recently, I published a preprint of a paper &amp;lsquo;Finite-sample Rousseeuw-Croux scale estimators&amp;rsquo;.
It&amp;rsquo;s based on a series of my &lt;a href="https://aakinshin.net/tags/research-frc/">research notes&lt;/a>.&lt;/p>
&lt;p>The paper preprint is available on arXiv:
&lt;a href="https://arxiv.org/abs/2209.12268">arXiv:2209.12268 [stat.ME]&lt;/a>.
The paper source code is available on GitHub:
&lt;a href="https://github.com/AndreyAkinshin/paper-frc">AndreyAkinshin/paper-frc&lt;/a>.
You can cite it as follows:&lt;/p>
&lt;ul>
&lt;li>Andrey Akinshin (2022)
&amp;ldquo;Finite-sample Rousseeuw-Croux scale estimators&amp;rdquo;
&lt;a href="https://arxiv.org/abs/2209.12268">arXiv:2209.12268&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Abstract:&lt;/p>
&lt;blockquote>
&lt;p>The Rousseeuw-Croux $S_n$, $Q_n$ scale estimators and the median absolute deviation $\operatorname{MAD}_n$
can be used as consistent estimators for the standard deviation under normality.
All of them are highly robust: the breakdown point of all three estimators is $50\%$.
However, $S_n$ and $Q_n$ are much more efficient than $\operatorname{MAD}_n$:
their asymptotic Gaussian efficiency values are $58\%$ and $82\%$ respectively
compared to $37\%$ for $\operatorname{MAD}_n$.
Although these values look impressive, they are only asymptotic values.
The actual Gaussian efficiency of $S_n$ and $Q_n$ for small sample sizes
is noticeably lower than in the asymptotic case.&lt;/p>
&lt;p>The original work by Rousseeuw and Croux (1993)
provides only rough approximations of the finite-sample bias-correction factors for $S_n,\, Q_n$
and brief notes on their finite-sample efficiency values.
In this paper, we perform extensive Monte-Carlo simulations in order to obtain refined values of the
finite-sample properties of the Rousseeuw-Croux scale estimators.
We present accurate values of the bias-correction factors and Gaussian efficiency for small samples ($n \leq 100$)
and prediction equations for samples of larger sizes.&lt;/p>
&lt;/blockquote></description></item><item><title>Sensitivity curve of the Harrell-Davis quantile estimator, Part 3</title><link>https://aakinshin.net/posts/hd-sc3/</link><pubDate>Tue, 11 Oct 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/hd-sc3/</guid><description>&lt;p>In the previous posts (&lt;a href="https://aakinshin.net/posts/hd-sc1/">1&lt;/a>, &lt;a href="https://aakinshin.net/posts/hd-sc2/">2&lt;/a>), I have explored the sensitivity curves of
the Harrell-Davis quantile estimator on
the normal distribution, the exponential distribution, and the Cauchy distribution.
In this post, I build these sensitivity curves for some additional distributions.&lt;/p></description></item><item><title>Sensitivity curve of the Harrell-Davis quantile estimator, Part 2</title><link>https://aakinshin.net/posts/hd-sc2/</link><pubDate>Tue, 04 Oct 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/hd-sc2/</guid><description>&lt;p>In the &lt;a href="https://aakinshin.net/posts/hd-sc1/">previous post&lt;/a>, I have explored the sensitivity curves of
the Harrell-Davis quantile estimator on the normal distribution.
In this post, I continue the same investigation on the exponential and Cauchy distributions.&lt;/p></description></item><item><title>Sensitivity curve of the Harrell-Davis quantile estimator, Part 1</title><link>https://aakinshin.net/posts/hd-sc1/</link><pubDate>Tue, 27 Sep 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/hd-sc1/</guid><description>&lt;p>The Harrell-Davis quantile estimator is an efficient replacement for the traditional quantile estimator,
especially in the case of light-tailed distributions.
Unfortunately, it is not robust: its breakdown point is zero.
However, the breakdown point is not the only descriptor of robustness.
While the breakdown point describes the portion of the distribution that should be replaced by
arbitrary large values to corrupt the estimation,
it does not describe the actual impact of finite outliers.
The arithmetic mean also has the breakdown point of zero,
but the practical robustness of the mean and the Harrell-Davis quantile estimator are not the same.
The Harrell-Davis quantile estimator is an L-estimator
that assigns extremely low weights to sample elements near the tails
(especially, for reasonably large sample sizes).
Therefore, the actual impact of potential outliers is not so noticeable.
In this post, we use the standardized sensitivity curve to evaluate this impact.&lt;/p></description></item><item><title>Weighted quantile estimators for exponential smoothing and mixture distributions</title><link>https://aakinshin.net/posts/wqe-smoothing-mixture/</link><pubDate>Tue, 20 Sep 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/wqe-smoothing-mixture/</guid><description>&lt;p>There are various ways to estimate quantiles of weighted samples.
The proper choice of the most appropriate weighted quantile estimator depends not only on the own estimator properties
but also on the goal.&lt;/p>
&lt;p>Let us consider two problems:&lt;/p>
&lt;ol>
&lt;li>&lt;em>Estimating quantiles of a weighted mixture distribution.&lt;/em>&lt;br />
In this problem, we have a weighted mixture distribution given by $F = \sum_{i=1}^m w_i F_i$.
We collect samples $\mathbf{x_1}, \mathbf{x_2}, \ldots, \mathbf{x_m}$ from $F_1, F_2, \ldots F_m$,
and want to estimate quantile function $F^{-1}$ of the mixture distribution based on the given samples.&lt;/li>
&lt;li>&lt;em>Quantile exponential smoothing.&lt;/em>&lt;br />
In this problem, we have a time series $\mathbf{x} = \{ x_1, x_2, \ldots, x_n \}$.
We want to describe the distribution &amp;ldquo;at the end&amp;rdquo; of this time series.
The latest series element $x_n$ is the most &amp;ldquo;actual&amp;rdquo; one, but we cannot build a distribution based on a single element.
Therefore, we have to consider more elements at the end of $\mathbf{x}$.
However, if we take too many elements, we may corrupt the estimations due to obsolete measurements.
To resolve this problem, we can assign weights to all elements according to the exponential law
and estimate weighted quantiles.&lt;/li>
&lt;/ol>
&lt;p>In both problems, the usage of weighted quantile estimators looks like a reasonable solution.
However, in each problem, we have different expectations of the estimator behavior.
In this post, we provide an example that illustrates the difference in these expectations.&lt;/p></description></item><item><title>The Huggins-Roy family of effective sample sizes</title><link>https://aakinshin.net/posts/huggins-roy-ess/</link><pubDate>Tue, 13 Sep 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/huggins-roy-ess/</guid><description>&lt;p>When we work with weighted samples, it&amp;rsquo;s essential to introduce adjustments for the sample size.
Indeed, let&amp;rsquo;s consider two following weighted samples:&lt;/p>
$$
\mathbf{x}_1 = \{ x_1, x_2, \ldots, x_n \}, \quad \mathbf{w}_1 = \{ w_1, w_2, \ldots, w_n \},
$$
$$
\mathbf{x}_2 = \{ x_1, x_2, \ldots, x_n, x_{n+1} \}, \quad \mathbf{w}_2 = \{ w_1, w_2, \ldots, w_n, 0 \}.
$$
&lt;p>Since the weight of $x_{n+1}$ in the second sample is zero,
it&amp;rsquo;s natural to expect that both samples have the same set of properties.
However, there is a major difference between $\mathbf{x}_1$ and $\mathbf{x}_2$: their sample sizes which are
$n$ and $n+1$.
In order to eliminate this difference, we typically introduce the &lt;em>effective sample size&lt;/em> (ESS)
which is estimated based on the list of weights.&lt;/p>
&lt;p>There are various ways to estimate the ESS.
In this post, we briefly discuss the Huggins-Roy&amp;rsquo;s family of ESS.&lt;/p></description></item><item><title>Finite-sample bias correction factors for Rousseeuw-Croux scale estimators</title><link>https://aakinshin.net/posts/rousseeuw-croux-finite-factors/</link><pubDate>Tue, 06 Sep 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/rousseeuw-croux-finite-factors/</guid><description>&lt;p>The Rousseeuw-Croux scale estimators $S_n$ and $Q_n$
are &lt;a href="https://aakinshin.net/posts/rousseeuw-croux-finite-efficiency/">efficient&lt;/a> alternatives to the median absolute deviation ($\operatorname{MAD}_n$).
While all three estimators have the same breakdown point of $50\%$,
$S_n$ and $Q_n$ have higher statistical efficiency than $\operatorname{MAD}_n$.
The asymptotic Gaussian efficiency values of $\operatorname{MAD}_n$, $S_n$, and $Q_n$
are $37\%$, $58\%$, and $82\%$ respectively.&lt;/p>
&lt;p>Using scale constants, we can make $S_n$ and $Q_n$ consistent estimators for the standard deviation under normality.
The asymptotic values of these constants are well-known.
However, for finite-samples, only approximated scale constants are known.
In this post, we provide refined values of these constants with higher accuracy.&lt;/p></description></item><item><title>Preprint announcement: 'Quantile absolute deviation'</title><link>https://aakinshin.net/posts/preprint-qad/</link><pubDate>Thu, 01 Sep 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/preprint-qad/</guid><description>&lt;p>I have just published a preprint of a paper &amp;lsquo;Quantile absolute deviation&amp;rsquo;.
It&amp;rsquo;s based on a series of my &lt;a href="https://aakinshin.net/tags/research-qad/">research notes&lt;/a>
that I have been writing since December 2020.&lt;/p>
&lt;p>The paper preprint is available on arXiv:
&lt;a href="https://arxiv.org/abs/2208.13459">arXiv:2208.13459 [stat.ME]&lt;/a>.
The paper source code is available on GitHub:
&lt;a href="https://github.com/AndreyAkinshin/paper-qad">AndreyAkinshin/paper-qad&lt;/a>.
You can cite it as follows:&lt;/p>
&lt;ul>
&lt;li>Andrey Akinshin (2022)
&amp;ldquo;Quantile absolute deviation&amp;rdquo;
&lt;a href="https://arxiv.org/abs/2208.13459">arXiv:2208.13459&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Abstract:&lt;/p>
&lt;blockquote>
&lt;p>The median absolute deviation (MAD) is a popular robust measure of statistical dispersion.
However, when it is applied to non-parametric distributions (especially multimodal, discrete, or heavy-tailed),
lots of statistical inference issues arise.
Even when it is applied to distributions with slight deviations from normality and these issues are not actual,
the Gaussian efficiency of the MAD is only 37% which is not always enough.&lt;/p>
&lt;p>In this paper, we introduce the &lt;em>quantile absolute deviation&lt;/em> (QAD) as a generalization of the MAD.
This measure of dispersion provides a flexible approach to analyzing properties of non-parametric distributions.
It also allows controlling the trade-off between robustness and statistical efficiency.
We use the trimmed Harrell-Davis median estimator based on the highest density interval of the given width
as a complimentary median estimator that gives
increased finite-sample Gaussian efficiency compared to the sample median
and a breakdown point matched to the QAD.&lt;/p>
&lt;p>As a rule of thumb, we suggest using two new measures of dispersion
called the &lt;em>standard QAD&lt;/em> and the &lt;em>optimal QAD&lt;/em>.
They give 54% and 65% of Gaussian efficiency having breakdown points of 32% and 14% respectively.&lt;/p>
&lt;/blockquote></description></item><item><title>Standard trimmed Harrell-Davis median estimator</title><link>https://aakinshin.net/posts/sthdme/</link><pubDate>Wed, 31 Aug 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/sthdme/</guid><description>&lt;p>In &lt;a href="https://aakinshin.net/posts/sqad/">one of the previous posts&lt;/a>, I suggested a new measure of dispersion called
&lt;em>the standard quantile absolute deviation around the median&lt;/em> ($\operatorname{SQAD}$) which can be used as an alternative
to the median absolute deviation ($\operatorname{MAD}$) as a consistent estimator for the standard deviation under normality.
The Gaussian efficiency of $\operatorname{SQAD}$ is $54\%$ (comparing to $37\%$ for MAD),
and its breakdown point is $32\%$ (comparing to $50\%$ for MAD).
$\operatorname{SQAD}$ is a symmetric dispersion measure around the median:
the interval $[\operatorname{Median} - \operatorname{SQAD}; \operatorname{Median} + \operatorname{SQAD}]$
covers $68\%$ of the distribution.
In the case of the normal distribution, this corresponds to the interval $[\mu - \sigma; \mu + \sigma]$.&lt;/p>
&lt;p>If we use $\operatorname{SQAD}$, we accept the breakdown point of $32\%$.
This makes the sample median a non-optimal choice for the median estimator.
Indeed, the sample median has high robustness (the breakdown point is $50\%$),
but relatively poor Gaussian efficiency.
If we use $\operatorname{SQAD}$, it doesn&amp;rsquo;t make sense to require a breakdown point of more than $32\%$.
Therefore, we could trade the median robustness for efficiency
and come up with a complementary measure of the median for $\operatorname{SQAD}$.&lt;/p>
&lt;p>In this post, we introduce the standard trimmed Harrell-Davis median estimator which shares
the breakdown point with $\operatorname{SQAD}$ and provides better finite-sample efficiency comparing
to the sample median.&lt;/p></description></item><item><title>Optimal quantile absolute deviation</title><link>https://aakinshin.net/posts/oqad/</link><pubDate>Tue, 30 Aug 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/oqad/</guid><description>&lt;p>We consider the quantile absolute deviation around the median defined as follows:&lt;/p>
$$
\newcommand{\E}{\mathbb{E}}
\newcommand{\PR}{\mathbb{P}}
\newcommand{\Q}{\operatorname{Q}}
\newcommand{\OQAD}{\operatorname{OQAD}}
\newcommand{\QAD}{\operatorname{QAD}}
\newcommand{\median}{\operatorname{median}}
\newcommand{\Exp}{\operatorname{Exp}}
\newcommand{\SD}{\operatorname{SD}}
\newcommand{\V}{\mathbb{V}}
\QAD(X, p) = K_p \Q(|X - \median(X)|, p),
$$
&lt;p>where $\Q$ is a quantile estimator,
and $K_p$ is a scale constant which we use to make $\QAD(X, p)$ an asymptotically consistent estimator
for the standard deviation under the normal distribution.&lt;/p>
&lt;p>In this post, we get the exact values of the $K_p$ values,
derive the corresponding equation for the asymptotic Gaussian efficiency of $\QAD(X, p)$,
and find the point in which $\QAD(X, p)$ achieves the highest Gaussian efficiency.&lt;/p></description></item><item><title>Quantile absolute deviation of the Pareto distribution</title><link>https://aakinshin.net/posts/qad-pareto/</link><pubDate>Mon, 29 Aug 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/qad-pareto/</guid><description>&lt;p>In this post,
we derive the exact equation for the quantile absolute deviation around the median of the Pareto(1,1) distribution.&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/qad-pareto/img/qad-light.png" target="_blank" alt="qad">
 &lt;img
 src="https://aakinshin.net/posts/qad-pareto/img/qad-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/qad-pareto/img/qad-dark.png" target="_blank" alt="qad">
 &lt;img
 src="https://aakinshin.net/posts/qad-pareto/img/qad-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div></description></item><item><title>Quantile absolute deviation of the Exponential distribution</title><link>https://aakinshin.net/posts/qad-exp/</link><pubDate>Fri, 26 Aug 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/qad-exp/</guid><description>&lt;p>In this post,
we derive the exact equation for the quantile absolute deviation around the median of the Exponential distribution.&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/qad-exp/img/qad-light.png" target="_blank" alt="qad">
 &lt;img
 src="https://aakinshin.net/posts/qad-exp/img/qad-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/qad-exp/img/qad-dark.png" target="_blank" alt="qad">
 &lt;img
 src="https://aakinshin.net/posts/qad-exp/img/qad-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div></description></item><item><title>Quantile absolute deviation of the Uniform distribution</title><link>https://aakinshin.net/posts/qad-uniform/</link><pubDate>Thu, 25 Aug 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/qad-uniform/</guid><description>&lt;p>In this post,
we derive the exact equation for the quantile absolute deviation around the median of the Uniform distribution.&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/qad-uniform/img/qad-light.png" target="_blank" alt="qad">
 &lt;img
 src="https://aakinshin.net/posts/qad-uniform/img/qad-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/qad-uniform/img/qad-dark.png" target="_blank" alt="qad">
 &lt;img
 src="https://aakinshin.net/posts/qad-uniform/img/qad-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div></description></item><item><title>Quantile absolute deviation of the Normal distribution</title><link>https://aakinshin.net/posts/qad-normal/</link><pubDate>Wed, 24 Aug 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/qad-normal/</guid><description>&lt;p>In this post,
we derive the exact equation for the quantile absolute deviation around the median of the Normal distribution.&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/qad-normal/img/qad-light.png" target="_blank" alt="qad">
 &lt;img
 src="https://aakinshin.net/posts/qad-normal/img/qad-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/qad-normal/img/qad-dark.png" target="_blank" alt="qad">
 &lt;img
 src="https://aakinshin.net/posts/qad-normal/img/qad-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div></description></item><item><title>Standard quantile absolute deviation</title><link>https://aakinshin.net/posts/sqad/</link><pubDate>Tue, 23 Aug 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/sqad/</guid><description>&lt;p>The median absolute deviation (MAD) is a popular robust replacement of the standard deviation (StdDev).
It&amp;rsquo;s truly robust: its breakdown point is $50\%$.
However, it&amp;rsquo;s not so efficient when we use it as a consistent estimator for the standard deviation under normality:
the asymptotic relative efficiency against StdDev (we call it the &lt;em>Gaussian efficiency&lt;/em>) is only about $\approx 37\%$.&lt;/p>
&lt;p>In practice, such robustness is not always essential, while we typically want to have the highest possible efficiency.
I already described the concept of the &lt;a href="https://aakinshin.net/posts/qad/">&lt;em>quantile absolute deviation&lt;/em>&lt;/a> which aims
to provide a customizable trade-off between robustness and efficiency.
In this post, I would like to suggest a new default option for this measure of dispersion
called the &lt;em>standard quantile absolute deviation&lt;/em>.
Its Gaussian efficiency is $\approx 54\%$ while the breakdown point is $\approx 32\%$&lt;/p></description></item><item><title>Asymptotic Gaussian efficiency of the quantile absolute deviation</title><link>https://aakinshin.net/posts/qad-are/</link><pubDate>Tue, 16 Aug 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/qad-are/</guid><description>&lt;p>I have already discussed the concept of the &lt;a href="https://aakinshin.net/posts/qad/">quantile absolute deviation&lt;/a>
in &lt;a href="https://aakinshin.net/tags/research-qad/">several previous posts&lt;/a>.
In this post, we derive the equation for the relative statistical efficiency of the quantile absolute deviation
against the standard deviation under the normal distribution (so call Gaussian efficiency).&lt;/p></description></item><item><title>Finite-sample efficiency of the Rousseeuw-Croux estimators</title><link>https://aakinshin.net/posts/rousseeuw-croux-finite-efficiency/</link><pubDate>Tue, 09 Aug 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/rousseeuw-croux-finite-efficiency/</guid><description>&lt;p>The Rousseeuw-Croux $S_n$ and $Q_n$ estimators are robust and efficient measures of scale.
Their breakdown points are equal to $0.5$ which is also the breakdown point of the median absolute deviation (MAD).
However, their statistical efficiency values are much better than the efficiency of MAD.
To be specific, the MAD asymptotic relative Gaussian efficiency against the standard deviation is about $37\%$,
whereas the corresponding values for $S_n$ and $Q_n$ are $58\%$ and $82\%$ respectively.
Although these numbers are quite impressive, they are only &lt;em>asymptotic&lt;/em> values.
In practice, we work with finite samples.
And the &lt;em>finite-sample efficiency&lt;/em> could be much lower than the asymptotic one.
In this post, we perform a simulation study in order to obtain the actual finite-sample efficiency values
for these two estimators.&lt;/p></description></item><item><title>Caveats of using the median absolute deviation</title><link>https://aakinshin.net/posts/mad-caveats/</link><pubDate>Tue, 02 Aug 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/mad-caveats/</guid><description>&lt;p>The median absolute deviation is a measure of dispersion
which can be used as a robust alternative to the standard deviation.
It works great for slight deviations from normality
(e.g., for contaminated normal distributions or slightly skewed unimodal distributions).
Unfortunately, if we apply it to distributions with huge deviations from normality,
we may experience a lot of troubles.
In this post, I discuss some of the most important caveats which we should keep in mind
if we use the median absolute deviation.&lt;/p></description></item><item><title>Preprint announcement: 'Finite-sample bias-correction factors for the median absolute deviation based on the Harrell-Davis quantile estimator and its trimmed modification'</title><link>https://aakinshin.net/posts/preprint-mad-factors/</link><pubDate>Tue, 26 Jul 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/preprint-mad-factors/</guid><description>&lt;p>I have just published a preprint of a paper
&amp;lsquo;Finite-sample bias-correction factors for the median absolute deviation based on the Harrell-Davis quantile estimator and its trimmed modification&amp;rsquo;.
It&amp;rsquo;s based on a series of my &lt;a href="https://aakinshin.net/tags/research-unbiased-mad/">research notes&lt;/a>
that I have been writing since February 2021.&lt;/p>
&lt;p>The paper preprint is available on arXiv:
&lt;a href="https://arxiv.org/abs/2207.12005">arXiv:2207.12005 [stat.ME]&lt;/a>.
The paper source code is available on GitHub:
&lt;a href="https://github.com/AndreyAkinshin/paper-mad-factors">AndreyAkinshin/paper-mad-factors&lt;/a>.
You can cite it as follows:&lt;/p>
&lt;ul>
&lt;li>Andrey Akinshin (2022)
&amp;ldquo;Finite-sample bias-correction factors for the median absolute deviation based on the Harrell-Davis quantile estimator and its trimmed modification,&amp;rdquo;
&lt;a href="https://arxiv.org/abs/2207.12005">arXiv:2207.12005&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Abstract:&lt;/p>
&lt;blockquote>
&lt;p>The median absolute deviation is a widely used robust measure of statistical dispersion.
Using a scale constant, we can use it as an asymptotically consistent estimator for the standard deviation under normality.
For finite samples, the scale constant should be corrected in order to obtain an unbiased estimator.
The bias-correction factor depends on the sample size and the median estimator.
When we use the traditional sample median, the factor values are well known,
but this approach does not provide optimal statistical efficiency.
In this paper, we present the bias-correction factors for the median absolute deviation
based on the Harrell-Davis quantile estimator and its trimmed modification
which allow us to achieve better statistical efficiency of the standard deviation estimations.
The obtained estimators are especially useful for samples with a small number of elements.&lt;/p>
&lt;/blockquote></description></item><item><title>Challenges of change point detection in CI performance data</title><link>https://aakinshin.net/posts/cpd-perf-challenges/</link><pubDate>Tue, 19 Jul 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/cpd-perf-challenges/</guid><description>&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Change_detection">Change point detection&lt;/a> is a popular task in various disciplines.
There are many algorithms that solve this problem.
For example, in &lt;a href="https://aakinshin.net/library/papers/truong2020/">&lt;svg class="rating-icon">&lt;use xlink:href="https://aakinshin.net/img/fa/all.svg#paper">&lt;/use>&lt;/svg>truong2020&lt;/a>,
the authors presented a classification of different approaches and discussed 35 algorithms.
However, not all the algorithms fit all the situations.&lt;/p>
&lt;p>In this post, we consider the problem of change point detection in time series based on
software performance measurements obtained from a continuous integration (CI) server.
Examples of data sources are CI builds, unit tests, benchmarks, performance tests, and so on.
We would like to automatically find performance degradations in such time series.
Unfortunately, most of the available algorithms do not provide decent solutions for this problem.
In this post, I discuss some challenges that arise when we are looking for change points in CI performance data.&lt;/p></description></item><item><title>Degenerate point of dispersion estimators</title><link>https://aakinshin.net/posts/degenerate-point/</link><pubDate>Tue, 12 Jul 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/degenerate-point/</guid><description>&lt;p>Recently, I have been working on searching for a robust statistical dispersion estimator
that doesn&amp;rsquo;t become zero on samples with a huge number of tied values.
I have already created a few of such estimators like
the &lt;em>middle non-zero quantile absolute deviation&lt;/em> (&lt;a href="https://aakinshin.net/posts/mnzqad/">part 1&lt;/a>, &lt;a href="https://aakinshin.net/posts/mnzqad2/">part 2&lt;/a>) and
the &lt;em>&lt;a href="https://aakinshin.net/posts/uqad/">untied quantile absolute deviation&lt;/a>&lt;/em>.
Having several options to compare, we need a proper metric that allows us to perform such a comparison.
Similar to the breakdown point (that is used to describe estimator robustness),
we could introduce the &lt;em>degenerate point&lt;/em> that describes the resistance of a dispersion estimator to the tied values.
In this post, I will briefly describe this concept.&lt;/p></description></item><item><title>Untied quantile absolute deviation</title><link>https://aakinshin.net/posts/uqad/</link><pubDate>Tue, 05 Jul 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/uqad/</guid><description>&lt;p>In the previous posts, I tried to adapt the concept of the &lt;a href="https://aakinshin.net/posts/qad/">quantile absolute deviation&lt;/a>
to samples with tied values so that this measure of dispersion never becomes zero for nondegenerate ranges.
My previous attempt was the &lt;em>middle non-zero quantile absolute deviation&lt;/em>
(&lt;a href="https://aakinshin.net/posts/mnzqad/">modification 1&lt;/a>, &lt;a href="https://aakinshin.net/posts/mnzqad2/">modification 2&lt;/a>).
However, I&amp;rsquo;m not completely satisfied with the behavior of this metric.
In this post, I want to consider another way to work around the problem with tied values.&lt;/p></description></item><item><title>Middle non-zero quantile absolute deviation, Part 2</title><link>https://aakinshin.net/posts/mnzqad2/</link><pubDate>Tue, 28 Jun 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/mnzqad2/</guid><description>&lt;p>In one of the previous posts, I &lt;a href="https://aakinshin.net/posts/mnzqad/">described&lt;/a> the idea of the
middle non-zero quantile absolute deviation.
It&amp;rsquo;s defined as follows:&lt;/p>
$$
\operatorname{MNZQAD}(x, p) = \operatorname{QAD}(x, p, q_m),
$$
$$
q_m = \frac{q_0 + 1}{2}, \quad
q_0 = \frac{\max(k - 1, 0)}{n - 1}, \quad
k = \sum_{i=1}^n \mathbf{1}_{Q(x, p)}(x_i),
$$
&lt;p>where $\mathbf{1}$ is the indicator function&lt;/p>
$$
\mathbf{1}_U(u) = \begin{cases}
1 &amp; \textrm{if}\quad u = U,\\
0 &amp; \textrm{if}\quad u \neq U,
\end{cases}
$$
&lt;p>and $\operatorname{QAD}$ is the &lt;a href="https://aakinshin.net/posts/qad/">quantile absolute deviation&lt;/a>&lt;/p>
$$
\operatorname{QAD}(x, p, q) = Q(|x - Q(x, p)|, q).
$$
&lt;p>The $\operatorname{MNZQAD}$ approach tries to work around a problem with tied values.
While it works well in the generic case, there are some corner cases
where the suggested metric behaves poorly.
In this post, we discuss this problem and how to solve it.&lt;/p></description></item><item><title>The expected number of takes from a discrete distribution before observing the given element</title><link>https://aakinshin.net/posts/expected-discrete-takes/</link><pubDate>Tue, 21 Jun 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/expected-discrete-takes/</guid><description>&lt;p>Let&amp;rsquo;s consider a discrete distribution $X$ defined by its probability mass function $p_X(x)$.
We randomly take elements from $X$ until we observe the given element $x_0$.
What&amp;rsquo;s the expected number of takes in this process?&lt;/p>
&lt;p>This classic statistical problem could be solved in various ways.
I would like to share one of my favorite approaches that involves the derivative of the series
$\sum_{n=0}^\infty x^n$.&lt;/p></description></item><item><title>Folded medians</title><link>https://aakinshin.net/posts/folded-medians/</link><pubDate>Tue, 14 Jun 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/folded-medians/</guid><description>&lt;p>In the &lt;a href="https://aakinshin.net/posts/gastwirth/">previous post&lt;/a>, we discussed the Gastwirth&amp;rsquo;s location estimator.
In this post, we continue playing with different location estimators.
To be more specific, we consider an approach called &lt;em>folded medians&lt;/em>.
Let $x = \{ x_1, x_2, \ldots, x_n \}$ be a random sample with order statistics
$\{ x_{(1)}, x_{(2)}, \ldots, x_{(n)} \}$.
We build a folded sample using the following form:&lt;/p>
$$
\Bigg\{ \frac{x_{(1)}+x_{(n)}}{2}, \frac{x_{(2)}+x_{(n-1)}}{2}, \ldots, \Bigg\}.
$$
&lt;p>If $n$ is odd, the middle sample element is folded with itself.
The folding operation could be applied several times.
Once folding is conducted, the median of the final folded sample is the folded median.
A single folding operation gives us the Bickel-Hodges estimator.&lt;/p>
&lt;p>In this post, we briefly check how this metric behaves in the case of the Normal and Cauchy distributions.&lt;/p></description></item><item><title>Gastwirth's location estimator</title><link>https://aakinshin.net/posts/gastwirth/</link><pubDate>Tue, 07 Jun 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/gastwirth/</guid><description>&lt;p>Let $x = \{ x_1, x_2, \ldots, x_n \}$ be a random sample.
The Gastwirth&amp;rsquo;s location estimator is defined as follows:&lt;/p>
$$
0.3 \cdot Q_{⅓}(x) + 0.4 \cdot Q_{½}(x) + 0.3 \cdot Q_{⅔}(x),
$$
&lt;p>where $Q_p$ is an estimation of the $p^{\textrm{th}}$ quantile (using classic sample quantiles).&lt;/p>
&lt;p>This estimator could be quite interesting from a practical point of view.
On the one hand, it&amp;rsquo;s robust (the breakdown point ⅓)
and it has better statistical efficiency than the classic sample median.
On the other hand, it has better computational efficiency
than other robust and statistical efficient measures of location
like the Harrell-Davis median estimator or
the &lt;a href="https://aakinshin.net/posts/hodges-lehmann-efficiency2/">Hodges-Lehmann median estimator&lt;/a>.&lt;/p>
&lt;p>In this post, we conduct a short simulation study that shows its behavior for the standard Normal distribution
and the Cauchy distribution.&lt;/p></description></item><item><title>Hodges-Lehmann-Sen shift and shift confidence interval estimators</title><link>https://aakinshin.net/posts/hodges-lehmann-sen-shift-ci/</link><pubDate>Tue, 31 May 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/hodges-lehmann-sen-shift-ci/</guid><description>&lt;p>In the previous two posts
(&lt;a href="https://aakinshin.net/posts/hodges-lehmann-efficiency1/">1&lt;/a>, &lt;a href="https://aakinshin.net/posts/hodges-lehmann-efficiency2/">2&lt;/a>),
I discussed the Hodges-Lehmann median estimator.
The suggested idea of getting median estimations based on a cartesian product
could be adopted to estimate the shift between two samples.
In this post, we discuss how to build Hodges-Lehmann-Sen shift estimator
and how to get confidence intervals for the obtained estimations.
Also, we perform a simulation study that checks the actual coverage percentage of these intervals.&lt;/p></description></item><item><title>Statistical efficiency of the Hodges-Lehmann median estimator, Part 2</title><link>https://aakinshin.net/posts/hodges-lehmann-efficiency2/</link><pubDate>Tue, 24 May 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/hodges-lehmann-efficiency2/</guid><description>&lt;p>In the &lt;a href="https://aakinshin.net/posts/hodges-lehmann-efficiency1/">previous post&lt;/a>,
we evaluated the relative statistical efficiency of the Hodges-Lehmann median estimator
against the sample median under the normal distribution.
In this post, we extended this experiment to a set of various light-tailed and heavy-tailed distributions.&lt;/p></description></item><item><title>Statistical efficiency of the Hodges-Lehmann median estimator, Part 1</title><link>https://aakinshin.net/posts/hodges-lehmann-efficiency1/</link><pubDate>Tue, 17 May 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/hodges-lehmann-efficiency1/</guid><description>&lt;p>In this post, we evaluate the relative statistical efficiency of the Hodges-Lehmann median estimator
against the sample median under the normal distribution.
We also compare it with the efficiency of the Harrell-Davis quantile estimator.&lt;/p></description></item><item><title>Expected value of the maximum of two standard half-normal distributions</title><link>https://aakinshin.net/posts/expected-max-half-normal/</link><pubDate>Tue, 10 May 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/expected-max-half-normal/</guid><description>&lt;p>Let $X_1, X_2$ be &lt;a href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">i.i.d.&lt;/a>
random variables that follow the standard normal distribution $\mathcal{N}(0,1^2)$.
In the &lt;a href="https://aakinshin.net/posts/expected-min-half-normal/">previous post&lt;/a>,
I have found the expected value of $\min(|X_1|, |X_2|)$.
Now it&amp;rsquo;s time to find the value of $Z = \max(|X_1|, |X_2|)$.&lt;/p></description></item><item><title>Expected value of the minimum of two standard half-normal distributions</title><link>https://aakinshin.net/posts/expected-min-half-normal/</link><pubDate>Tue, 03 May 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/expected-min-half-normal/</guid><description>&lt;p>Let $X_1, X_2$ be &lt;a href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">i.i.d.&lt;/a>
random variables that follow the standard normal distribution $\mathcal{N}(0,1^2)$.
One day I wondered, what is the expected value of $Z = \min(|X_1|, |X_2|)$?
It turned out to be a fun exercise.
Let&amp;rsquo;s solve it together!&lt;/p></description></item><item><title>Unbiased median absolute deviation for n=2</title><link>https://aakinshin.net/posts/unbiased-mad-n2/</link><pubDate>Tue, 26 Apr 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/unbiased-mad-n2/</guid><description>&lt;p>I already covered the topic of the unbiased median deviation based on
&lt;a href="https://aakinshin.net/posts/unbiased-mad/">the traditional sample median&lt;/a>,
&lt;a href="https://aakinshin.net/posts/unbiased-mad-hd/">the Harrell-Davis quantile estimator&lt;/a>, and
&lt;a href="https://aakinshin.net/posts/unbiased-mad-thd/">the trimmed Harrell-Davis quantile estimator&lt;/a>.
In all the posts, the values of bias-correction factors were evaluated using the Monte-Carlo simulation.
In this post, we calculate the exact value of the bias-correction factor for two-element samples.&lt;/p></description></item><item><title>Weighted trimmed Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/wthdqe/</link><pubDate>Tue, 19 Apr 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/wthdqe/</guid><description>&lt;p>In this post, I combine ideas from two of my previous posts:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aakinshin.net/posts/pub-thdqe/">Trimmed Harrell-Davis quantile estimator&lt;/a>:
quantile estimator that provides an optimal trade-off between statistical efficiency and robustness&lt;/li>
&lt;li>&lt;a href="https://aakinshin.net/posts/weighted-quantiles/">Weighted quantile estimators&lt;/a>:
a general scheme that allows building weighted quantile estimators.
Could be used for &lt;a href="https://aakinshin.net/posts/quantile-exponential-smoothing/">quantile exponential smoothing&lt;/a>
and &lt;a href="https://aakinshin.net/posts/dispersion-exponential-smoothing/">dispersion exponential smoothing&lt;/a>.&lt;/li>
&lt;/ul>
&lt;p>Thus, we are going to build a weighted version of the trimmed Harrell-Davis quantile estimator based on the highest
density interval of the given width.&lt;/p></description></item><item><title>Minimum meaningful statistical level for the Mann–Whitney U test</title><link>https://aakinshin.net/posts/mann-whitney-min-stat-level/</link><pubDate>Tue, 12 Apr 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/mann-whitney-min-stat-level/</guid><description>&lt;p>The &lt;a href="https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test">Mann–Whitney U test&lt;/a> is one of the most popular
nonparametric null hypothesis significance tests.
However, like any statistical test, it has limitations.
We should always carefully match them with our business requirements.
In this post, we discuss how to properly choose the statistical level for the Mann–Whitney U test on small samples.&lt;/p>
&lt;p>Let&amp;rsquo;s say we want to compare two samples $x = \{ x_1, x_2, \ldots, x_n \}$ and $y = \{ y_1, y_2, \ldots, y_m \}$
using the one-sided Mann–Whitney U test.
Sometimes, we don&amp;rsquo;t have an opportunity to gather enough data and we have to work with small samples.
Imagine that the size of both samples is six: $n=m=6$.
We want to set the statistical level $\alpha$ to $0.001$ (because we really don&amp;rsquo;t want to get false-positive results).
Is it a valid requirement?
In fact, the minimum p-value we can observe with $n=m=6$ is $\approx 0.001082$.
Thus, with $\alpha = 0.001$, it&amp;rsquo;s impossible to get a positive result.
Meanwhile, everything is correct from the technical point of view:
since we can&amp;rsquo;t get any positive results, the false positive rate is exactly zero which is less than $0.001$.
However, it&amp;rsquo;s definitely not something that we want: with this setup the test becomes useless because
it always provides negative results regardless of the input data.&lt;/p>
&lt;p>This brings an important question: what is the minimum meaningful statistical level
that we can require for the one-sided Mann–Whitney U test knowing the sample sizes?&lt;/p></description></item><item><title>Fence-based outlier detectors, Part 2</title><link>https://aakinshin.net/posts/fenced-outlier-detectors2/</link><pubDate>Tue, 05 Apr 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/fenced-outlier-detectors2/</guid><description>&lt;p>In the &lt;a href="https://aakinshin.net/posts/fenced-outlier-detectors1/">previous post&lt;/a>,
I discussed different fence-based outlier detectors.
In this post, I show some examples of these detectors with different parameters.&lt;/p></description></item><item><title>Fence-based outlier detectors, Part 1</title><link>https://aakinshin.net/posts/fenced-outlier-detectors1/</link><pubDate>Tue, 29 Mar 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/fenced-outlier-detectors1/</guid><description>&lt;p>In previous posts, I discussed properties of &lt;a href="https://aakinshin.net/posts/tukey-outlier-probability/">Tukey&amp;rsquo;s fences&lt;/a>
and asymmetric decile-based outlier detector
(&lt;a href="https://aakinshin.net/posts/asymmetric-decile-outliers1/">Part 1&lt;/a>, &lt;a href="https://aakinshin.net/posts/asymmetric-decile-outliers2/">Part 2&lt;/a>).
In this post, I discuss the generalization of fence-based outlier detectors.&lt;/p></description></item><item><title>Publication announcement: 'Trimmed Harrell-Davis quantile estimator based on the highest density interval of the given width'</title><link>https://aakinshin.net/posts/pub-thdqe/</link><pubDate>Tue, 22 Mar 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/pub-thdqe/</guid><description>&lt;p>Since the beginning of previous year, I have been working on building a quantile estimator
that provides an optimal trade-off between statistical efficiency and robustness.
At the end of the year, I &lt;a href="https://aakinshin.net/posts/preprint-thdqe/">published&lt;/a> the corresponding preprint
where I presented a description of such an estimator:
&lt;a href="https://arxiv.org/abs/2111.11776">arXiv:2111.11776 [stat.ME]&lt;/a>.
The paper source code is available on GitHub:
&lt;a href="https://github.com/AndreyAkinshin/paper-thdqe">AndreyAkinshin/paper-thdqe&lt;/a>.&lt;/p>
&lt;p>Finally, the paper was published in &lt;em>Communications in Statistics - Simulation and Computation&lt;/em>.
You can cite it as follows:&lt;/p>
&lt;ul>
&lt;li>Andrey Akinshin (2022)
&lt;em>Trimmed Harrell-Davis quantile estimator based on the highest density interval of the given width,&lt;/em>
Communications in Statistics - Simulation and Computation,
DOI: &lt;a href="https://www.tandfonline.com/doi/abs/10.1080/03610918.2022.2050396">10.1080/03610918.2022.2050396&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Asymmetric decile-based outlier detector, Part 2</title><link>https://aakinshin.net/posts/asymmetric-decile-outliers2/</link><pubDate>Tue, 15 Mar 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/asymmetric-decile-outliers2/</guid><description>&lt;p>In the &lt;a href="https://aakinshin.net/posts/asymmetric-decile-outliers1/">previous post&lt;/a>,
I suggested an asymmetric decile-based outlier detector
as an alternative to &lt;a href="https://aakinshin.net/posts/tukey-outlier-probability/">Tukey&amp;rsquo;s fences&lt;/a>.
In this post, we run some numerical simulations to check out
the suggested outlier detector in action.&lt;/p></description></item><item><title>Asymmetric decile-based outlier detector, Part 1</title><link>https://aakinshin.net/posts/asymmetric-decile-outliers1/</link><pubDate>Tue, 08 Mar 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/asymmetric-decile-outliers1/</guid><description>&lt;p>In the &lt;a href="https://aakinshin.net/posts/tukey-outlier-probability/">previous post&lt;/a>, I covered some problems with the outlier detector
based on Tukey fences.
Mainly, I discussed the probability of observing outliers using Tukey&amp;rsquo;s fences
with different factors under different distributions.
However, it&amp;rsquo;s not the only problem with this approach.&lt;/p>
&lt;p>Since Tukey&amp;rsquo;s fences are based on quartiles,
under multimodal distributions, we could get a situation
when 50% of all sample elements are marked as outliers.
Also, Tukey&amp;rsquo;s fences are designed for symmetric distributions,
so we could get strange results with asymmetric distributions.&lt;/p>
&lt;p>In this post, I want to suggest an asymmetric outlier detector based on deciles
which mitigates this problem.&lt;/p></description></item><item><title>Probability of observing outliers using Tukey's fences</title><link>https://aakinshin.net/posts/tukey-outlier-probability/</link><pubDate>Tue, 01 Mar 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/tukey-outlier-probability/</guid><description>&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Outlier#Tukey's_fences">Tukey&amp;rsquo;s fences&lt;/a> is one of the most popular
simple outlier detectors for one-dimensional number arrays.
This approach assumes that for a given sample, we calculate first and third quartiles ($Q_1$ and $Q_3$),
and mark all the sample elements outside the interval&lt;/p>
$$
[Q_1 - k (Q_3 - Q_1),\, Q_3 + k (Q_3 - Q_1)]
$$
&lt;p>as outliers.
Typical recommendation for $k$ is $1.5$ for &amp;ldquo;regular&amp;rdquo; outliers and $3.0$ for &amp;ldquo;far outliers&amp;rdquo;.
Here is a box plot example for a sample taken from the standard normal distributions (sample size is $1000$):&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/tukey-outlier-probability/img/boxplot1-light.png" target="_blank" alt="boxplot1">
 &lt;img
 src="https://aakinshin.net/posts/tukey-outlier-probability/img/boxplot1-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/tukey-outlier-probability/img/boxplot1-dark.png" target="_blank" alt="boxplot1">
 &lt;img
 src="https://aakinshin.net/posts/tukey-outlier-probability/img/boxplot1-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>As we can see, 11 elements were marked as outliers (shown as dots).
Is it an expected result or not?
The answer depends on your goals.
There is no single definition of an outlier.
In fact, the chosen outlier detector provides a unique outlier definition.&lt;/p>
&lt;p>In my applications, I typically consider outliers as rare events that should be investigated.
When I detect too many outliers, all such reports become useless noise.
For example, on the above image, I wouldn&amp;rsquo;t treat any of the sample elements as outliers.
However, If we add $10.0$ to this sample, this element is an obvious outlier (which will be the only one):&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/tukey-outlier-probability/img/boxplot2-light.png" target="_blank" alt="boxplot2">
 &lt;img
 src="https://aakinshin.net/posts/tukey-outlier-probability/img/boxplot2-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/tukey-outlier-probability/img/boxplot2-dark.png" target="_blank" alt="boxplot2">
 &lt;img
 src="https://aakinshin.net/posts/tukey-outlier-probability/img/boxplot2-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>Thus, an important property of an outlier detector is the &amp;ldquo;false positive rate&amp;rdquo;:
the percentage of samples with detected outliers which I wouldn&amp;rsquo;t treat as outliers.
In this post, I perform numerical simulations that show the probability of observing outliers
using Tukey&amp;rsquo;s fences with different $k$ values.&lt;/p></description></item><item><title>Gamma effect size powered by the middle non-zero quantile absolute deviation</title><link>https://aakinshin.net/posts/gamma-es-mnzqad/</link><pubDate>Tue, 22 Feb 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/gamma-es-mnzqad/</guid><description>&lt;p>In &lt;a href="https://aakinshin.net/tags/research-gamma-es/">previous posts&lt;/a>, I covered the concept of the gamma effect size.
It&amp;rsquo;s a nonparametric effect size which is consistent with Cohen&amp;rsquo;s d under the normal distribution.
However, the original definition has drawbacks: this statistic becomes zero
if half of the sample elements are equal to each other.
Last time, I &lt;a href="https://aakinshin.net/posts/zero-mad-gamma-es/">suggested&lt;/a>) a workaround for this problem:
we can replace the median absolute deviation by the &lt;a href="https://aakinshin.net/posts/qad/">quantile absolute deviation&lt;/a>.
Unfortunately, this trick requires parameter tuning:
we should choose a proper quantile position to make this approach work.
Today I want to suggest a strategy that provides a way to make a generic choice:
we can use the &lt;a href="https://aakinshin.net/posts/mnzqad/">middle non-zero quantile absolute deviation&lt;/a>.&lt;/p></description></item><item><title>Middle non-zero quantile absolute deviation</title><link>https://aakinshin.net/posts/mnzqad/</link><pubDate>Tue, 15 Feb 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/mnzqad/</guid><description>&lt;p>Median absolute deviation ($\operatorname{MAD}$) around the median is a popular robust measure of statistical dispersion.
Unfortunately, if we &lt;a href="https://aakinshin.net/posts/discrete-performance-distributions/">work&lt;/a> with discrete distributions,
we could get zero $\operatorname{MAD}$ values.
It could bring some problems if we &lt;a href="https://aakinshin.net/posts/zero-mad-gamma-es/">use&lt;/a> $\operatorname{MAD}$ as a denominator.
Such a problem is also relevant to some other quantile-based measures of dispersion
like interquartile range ($\operatorname{IQR}$).&lt;/p>
&lt;p>This problem could be solved using the &lt;a href="https://aakinshin.net/posts/qad/">quantile absolute deviation&lt;/a> around the median.
However, it&amp;rsquo;s not always clear how to choose the right quantile to estimate.
In this post, I&amp;rsquo;m going to suggest a choosing approach that is consistent with the classic $\operatorname{MAD}$
under continuous distributions (and samples without tied values).&lt;/p></description></item><item><title>Unbiased median absolute deviation based on the trimmed Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/unbiased-mad-thd/</link><pubDate>Tue, 08 Feb 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/unbiased-mad-thd/</guid><description>&lt;p>The &lt;a href="https://en.wikipedia.org/wiki/Median_absolute_deviation">median absolute deviation&lt;/a> ($\operatorname{MAD}$)
is a robust measure of scale.
For a sample $x = \{ x_1, x_2, \ldots, x_n \}$, it&amp;rsquo;s defined as follows:&lt;/p>
$$
\operatorname{MAD}_n = C_n \cdot \operatorname{median}(|x - \operatorname{median}(x)|)
$$
&lt;p>where $\operatorname{median}$ is a median estimator, $C_n$ is a scale factor.
Using the right scale factor, we can use $\operatorname{MAD}$ as a consistent estimator
for the estimation of the standard deviation under the normal distribution.
For huge samples, we can use the asymptotic value of $C_n$ which is&lt;/p>
$$
C_\infty = \dfrac{1}{\Phi^{-1}(3/4)} \approx 1.4826022185056.
$$
&lt;p>For small samples, we should use adjusted values $C_n$ which depend on the sample size.
However, $C_n$ depends not only on the sample size but also on the median estimator.
I have already covered how to obtain this values for
&lt;a href="https://aakinshin.net/posts/unbiased-mad/">the traditional median estimator&lt;/a> and
&lt;a href="https://aakinshin.net/posts/unbiased-mad-hd/">the Harrell-Davis median estimator&lt;/a>.
It&amp;rsquo;s time to get the $C_n$ values for
&lt;a href="https://aakinshin.net/posts/preprint-thdqe/">the trimmed Harrell-Davis median estimator&lt;/a>.&lt;/p></description></item><item><title>Median absolute deviation vs. Shamos estimator</title><link>https://aakinshin.net/posts/mad-vs-shamos/</link><pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/mad-vs-shamos/</guid><description>&lt;p>There are multiple ways to estimate statistical dispersion.
The standard deviation is the most popular one, but it&amp;rsquo;s not robust:
a single outlier could heavily corrupt the results.
Fortunately, we have robust measures of dispersions like the &lt;em>median absolute deviation&lt;/em> and the &lt;em>Shamos estimator&lt;/em>.
In this post, we perform numerical simulations and
compare these two estimators on different distributions and sample sizes.&lt;/p></description></item><item><title>Moving extended P² quantile estimator</title><link>https://aakinshin.net/posts/moving-ex-p2-quantile-estimator/</link><pubDate>Tue, 25 Jan 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/moving-ex-p2-quantile-estimator/</guid><description>&lt;p>In the previous posts, I discussed
&lt;a href="https://aakinshin.net/posts/p2-quantile-estimator/">the P² quantile estimator&lt;/a>
(a sequential estimator which takes $O(1)$ memory and estimates a single predefined quantile),
&lt;a href="https://aakinshin.net/posts/mp2-quantile-estimator/">the moving P² quantile estimator&lt;/a>
(a moving modification of P² which estimates quantiles within the moving window),
and &lt;a href="https://aakinshin.net/posts/ex-p2-quantile-estimator/">the extended P² quantile estimator&lt;/a>
(a sequential estimator which takes $O(m)$ memory and estimates $m$ predefined quantiles).&lt;/p>
&lt;p>Now it&amp;rsquo;s time to build &lt;em>the moving modification of the extended P² quantile estimator&lt;/em>
which estimates $m$ predefined quantiles using $O(m)$ memory within the moving window.&lt;/p></description></item><item><title>Extended P² quantile estimator</title><link>https://aakinshin.net/posts/ex-p2-quantile-estimator/</link><pubDate>Tue, 18 Jan 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/ex-p2-quantile-estimator/</guid><description>&lt;p>I already covered &lt;em>the P² quantile estimator&lt;/em> and its possible implementation improvements
in &lt;a href="https://aakinshin.net/tags/research-p2qe/">several blog posts&lt;/a>.
This sequential estimator uses $O(1)$ memory and allows estimating a single predefined quantile.
Now it&amp;rsquo;s time to discuss &lt;em>the extended P² quantile estimator&lt;/em> that allows estimating multiple predefined quantiles.
This extended version was suggested in the paper
&lt;a href="https://doi.org/10.1177/003754978704900405">&amp;ldquo;Simultaneous estimation of several percentiles&amp;rdquo;&lt;/a>.
In this post, we briefly discuss the approach from this paper and how we can improve its implementation.&lt;/p></description></item><item><title>P² quantile estimator marker adjusting order</title><link>https://aakinshin.net/posts/p2-quantile-estimator-adjusting-order/</link><pubDate>Tue, 11 Jan 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/p2-quantile-estimator-adjusting-order/</guid><description>&lt;p>I have already written a few blog posts about the P² quantile estimator
(which is a sequential estimator that uses $O(1)$ memory):&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aakinshin.net/posts/p2-quantile-estimator/">&lt;svg class="rating-icon">&lt;use xlink:href="https://aakinshin.net/img/fa/all.svg#note">&lt;/use>&lt;/svg>P² quantile estimator&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aakinshin.net/posts/p2-quantile-estimator-rounding-issue/">&lt;svg class="rating-icon">&lt;use xlink:href="https://aakinshin.net/img/fa/all.svg#note">&lt;/use>&lt;/svg>P² quantile estimator rounding issue&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aakinshin.net/posts/p2-quantile-estimator-initialization/">&lt;svg class="rating-icon">&lt;use xlink:href="https://aakinshin.net/img/fa/all.svg#note">&lt;/use>&lt;/svg>P² quantile estimator initialization strategy&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>In this post, we continue improving the P² implementation
so that it gives better estimations for streams with a small number of elements.&lt;/p></description></item><item><title>P² quantile estimator initialization strategy</title><link>https://aakinshin.net/posts/p2-quantile-estimator-initialization/</link><pubDate>Tue, 04 Jan 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/p2-quantile-estimator-initialization/</guid><description>&lt;p>&lt;strong>Update: the estimator accuracy could be improved using a bunch of &lt;a href="https://aakinshin.net/tags/research-p2qe/">patches&lt;/a>.&lt;/strong>&lt;/p>
&lt;p>The P² quantile estimator is a sequential estimator that uses $O(1)$ memory.
Thus, for the given sequence of numbers, it allows estimating quantiles without storing values.
I have already written a few blog posts about it:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aakinshin.net/posts/p2-quantile-estimator/">&lt;svg class="rating-icon">&lt;use xlink:href="https://aakinshin.net/img/fa/all.svg#note">&lt;/use>&lt;/svg>P² quantile estimator&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aakinshin.net/posts/p2-quantile-estimator-rounding-issue/">&lt;svg class="rating-icon">&lt;use xlink:href="https://aakinshin.net/img/fa/all.svg#note">&lt;/use>&lt;/svg>P² quantile estimator rounding issue&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>I tried this estimator in various contexts, and it shows pretty decent results.
However, recently I stumbled on a corner case:
if we want to estimate extreme quantile ($p &lt; 0.1$ or $p > 0.9$),
this estimator provides inaccurate results on small number streams ($n &lt; 10$).
While it looks like a minor issue, it would be nice to fix it.
In this post, we briefly discuss choosing a better initialization strategy to workaround this problem.&lt;/p></description></item><item><title>Misleading geometric mean</title><link>https://aakinshin.net/posts/misleading-geometric-mean/</link><pubDate>Tue, 28 Dec 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/misleading-geometric-mean/</guid><description>&lt;p>There are multiple ways to compute the &amp;ldquo;average&amp;rdquo; value of an array of numbers.
One of such ways is the &lt;em>geometric mean&lt;/em>.
For a sample $x = \{ x_1, x_2, \ldots, x_n \}$, the geometric means is defined as follows:&lt;/p>
$$
\operatorname{GM}(x) = \sqrt[n]{x_1 x_2 \ldots x_n}
$$
&lt;p>This approach is widely recommended for some specific tasks.
Let&amp;rsquo;s say we want to compare the performance of two machines $M_x$ and $M_y$.
In order to do this, we design a set of benchmarks $b = \{b_1, b_2, \ldots, b_n \}$
and obtain two sets of measurements
$x = \{ x_1, x_2, \ldots, x_n \}$ and $y = \{ y_1, y_2, \ldots, y_n \}$.
Once we have these two samples, we may have a desire to express the difference
between two machines as a single number and get a conclusion like
&amp;ldquo;Machine $M_y$ works two times faster than $M_x$.&amp;rdquo;
I think that this approach is flawed because such a difference couldn&amp;rsquo;t be expressed as a single number:
the result heavily depends on the workloads that we analyze.
For example, imagine that $M_x$ is a machine with HDD and fast CPU, $M_y$ is a machine with SSD and slow CPU.
In this case, $M_x$ could be faster on CPU-bound workloads while $M_y$ could be faster on disk-bound workloads.
I really like this summary from
&lt;a href="https://www.eecs.umich.edu/techreports/cse/95/CSE-TR-231-95.pdf">&amp;ldquo;Notes on Calculating Computer Performance&amp;rdquo;&lt;/a>
by Bruce Jacob and Trevor Mudge (in the same paper, the authors criticize the approach with the geometric mean):&lt;/p>
&lt;blockquote>
&lt;p>Performance is therefore not a single number, but really a collection of implications.
It is nothing more or less than the measure of
how much time &lt;em>we&lt;/em> save running &lt;em>our&lt;/em> tests on the machines in question.
If someone else has similar needs to ours, our performance numbers will be useful to them.
However, two people with different sets of criteria will likely walk away
with two completely different performance numbers for the same machine.&lt;/p>
&lt;/blockquote>
&lt;p>However, some other authors (e.g., &lt;a href="https://doi.org/10.1145/5666.5673">&amp;ldquo;How not to lie with statistics: the correct way to summarize benchmark results&amp;rdquo;&lt;/a>)
actually recommend using the geometric mean to get such a number
that describes the performance ratio of $M_x$ and $M_y$.
I have to admit that the geometric mean &lt;em>could&lt;/em> provide a reasonable result in &lt;em>some simple cases&lt;/em>.
Indeed, on normalized numbers, it works much better than the arithmetic mean
(that provides meaningless result) because of its nice &lt;a href="https://en.wikipedia.org/wiki/Geometric_mean#Application_to_normalized_values">property&lt;/a>:
$\operatorname{GM}(x_i/y_i) = \operatorname{GM}(x_i) / \operatorname{GM}(y_i)$.
However, it doesn&amp;rsquo;t work properly in the general case.
Firstly, the desire to express the difference between two machines is vicious:
the result heavily depends on the chosen workloads.
Secondly, the performance of a single benchmark $b_i$ couldn&amp;rsquo;t be described as a single number $x_i$:
we should consider the whole performance distributions.
In order to describe the difference between two distributions,
we could consider the &lt;a href="https://aakinshin.net/posts/shift-and-ratio-functions/">shift and ration functions&lt;/a>
(that work much better than the &lt;a href="https://aakinshin.net/posts/shift-function-vs-distribution/">shift&lt;/a> and
&lt;a href="https://aakinshin.net/posts/ratio-function-vs-distribution/">ratio&lt;/a> distributions).&lt;/p>
&lt;p>Even if you consider a pretty homogenous set of benchmarks and all the distributions are pretty narrow,
the geometric mean has severe drawbacks that you should keep in mind.
In this post, I briefly cover some of these drawbacks and highlight problems that you may have if you use this metric.&lt;/p></description></item><item><title>Matching quantile sets using likelihood based on the binomial coefficients</title><link>https://aakinshin.net/posts/binomial-quantile-likelihood/</link><pubDate>Tue, 21 Dec 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/binomial-quantile-likelihood/</guid><description>&lt;p>Let&amp;rsquo;s say we have a distribution $X$ that is given by its $s$-quantile values:&lt;/p>
$$
q_{X_1} = Q_X(p_1),\; q_{X_2} = Q_X(p_2),\; \ldots,\; q_{X_{s-1}} = Q_X(p_{s-1})
$$
&lt;p>where $Q_X$ is the quantile function of $X$, $p_j = j / s$.&lt;/p>
&lt;p>We also have a sample $y = \{y_1, y_2, \ldots, y_n \}$ that is given by its $s$-quantile estimations:&lt;/p>
$$
q_{y_1} = Q_y(p_1),\; q_{y_2} = Q_y(p_2),\; \ldots,\; q_{y_{s-1}} = Q_y(p_{s-1}),
$$
&lt;p>where $Q_y$ is the quantile estimation function for sample $y$.
We also assume that $q_{y_0} = \min(y)$, $q_{y_s} = \max(y)$.&lt;/p>
&lt;p>We want to know the likelihood of &amp;ldquo;$y$ is drawn from $X$&amp;rdquo;.
In this post, I want to suggest a nice way to do this using the binomial coefficients.&lt;/p></description></item><item><title>Ratio function vs. ratio distribution</title><link>https://aakinshin.net/posts/ratio-function-vs-distribution/</link><pubDate>Tue, 14 Dec 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/ratio-function-vs-distribution/</guid><description>&lt;p>Let&amp;rsquo;s say we have two distributions $X$ and $Y$.
In the &lt;a href="https://aakinshin.net/posts/shift-function-vs-distribution/">previous post&lt;/a>,
we discussed how to express the &amp;ldquo;absolute difference&amp;rdquo; between them
using the shift function and the shift distribution.
Now let&amp;rsquo;s discuss how to express the &amp;ldquo;relative difference&amp;rdquo; between them.
This abstract term also could be expressed in various ways.
My favorite approach is to build the &lt;a href="https://aakinshin.net/posts/shift-and-ratio-functions/">ratio function&lt;/a>.
In order to do this, for each quantile $p$, we should calculate $Q_Y(p)/Q_X(p)$ where $Q$ is the quantile function.
However, some people prefer using the &lt;a href="https://en.wikipedia.org/wiki/Ratio_distribution">ratio distribution&lt;/a> $Y/X$.
While both approaches may provide similar results for narrow positive non-overlapping distributions,
they are not equivalent in the general case.
In this post, we briefly consider examples of both approaches.&lt;/p></description></item><item><title>Shift function vs. shift distribution</title><link>https://aakinshin.net/posts/shift-function-vs-distribution/</link><pubDate>Tue, 07 Dec 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/shift-function-vs-distribution/</guid><description>&lt;p>Let&amp;rsquo;s say we have two distributions $X$ and $Y$,
and we want to express the &amp;ldquo;absolute difference&amp;rdquo; between them.
This abstract term could be expressed in various ways.
My favorite approach is to build the &lt;a href="https://aakinshin.net/posts/shift-and-ratio-functions/">Doksum&amp;rsquo;s shift function&lt;/a>.
In order to do this, for each quantile $p$, we should calculate $Q_Y(p)-Q_X(p)$ where $Q$ is the quantile function.
However, some people prefer using the shift distribution $Y-X$.
While both approaches may provide similar results for narrow non-overlapping distributions,
they are not equivalent in the general case.
In this post, we briefly consider examples of both approaches.&lt;/p></description></item><item><title>Preprint announcement: 'Trimmed Harrell-Davis quantile estimator based on the highest density interval of the given width'</title><link>https://aakinshin.net/posts/preprint-thdqe/</link><pubDate>Tue, 30 Nov 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/preprint-thdqe/</guid><description>&lt;p>&lt;strong>Update: the &lt;a href="https://aakinshin.net/posts/pub-thdqe/">final paper&lt;/a> was published in &lt;em>Communications in Statistics - Simulation and Computation&lt;/em> (DOI: &lt;a href="https://www.tandfonline.com/doi/abs/10.1080/03610918.2022.2050396">10.1080/03610918.2022.2050396&lt;/a>).&lt;/strong>&lt;/p>
&lt;p>Since the beginning of this year, I have been working on building a quantile estimator
that provides an optimal trade-off between statistical efficiency and robustness.
Finally, I have built such an estimator.
A paper preprint is available on arXiv:
&lt;a href="https://arxiv.org/abs/2111.11776">arXiv:2111.11776 [stat.ME]&lt;/a>.
The paper source code is available on GitHub:
&lt;a href="https://github.com/AndreyAkinshin/paper-thdqe">AndreyAkinshin/paper-thdqe&lt;/a>.
You can cite it as follows:&lt;/p>
&lt;ul>
&lt;li>Andrey Akinshin (2021)
Trimmed Harrell-Davis quantile estimator based on the highest density interval of the given width,
&lt;a href="https://arxiv.org/abs/2111.11776">arXiv:2111.11776&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Non-normal median sampling distribution</title><link>https://aakinshin.net/posts/non-normal-median-distribution/</link><pubDate>Tue, 23 Nov 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/non-normal-median-distribution/</guid><description>&lt;p>Let&amp;rsquo;s consider the classic sample median.
If a sample is sorted and the number of sample elements is odd, the median is the middle element.
In the case of an even number of sample elements, the median is an arithmetic average of the two middle elements.&lt;/p>
&lt;p>Now let&amp;rsquo;s say we randomly take many samples from the same distribution and calculate the median for each of them.
Next, we build a sampling distribution based on these median values.
There is a well-known fact that this distribution is asymptotically normal with mean $M$ and variance $1/(4nf^2(M))$,
where $n$ is the number of elements in samples,
$f$ is the probability density function of the original distribution,
and $M$ is the true median of the original distribution.&lt;/p>
&lt;p>Unfortunately, if we try to build such sampling distributions in practice,
we may see that they are not always normal.
There are some corner cases that prevent us from using the normal model in general.
If you implement general routines that analyze the median behavior,
you should keep such cases in mind.
In this post, we briefly talk about some of these cases.&lt;/p></description></item><item><title>Misleading kurtosis</title><link>https://aakinshin.net/posts/misleading-kurtosis/</link><pubDate>Tue, 16 Nov 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/misleading-kurtosis/</guid><description>&lt;p>I already discussed misleadingness of such metrics like
&lt;a href="https://aakinshin.net/posts/misleading-stddev/">standard deviation&lt;/a> and &lt;a href="https://aakinshin.net/posts/misleading-skewness/">skewness&lt;/a>.
It&amp;rsquo;s time to discuss misleadingness of the measure of tailedness: kurtosis
(which, sometimes, could be incorrectly interpreted as a measure of peakedness).
Typically, the concept of kurtosis is explained with the help of images like this:&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/misleading-kurtosis/img/kurt_intro-light.png" target="_blank" alt="kurt_intro">
 &lt;img
 src="https://aakinshin.net/posts/misleading-kurtosis/img/kurt_intro-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/misleading-kurtosis/img/kurt_intro-dark.png" target="_blank" alt="kurt_intro">
 &lt;img
 src="https://aakinshin.net/posts/misleading-kurtosis/img/kurt_intro-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>Unfortunately, the raw kurtosis value may provide wrong insights about distribution properties.
In this post, we briefly discuss the sources of its misleadingness:&lt;/p>
&lt;ul>
&lt;li>There are multiple definitions of kurtosis.
The most significant confusion arises between &amp;ldquo;kurtosis&amp;rdquo; and &amp;ldquo;excess kurtosis,&amp;rdquo;
but there are other definitions of this measure.&lt;/li>
&lt;li>Kurtosis may work fine for unimodal distributions, but it performs not so clear for multimodal distributions.&lt;/li>
&lt;li>The classic definition of kurtosis is not robust: it could be easily spoiled by extreme outliers.&lt;/li>
&lt;/ul></description></item><item><title>Misleading skewness</title><link>https://aakinshin.net/posts/misleading-skewness/</link><pubDate>Tue, 09 Nov 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/misleading-skewness/</guid><description>&lt;p>Skewness is a commonly used measure of the asymmetry of the probability distributions.
A typical skewness interpretation comes down to an image like this:&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/misleading-skewness/img/skew_intro-light.png" target="_blank" alt="skew_intro">
 &lt;img
 src="https://aakinshin.net/posts/misleading-skewness/img/skew_intro-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/misleading-skewness/img/skew_intro-dark.png" target="_blank" alt="skew_intro">
 &lt;img
 src="https://aakinshin.net/posts/misleading-skewness/img/skew_intro-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>It looks extremely simple: using the skewness sign,
we get an idea of the distribution form and the arrangement of the mean and the median.
Unfortunately, it doesn&amp;rsquo;t always work as expected.
Skewness estimation could be a highly misleading metric
(even more misleading than the &lt;a href="https://aakinshin.net/posts/misleading-stddev/">standard deviation&lt;/a>).
In this post, I discuss four sources of its misleadingness:&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;Skewness&amp;rdquo; is a generic term; it has multiple definitions.
When a skewness value is presented, you can&amp;rsquo;t always guess the underlying equation without additional details.&lt;/li>
&lt;li>Skewness is &amp;ldquo;designed&amp;rdquo; for unimodal distributions; it&amp;rsquo;s meaningless in the case of multimodality.&lt;/li>
&lt;li>Most default skewness definitions are not robust: a single outlier could completely distort the skewness value.&lt;/li>
&lt;li>We can&amp;rsquo;t make conclusions about the locations of the mean and the median based on the skewness sign.&lt;/li>
&lt;/ul></description></item><item><title>Greenwald-Khanna quantile estimator</title><link>https://aakinshin.net/posts/greenwald-khanna-quantile-estimator/</link><pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/greenwald-khanna-quantile-estimator/</guid><description>&lt;p>The Greenwald-Khanna quantile estimator is a classic sequential quantile estimator
which has the following features:&lt;/p>
&lt;ul>
&lt;li>It allows estimating quantiles with respect to the given precision $\epsilon$.&lt;/li>
&lt;li>It requires $O(\frac{1}{\epsilon} log(\epsilon N))$ memory in the worst case.&lt;/li>
&lt;li>It doesn&amp;rsquo;t require knowledge of the total number of elements in the sequence
and the positions of the requested quantiles.&lt;/li>
&lt;/ul>
&lt;p>In this post,
I briefly explain the basic idea of the underlying data structure,
and share a copy-pastable C# implementation.
At the end of the post, I discuss some important implementation decisions
that are unclear from the original paper,
but heavily affect the estimator accuracy.&lt;/p></description></item><item><title>P² quantile estimator rounding issue</title><link>https://aakinshin.net/posts/p2-quantile-estimator-rounding-issue/</link><pubDate>Tue, 26 Oct 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/p2-quantile-estimator-rounding-issue/</guid><description>&lt;p>&lt;strong>Update: the estimator accuracy could be improved using a bunch of &lt;a href="https://aakinshin.net/tags/research-p2qe/">patches&lt;/a>.&lt;/strong>&lt;/p>
&lt;p>The P² quantile estimator is a sequential estimator that uses $O(1)$ memory.
Thus, for the given sequence of numbers, it allows estimating quantiles without storing values.
I already wrote &lt;a href="https://aakinshin.net/posts/p2-quantile-estimator/">a blog post&lt;/a> about this approach and
&lt;a href="https://github.com/AndreyAkinshin/perfolizer/commit/9e9ff80a4d097fe4c0814ca51c7fbe942763e308">added&lt;/a>
its implementation in &lt;a href="https://github.com/AndreyAkinshin/perfolizer">perfolizer&lt;/a>.
Recently, I got a &lt;a href="https://github.com/AndreyAkinshin/perfolizer/issues/8">bug report&lt;/a>
that revealed a flaw of the &lt;a href="https://doi.org/10.1145/4372.4378">original paper&lt;/a>.
In this post, I&amp;rsquo;m going to briefly discuss this issue and the corresponding fix.&lt;/p></description></item><item><title>Trimmed Harrell-Davis quantile estimator based on the highest density interval of the given width</title><link>https://aakinshin.net/posts/thdqe-hdi/</link><pubDate>Tue, 19 Oct 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/thdqe-hdi/</guid><description>&lt;p>Traditional quantile estimators that are based on one or two order statistics are a common way to estimate
distribution quantiles based on the given samples.
These estimators are robust, but their statistical efficiency is not always good enough.
A more efficient alternative is the Harrell-Davis quantile estimator which uses
a weighted sum of all order statistics.
Whereas this approach provides more accurate estimations for the light-tailed distributions, it&amp;rsquo;s not robust.
To be able to customize the trade-off between statistical efficiency and robustness,
we could consider &lt;em>a trimmed modification of the Harrell-Davis quantile estimator&lt;/em>.
In this approach, we discard order statistics with low weights according to
the highest density interval of the beta distribution.&lt;/p></description></item><item><title>Optimal window of the trimmed Harrell-Davis quantile estimator, Part 2: Trying Planck-taper window</title><link>https://aakinshin.net/posts/thdqe-ow2/</link><pubDate>Tue, 12 Oct 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/thdqe-ow2/</guid><description>&lt;p>In the &lt;a href="https://aakinshin.net/posts/thdqe-ow1/">previous post&lt;/a>,
I discussed the problem of non-smooth quantile-respectful density estimation (QRDE)
which is generated by the trimmed Harrell-Davis quantile estimator
based on the highest density interval of the given width.
I assumed that non-smoothness was caused by a non-smooth rectangular window
which was used to build the truncated beta distribution.
In this post, we are going to try another option: the Planck-taper window.&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/thdqe-ow2/img/qrde-light.png" target="_blank" alt="qrde">
 &lt;img
 src="https://aakinshin.net/posts/thdqe-ow2/img/qrde-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/thdqe-ow2/img/qrde-dark.png" target="_blank" alt="qrde">
 &lt;img
 src="https://aakinshin.net/posts/thdqe-ow2/img/qrde-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div></description></item><item><title>Optimal window of the trimmed Harrell-Davis quantile estimator, Part 1: Problems with the rectangular window</title><link>https://aakinshin.net/posts/thdqe-ow1/</link><pubDate>Tue, 05 Oct 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/thdqe-ow1/</guid><description>&lt;p>In the previous post, we have obtained a nice version of the trimmed Harrell-Davis quantile estimator
which provides an opportunity to get a nice trade-off between robustness and statistical efficiency
of quantile estimations.
Unfortunately, it has a severe drawback.
If we build a &lt;a href="https://aakinshin.net/posts/qrde-hd/">quantile-respectful density estimation&lt;/a> based on the suggested estimator,
we won&amp;rsquo;t get a smooth density function as in the case of the classic Harrell-Davis quantile estimator:&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/thdqe-ow1/img/qrde-light.png" target="_blank" alt="qrde">
 &lt;img
 src="https://aakinshin.net/posts/thdqe-ow1/img/qrde-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/thdqe-ow1/img/qrde-dark.png" target="_blank" alt="qrde">
 &lt;img
 src="https://aakinshin.net/posts/thdqe-ow1/img/qrde-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>In this blog post series, we are going to find a way to improve the trimmed Harrell-Davis quantile estimator
so that it gives a smooth density function and keeps its advantages in terms of robustness and statistical efficiency.&lt;/p></description></item><item><title>Beta distribution highest density interval of the given width</title><link>https://aakinshin.net/posts/beta-hdi/</link><pubDate>Tue, 28 Sep 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/beta-hdi/</guid><description>&lt;p>In one of &lt;a href="https://aakinshin.net/posts/kosqe5/">the previous posts&lt;/a>, I discussed the idea of the trimmed Harrell-Davis quantile estimator
based on the highest density interval of the given width.
Since the Harrell-Davis quantile estimator uses the Beta distribution,
we should be able to find the beta distribution highest density interval of the given width.
In this post, I will show how to do this.&lt;/p></description></item><item><title>Quantile estimators based on k order statistics, Part 8: Winsorized Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/kosqe8/</link><pubDate>Tue, 21 Sep 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/kosqe8/</guid><description>&lt;p>In the &lt;a href="https://aakinshin.net/posts/kosqe7/">previous post&lt;/a>, we have discussed
the trimmed modification of the Harrell-Davis quantile estimator
based on the highest density interval of size $\sqrt{n}/n$.
This quantile estimator showed a decent level of statistical efficiency.
However, the research wouldn&amp;rsquo;t be complete without comparison with the winsorized modification.
Let&amp;rsquo;s fix it!&lt;/p></description></item><item><title>Quantile estimators based on k order statistics, Part 7: Optimal threshold for the trimmed Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/kosqe7/</link><pubDate>Tue, 14 Sep 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/kosqe7/</guid><description>&lt;p>In the &lt;a href="https://aakinshin.net/posts/kosqe6/">previous post&lt;/a>, we have obtained a nice quantile estimator.
To be specific, we considered a trimmed modification of the Harrell-Davis quantile estimator
based on the highest density interval of the given size.
The interval size is a parameter that controls the trade-off between statistical efficiency and robustness.
While it&amp;rsquo;s nice to have the ability to control this trade-off, there is also a need for the default value,
which could be used as a starting point
when we have neither estimator breakdown point requirements nor prior knowledge about distribution properties.&lt;/p>
&lt;p>After a series of unsuccessful attempts, it seems that I have found an acceptable solution.
We should build the new estimator based on $\sqrt{n}/n$ order statistics.
In this post, I&amp;rsquo;m going to briefly explain the idea behind the suggested estimator and
share some numerical simulations that compare the proposed estimator
and the classic Harrell-Davis quantile estimator.&lt;/p></description></item><item><title>Quantile estimators based on k order statistics, Part 6: Continuous trimmed Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/kosqe6/</link><pubDate>Tue, 07 Sep 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/kosqe6/</guid><description>&lt;p>In my &lt;a href="https://aakinshin.net/posts/kosqe5/">previous post&lt;/a>,
I tried the idea of using the trimmed modification of the Harrell-Davis quantile estimator
based on the highest density interval of the given width.
The width was defined so that it covers exactly k order statistics (the width equals $(k-1)/n$).
I was pretty satisfied with the result and decided to continue evolving this approach.
While &amp;ldquo;k order statistics&amp;rdquo; is a good mental model that described the trimmed interval,
it doesn&amp;rsquo;t actually require an integer k.
In fact, we can use any real number as the trimming percentage.&lt;/p>
&lt;p>In this post, we are going to perform numerical simulations that check the statistical efficiency
of the trimmed Harrell-Davis quantile estimator with different trimming percentages.&lt;/p></description></item><item><title>Quantile estimators based on k order statistics, Part 5: Improving trimmed Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/kosqe5/</link><pubDate>Tue, 31 Aug 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/kosqe5/</guid><description>&lt;p>During the last several months,
I have been experimenting with different variations of the trimmed Harrell-Davis quantile estimator.
&lt;a href="https://aakinshin.net/posts/trimmed-hdqe/">My original idea&lt;/a>
of using the highest density interval based on the fixed area percentage (e.g., HDI 95% or HDI 99%)
led to a set of problems with &lt;a href="https://aakinshin.net/posts/thdqe-overtrimming/">overtrimming&lt;/a>.
I tried to solve them with &lt;a href="https://aakinshin.net/posts/customized-wthdqe/">manually customized&lt;/a> trimming strategy,
but this approach turned out to be too inconvenient;
it was too hard to come up with &lt;a href="https://aakinshin.net/posts/thdqe-threshold/">optimal thresholds&lt;/a>.
One of the main problems was about the suboptimal number of elements
that we actually aggregate to obtain the quantile estimation.
So, I decided to try an &lt;a href="https://aakinshin.net/posts/kosqe1/">approach that involves exactly k order statistics&lt;/a>.
The idea was so promising,
but numerical simulations &lt;a href="https://aakinshin.net/posts/kosqe4/">haven&amp;rsquo;t shown&lt;/a> the appropriate efficiency level.&lt;/p>
&lt;p>This bothered me the whole week.
It sounded so reasonable to trim the Harrell-Davis quantile estimator using exactly k order statistics.
Why didn&amp;rsquo;t this work as expected?
Finally, I have found a fatal flaw in &lt;a href="https://aakinshin.net/posts/kosqe4/">my previous approach&lt;/a>:
while it was a good idea to fix the size of the trimming window,
I mistakenly chose its location following the equation from the Hyndman-Fan Type 7 quantile estimator!&lt;/p>
&lt;p>In this post, we fix this problem and try another modification of the trimmed Harrell-Davis quantile estimator based on
k order statistics &lt;strong>and&lt;/strong> highest density intervals at the same time.&lt;/p></description></item><item><title>Quantile estimators based on k order statistics, Part 4: Adopting trimmed Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/kosqe4/</link><pubDate>Tue, 24 Aug 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/kosqe4/</guid><description>&lt;p>In the previous posts, I discussed various aspects of
&lt;a href="https://aakinshin.net/posts/kosqe1/">quantile estimators based on k order statistics&lt;/a>.
I already tried a few weight functions that aggregate the sample values to the quantile estimators
(see posts about &lt;a href="https://aakinshin.net/posts/kosqe2/">an extension of the Hyndman-Fan Type 7 equation&lt;/a> and
about &lt;a href="https://aakinshin.net/posts/kosqe3/">adjusted regularized incomplete beta function&lt;/a>).
In this post, I continue my experiments and try to adopt the
&lt;a href="https://aakinshin.net/posts/trimmed-hdqe/">trimmed modifications of the Harrell-Davis quantile estimator&lt;/a> to this approach.&lt;/p></description></item><item><title>Quantile estimators based on k order statistics, Part 3: Playing with the Beta function</title><link>https://aakinshin.net/posts/kosqe3/</link><pubDate>Tue, 17 Aug 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/kosqe3/</guid><description>&lt;p>In the previous two posts, I discussed the idea of quantile estimators based on k order statistics.
A already covered the &lt;a href="https://aakinshin.net/posts/kosqe1/">motivation behind this idea&lt;/a>
and the statistical efficiency of such estimators using the &lt;a href="https://aakinshin.net/posts/kosqe2/">extended Hyndman-Fan equations&lt;/a>
as a weight function.
Now it&amp;rsquo;s time to experiment with the Beta function as a primary way to aggregate k order statistics
into a single quantile estimation!&lt;/p></description></item><item><title>Quantile estimators based on k order statistics, Part 2: Extending Hyndman-Fan equations</title><link>https://aakinshin.net/posts/kosqe2/</link><pubDate>Tue, 10 Aug 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/kosqe2/</guid><description>&lt;p>In the &lt;a href="https://aakinshin.net/posts/kosqe1/">previous post&lt;/a>,
I described the idea of using quantile estimators based on k order statistics.
Potentially, such estimators could be more robust than estimators based on all samples elements (like
Harrell-Davis,
&lt;a href="https://aakinshin.net/posts/sfakianakis-verginis-quantile-estimator/">Sfakianakis-Verginis&lt;/a>, or
&lt;a href="https://aakinshin.net/posts/navruz-ozdemir-quantile-estimator/">Navruz-Özdemir&lt;/a>)
and more statistically efficient than traditional quantile estimators (based on 1 or 2 order statistics).
Moreover, we should be able to control this trade-off based on the business requirements
(e.g., setting the desired breakdown point).&lt;/p>
&lt;p>The only challenging thing here is choosing the weight function
that aggregates k order statistics to a single quantile estimation.
We are going to try several options, perform Monte-Carlo simulations for each of them, and compare the results.
A reasonable starting point is an extension of the traditional quantile estimators.
In this post, we are going to extend the Hyndman-Fan Type 7 quantile estimator
(nowadays, it&amp;rsquo;s one of the most popular estimators).
It estimates quantiles as a linear interpolation of two subsequent order statistics.
We are going to make some modifications, so a new version is going to be based on k order statistics.&lt;/p>
&lt;p>&lt;strong>Spoiler: this approach doesn&amp;rsquo;t seem like an optimal one.&lt;/strong>
I&amp;rsquo;m pretty disappointed with its statistical efficiency on samples from light-tailed distributions.
So, what&amp;rsquo;s the point of writing a blog post about an inefficient approach?
Because of the following reasons:&lt;/p>
&lt;ol>
&lt;li>I believe it&amp;rsquo;s crucial to share negative results.
Sometimes, knowledge about approaches that don&amp;rsquo;t work
could be more important than knowledge about more effective techniques.
Negative results give you a broader view of the problem
and protect you from wasting your time on potential promising (but not so useful) ideas.&lt;/li>
&lt;li>Negative results improve research completeness.
When we present an approach, it&amp;rsquo;s essential to not only show why it solves problems well,
but also why it solves problems better than other similar approaches.&lt;/li>
&lt;li>While I wouldn&amp;rsquo;t recommend my extension of the Hyndman-Fan Type 7 quantile estimator to the k order statistics case
as the default quantile estimator, there are some specific cases where it could be useful.
For example, if we estimate the median based on small samples from a symmetric light-tailed distribution,
it could outperform not only the original version but also the Harrell-Davis quantile estimator.
The &amp;ldquo;negativity&amp;rdquo; of the negative results always exists in a specific context.
So, there may be cases when negative results for the general case transform to positive results
for a particular niche problem.&lt;/li>
&lt;li>Finally, it&amp;rsquo;s my personal blog, so I have the freedom to write on any topic I like.
My blog posts are not publications to scientific journals (which typically don&amp;rsquo;t welcome negative results),
but rather research notes about conducted experiments.
It&amp;rsquo;s important for me to keep records of all the experiments I perform regardless of the usefulness of the results.&lt;/li>
&lt;/ol>
&lt;p>So, let&amp;rsquo;s briefly look at the results of this not-so-useful approach.&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/kosqe2/img/LightAndHeavy__N15_Efficiency-light.png" target="_blank" alt="LightAndHeavy__N15_Efficiency">
 &lt;img
 src="https://aakinshin.net/posts/kosqe2/img/LightAndHeavy__N15_Efficiency-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/kosqe2/img/LightAndHeavy__N15_Efficiency-dark.png" target="_blank" alt="LightAndHeavy__N15_Efficiency">
 &lt;img
 src="https://aakinshin.net/posts/kosqe2/img/LightAndHeavy__N15_Efficiency-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div></description></item><item><title>Quantile estimators based on k order statistics, Part 1: Motivation</title><link>https://aakinshin.net/posts/kosqe1/</link><pubDate>Tue, 03 Aug 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/kosqe1/</guid><description>&lt;p>It&amp;rsquo;s not easy to choose a good quantile estimator.
In my previous posts, I considered several groups of quantile estimators:&lt;/p>
&lt;ul>
&lt;li>Quantile estimators based 1 or 2 order statistics (Hyndman-Fan Type1-9)&lt;/li>
&lt;li>Quantile estimators based on all order statistics
(the Harrell-Davis quantile estimator,
the &lt;a href="https://aakinshin.net/posts/sfakianakis-verginis-quantile-estimator/">Sfakianakis-Verginis quantile estimator&lt;/a>, and
the &lt;a href="https://aakinshin.net/posts/navruz-ozdemir-quantile-estimator/">Navruz-Özdemir quantile estimator&lt;/a>)&lt;/li>
&lt;li>Quantile estimators based on a variable number of order statistics
(the &lt;a href="https://aakinshin.net/posts/trimmed-hdqe/">trimmed&lt;/a> and &lt;a href="https://aakinshin.net/posts/winsorized-hdqe/">winsorized&lt;/a> modifications
of the Harrell-Davis quantile estimator)&lt;/li>
&lt;/ul>
&lt;p>Unfortunately, all of these estimators have significant drawbacks
(e.g., poor statistical efficiency or poor robustness).
In this post, I want to discuss all of the advantages and disadvantages of each approach
and suggest another family of quantile estimators that are based on k order statistics.&lt;/p></description></item><item><title>Avoiding over-trimming with the trimmed Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/thdqe-overtrimming/</link><pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/thdqe-overtrimming/</guid><description>&lt;p>Previously, I already discussed the
&lt;a href="https://aakinshin.net/posts/trimmed-hdqe/">trimmed modification of the Harrell-Davis quantile estimator&lt;/a> several times.
I performed several numerical simulations that compare the statistical efficiency of this estimator
with the efficiency of the &lt;a href="https://aakinshin.net/posts/wthdqe-efficiency/">classic Harrell-Davis quantile estimator&lt;/a> (HDQE)
and its &lt;a href="https://aakinshin.net/posts/winsorized-hdqe/">winsorized modification&lt;/a>;
I showed how we can improve the efficiency using &lt;a href="https://aakinshin.net/posts/customized-wthdqe/">custom trimming strategies&lt;/a>
and how to choose a &lt;a href="https://aakinshin.net/posts/thdqe-threshold/">good trimming threshold value&lt;/a>.&lt;/p>
&lt;p>In the heavy-tailed cases, the trimmed HDQE provides better estimations than the classic HDQE
because of its higher breakdown point.
However, in the light-tailed cases, we could get efficiency that is worse than
the baseline Hyndman-Fan Type 7 (HF7) quantile estimator.
In many cases, such an effect arises because of the over-trimming effect.
If the trimming percentage is too high or if the evaluated quantile is too far from the median,
the trimming strategy based on the highest-density interval may lead to an estimation
that is based on single order statistics.
In this case, we get an efficiency level similar to the Hyndman-Fan Type 1-3 quantile estimators
(which are also based on single order statistics).
In the light-tailed case, such a result is less preferable than Hyndman-Fan Type 4-9 quantile estimators
(which are based on two subsequent order statistics).&lt;/p>
&lt;p>In order to improve the situation, we could introduce the lower bound for the number of order statistics
that contribute to the final quantile estimations.
In this post, I look at some numerical simulations
that compare trimmed HDQEs with different lower bounds.&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/thdqe-overtrimming/img/LightAndHeavy__N05_Efficiency-light.png" target="_blank" alt="LightAndHeavy__N05_Efficiency">
 &lt;img
 src="https://aakinshin.net/posts/thdqe-overtrimming/img/LightAndHeavy__N05_Efficiency-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/thdqe-overtrimming/img/LightAndHeavy__N05_Efficiency-dark.png" target="_blank" alt="LightAndHeavy__N05_Efficiency">
 &lt;img
 src="https://aakinshin.net/posts/thdqe-overtrimming/img/LightAndHeavy__N05_Efficiency-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div></description></item><item><title>Optimal threshold of the trimmed Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/thdqe-threshold/</link><pubDate>Tue, 20 Jul 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/thdqe-threshold/</guid><description>&lt;p>The traditional quantile estimators (which are based on 1 or 2 order statistics) have great robustness.
However, the statistical efficiency of these estimators is not so great.
The Harrell-Davis quantile estimator has much better efficiency (at least in the light-tailed case),
but it&amp;rsquo;s not robust (because it calculates a weighted sum of all sample values).
I already wrote a &lt;a href="https://aakinshin.net/posts/trimmed-hdqe/">post about trimmed Harrell-Davis quantile estimator&lt;/a>:
this approach suggest dropping some of the low-weight sample values to improve robustness
(keeping good statistical efficiency).
I also perform a numerical simulations that &lt;a href="https://aakinshin.net/posts/wthdqe-efficiency/">compare efficiency&lt;/a>
of the original Harrell-Davis quantile estimator against its trimmed and winsorized modifications.
It&amp;rsquo;s time to discuss how to choose the optimal trimming threshold
and how it affects the estimator efficiency.&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/thdqe-threshold/img/LightAndHeavy__N40_Efficiency-light.png" target="_blank" alt="LightAndHeavy__N40_Efficiency">
 &lt;img
 src="https://aakinshin.net/posts/thdqe-threshold/img/LightAndHeavy__N40_Efficiency-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/thdqe-threshold/img/LightAndHeavy__N40_Efficiency-dark.png" target="_blank" alt="LightAndHeavy__N40_Efficiency">
 &lt;img
 src="https://aakinshin.net/posts/thdqe-threshold/img/LightAndHeavy__N40_Efficiency-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div></description></item><item><title>Estimating quantile confidence intervals: Maritz-Jarrett vs. jackknife</title><link>https://aakinshin.net/posts/maritz-jarrett-vs-jackknife/</link><pubDate>Tue, 13 Jul 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/maritz-jarrett-vs-jackknife/</guid><description>&lt;p>When it comes to estimating quantiles of the given sample,
my estimator of choice is the Harrell-Davis quantile estimator
(to be more specific, its &lt;a href="https://aakinshin.net/posts/trimmed-hdqe/">trimmed version&lt;/a>).
If I need to get a confidence interval for the obtained quantiles,
I use the &lt;a href="https://aakinshin.net/posts/weighted-quantiles-ci/#the-maritz-jarrett-method">Maritz-Jarrett method&lt;/a>
because it provides a &lt;a href="https://aakinshin.net/posts/quantile-ci-coverage/">decent coverage percentage&lt;/a>.
Both approaches work pretty nicely together.&lt;/p>
&lt;p>However, in the original paper by &lt;a href="https://doi.org/10.2307/2335999">Harrell and Davis (1982)&lt;/a>,
the authors suggest using the jackknife variance estimator in order to get the confidence intervals.
The obvious question here is which approach better: the Maritz-Jarrett method or the jackknife estimator?
In this post, I perform a numerical simulation that compares both techniques using different distributions.&lt;/p></description></item><item><title>Using Kish's effective sample size with weighted quantiles</title><link>https://aakinshin.net/posts/kish-ess-weighted-quantiles/</link><pubDate>Tue, 06 Jul 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/kish-ess-weighted-quantiles/</guid><description>&lt;p>In my previous posts, I described how to calculate
&lt;a href="https://aakinshin.net/posts/weighted-quantiles/">weighted quantiles&lt;/a> and
their &lt;a href="https://aakinshin.net/posts/weighted-quantiles-ci/">confidence intervals&lt;/a>
using the Harrell-Davis quantile estimator.
This powerful technique allows applying
&lt;a href="https://aakinshin.net/posts/quantile-exponential-smoothing/">quantile exponential smoothing&lt;/a> and
&lt;a href="https://aakinshin.net/posts/dispersion-exponential-smoothing/">dispersion exponential smoothing&lt;/a> for
time series in order to get its moving properties.&lt;/p>
&lt;p>When we work with weighted samples, we need a way to calculate the
&lt;a href="https://en.wikipedia.org/wiki/Effective_sample_size">effective samples size&lt;/a>.
Previously, I used the sum of all weights normalized by the maximum weight.
In most cases, it worked OK.&lt;/p>
&lt;p>Recently, &lt;a href="https://www.soz.unibe.ch/about_us/people/prof_dr_jann_ben/index_eng.html">Ben Jann&lt;/a> pointed out
that it would be better to use the Kish&amp;rsquo;s formula to calculate the effective sample size.
In this post, you find the formula and a few numerical simulations that illustrate the actual impact of
the underlying sample size formula.&lt;/p></description></item><item><title>Partial binning compression of performance series</title><link>https://aakinshin.net/posts/partial-binning-compression/</link><pubDate>Tue, 29 Jun 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/partial-binning-compression/</guid><description>&lt;p>Let&amp;rsquo;s start with a problem from real life.
Imagine we have thousands of application components that should be initialized.
We care about the total initialization time of the whole application,
so we want to automatically track the slowest components using a continuous integration (CI) system.
The easiest way to do it is to measure the initialization time of each component in each CI build
and save all the measurements to a database.
Unfortunately, if the total number of components is huge, the overall artifact size may be quite extensive.
Thus, this approach may introduce an unwanted negative impact on the database size and data processing time.&lt;/p>
&lt;p>However, we don&amp;rsquo;t actually need all the measurements.
We want to track only the slowest components.
Typically, it&amp;rsquo;s possible to introduce a reasonable threshold that defines such components.
For example, we can say that all components that are initialized in less than 1ms are &amp;ldquo;fast enough,&amp;rdquo;
so there is no need to know the exact initialization time for them.
Since these time values are insignificant, we can just omit all the measurements below the given thresholds.
This allows to significantly reduce the data traffic without losing any important information.&lt;/p>
&lt;p>The suggested trick can be named &lt;em>partial binning compression&lt;/em>.
Indeed, we introduce a single bin (perform &lt;em>binning&lt;/em>) and
omit all the values inside this bin (perform &lt;em>compression&lt;/em>).
On the other hand, we don&amp;rsquo;t build an honest histogram since we keep all the raw values outside the given bin
(the binning is &lt;em>partial&lt;/em>).&lt;/p>
&lt;p>Let&amp;rsquo;s discuss a few aspects of using partial binning compression.&lt;/p></description></item><item><title>Calculating gamma effect size for samples with zero median absolute deviation</title><link>https://aakinshin.net/posts/zero-mad-gamma-es/</link><pubDate>Tue, 22 Jun 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/zero-mad-gamma-es/</guid><description>&lt;p>In previous posts, I discussed the &lt;a href="https://aakinshin.net/posts/nonparametric-effect-size/">gamma effect size&lt;/a>
which is a Cohen&amp;rsquo;s d-consistent nonparametric and robust measure of the effect size.
Also, I discussed &lt;a href="https://aakinshin.net/posts/nonparametric-effect-size2/">various ways to customize this metric&lt;/a>
and adjust it to different kinds of business requirements.
In this post, I want to briefly cover one more corner case that requires special adjustments.
We are going to discuss the situation when the median absolute deviation is zero.&lt;/p></description></item><item><title>Discrete performance distributions</title><link>https://aakinshin.net/posts/discrete-performance-distributions/</link><pubDate>Tue, 15 Jun 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/discrete-performance-distributions/</guid><description>&lt;p>When we collect software performance measurements, we get a bunch of time intervals.
Typically, we tend to interpret time values as continuous values.
However, the obtained values are actually discrete due to the limited resolution of our measurement tool.
In simple cases, we can treat these discrete values as continuous and get meaningful results.
Unfortunately, discretization may produce strange phenomena like pseudo-multimodality or zero dispersion.
If we want to set up a reliable system that automatically analyzes such distributions,
we should be aware of such problems so we could correctly handle them.&lt;/p>
&lt;p>In this post, I want to share a few of discretization problems in real-life performance data sets
(based on the &lt;a href="https://www.jetbrains.com/rider/">Rider&lt;/a> performance tests).&lt;/p></description></item><item><title>Customization of the nonparametric Cohen's d-consistent effect size</title><link>https://aakinshin.net/posts/nonparametric-effect-size2/</link><pubDate>Tue, 08 Jun 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/nonparametric-effect-size2/</guid><description>&lt;p>One year ago, I publish a post called &lt;a href="https://aakinshin.net/posts/nonparametric-effect-size/">&lt;svg class="rating-icon">&lt;use xlink:href="https://aakinshin.net/img/fa/all.svg#note">&lt;/use>&lt;/svg>Nonparametric Cohen&amp;#39;s d-consistent effect size&lt;/a>.
During this year, I got a lot of internal and external feedback from
my own statistical experiments and
&lt;a href="https://twitter.com/ViljamiSairanen/status/1400457118340108293">people&lt;/a>
&lt;a href="https://sherbold.github.io/autorank/autorank/">who&lt;/a>
&lt;a href="https://github.com/Ramon-Diaz/Thesis-Project/blob/85df6b11050c7e05c4394d873585f701a7e3f32e/_util.py#L100">tried&lt;/a>
to use the suggested approach.
It seems that the nonparametric version of Cohen&amp;rsquo;s d works much better with real-life not-so-normal data.
While the classic Cohen&amp;rsquo;s d based on
the non-robust arithmetic mean and
the &lt;a href="https://aakinshin.net/posts/misleading-stddev/">non-robust standard deviation&lt;/a>
can be easily &lt;a href="https://aakinshin.net/posts/cohend-and-outliers/">corrupted by a single outlier&lt;/a>,
my approach is much more resistant to unexpected extreme values.
Also, it allows exploring
&lt;a href="https://aakinshin.net/posts/comparing-distributions-using-gamma-es/">the difference between specific quantiles of considered samples&lt;/a>,
which can be useful in the non-parametric case.&lt;/p>
&lt;p>However, I wasn&amp;rsquo;t satisfied with the results of all of my experiments.
While I still like the basic idea
(replace the mean with the median; replace the standard deviation with the median absolute deviation),
it turned out that the final results heavily depend on the used quantile estimator.
To be more specific, the original Harrell-Davis quantile estimator is not always optimal;
in most cases, it&amp;rsquo;s better to replace it with its &lt;a href="https://aakinshin.net/posts/trimmed-hdqe/">trimmed&lt;/a> modification.
However, the particular choice of the quantile estimators depends on the situation.
Also, the consistency constant for the median absolute deviation
should be adjusted according to the current sample size and the used quantile estimator.
Of course, it also can be replaced by other dispersion estimators
that can be used as consistent estimators of the standard deviation.&lt;/p>
&lt;p>In this post, I want to get a brief overview of possible customizations of the suggested metrics.&lt;/p></description></item><item><title>Robust alternative to statistical efficiency</title><link>https://aakinshin.net/posts/robust-statistical-efficiency/</link><pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/robust-statistical-efficiency/</guid><description>&lt;p>Statistical efficiency is a common measure of the quality of an estimator.
Typically, it&amp;rsquo;s expressed via the mean square error ($\operatorname{MSE}$).
For the given estimator $T$ and the true parameter value $\theta$,
the $\operatorname{MSE}$ can be expressed as follows:&lt;/p>
$$
\operatorname{MSE}(T) = \operatorname{E}[(T-\theta)^2]
$$
&lt;p>In numerical simulations, the $\operatorname{MSE}$ can&amp;rsquo;t be used as a robust metric
because its breakdown point is zero
(a corruption of a single measurement leads to a corrupted result).
Typically, it&amp;rsquo;s not a problem for light-tailed distributions.
Unfortunately, in the heavy-tailed case,
the $\operatorname{MSE}$ becomes an unreliable and unreproducible metric
because it can be easily spoiled by a single outlier.&lt;/p>
&lt;p>I suggest an alternative way to compare statistical estimators.
Instead of using non-robust $\operatorname{MSE}$,
we can use robust quantile estimations of the absolute error distribution.
In this post, I want to share numerical simulations
that show a problem of irreproducible $\operatorname{MSE}$ values
and how they can be replaced by reproducible quantile values.&lt;/p></description></item><item><title>Improving the efficiency of the Harrell-Davis quantile estimator for special cases using custom winsorizing and trimming strategies</title><link>https://aakinshin.net/posts/customized-wthdqe/</link><pubDate>Tue, 25 May 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/customized-wthdqe/</guid><description>&lt;p>Let&amp;rsquo;s say we want to
&lt;strong>estimate the median&lt;/strong>
based on a &lt;strong>small sample&lt;/strong> (3 $\leq n \leq 7$)
from a &lt;strong>right-skewed heavy-tailed distribution&lt;/strong>
with &lt;strong>high statistical efficiency&lt;/strong>.&lt;/p>
&lt;p>The traditional median estimator is the most robust estimator, but it&amp;rsquo;s not the most efficient one.
Typically, the Harrell-Davis quantile estimator provides better efficiency,
but it&amp;rsquo;s not robust (its breakdown point is zero),
so it may have worse efficiency in the given case.
The &lt;a href="https://aakinshin.net/posts/winsorized-hdqe/">winsorized&lt;/a> and &lt;a href="https://aakinshin.net/posts/trimmed-hdqe/">trimmed&lt;/a>
modifications of the Harrell-Davis quantile estimator provide a good trade-off
between efficiency and robustness, but they require a proper winsorizing/trimming rule.
A reasonable choice of such a rule for medium-size samples is based on the highest density interval of the Beta function
(as described &lt;a href="https://aakinshin.net/posts/winsorized-hdqe/">here&lt;/a>).
Unfortunately, this approach may be suboptimal for small samples.
E.g., if we use the 99% highest density interval to estimate the median,
it starts to trim sample values only for $n \geq 8$.&lt;/p>
&lt;p>In this post, we are going to discuss custom winsorizing/trimming strategies for special cases of the quantile estimation problem.&lt;/p></description></item><item><title>Comparing the efficiency of the Harrell-Davis, Sfakianakis-Verginis, and Navruz-Özdemir quantile estimators</title><link>https://aakinshin.net/posts/hd-sv-no-efficiency/</link><pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/hd-sv-no-efficiency/</guid><description>&lt;p>In the previous posts, I discussed the statistical efficiency of different quantile estimators
(&lt;a href="https://aakinshin.net/posts/hdqe-efficiency/">Efficiency of the Harrell-Davis quantile estimator&lt;/a> and
&lt;a href="https://aakinshin.net/posts/wthdqe-efficiency/">Efficiency of the winsorized and trimmed Harrell-Davis quantile estimators&lt;/a>).&lt;/p>
&lt;p>In this post, I continue this research and compare the efficiency of
the Harrell-Davis quantile estimator,
the &lt;a href="https://aakinshin.net/posts/sfakianakis-verginis-quantile-estimator/">Sfakianakis-Verginis quantile estimators&lt;/a>, and
the &lt;a href="https://aakinshin.net/posts/navruz-ozdemir-quantile-estimator/">Navruz-Özdemir quantile estimator&lt;/a>.&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/hd-sv-no-efficiency/img/LightAndHeavy_N10_Efficiency-light.png" target="_blank" alt="LightAndHeavy_N10_Efficiency">
 &lt;img
 src="https://aakinshin.net/posts/hd-sv-no-efficiency/img/LightAndHeavy_N10_Efficiency-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/hd-sv-no-efficiency/img/LightAndHeavy_N10_Efficiency-dark.png" target="_blank" alt="LightAndHeavy_N10_Efficiency">
 &lt;img
 src="https://aakinshin.net/posts/hd-sv-no-efficiency/img/LightAndHeavy_N10_Efficiency-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div></description></item><item><title>Dispersion exponential smoothing</title><link>https://aakinshin.net/posts/dispersion-exponential-smoothing/</link><pubDate>Tue, 11 May 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/dispersion-exponential-smoothing/</guid><description>&lt;p>In this &lt;a href="https://aakinshin.net/posts/quantile-exponential-smoothing/">previous post&lt;/a>,
I showed how to apply exponential smoothing to quantiles
using the &lt;a href="https://aakinshin.net/posts/weighted-quantiles/">weighted Harrell-Davis quantile estimator&lt;/a>.
This technique allows getting smooth and stable moving median estimations.
In this post, I&amp;rsquo;m going to discuss how to use the same approach
to estimate moving dispersion.&lt;/p></description></item><item><title>Quantile exponential smoothing</title><link>https://aakinshin.net/posts/quantile-exponential-smoothing/</link><pubDate>Tue, 04 May 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/quantile-exponential-smoothing/</guid><description>&lt;p>One of the popular problems in time series analysis is estimating the moving &amp;ldquo;average&amp;rdquo; value.
Let&amp;rsquo;s define the &amp;ldquo;average&amp;rdquo; as a central tendency metric like the mean or the median.
When we talk about the moving value, we assume that we are interested in
the average value &amp;ldquo;at the end&amp;rdquo; of the time series
instead of the average of all available observations.&lt;/p>
&lt;p>One of the most straightforward approaches to estimate the moving average is the &lt;em>simple moving mean&lt;/em>.
Unfortunately, this approach is not robust: outliers can instantly spoil the evaluated mean value.
As an alternative, we can consider &lt;em>simple moving median&lt;/em>.
I already discussed a few of such methods:
&lt;a href="https://aakinshin.net/posts/mp2-quantile-estimator/">the MP² quantile estimator&lt;/a> and
&lt;a href="https://aakinshin.net/posts/partitioning-heaps-quantile-estimator2/">a moving quantile estimator based on partitioning heaps&lt;/a>
(a modification of the Hardle-Steiger method).
When we talk about &lt;em>simple moving averages&lt;/em>, we typically assume
that we estimate the average value over the last $k$ observations ($k$ is the &lt;em>window size&lt;/em>).
This approach is also known as &lt;em>unweighted moving averages&lt;/em> because
all target observations have the same weight.&lt;/p>
&lt;p>As an alternative to the simple moving average, we can also consider the &lt;em>weighted moving average&lt;/em>.
In this case, we assign a weight for each observation and aggregate the whole time series according to these weights.
A famous example of such a weight function is &lt;em>exponential smoothing&lt;/em>.
And the simplest form of exponential smoothing is the &lt;em>exponentially weighted moving mean&lt;/em>.
This approach estimates the weighted moving mean using exponentially decreasing weights.
Switching from the simple moving mean to the exponentially weighted moving mean provides some benefits
in terms of smoothness and estimation efficiency.&lt;/p>
&lt;p>Although exponential smoothing has advantages over the simple moving mean,
it still estimates the mean value which is not robust.
We can improve the robustness of this approach if we reuse the same idea for weighted moving quantiles.
It&amp;rsquo;s possible because the quantiles also can be estimated for weighted samples.
In one of my previous posts, I &lt;a href="https://aakinshin.net/posts/weighted-quantiles/">showed&lt;/a> how to adapt
the Hyndman-Fan Type 7 and Harrell-Davis quantile estimators to the weighted samples.
In this post, I&amp;rsquo;m going to show how we can use this technique to estimate
the weighted moving quantiles using exponentially decreasing weights.&lt;/p></description></item><item><title>Improving quantile-respectful density estimation for discrete distributions using jittering</title><link>https://aakinshin.net/posts/qrde-discrete/</link><pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/qrde-discrete/</guid><description>&lt;p>In my previous posts, I already discussed the &lt;a href="https://aakinshin.net/posts/kde-discrete/">problem&lt;/a> that arise
when we try to build the kernel density estimation (KDE) for samples with ties.
We may get such samples in real life from discrete or mixed discrete/continuous distributions.
Even if the original distribution is continuous,
we may observe artificial sample discretization due to a limited resolution of the measuring tool.
Such discretization may lead to inaccurate density plots due to undersmoothing.
The problem can be resolved using a nice technique called &lt;em>jittering&lt;/em>.
I also discussed &lt;a href="https://aakinshin.net/posts/discrete-sample-jittering/">how to apply&lt;/a> jittering to get a smoother version of KDE.&lt;/p>
&lt;p>However, I&amp;rsquo;m not a huge fan of KDE because of two reasons.
The first one is the &lt;a href="https://aakinshin.net/posts/kde-bw/">problem of choosing a proper bandwidth value&lt;/a>.
With poorly chosen bandwidth, we can easily get oversmoothing or undersmoothing even without the discretization problem.
The second one is an inconsistency between the KDE-based probability density function and evaluated sample quantiles.
It could lead to inconsistent visualizations (e.g., KDE-based violin plots with non-KDE-based quantile values)
or it could introduce problems for algorithms that require density function and quantile values at the same time.
The inconsistency could be resolved using &lt;a href="https://aakinshin.net/posts/qrde-hd/">quantile-respectful density estimation&lt;/a> (QRDE).
This kind of estimation builds the density function which matches the evaluated sample quantiles.
To get a smooth QRDE, we also need a smooth quantile estimator like the Harrell-Davis quantile estimator.
The robustness and componential efficiency of this approach can be improved using
the &lt;a href="https://aakinshin.net/posts/winsorized-hdqe/">winsorized&lt;/a> and &lt;a href="https://aakinshin.net/posts/trimmed-hdqe/">trimmed&lt;/a>
modifications of the Harrell-Davis quantile estimator
(which also have a &lt;a href="https://aakinshin.net/posts/wthdqe-efficiency/">decent statistical efficiency level&lt;/a>).&lt;/p>
&lt;p>Unfortunately, the straightforward QRDE calculation is not always applicable for samples with ties
because it&amp;rsquo;s impossible to build an &amp;ldquo;honest&amp;rdquo; density function for discrete distributions
without using the Dirac delta function.
This is a severe problem for QRDE-based algorithms like the
&lt;a href="https://aakinshin.net/posts/lowland-multimodality-detection/">lowland multimodality detection algorithm&lt;/a>.
In this post, I will show how jittering could help to solve this problem and get a smooth QRDE on samples with ties.&lt;/p></description></item><item><title>How to build a smooth density estimation for a discrete sample using jittering</title><link>https://aakinshin.net/posts/discrete-sample-jittering/</link><pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/discrete-sample-jittering/</guid><description>&lt;p>Let&amp;rsquo;s say you have a sample with tied values.
If you draw a kernel density estimation (KDE) for such a sample,
you may get a serrated pattern like this:&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/discrete-sample-jittering/img/intro-light.png" target="_blank" alt="intro">
 &lt;img
 src="https://aakinshin.net/posts/discrete-sample-jittering/img/intro-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/discrete-sample-jittering/img/intro-dark.png" target="_blank" alt="intro">
 &lt;img
 src="https://aakinshin.net/posts/discrete-sample-jittering/img/intro-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>KDE requires samples from continuous distributions
while tied values arise in discrete or mixture distributions.
Even if the original distribution is continuous,
you may observe artificial sample discretization due to a limited resolution of the measuring tool.
This effect may lead to distorted density plots like in the above picture.&lt;/p>
&lt;p>The problem could be solved using a nice technique called &lt;em>jittering&lt;/em>.
In the simplest case, jittering just adds random noise to each measurement.
Such a trick removes all ties from the sample and allows building a smooth density estimation.&lt;/p>
&lt;p>However, there are many different ways to apply jittering.
The trickiest question here is how to choose proper noise values.
In this post, I want to share one of my favorite jittering approaches.
It generates a non-randomized noise pattern with a low risk of noticeable sample corruption.&lt;/p></description></item><item><title>Kernel density estimation and discrete values</title><link>https://aakinshin.net/posts/kde-discrete/</link><pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/kde-discrete/</guid><description>&lt;p>Kernel density estimation (KDE) is a popular technique of data visualization.
Based on the given sample, it allows estimating the probability density function (PDF) of the underlying distribution.
Here is an example of KDE for &lt;code>x = {3.82, 4.61, 4.89, 4.91, 5.31, 5.6, 5.66, 7.00, 7.00, 7.00}&lt;/code>
(normal kernel, Sheather &amp;amp; Jones bandwidth selector):&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/kde-discrete/img/intro-light.png" target="_blank" alt="intro">
 &lt;img
 src="https://aakinshin.net/posts/kde-discrete/img/intro-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/kde-discrete/img/intro-dark.png" target="_blank" alt="intro">
 &lt;img
 src="https://aakinshin.net/posts/kde-discrete/img/intro-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>KDE is a simple and straightforward way to build a PDF, but it&amp;rsquo;s not always the best one.
In addition to my &lt;a href="https://aakinshin.net/posts/kde-bw/">concerns about bandwidth selection&lt;/a>,
continuous use of KDE creates an illusion that all distributions are smooth and continuous.
In practice, it&amp;rsquo;s not always true.&lt;/p>
&lt;p>In the above picture, the distribution looks pretty continuous.
However, the picture hides the fact that we have three &lt;code>7.00&lt;/code> elements in the original sample.
With continuous distributions, the probability of getting tied observations (that have the same value) is almost zero.
If a sample contains ties, we are most likely working with
either a discrete distribution or a mixture of discrete and continuous distributions.
A KDE for such a sample may significantly differ from the actual PDF.
Thus, this technique may mislead us instead of providing insights about the true underlying distribution.&lt;/p>
&lt;p>In this post, we discuss the usage of PDF and PMF with continuous and discrete distributions.
Also, we look at examples of corrupted density estimation plots for distributions with discrete features.&lt;/p></description></item><item><title>Efficiency of the winsorized and trimmed Harrell-Davis quantile estimators</title><link>https://aakinshin.net/posts/wthdqe-efficiency/</link><pubDate>Tue, 06 Apr 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/wthdqe-efficiency/</guid><description>&lt;p>In previous posts, I suggested two modifications of the Harrell-Davis quantile estimator:
&lt;a href="https://aakinshin.net/posts/winsorized-hdqe/">winsorized&lt;/a> and &lt;a href="https://aakinshin.net/posts/trimmed-hdqe/">trimmed&lt;/a>.
Both modifications have a higher level of robustness in comparison to the original estimator.
Also, I &lt;a href="https://aakinshin.net/posts/hdqe-efficiency/">discussed&lt;/a> the &lt;a href="https://en.wikipedia.org/wiki/Efficiency_(statistics)">efficiency&lt;/a>
of the Harrell-Davis quantile estimator.
In this post, I&amp;rsquo;m going to continue numerical simulation and estimate the efficiency of
the winsorized and trimmed modifications.&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/wthdqe-efficiency/img/LightAndHeavy_N10_Efficiency-light.png" target="_blank" alt="LightAndHeavy_N10_Efficiency">
 &lt;img
 src="https://aakinshin.net/posts/wthdqe-efficiency/img/LightAndHeavy_N10_Efficiency-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/wthdqe-efficiency/img/LightAndHeavy_N10_Efficiency-dark.png" target="_blank" alt="LightAndHeavy_N10_Efficiency">
 &lt;img
 src="https://aakinshin.net/posts/wthdqe-efficiency/img/LightAndHeavy_N10_Efficiency-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div></description></item><item><title>Trimmed modification of the Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/trimmed-hdqe/</link><pubDate>Tue, 30 Mar 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/trimmed-hdqe/</guid><description>&lt;p>In one of &lt;a href="https://aakinshin.net/posts/winsorized-hdqe/">the previous posts&lt;/a>, I discussed winsorized Harrell-Davis quantile estimator.
This estimator is more robust than the classic Harrell-Davis quantile estimator.
In this post, I want to suggest another modification that may be better for some corner cases:
the &lt;em>trimmed&lt;/em> Harrell-Davis quantile estimator.&lt;/p></description></item><item><title>Efficiency of the Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/hdqe-efficiency/</link><pubDate>Tue, 23 Mar 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/hdqe-efficiency/</guid><description>&lt;p>One of the most essential properties of a quantile estimator is
its &lt;a href="https://en.wikipedia.org/wiki/Efficiency_(statistics)">efficiency&lt;/a>.
In simple words, the efficiency describes the estimator accuracy.
The Harrell-Davis quantile estimator is a good option to achieve higher efficiency.
However, this estimator may provide lower efficiency in some special cases.
In this post, we will conduct a set of simulations that show the actual efficiency numbers.
We compare different distributions (symmetric and right-skewed, heavy-tailed and light-tailed),
quantiles, and sample sizes.&lt;/p></description></item><item><title>Navruz-Özdemir quantile estimator</title><link>https://aakinshin.net/posts/navruz-ozdemir-quantile-estimator/</link><pubDate>Tue, 16 Mar 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/navruz-ozdemir-quantile-estimator/</guid><description>&lt;p>The Navruz-Özdemir quantile estimator
suggests the following equation to estimate the $p^\textrm{th}$ quantile of sample $X$:&lt;/p>
$$
\begin{split}
\operatorname{NO}_p =
&amp; \Big( (3p-1)X_{(1)} + (2-3p)X_{(2)} - (1-p)X_{(3)} \Big) B_0 +\\
&amp; +\sum_{i=1}^n \Big((1-p)B_{i-1}+pB_i\Big)X_{(i)} +\\
&amp; +\Big( -pX_{(n-2)} + (3p-1)X_{(n-1)} + (2-3p)X_{(n)} \Big) B_n
\end{split}
$$
&lt;p>where $B_i = B(i; n, p)$ is probability mass function of the binomial distribution $B(n, p)$,
$X_{(i)}$ are order statistics of sample $X$.&lt;/p>
&lt;p>In this post, I derive these equations following the paper
&lt;a href="https://doi.org/10.1111/bmsp.12198">&amp;ldquo;A new quantile estimator with weights based on a subsampling approach&amp;rdquo;&lt;/a> (2020)
by Gözde Navruz and A. Fırat Özdemir.
Also, I add some additional explanations,
simplify the final equation,
and provide reference implementations in C# and R.&lt;/p></description></item><item><title>Sfakianakis-Verginis quantile estimator</title><link>https://aakinshin.net/posts/sfakianakis-verginis-quantile-estimator/</link><pubDate>Tue, 09 Mar 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/sfakianakis-verginis-quantile-estimator/</guid><description>&lt;p>There are dozens of different ways to estimate quantiles.
One of these ways is to use the Sfakianakis-Verginis quantile estimator.
To be more specific, it&amp;rsquo;s a family of three estimators.
If we want to estimate the $p^\textrm{th}$ quantile of sample $X$,
we can use one of the following equations:&lt;/p>
$$
\begin{split}
\operatorname{SV1}_p =&amp;
\frac{B_0}{2} \big( X_{(1)}+X_{(2)}-X_{(3)} \big) +
\sum_{i=1}^{n} \frac{B_i+B_{i-1}}{2} X_{(i)} +
\frac{B_n}{2} \big(- X_{(n-2)}+X_{(n-1)}-X_{(n)} \big),\\
\operatorname{SV2}_p =&amp; \sum_{i=1}^{n} B_{i-1} X_{(i)} + B_n \cdot \big(2X_{(n)} - X_{(n-1)}\big),\\
\operatorname{SV3}_p =&amp; \sum_{i=1}^n B_i X_{(i)} + B_0 \cdot \big(2X_{(1)}-X_{(2)}\big).
\end{split}
$$
&lt;p>where $B_i = B(i; n, p)$ is probability mass function of the binomial distribution $B(n, p)$,
$X_{(i)}$ are order statistics of sample $X$.&lt;/p>
&lt;p>In this post, I derive these equations following the paper
&lt;a href="https://doi.org/10.1080/03610910701790491">&amp;ldquo;A new family of nonparametric quantile estimators&amp;rdquo;&lt;/a> (2008)
by Michael E. Sfakianakis and Dimitris G. Verginis.
Also, I add some additional explanations,
reconstruct missing steps,
simplify the final equations,
and provide reference implementations in C# and R.&lt;/p></description></item><item><title>Winsorized modification of the Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/winsorized-hdqe/</link><pubDate>Tue, 02 Mar 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/winsorized-hdqe/</guid><description>&lt;p>The Harrell-Davis quantile estimator is one of my favorite quantile estimators
because of its &lt;a href="https://en.wikipedia.org/wiki/Efficiency_(statistics)">efficiency&lt;/a>.
It has a small mean square error which allows getting accurate estimations.
However, it has a severe drawback: it&amp;rsquo;s not robust.
Indeed, since the estimator includes all sample elements with positive weights,
its &lt;a href="https://en.wikipedia.org/wiki/Robust_statistics#Breakdown_point">breakdown point&lt;/a> is zero.&lt;/p>
&lt;p>In this post, I want to suggest modifications of the Harrell-Davis quantile estimator
which increases its &lt;em>robustness&lt;/em> keeping almost the same level of &lt;em>efficiency&lt;/em>.&lt;/p></description></item><item><title>Misleading standard deviation</title><link>https://aakinshin.net/posts/misleading-stddev/</link><pubDate>Tue, 23 Feb 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/misleading-stddev/</guid><description>&lt;p>The &lt;a href="https://en.wikipedia.org/wiki/Standard_deviation">standard deviation&lt;/a> may be an extremely misleading metric.
Even minor deviations from normality could make it completely unreliable and deceiving.
Let me demonstrate this problem using an example.&lt;/p>
&lt;p>Below you can see three density plots of some distributions.
Could you guess their standard deviations?&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/misleading-stddev/img/density1-light.png" target="_blank" alt="density1">
 &lt;img
 src="https://aakinshin.net/posts/misleading-stddev/img/density1-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/misleading-stddev/img/density1-dark.png" target="_blank" alt="density1">
 &lt;img
 src="https://aakinshin.net/posts/misleading-stddev/img/density1-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>The correct answers are $1.0, 3.0, 11.0$.
And here is a more challenging problem: could you match these values with the corresponding distributions?&lt;/p></description></item><item><title>Unbiased median absolute deviation based on the Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/unbiased-mad-hd/</link><pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/unbiased-mad-hd/</guid><description>&lt;p>The &lt;a href="https://en.wikipedia.org/wiki/Median_absolute_deviation">median absolute deviation&lt;/a> ($\textrm{MAD}$)
is a robust measure of scale.
In the previous post, I &lt;a href="https://aakinshin.net/posts/unbiased-mad/">showed&lt;/a>
how to use the &lt;a href="https://en.wikipedia.org/wiki/Bias_of_an_estimator">unbiased&lt;/a>
version of the $\textrm{MAD}$ estimator
as a robust alternative to the standard deviation.
&amp;ldquo;Unbiasedness&amp;rdquo; means that such estimator&amp;rsquo;s expected value equals the true value of the standard deviation.
Unfortunately, there is such thing as the &lt;a href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff">bias–variance tradeoff&lt;/a>:
when we remove the bias of the $\textrm{MAD}$ estimator,
we increase its variance and mean squared error ($\textrm{MSE}$).&lt;/p>
&lt;p>In this post, I want to suggest a more &lt;a href="https://en.wikipedia.org/wiki/Efficiency_(statistics)">efficient&lt;/a>
unbiased $\textrm{MAD}$ estimator.
It&amp;rsquo;s also a consistent estimator for the standard deviation, but it has smaller $\textrm{MSE}$.
To build this estimator,
we should replace the classic &amp;ldquo;straightforward&amp;rdquo; median estimator with the Harrell-Davis quantile estimator
and adjust bias-correction factors.
Let&amp;rsquo;s discuss this approach in detail.&lt;/p></description></item><item><title>Unbiased median absolute deviation</title><link>https://aakinshin.net/posts/unbiased-mad/</link><pubDate>Tue, 09 Feb 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/unbiased-mad/</guid><description>&lt;p>The &lt;a href="https://en.wikipedia.org/wiki/Median_absolute_deviation">median absolute deviation&lt;/a> ($\textrm{MAD}$)
is a robust measure of scale.
For distribution $X$, it can be calculated as follows:&lt;/p>
$$
\textrm{MAD} = C \cdot \textrm{median}(|X - \textrm{median}(X)|)
$$
&lt;p>where $C$ is a constant scale factor.
This metric can be used as a robust alternative to the standard deviation.
If we want to use the $\textrm{MAD}$ as a &lt;a href="https://en.wikipedia.org/wiki/Consistent_estimator">consistent estimator&lt;/a>
for the standard deviation under the normal distribution,
we should set&lt;/p>
$$
C = C_{\infty} = \dfrac{1}{\Phi^{-1}(3/4)} \approx 1.4826022185056.
$$
&lt;p>where $\Phi^{-1}$ is the quantile function of the standard normal distribution
(or the inverse of the cumulative distribution function).
If $X$ is the normal distribution, we get $\textrm{MAD} = \sigma$ where $\sigma$ is the standard deviation.&lt;/p>
&lt;p>Now let&amp;rsquo;s consider a sample $x = \{ x_1, x_2, \ldots x_n \}$.
Let&amp;rsquo;s denote the median absolute deviation for a sample of size $n$ as $\textrm{MAD}_n$.
The corresponding equation looks similar to the definition of $\textrm{MAD}$ for a distribution:&lt;/p>
$$
\textrm{MAD}_n = C_n \cdot \textrm{median}(|x - \textrm{median}(x)|).
$$
&lt;p>Let&amp;rsquo;s assume that $\textrm{median}$ is the straightforward definition of the median
(if $n$ is odd, the median is the middle element of the sorted sample,
if $n$ is even, the median is the arithmetic average of the two middle elements of the sorted sample).
We still can use $C_n = C_{\infty}$ for extremely large sample sizes.
However, for small $n$, $\textrm{MAD}_n$ becomes a &lt;a href="https://en.wikipedia.org/wiki/Bias_of_an_estimator">biased estimator&lt;/a>.
If we want to get an unbiased version, we should adjust the value of $C_n$.&lt;/p>
&lt;p>In this post, we look at the possible approaches and learn the way to get the exact value of $C_n$
that makes $\textrm{MAD}_n$ unbiased estimator of the median absolute deviation for any $n$.&lt;/p></description></item><item><title>Comparing distribution quantiles using gamma effect size</title><link>https://aakinshin.net/posts/comparing-distributions-using-gamma-es/</link><pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/comparing-distributions-using-gamma-es/</guid><description>&lt;p>There are several ways to describe the difference between two distributions.
Here are a few examples:&lt;/p>
&lt;ul>
&lt;li>Effect sizes based on differences between means (e.g., Cohen&amp;rsquo;s d, Glass&amp;rsquo; Δ, Hedges&amp;rsquo; g)&lt;/li>
&lt;li>&lt;a href="https://aakinshin.net/posts/shift-and-ratio-functions/">The shift and ration functions&lt;/a> that
estimate differences between matched quantiles.&lt;/li>
&lt;/ul>
&lt;p>In one of the previous post, I &lt;a href="https://aakinshin.net/posts/nonparametric-effect-size/">described&lt;/a>
the gamma effect size which is defined not for the mean but for quantiles.
In this post, I want to share a few case studies that demonstrate
how the suggested metric combines the advantages of the above approaches.&lt;/p></description></item><item><title>A single outlier could completely distort your Cohen's d value</title><link>https://aakinshin.net/posts/cohend-and-outliers/</link><pubDate>Tue, 26 Jan 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/cohend-and-outliers/</guid><description>&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Effect_size#Cohen's_d">Cohen&amp;rsquo;s d&lt;/a> is a popular way to estimate
the &lt;a href="https://en.wikipedia.org/wiki/Effect_size">effect size&lt;/a> between two samples.
It works excellent for perfectly normal distributions.
Usually, people think that slight deviations from normality
shouldn&amp;rsquo;t produce a noticeable impact on the result.
Unfortunately, it&amp;rsquo;s not always true.
In fact, a single outlier value can completely distort the result even in large samples.&lt;/p>
&lt;p>In this post, I will present some illustrations for this problem and will show how to fix it.&lt;/p></description></item><item><title>Better moving quantile estimations using the partitioning heaps</title><link>https://aakinshin.net/posts/partitioning-heaps-quantile-estimator2/</link><pubDate>Tue, 19 Jan 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/partitioning-heaps-quantile-estimator2/</guid><description>&lt;p>In one of the previous posts, I &lt;a href="https://aakinshin.net/posts/partitioning-heaps-quantile-estimator/">have discussed&lt;/a> the Hardle-Steiger method.
This algorithm allows estimating &lt;a href="https://en.wikipedia.org/wiki/Moving_average#Moving_median">the moving median&lt;/a>
using $O(L)$ memory and $O(log(L))$ element processing complexity (where $L$ is the window size).
Also, I have shown how to adapt this approach to estimate &lt;em>any&lt;/em> moving quantile.&lt;/p>
&lt;p>In this post, I&amp;rsquo;m going to present further improvements.
The Hardle-Steiger method always returns the &lt;a href="https://en.wikipedia.org/wiki/Order_statistic">order statistics&lt;/a>
which is the $k\textrm{th}$ smallest element from the sample.
It means that the estimated quantile value always equals one of the last $L$ observed numbers.
However, many of the classic quantile estimators use two elements.
For example, if we want to estimate the median for $x = \{4, 5, 6, 7\}$,
some estimators return $5.5$ (which is the arithmetical mean of $5$ and $6$)
instead of $5$ or $6$ (which are order statistics).&lt;/p>
&lt;p>Let&amp;rsquo;s learn how to implement a moving version of such estimators using
the partitioning heaps from the Hardle-Steiger method.&lt;/p></description></item><item><title>MP² quantile estimator: estimating the moving median without storing values</title><link>https://aakinshin.net/posts/mp2-quantile-estimator/</link><pubDate>Tue, 12 Jan 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/mp2-quantile-estimator/</guid><description>&lt;p>In one of the previous posts, I &lt;a href="https://aakinshin.net/posts/p2-quantile-estimator/">described&lt;/a> the P² quantile estimator.
It allows estimating quantiles on a stream of numbers without storing them.
Such sequential (streaming/online) quantile estimators are useful in software telemetry because
they help to evaluate the median and other distribution quantiles without a noticeable memory footprint.&lt;/p>
&lt;p>After the publication, I got a lot of questions about &lt;em>moving&lt;/em> sequential quantile estimators.
Such estimators return quantile values not for the whole stream of numbers,
but only for the recent values.
So, I &lt;a href="https://aakinshin.net/posts/partitioning-heaps-quantile-estimator/">wrote&lt;/a> another post about
a quantile estimator based on a partitioning heaps (inspired by the Hardle-Steiger method).
This algorithm gives you the exact value of any order statistics for the last $L$ numbers
($L$ is known as the window size).
However, it requires $O(L)$ memory, and it takes $O(log(L))$ time to process each element.
This may be acceptable in some cases.
Unfortunately, it doesn&amp;rsquo;t allow implementing low-overhead telemetry in the case of large $L$.&lt;/p>
&lt;p>In this post, I&amp;rsquo;m going to present a moving modification of the P² quantile estimator.
Let&amp;rsquo;s call it MP² (moving P²).
It requires $O(1)$ memory, it takes $O(1)$ to process each element,
and it supports windows of any size.
Of course, we have a trade-off with the estimation accuracy:
it returns a quantile approximation instead of the exact order statistics.
However, in most cases, the MP² estimations are pretty accurate from the practical point of view.&lt;/p>
&lt;p>Let&amp;rsquo;s discuss MP² in detail!&lt;/p></description></item><item><title>Case study: Accuracy of the MAD estimation using the Harrell-Davis quantile estimator (Gumbel distribution)</title><link>https://aakinshin.net/posts/cs-mad-hd-gumbel/</link><pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/cs-mad-hd-gumbel/</guid><description>&lt;p>In some of my previous posts, I used
the &lt;a href="https://en.wikipedia.org/wiki/Median_absolute_deviation">median absolute deviation&lt;/a> (MAD)
to describe the distribution dispersion:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aakinshin.net/posts/harrell-davis-double-mad-outlier-detector/">DoubleMAD outlier detector based on the Harrell-Davis quantile estimator&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aakinshin.net/posts/nonparametric-effect-size/">Nonparametric Cohen&amp;rsquo;s d-consistent effect size&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aakinshin.net/posts/qad/">Quantile absolute deviation: estimating statistical dispersion around quantiles&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>The MAD estimation depends on the chosen median estimator:
we may get different MAD values with different median estimators.
To get better accuracy,
I always encourage readers to use the Harrell-Davis quantile estimator
instead of the classic Type 7 quantile estimator.&lt;/p>
&lt;p>In this case study, I decided to compare these two quantile estimators using
the &lt;a href="https://en.wikipedia.org/wiki/Gumbel_distribution">Gumbel distribution&lt;/a>
(it&amp;rsquo;s a good model for slightly right-skewed distributions).
According to the performed Monte Carlo simulation,
the Harrell-Davis quantile estimator always has better accuracy:&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/cs-mad-hd-gumbel/img/summary-light.png" target="_blank" alt="summary">
 &lt;img
 src="https://aakinshin.net/posts/cs-mad-hd-gumbel/img/summary-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/cs-mad-hd-gumbel/img/summary-dark.png" target="_blank" alt="summary">
 &lt;img
 src="https://aakinshin.net/posts/cs-mad-hd-gumbel/img/summary-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div></description></item><item><title>Fast implementation of the moving quantile based on the partitioning heaps</title><link>https://aakinshin.net/posts/partitioning-heaps-quantile-estimator/</link><pubDate>Tue, 29 Dec 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/partitioning-heaps-quantile-estimator/</guid><description>&lt;p>Imagine you have a time series.
Let&amp;rsquo;s say, after each new observation, you want to know an &amp;ldquo;average&amp;rdquo; value across the last $L$ observations.
Such a metric is known as &lt;a href="https://en.wikipedia.org/wiki/Moving_average">a moving average&lt;/a>
(or rolling/running average).&lt;/p>
&lt;p>The most popular moving average example is &lt;a href="https://en.wikipedia.org/wiki/Moving_average#Simple_moving_average">the moving mean&lt;/a>.
It&amp;rsquo;s easy to efficiently implement this metric.
However, it has a major drawback: it&amp;rsquo;s not robust.
Outliers can easily spoil the moving mean and transform it into a meaningless and untrustable metric.&lt;/p>
&lt;p>Fortunately, we have a good alternative: &lt;a href="https://en.wikipedia.org/wiki/Moving_average#Moving_median">the moving median&lt;/a>.
Typically, it generates a stable and smooth series of values.
In the below figure, you can see the difference between the moving mean and the moving median on noisy data.&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/partitioning-heaps-quantile-estimator/img/example-light.png" target="_blank" alt="example">
 &lt;img
 src="https://aakinshin.net/posts/partitioning-heaps-quantile-estimator/img/example-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/partitioning-heaps-quantile-estimator/img/example-dark.png" target="_blank" alt="example">
 &lt;img
 src="https://aakinshin.net/posts/partitioning-heaps-quantile-estimator/img/example-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>The moving median also has a drawback: it&amp;rsquo;s not easy to efficiently implement it.
Today we going to discuss the Hardle-Steiger method to estimate the median
(memory: $O(L)$, element processing complexity: $O(log(L))$, median estimating complexity: $O(1)$).
Also, we will learn how to calculate &lt;em>the moving quantiles&lt;/em> based on this method.&lt;/p>
&lt;p>In this post, you will find the following:&lt;/p>
&lt;ul>
&lt;li>An overview of the Hardle-Steiger method&lt;/li>
&lt;li>A simple way to implement the Hardle-Steiger method&lt;/li>
&lt;li>Moving quantiles inspired by the Hardle-Steiger method&lt;/li>
&lt;li>How to process initial elements&lt;/li>
&lt;li>Reference C# implementation&lt;/li>
&lt;/ul></description></item><item><title>Coverage of quantile confidence intervals</title><link>https://aakinshin.net/posts/quantile-ci-coverage/</link><pubDate>Tue, 22 Dec 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/quantile-ci-coverage/</guid><description>&lt;p>There is a common &lt;a href="https://en.wikipedia.org/wiki/Confidence_interval#Misunderstandings">misunderstanding&lt;/a>
that a 95% confidence interval is an interval that covers the true parameter value with 95% probability.
Meanwhile, the correct definition assumes that
the true parameter value will be covered by 95% of 95% confidence intervals &lt;em>in the long run&lt;/em>.
These two statements sound similar, but there is a huge difference between them.
95% in this context is not a property of a single confidence interval.
Once you get a calculated interval, it may cover the true value (100% probability) or
it may don&amp;rsquo;t cover it (0% probability).
In fact, 95% is a &lt;em>prediction&lt;/em> about the percentage of &lt;em>future&lt;/em> confidence intervals
that cover the true value &lt;em>in the long run&lt;/em>.&lt;/p>
&lt;p>However, even if you know the correct definition, you still may experience some troubles.
The first thing people usually forgot is the &amp;ldquo;long run&amp;rdquo; part.
For example, if we collected 100 samples and calculated a 95% confidence interval of a parameter for each of them,
we shouldn&amp;rsquo;t expect that 95 of these intervals cover the true parameter value.
In fact, we can observe a situation when none of these intervals covers the true value.
Of course, this is an unlikely event, but if you automatically perform thousands of different experiments,
you will definitely get some extreme situations.&lt;/p>
&lt;p>The second thing that may create trouble is the &amp;ldquo;prediction&amp;rdquo; part.
If weather forecasters predicted that it will rain tomorrow, this does not mean that it will rain tomorrow.
The same works for statistical predictions.
The actual prediction reliability may depend on many factors.
If you estimate confidence intervals around the mean for the normal distribution, you are most likely safe.
However, if you estimate confidence intervals around quantiles for non-parametric distributions,
you should care about the following things:&lt;/p>
&lt;ul>
&lt;li>The used approach to estimate confidence intervals&lt;/li>
&lt;li>The underlying distribution&lt;/li>
&lt;li>The sample size&lt;/li>
&lt;li>The position of the target quantile&lt;/li>
&lt;/ul>
&lt;p>I &lt;a href="https://aakinshin.net/posts/weighted-quantiles-ci/">have already showed&lt;/a> how to estimate
the confidence interval around the given quantile using the Maritz-Jarrett method.
It&amp;rsquo;s time to verify the reliability of this approach.
In this post, I&amp;rsquo;m going to show some Monte-Carlo simulations that evaluate the coverage percentage in different situations.&lt;/p></description></item><item><title>Statistical approaches for performance analysis</title><link>https://aakinshin.net/posts/statistics-for-performance/</link><pubDate>Tue, 15 Dec 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/statistics-for-performance/</guid><description>&lt;p>Software performance is a complex discipline that requires knowledge in different areas
from benchmarking to the internals of modern runtimes, operating systems, and hardware.
Surprisingly, the most difficult challenges in performance analysis are not about programming,
they are about mathematical statistics!&lt;/p>
&lt;p>Many software developers can drill into performance problems and implement excellent optimizations,
but they are not always know how to correctly verify these optimizations.
This may not look like a problem in the case of a single performance investigation.
However, the situation became worse when developers try to set up an infrastructure that
should automatically find performance problems or prevent degradations from merging.
In order to make such an infrastructure reliable and useful,
it&amp;rsquo;s crucial to achieve an extremely low false-positive rate (otherwise, it&amp;rsquo;s not trustable)
and be able to detect most of the degradations (otherwise, it&amp;rsquo;s not so useful).
It&amp;rsquo;s not easy if you don&amp;rsquo;t know which statistical approaches should be used.
If you try to google it, you may find thousands of papers about statistics,
but only a small portion of them really works in practice.&lt;/p>
&lt;p>In this post, I want to share some approaches that I use for performance analysis in everyday life.
I have been analyzing performance distributions for the last seven years,
and I have found a lot of approaches, metrics, and tricks which nice to have
in your statistical toolbox.
I would not say that all of them are must have to know,
but they can definitely help you to improve the reliability of your statistical checks
in different problems of performance analysis.
Consider the below list as a letter to a younger version of myself with a brief list of topics that are good to learn.&lt;/p></description></item><item><title>Quantile confidence intervals for weighted samples</title><link>https://aakinshin.net/posts/weighted-quantiles-ci/</link><pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/weighted-quantiles-ci/</guid><description>&lt;p>&lt;strong>Update 2021-07-06:
the approach was updated using the &lt;a href="https://aakinshin.net/posts/kish-ess-weighted-quantiles/">Kish&amp;rsquo;s effective sample size&lt;/a>.&lt;/strong>&lt;/p>
&lt;p>When you work with non-parametric distributions,
quantile estimations are essential to get the main distribution properties.
Once you get the estimation values, you may be interested in measuring the accuracy of these estimations.
Without it, it&amp;rsquo;s hard to understand how trustable the obtained values are.
One of the most popular ways to evaluate accuracy is confidence interval estimation.&lt;/p>
&lt;p>Now imagine that you collect some measurements every day.
Each day you get a small sample of values that is not enough to get the accurate daily quantile estimations.
However, the full time-series over the last several weeks has a decent size.
You suspect that past measurements should be similar to today measurements,
but you are not 100% sure about it.
You feel a temptation to extend the up-to-date sample by the previously collected values,
but it may spoil the estimation (e.g., in the case of recent change points or positive/negative trends).&lt;/p>
&lt;p>One of the possible approaches in this situation is to use &lt;em>weighted samples&lt;/em>.
This assumes that we add past measurements to the &amp;ldquo;today sample,&amp;rdquo;
but these values should have smaller weight.
The older measurement we take, the smaller weight it gets.
If you have consistent values across the last several days,
this approach works like a charm.
If you have any recent changes, you can detect such situations by huge confidence intervals
due to the sample inconsistency.&lt;/p>
&lt;p>So, how do we estimate confidence intervals around quantiles for the weighted samples?
In one of the previous posts, I have already shown how to &lt;a href="https://aakinshin.net/posts/weighted-quantiles/">estimate quantiles on weighted samples&lt;/a>.
In this post, I will show how to estimate quantile confidence intervals for weighted samples.&lt;/p></description></item><item><title>Quantile absolute deviation: estimating statistical dispersion around quantiles</title><link>https://aakinshin.net/posts/qad/</link><pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/qad/</guid><description>&lt;p>There are many different metrics for &lt;a href="https://en.wikipedia.org/wiki/Statistical_dispersion">statistical dispersion&lt;/a>.
The most famous one is the &lt;a href="https://en.wikipedia.org/wiki/Standard_deviation">standard deviation&lt;/a>.
The standard deviation is the most popular way to describe the spread around the mean when
you work with normally distributed data.
However, if you work with non-normal distributions, this metric may be misleading.&lt;/p>
&lt;p>In the world of non-parametric distributions,
the most common measure of &lt;a href="https://en.wikipedia.org/wiki/Central_tendency">central tendency&lt;/a> is the median.
For the median, you can describe dispersion using the
&lt;a href="https://en.wikipedia.org/wiki/Median_absolute_deviation">median absolute deviation around the median&lt;/a> (MAD).
It works great if the median is the only &lt;a href="https://en.wikipedia.org/wiki/Summary_statistics">summary statistic&lt;/a> that you care about.
However, if you work with multimodal distributions
(they can be detected using the &lt;a href="https://aakinshin.net/posts/lowland-multimodality-detection/">lowland multimodality detector&lt;/a>),
you may be interested in other quantiles as well.
So, it makes sense to learn how to describe dispersion around the given quantile.
Which metric should we choose?&lt;/p>
&lt;p>Recently, I came up with a great solution to this problem.
We can generalize the median absolute deviation into the quantile absolute deviation (QAD) around the given quantile based on the Harrell-Davis quantile estimator.
I will show how to calculate it, how to interpret it, and how to get insights about distribution properties
from images like this one:&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/qad/img/modal5-light.png" target="_blank" alt="modal5">
 &lt;img
 src="https://aakinshin.net/posts/qad/img/modal5-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/qad/img/modal5-dark.png" target="_blank" alt="modal5">
 &lt;img
 src="https://aakinshin.net/posts/qad/img/modal5-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div></description></item><item><title>P² quantile estimator: estimating the median without storing values</title><link>https://aakinshin.net/posts/p2-quantile-estimator/</link><pubDate>Tue, 24 Nov 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/p2-quantile-estimator/</guid><description>&lt;p>&lt;strong>Update: the estimator accuracy could be improved using a bunch of &lt;a href="https://aakinshin.net/tags/research-p2qe/">patches&lt;/a>.&lt;/strong>&lt;/p>
&lt;p>Imagine that you are implementing performance telemetry in your application.
There is an operation that is executed millions of times, and you want to get its &amp;ldquo;average&amp;rdquo; duration.
It&amp;rsquo;s not a good idea to use the arithmetic mean because the obtained value can be easily spoiled by outliers.
It&amp;rsquo;s much better to use the median which is one of the most robust ways to describe the average.&lt;/p>
&lt;p>The straightforward median estimation approach requires storing all the values.
In our case, it&amp;rsquo;s a bad idea to keep all the values because it will significantly increase the memory footprint.
Such telemetry is harmful because it may become a new bottleneck instead of monitoring the actual performance.&lt;/p>
&lt;p>Another way to get the median value is to use a sequential quantile estimator
(also known as an online quantile estimator or a streaming quantile estimator).
This is an algorithm that allows calculating the median value (or any other quantile value)
using a fixed amount of memory.
Of course, it provides only an approximation of the real median value,
but it&amp;rsquo;s usually enough for typical telemetry use cases.&lt;/p>
&lt;p>In this post, I will show one of the simplest sequential quantile estimators that is called the P² quantile estimator
(or the Piecewise-Parabolic quantile estimator).&lt;/p></description></item><item><title>Plain-text summary notation for multimodal distributions</title><link>https://aakinshin.net/posts/modality-summary-notation/</link><pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/modality-summary-notation/</guid><description>&lt;p>Let&amp;rsquo;s say you collected a lot of data and want to explore the underlying distributions of collected samples.
If you have only a few distributions, the best way to do that is to look at the density plots
(expressed via histograms, kernel density estimations, or &lt;a href="https://aakinshin.net/posts/qrde-hd/">quantile-respectful density estimations&lt;/a>).
However, it&amp;rsquo;s not always possible.&lt;/p>
&lt;p>Suppose you have to process dozens, hundreds, or even thousands of distributions.
In that case,
it may be extremely time-consuming to manually check visualizations of each distribution.
If you analyze distributions from the command line or send notifications about suspicious samples,
it may be impossible to embed images in the reports.
In these cases, there is a need to present a distribution using plain text.&lt;/p>
&lt;p>One way to do that is plain text histograms.
Unfortunately, this kind of visualization may occupy o lot of space.
In complicated cases, you may need 20 or 30 lines per a single distribution.&lt;/p>
&lt;p>Another way is to present classic &lt;a href="https://en.wikipedia.org/wiki/Summary_statistics">summary statistics&lt;/a>
like mean or median, standard deviation or median absolute deviation, quantiles, skewness, and kurtosis.
There is another problem here:
without experience, it&amp;rsquo;s hard to reconstruct the true distribution shape based on these values.
Even if you are an experienced researcher, the statistical metrics may become misleading in the case of multimodal distributions.
Multimodality is one of the most severe challenges in distribution analysis because it distorts basic summary statistics.
It&amp;rsquo;s important to not only find such distribution but also have a way to present brief information about multimodality effects.&lt;/p>
&lt;p>So, how can we condense the underlying distribution shape of a given sample to a short text line?
I didn&amp;rsquo;t manage to find an approach that works fine in my cases, so I came up with my own notation.
Most of the interpretation problems in my experiments arise from multimodality and outliers,
so I decided to focus on these two things and specifically highlight them.
Let&amp;rsquo;s consider this plot:&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/modality-summary-notation/img/thumbnail-light.svg" target="_blank" alt="thumbnail">
 &lt;img
 src="https://aakinshin.net/posts/modality-summary-notation/img/thumbnail-light.svg" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/modality-summary-notation/img/thumbnail-dark.svg" target="_blank" alt="thumbnail">
 &lt;img
 src="https://aakinshin.net/posts/modality-summary-notation/img/thumbnail-dark.svg" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>I suggest describing it like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="o">{&lt;/span>1.00, 2.00&lt;span class="o">}&lt;/span> + &lt;span class="o">[&lt;/span>7.16&lt;span class="p">;&lt;/span> 13.12&lt;span class="o">]&lt;/span>_100 + &lt;span class="o">{&lt;/span>19.00&lt;span class="o">}&lt;/span> + &lt;span class="o">[&lt;/span>27.69&lt;span class="p">;&lt;/span> 32.34&lt;span class="o">]&lt;/span>_100 + &lt;span class="o">{&lt;/span>37.00..39.00&lt;span class="o">}&lt;/span>_3
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Let me explain the suggested notation in detail.&lt;/p></description></item><item><title>Intermodal outliers</title><link>https://aakinshin.net/posts/intermodal-outliers/</link><pubDate>Tue, 10 Nov 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/intermodal-outliers/</guid><description>&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Outlier">Outlier&lt;/a> analysis is a typical step in distribution exploration.
Usually, we work with the &amp;ldquo;lower outliers&amp;rdquo; (extremely low values) and the &amp;ldquo;upper outliers&amp;rdquo; (extremely high values).
However, outliers are not always extreme values.
In the general case, an outlier is a value that significantly differs from other values in the same sample.
In the case of multimodal distribution, we can also consider outliers in the middle of the distribution.
Let&amp;rsquo;s call such outliers that we found between modes the &amp;ldquo;&lt;em>intermodal outliers&lt;/em>.&amp;rdquo;&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/intermodal-outliers/img/step4-light.svg" target="_blank" alt="step4">
 &lt;img
 src="https://aakinshin.net/posts/intermodal-outliers/img/step4-light.svg" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/intermodal-outliers/img/step4-dark.svg" target="_blank" alt="step4">
 &lt;img
 src="https://aakinshin.net/posts/intermodal-outliers/img/step4-dark.svg" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>Look at the above density plot.
It&amp;rsquo;s a bimodal distribution that is formed as a combination of two unimodal distributions.
Each of the unimodal distributions may have its own lower and upper outliers.
When we merge them, the upper outliers of the first distribution and the lower outliers of the second distribution
stop being lower or upper outliers.
However, if these values don&amp;rsquo;t belong to the modes, they still are a subject of interest.
In this post, I will show you how to detect such intermodal outliers
and how they can be used to form a better distribution description.&lt;/p></description></item><item><title>Lowland multimodality detection</title><link>https://aakinshin.net/posts/lowland-multimodality-detection/</link><pubDate>Tue, 03 Nov 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/lowland-multimodality-detection/</guid><description>&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/lowland-multimodality-detection/img/data5-light.svg" target="_blank" alt="data5">
 &lt;img
 src="https://aakinshin.net/posts/lowland-multimodality-detection/img/data5-light.svg" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/lowland-multimodality-detection/img/data5-dark.svg" target="_blank" alt="data5">
 &lt;img
 src="https://aakinshin.net/posts/lowland-multimodality-detection/img/data5-dark.svg" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>Multimodality is an essential feature of a distribution, which may create many troubles during automatic analysis.
One of the best ways to work with such distributions is to detect all the modes in advance based on the given samples.
Unfortunately, this problem is much harder than it looks like.&lt;/p>
&lt;p>I tried many different approaches for multimodality detection, but none of them was good enough.
During the past several years, my approach of choice was the &lt;a href="http://www.brendangregg.com/FrequencyTrails/modes.html">mvalue-based modal test&lt;/a> by Brendan Gregg.
It works nicely in simple cases, but I was constantly stumbling over noisy samples where this algorithm doesn&amp;rsquo;t produce reliable results.
Also, it has some limitations that make it unapplicable to some corner cases.&lt;/p>
&lt;p>So, I needed a better approach.
Here are my main requirements:&lt;/p>
&lt;ul>
&lt;li>It should detect the exact mode locations and ranges&lt;/li>
&lt;li>It should provide reliable results even on noisy samples&lt;/li>
&lt;li>It should be able to detect multimodality even when some modes are extremely close to each other&lt;/li>
&lt;li>It should work out of the box without tricky parameter tuning for each specific distribution&lt;/li>
&lt;/ul>
&lt;p>I failed to find such an algorithm anywhere, so I came up with my own!
The current working title is &amp;ldquo;the lowland multimodality detector.&amp;rdquo;
It takes an estimation of the probability density function (PDF) and tries to find &amp;ldquo;lowlands&amp;rdquo; (areas that are much lower than neighboring peaks).
Next, it splits the plot by these lowlands and detects modes between them.
For the PDF estimation, it uses the &lt;a href="https://aakinshin.net/posts/qrde-hd/">quantile-respectful density estimation based on the Harrell-Davis quantile estimator&lt;/a> (QRDE-HD).
Let me explain how it works in detail.&lt;/p></description></item><item><title>Quantile-respectful density estimation based on the Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/qrde-hd/</link><pubDate>Tue, 27 Oct 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/qrde-hd/</guid><description>&lt;p>The idea of this post was born when I was working on a presentation for my recent &lt;a href="https://dotnext.ru/en/">DotNext&lt;/a> &lt;a href="https://www.youtube.com/watch?v=gc3yVybPuaY&amp;list=PL21xssNXOJNGUROqzSTOC8uZL4W2QZpvK&amp;index=1">talk&lt;/a>.
It had a &lt;a href="https://slides.aakinshin.net/dotnext-piter2020/#193">slide&lt;/a> with a density plot like this:&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/qrde-hd/img/riddle-light.png" target="_blank" alt="riddle">
 &lt;img
 src="https://aakinshin.net/posts/qrde-hd/img/riddle-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/qrde-hd/img/riddle-dark.png" target="_blank" alt="riddle">
 &lt;img
 src="https://aakinshin.net/posts/qrde-hd/img/riddle-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>Here we can see a density plot based on a sample with highlighted &lt;a href="https://en.wikipedia.org/wiki/Decile">decile&lt;/a> locations that split the plot into 10 equal parts.
Before the conference, I have been reviewed by &lt;a href="https://twitter.com/VladimirSitnikv">@VladimirSitnikv&lt;/a>.
He raised a reasonable concern: it doesn&amp;rsquo;t look like all the density plot segments are equal and contain exactly 10% of the whole plot.
And he was right!&lt;/p>
&lt;p>However, I didn&amp;rsquo;t make any miscalculations.
I generated a real sample with 61 elements.
Next, I build a density plot with the kernel density estimation (KDE) using the Sheather &amp;amp; Jones method and the normal kernel.
Next, I calculated decile values using the Harrell-Davis quantile estimator.
Although both the density plot and the decile values are calculated correctly and consistent with the sample,
they are not consistent with each other!
Indeed, such a density plot is just an estimation of the underlying distribution.
It has its own decile values, which are not equal to the sample decile values regardless of the used quantile estimator.
This problem is common for different kinds of visualization that presents density and quantiles at the same time (e.g., &lt;a href="https://towardsdatascience.com/violin-plots-explained-fb1d115e023d">violin plots&lt;/a>)&lt;/p>
&lt;p>It leads us to a question: how should we present the shape of our data together with quantile values without confusing inconsistency in the final image?
Today I will present a good solution: we should use the quantile-respectful density estimation based on the Harrell-Davis quantile estimator!
I know the title is a bit long, but it&amp;rsquo;s not so complicated as it sounds.
In this post, I will show how to build such plots.
Also I will compare them to the classic histograms and kernel density estimations.
As a bonus, I will demonstrate how awesome these plots are for multimodality detection.&lt;/p></description></item><item><title>Misleading histograms</title><link>https://aakinshin.net/posts/misleading-histograms/</link><pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/misleading-histograms/</guid><description>&lt;p>Below you see two histograms.
What could you say about them?&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/misleading-histograms/img/hist-riddle-light.svg" target="_blank" alt="hist-riddle">
 &lt;img
 src="https://aakinshin.net/posts/misleading-histograms/img/hist-riddle-light.svg" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/misleading-histograms/img/hist-riddle-dark.svg" target="_blank" alt="hist-riddle">
 &lt;img
 src="https://aakinshin.net/posts/misleading-histograms/img/hist-riddle-dark.svg" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>Most likely, you say that the first histogram is based on a uniform distribution,
and the second one is based on a multimodal distribution with four modes.
Although this is not obvious from the plots,
both histograms are based on the same sample:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-cs" data-lang="cs">&lt;span class="line">&lt;span class="cl">&lt;span class="m">20.13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">19.94&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">20.03&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">20.06&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">20.04&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">19.98&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">20.15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">19.99&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">20.20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">19.99&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">20.13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">20.22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">19.86&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">19.97&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">19.98&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">20.06&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="m">29.97&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">29.73&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">29.75&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">30.13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">29.96&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">29.82&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">29.98&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">30.12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">30.18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">29.95&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">29.97&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">29.82&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">30.04&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">29.93&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">30.04&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">30.07&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="m">40.10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">39.93&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">40.05&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">39.82&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">39.92&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">39.91&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">39.75&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">40.00&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">40.02&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">39.96&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">40.07&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">39.92&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">39.86&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">40.04&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">39.91&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">40.14&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="m">49.95&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.06&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.03&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">49.92&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.06&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.00&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.02&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.06&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.00&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">49.70&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.02&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">49.96&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.01&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.05&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.13&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Thus, the only difference between histograms is the offset!&lt;/p>
&lt;p>Visualization is a simple way to understand the shape of your data.
Unfortunately, this way may easily become a slippery slope.
In the &lt;a href="https://aakinshin.net/posts/kde-bw/">previous post&lt;/a>, I have shown how density plots may deceive you when the bandwidth is poorly chosen.
Today, we talk about histograms and why you can&amp;rsquo;t trust them in the general case.&lt;/p></description></item><item><title>The importance of kernel density estimation bandwidth</title><link>https://aakinshin.net/posts/kde-bw/</link><pubDate>Tue, 13 Oct 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/kde-bw/</guid><description>&lt;p>Below see two kernel density estimations.
What could you say about them?&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/kde-bw/img/kde-riddle-light.svg" target="_blank" alt="kde-riddle">
 &lt;img
 src="https://aakinshin.net/posts/kde-bw/img/kde-riddle-light.svg" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/kde-bw/img/kde-riddle-dark.svg" target="_blank" alt="kde-riddle">
 &lt;img
 src="https://aakinshin.net/posts/kde-bw/img/kde-riddle-dark.svg" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>Most likely, you say that the first plot is based on a uniform distribution,
and the second one is based on a multimodal distribution with four modes.
Although this is not obvious from the plots,
both density plots are based on the same sample:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-txt" data-lang="txt">&lt;span class="line">&lt;span class="cl">21.370, 19.435, 20.363, 20.632, 20.404, 19.893, 21.511, 19.905, 22.018, 19.93,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">31.304, 32.286, 28.611, 29.721, 29.866, 30.635, 29.715, 27.343, 27.559, 31.32,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">39.693, 38.218, 39.828, 41.214, 41.895, 39.569, 39.742, 38.236, 40.460, 39.36,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">50.455, 50.704, 51.035, 49.391, 50.504, 48.282, 49.215, 49.149, 47.585, 50.03
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The only difference between plots is in &lt;a href="https://en.wikipedia.org/wiki/Kernel_density_estimation#Bandwidth_selection">bandwidth selection&lt;/a>!&lt;/p>
&lt;p>Bandwidth selection is crucial when you are trying to visualize your distributions.
Unfortunately, most people just call a regular function to build a density plot and don&amp;rsquo;t think about how the bandwidth will be chosen.
As a result, the plot may present data in the wrong way, which may lead to incorrect conclusions.
Let&amp;rsquo;s discuss bandwidth selection in detail and figure out how to improve the correctness of your density plots.
In this post, we will cover the following topics:&lt;/p>
&lt;ul>
&lt;li>Kernel density estimation&lt;/li>
&lt;li>How bandwidth selection affects plot smoothness&lt;/li>
&lt;li>Which bandwidth selectors can we use&lt;/li>
&lt;li>Which bandwidth selectors should we use&lt;/li>
&lt;li>Insidious default bandwidth selectors in statistical packages&lt;/li>
&lt;/ul></description></item><item><title>The median absolute deviation value of the Gumbel distribution</title><link>https://aakinshin.net/posts/gumbel-mad/</link><pubDate>Tue, 06 Oct 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/gumbel-mad/</guid><description>&lt;p>The &lt;a href="https://en.wikipedia.org/wiki/Gumbel_distribution">Gumbel distribution&lt;/a> is not only a useful model in the &lt;a href="https://en.wikipedia.org/wiki/Extreme_value_theory">extreme value theory&lt;/a>,
but it&amp;rsquo;s also a nice example of a slightly right-skewed distribution (skewness $\approx 1.14$).
Here is its density plot:&lt;/p>






&lt;div class="row">
&lt;div class="mx-auto">
 &lt;a href="https://aakinshin.net/posts/gumbel-mad/img/gumbel-light.svg" target="_blank" class="imgldlink" alt="gumbel">
 &lt;picture>
 &lt;source
 theme='dark'
 srcset="https://aakinshin.net/posts/gumbel-mad/img/gumbel-dark.svg"
 media="(prefers-color-scheme: dark)">
 &lt;source
 theme='light'
 srcset="https://aakinshin.net/posts/gumbel-mad/img/gumbel-light.svg"
 media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)">
 &lt;img
 class="mx-auto d-block img-fluid"
 width='600'
 src="https://aakinshin.net/posts/gumbel-mad/img/gumbel-light.svg">
 &lt;/picture>
 &lt;/a>
&lt;/div>
&lt;/div>
&lt;br />
&lt;p>In some of my statistical experiments, I like to use the Gumbel distribution as a sample generator for hypothesis checking or unit tests.
I also prefer the &lt;a href="https://en.wikipedia.org/wiki/Median_absolute_deviation">median absolute deviation&lt;/a> (MAD) over the standard deviation as a measure of dispersion because it&amp;rsquo;s more robust in the case of non-parametric distributions.
Numerical hypothesis verification often requires the exact value of the median absolute deviation of the original distribution.
I didn&amp;rsquo;t find this value in the reference tables, so I decided to do another exercise and derive it myself.
In this post, you will find a short derivation and the result (spoiler: the exact value is &lt;code>0.767049251325708 * β&lt;/code>).
The general approach of the MAD derivation is common for most distributions, so it can be easily reused.&lt;/p></description></item><item><title>Weighted quantile estimators</title><link>https://aakinshin.net/posts/weighted-quantiles/</link><pubDate>Tue, 29 Sep 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/weighted-quantiles/</guid><description>&lt;p>&lt;strong>Update 2021-07-06:
the approach was updated using the &lt;a href="https://aakinshin.net/posts/kish-ess-weighted-quantiles/">Kish&amp;rsquo;s effective sample size&lt;/a>.&lt;/strong>&lt;/p>
&lt;p>In this post, I will show how to calculate weighted quantile estimates and how to use them in practice.&lt;/p>
&lt;p>Let&amp;rsquo;s start with a problem from real life.
Imagine that you measure the total duration of a unit test executed daily on a CI server.
Every day you get a single number that corresponds to the test duration from the latest revision for this day:&lt;/p>






&lt;div class="row">
&lt;div class="mx-auto">
 &lt;a href="https://aakinshin.net/posts/weighted-quantiles/img/moving1-light.svg" target="_blank" class="imgldlink" alt="moving1">
 &lt;picture>
 &lt;source
 theme='dark'
 srcset="https://aakinshin.net/posts/weighted-quantiles/img/moving1-dark.svg"
 media="(prefers-color-scheme: dark)">
 &lt;source
 theme='light'
 srcset="https://aakinshin.net/posts/weighted-quantiles/img/moving1-light.svg"
 media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)">
 &lt;img
 class="mx-auto d-block img-fluid"
 width='600'
 src="https://aakinshin.net/posts/weighted-quantiles/img/moving1-light.svg">
 &lt;/picture>
 &lt;/a>
&lt;/div>
&lt;/div>
&lt;br />
&lt;p>You collect a history of such measurements for 100 days.
Now you want to describe the &amp;ldquo;actual&amp;rdquo; distribution of the performance measurements.&lt;/p>
&lt;p>However, for the latest &amp;ldquo;actual&amp;rdquo; revision, you have only a single measurement, which is not enough to build a distribution.
Also, you can&amp;rsquo;t build a distribution based on the last N measurements because they can contain change points that will spoil your results.
So, what you really want to do is to use all the measurements, but older values should have a lower impact on the final distribution form.&lt;/p>
&lt;p>Such a problem can be solved using the weighted quantiles!
This powerful approach can be applied to any time series regardless of the domain area.
In this post, we learn how to calculate and apply weighted quantiles.&lt;/p></description></item><item><title>Nonparametric Cohen's d-consistent effect size</title><link>https://aakinshin.net/posts/nonparametric-effect-size/</link><pubDate>Thu, 25 Jun 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/nonparametric-effect-size/</guid><description>&lt;p>&lt;strong>Update: the second part of this post is available &lt;a href="https://aakinshin.net/posts/nonparametric-effect-size2/">here&lt;/a>.&lt;/strong>&lt;/p>
&lt;p>The effect size is a common way to describe a difference between two distributions.
When these distributions are normal, one of the most popular approaches to express the effect size is &lt;a href="https://en.wikipedia.org/wiki/Effect_size#Cohen's_d">Cohen&amp;rsquo;s d&lt;/a>.
Unfortunately, it doesn&amp;rsquo;t work great for non-normal distributions.&lt;/p>
&lt;p>In this post, I will show a robust Cohen&amp;rsquo;s d-consistent effect size formula for nonparametric distributions.&lt;/p>





&lt;div class="row">
&lt;div class="mx-auto">
 &lt;a href="https://aakinshin.net/posts/nonparametric-effect-size/img/blackboard.png" target="_blank" alt="blackboard">
 &lt;img
 class="mx-auto d-block img-fluid"
 width='800'
 src="https://aakinshin.net/posts/nonparametric-effect-size/img/blackboard.png" />
 &lt;/a>
&lt;/div>
&lt;/div>
&lt;br /></description></item><item><title>DoubleMAD outlier detector based on the Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/harrell-davis-double-mad-outlier-detector/</link><pubDate>Mon, 22 Jun 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/harrell-davis-double-mad-outlier-detector/</guid><description>&lt;p>Outlier detection is an important step in data processing.
Unfortunately, if the distribution is not normal (e.g., right-skewed and heavy-tailed), it&amp;rsquo;s hard to choose
a robust outlier detection algorithm that will not be affected by tricky distribution properties.
During the last several years, I tried many different approaches, but I was not satisfied with their results.
Finally, I found an algorithm to which I have (almost) no complaints.
It&amp;rsquo;s based on the &lt;em>double median absolute deviation&lt;/em> and the &lt;em>Harrell-Davis quantile estimator&lt;/em>.
In this post, I will show how it works and why it&amp;rsquo;s better than some other approaches.&lt;/p></description></item><item><title>Distribution comparison via the shift and ratio functions</title><link>https://aakinshin.net/posts/shift-and-ratio-functions/</link><pubDate>Fri, 11 Oct 2019 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/shift-and-ratio-functions/</guid><description>&lt;p>When we compare two distributions, it&amp;rsquo;s not always enough to detect a statistically significant difference between them.
In many cases, we also want to evaluate the magnitude of this difference.
Let&amp;rsquo;s look at the following image:&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/shift-and-ratio-functions/img/compare1-light.png" target="_blank" alt="compare1">
 &lt;img
 src="https://aakinshin.net/posts/shift-and-ratio-functions/img/compare1-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/shift-and-ratio-functions/img/compare1-dark.png" target="_blank" alt="compare1">
 &lt;img
 src="https://aakinshin.net/posts/shift-and-ratio-functions/img/compare1-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>On the left side, we can see a timeline plot with 2000 points
(at the middle of this plot, the distribution was significantly changed).
On the right side, you can see density plots for the left and the right side of
the timeline plot (before and after the change).
It&amp;rsquo;s a pretty simple case, the difference between distributions be expressed via the
difference between mean values.&lt;/p>
&lt;p>Now let&amp;rsquo;s look at a more tricky case:&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/shift-and-ratio-functions/img/compare2-light.png" target="_blank" alt="compare2">
 &lt;img
 src="https://aakinshin.net/posts/shift-and-ratio-functions/img/compare2-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/shift-and-ratio-functions/img/compare2-dark.png" target="_blank" alt="compare2">
 &lt;img
 src="https://aakinshin.net/posts/shift-and-ratio-functions/img/compare2-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>Here we have a bimodal distribution; after the change, the left mode &amp;ldquo;moved right.&amp;rdquo;
Now it&amp;rsquo;s much harder to evaluate the difference between distributions
because the mean and the median values almost not changed:
the right mode has the biggest impact on these metrics than the left more.&lt;/p>
&lt;p>And here is a much more tricky case:&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/shift-and-ratio-functions/img/compare3-light.png" target="_blank" alt="compare3">
 &lt;img
 src="https://aakinshin.net/posts/shift-and-ratio-functions/img/compare3-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/shift-and-ratio-functions/img/compare3-dark.png" target="_blank" alt="compare3">
 &lt;img
 src="https://aakinshin.net/posts/shift-and-ratio-functions/img/compare3-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>Here we also have a bimodal distribution; after the change, both modes moved:
the left mode &amp;ldquo;moved right&amp;rdquo; and the right mode &amp;ldquo;moved left.&amp;rdquo;
How should we describe the difference between these distributions now?&lt;/p></description></item><item><title>Normality is a myth</title><link>https://aakinshin.net/posts/normality/</link><pubDate>Wed, 09 Oct 2019 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/normality/</guid><description>&lt;p>In many statistical papers, you can find the following phrase: &amp;ldquo;assuming that we have a normal distribution.&amp;rdquo;
Probably, you saw plots of the normal distribution density function in some statistics textbooks,
it looks like this:&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/normality/img/normal-light.png" target="_blank" alt="normal">
 &lt;img
 src="https://aakinshin.net/posts/normality/img/normal-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/normality/img/normal-dark.png" target="_blank" alt="normal">
 &lt;img
 src="https://aakinshin.net/posts/normality/img/normal-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>The normal distribution is a pretty user-friendly mental model when we are trying to interpret the statistical metrics
like mean and standard deviation.
However, it may also be an insidious and misleading model when your distribution is not normal.
There is a great sentence in the &lt;a href="https://doi.org/10.1093/biomet/34.3-4.209">&amp;ldquo;Testing for normality&amp;rdquo;&lt;/a> paper by R.C. Geary, 1947 (the quote was found &lt;a href="https://garstats.wordpress.com/2019/06/17/myth/">here&lt;/a>):&lt;/p>
&lt;blockquote>
&lt;p>Normality is a myth; there never was, and never will be, a normal distribution.&lt;/p>
&lt;/blockquote>
&lt;p>I 100% agree with this statement.
At least, if you are working with performance distributions
(that are based on the multiple iterations of your benchmarks that measure the performance metrics of your applications),
you should forget about normality.
That&amp;rsquo;s how a typical performance distribution looks like
(I built the below picture based on a real benchmark that measures the load time of assemblies
when we open the &lt;a href="https://github.com/OrchardCMS/Orchard">Orchard&lt;/a> solution in &lt;a href="https://www.jetbrains.com/rider/">Rider&lt;/a> on Linux):&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/normality/img/performance-light.png" target="_blank" alt="performance">
 &lt;img
 src="https://aakinshin.net/posts/normality/img/performance-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/normality/img/performance-dark.png" target="_blank" alt="performance">
 &lt;img
 src="https://aakinshin.net/posts/normality/img/performance-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div></description></item><item><title>Implementation of an efficient algorithm for changepoint detection: ED-PELT</title><link>https://aakinshin.net/posts/edpelt/</link><pubDate>Mon, 07 Oct 2019 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/edpelt/</guid><description>&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Change_detection">Changepoint detection&lt;/a> is an important task that has a lot of applications.
For example, I use it to detect changes in the &lt;a href="https://www.jetbrains.com/rider/">Rider&lt;/a> performance test suite.
It&amp;rsquo;s very important to detect not only performance degradations, but any kinds of performance changes
(e.g., the variance may increase, or an unimodal distribution may be split into several modes).
You can see examples of such changes in the following picture (we change the color when a changepoint is detected):&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/edpelt/img/edpelt-light.png" target="_blank" alt="edpelt">
 &lt;img
 src="https://aakinshin.net/posts/edpelt/img/edpelt-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/edpelt/img/edpelt-dark.png" target="_blank" alt="edpelt">
 &lt;img
 src="https://aakinshin.net/posts/edpelt/img/edpelt-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>Unfortunately, it&amp;rsquo;s pretty hard to write a reliable and fast algorithm for changepoint detection.
Recently, I found a cool paper &lt;a href="https://aakinshin.net/library/papers/haynes2016/">&lt;svg class="rating-icon">&lt;use xlink:href="https://aakinshin.net/img/fa/all.svg#paper">&lt;/use>&lt;/svg>haynes2016&lt;/a> that describes the ED-PELT algorithm.
It has &lt;code>O(N*log(N))&lt;/code> complexity and pretty good detection accuracy.
The reference implementation can be used via the &lt;a href="https://cran.r-project.org/web/packages/changepoint.np/index.html">changepoint.np&lt;/a> R package.
However, I can&amp;rsquo;t use &lt;a href="https://www.r-project.org/">R&lt;/a> on our build server, so I decided to write my own C# implementation.&lt;/p></description></item><item><title>Reflecting on performance testing</title><link>https://aakinshin.net/posts/reflecting-on-performance-testing/</link><pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/reflecting-on-performance-testing/</guid><description>&lt;p>Performance is an important feature for many projects.
Unfortunately, it&amp;rsquo;s an all too common situation when a developer accidentally spoils the performance adding some new code.
After a series of such incidents, people often start to think about performance regression testing.&lt;/p>
&lt;p>As developers, we write unit tests all the time.
These tests check that our business logic work as designed and that new features don&amp;rsquo;t break existing code.
It looks like a good idea to write some perf tests as well, which will verify that we don&amp;rsquo;t have any performance regressions.&lt;/p>
&lt;p>Turns out this is harder than it sounds.
A lot of developers don&amp;rsquo;t write perf tests at all.
Some teams write perf tests, but almost all of them use their own infrastructure for analysis
(which is not a bad thing in general because it&amp;rsquo;s usually designed for specific projects and requirements).
There are a lot of books about test-driven development (TDD),
but there are no books about performance-driven development (PDD).
There are well-known libraries for unit-testing (like xUnit/NUnit/MSTest for .NET),
but there are almost no libraries for performance regression testing.
Yeah, of course, there are &lt;em>some&lt;/em> libraries which you can use.
But there are troubles with &lt;em>well-known all recognized&lt;/em> libraries, approaches, and tools.
Ask your colleagues about it: some of them will give you different answers, the rest of them will start Googling it.&lt;/p>
&lt;p>There is no common understanding of what performance testing should look like.
This situation exists because it&amp;rsquo;s really hard to develop a solution which solves &lt;em>all problems&lt;/em> for &lt;em>all kind of projects&lt;/em>.
However, it doesn&amp;rsquo;t mean that we shouldn&amp;rsquo;t try.
And we should try, we should share our experience and discuss best practices.&lt;/p></description></item><item><title>0.05 Evidence-based Medicine from Magic to the Search for Immortality</title><link>https://aakinshin.net/library/books/talantov-005-evidence-based-medicine/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/talantov-005-evidence-based-medicine/</guid><description/></item><item><title>3 Easy Ways to Obtain Cohen’s d and Its CI</title><link>https://aakinshin.net/library/web/3cf11abcafe2b5d16c586dfb1af211bd/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/web/3cf11abcafe2b5d16c586dfb1af211bd/</guid><description/></item><item><title>A Cautionary Note on the Use of Error Bars</title><link>https://aakinshin.net/library/papers/lanzante2005/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/lanzante2005/</guid><description>Reference John R Lanzante “A Cautionary Note on the Use of Error Bars” (2005) // Journal of Climate. Publisher: American Meteorological Society. Vol. 18. No 17. Pp. 3699–3703. DOI: 10.1175/jcli3499.1
Bib @Article{lanzante2005, title = {A Cautionary Note on the Use of Error Bars}, volume = {18}, issn = {0894-8755}, url = {http://dx.doi.org/10.1175/JCLI3499.1}, doi = {10.1175/jcli3499.1}, number = {17}, journal = {Journal of Climate}, publisher = {American Meteorological Society}, author = {Lanzante, John R}, year = {2005}, month = {sep}, pages = {3699–3703} }</description></item><item><title>A Comprehensive Review of Reporting Practices in Psychological journals: Are Effect Sizes Really enough?</title><link>https://aakinshin.net/library/papers/fritz2012/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/fritz2012/</guid><description>Reference Astrid Fritz, Thomas Scherndl, Anton Kühberger “A comprehensive review of reporting practices in psychological journals: Are effect sizes really enough?” (2012) // Theory &amp;amp; Psychology. Publisher: SAGE Publications. Vol. 23. No 1. Pp. 98–122. DOI: 10.1177/0959354312436870
Bib @Article{fritz2012, title = {A comprehensive review of reporting practices in psychological journals: Are effect sizes really enough?}, volume = {23}, issn = {1461-7447}, url = {http://dx.doi.org/10.1177/0959354312436870}, doi = {10.1177/0959354312436870}, number = {1}, journal = {Theory &amp;amp;amp; Psychology}, publisher = {SAGE Publications}, author = {Fritz, Astrid and Scherndl, Thomas and Kühberger, Anton}, year = {2012}, month = {jun}, pages = {98–122} }</description></item><item><title>A Cosmetic ‘anti-ageing’ Product Improves Photoaged skin: A double-blind, Randomized Controlled Trial</title><link>https://aakinshin.net/library/papers/watson2009/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/watson2009/</guid><description>Critisism: bland2009
Reference REB Watson, S Ogden, LF Cotterell, JJ Bowden, JY Bastrilles, SP Long, CEM Griffiths “A cosmetic ‘anti-ageing’ product improves photoaged skin: a double-blind, randomized controlled trial” (2009) // British Journal of Dermatology. Publisher: Oxford University Press (OUP). Vol. 161. No 2. Pp. 419–426. DOI: 10.1111/j.1365-2133.2009.09216.x
Bib @Article{watson2009, title = {A cosmetic ‘anti-ageing’ product improves photoaged skin: a double-blind, randomized controlled trial}, volume = {161}, issn = {1365-2133}, url = {http://dx.doi.org/10.1111/j.1365-2133.2009.09216.x}, doi = {10.1111/j.1365-2133.2009.09216.x}, number = {2}, journal = {British Journal of Dermatology}, publisher = {Oxford University Press (OUP)}, author = {Watson, REB and Ogden, S and Cotterell, LF and Bowden, JJ and Bastrilles, JY and Long, SP and Griffiths, CEM}, year = {2009}, month = {aug}, pages = {419–426} }</description></item><item><title>A Critique and Improvement of the "CL" Common Language Effect Size Statistics of McGraw and Wong</title><link>https://aakinshin.net/library/papers/vargha2000/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/vargha2000/</guid><description>Reference András Vargha, Harold D Delaney, Andras Vargha “A Critique and Improvement of the &amp;ldquo;CL&amp;rdquo; Common Language Effect Size Statistics of McGraw and Wong” (2000) // Journal of Educational and Behavioral Statistics. Vol. 25. No 2. Pp. 101. DOI: 10.2307/1165329
Bib @Article{vargha2000, title = {A Critique and Improvement of the &amp;#34;CL&amp;#34; Common Language Effect Size Statistics of McGraw and Wong}, volume = {25}, issn = {10769986}, url = {http://links.jstor.org/sici?sici=1076-9986%28200022%2925%3A2%3C101%3AACAIOT%3E2.0.CO%3B2-O&amp;amp;origin=crossref}, doi = {10.2307/1165329}, number = {2}, urldate = {2023-10-22}, journal = {Journal of Educational and Behavioral Statistics}, author = {Vargha, András and Delaney, Harold D and Vargha, Andras}, year = {2000}, pages = {101} }</description></item><item><title>A Dirty dozen: Twelve p-value Misconceptions</title><link>https://aakinshin.net/library/papers/goodman2008/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/goodman2008/</guid><description>Reference Steven Goodman “A dirty dozen: twelve p-value misconceptions” (2008) // Seminars in hematology. Elsevier. Vol. 45. No 3. Pp. 135–140. DOI: 10.1053/j.seminhematol.2008.04.003
Abstract The P value is a measure of statistical evidence that appears in virtually all medical research papers. Its interpretation is made extraordinarily difficult because it is not part of any formal system of statistical inference. As a result, the P value&amp;rsquo;s inferential meaning is widely and often wildly misconstrued, a fact that has been pointed out in innumerable papers and books appearing since at least the 1940s. This commentary reviews a dozen of these common misinterpretations and explains why each is wrong. It also reviews the possible consequences of these improper understandings or representations of its meaning. Finally, it contrasts the P value with its Bayesian counterpart, the Bayes&amp;rsquo; factor, which has virtually all of the desirable properties of an evidential measure that the P value lacks, most notably interpretability. The most serious consequence of this array of P-value misconceptions is the false belief that the probability of a conclusion being in error can be calculated from the data in a single experiment without reference to external evidence or the plausibility of the underlying mechanism.
Bib @Inproceedings{goodman2008, title = {A dirty dozen: twelve p-value misconceptions}, author = {Goodman, Steven}, abstract = {The P value is a measure of statistical evidence that appears in virtually all medical research papers. Its interpretation is made extraordinarily difficult because it is not part of any formal system of statistical inference. As a result, the P value&amp;#39;s inferential meaning is widely and often wildly misconstrued, a fact that has been pointed out in innumerable papers and books appearing since at least the 1940s. This commentary reviews a dozen of these common misinterpretations and explains why each is wrong. It also reviews the possible consequences of these improper understandings or representations of its meaning.</description></item><item><title>A First Course in Order Statistics</title><link>https://aakinshin.net/library/papers/arnold2008/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/arnold2008/</guid><description>Reference Barry C Arnold, N Balakrishnan, H N Nagaraja “A first course in order statistics” (2008) // Publisher: SIAM. ISBN: 9780898716481. No 54. DOI: 10.1137/1.9780898719062
Bib @Book{arnold2008, location = {Philadelphia, PA}, title = {A first course in order statistics}, isbn = {9780898716481}, series = {Classics in applied mathematics}, pagetotal = {279}, number = {54}, publisher = {SIAM}, author = {Arnold, Barry C and Balakrishnan, N and Nagaraja, H N}, date = {2008}, note = {OCLC: ocn191882183}, doi = {10.1137/1.9780898719062} }</description></item><item><title>A History of Effect Size Indices</title><link>https://aakinshin.net/library/papers/huberty2002/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/huberty2002/</guid><description>Reference Carl J Huberty “A History of Effect Size Indices” (2002) // Educational and Psychological Measurement. Publisher: SAGE Publications. Vol. 62. No 2. Pp. 227–240. DOI: 10.1177/0013164402062002002
Bib @Article{huberty2002, title = {A History of Effect Size Indices}, volume = {62}, issn = {1552-3888}, url = {http://dx.doi.org/10.1177/0013164402062002002}, doi = {10.1177/0013164402062002002}, number = {2}, journal = {Educational and Psychological Measurement}, publisher = {SAGE Publications}, author = {Huberty, Carl J}, year = {2002}, month = {apr}, pages = {227–240} }</description></item><item><title>A Modern Introduction to Probability and Statistics: Understanding Why and How</title><link>https://aakinshin.net/library/papers/dekking2005/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/dekking2005/</guid><description>Reference Frederik Michel Dekking, Cornelis Kraaikamp, Hendrik Paul Lopuha&amp;quot;a, Ludolf Erwin Meester “A Modern Introduction to Probability and Statistics: Understanding why and how” (2005) // Publisher: Springer Science &amp;amp; Business Media. ISBN: 9781852338961.
Bib @Book{dekking2005, title = {A Modern Introduction to Probability and Statistics: Understanding why and how}, author = {Dekking, Frederik Michel and Kraaikamp, Cornelis and Lopuha\&amp;#34;a, Hendrik Paul and Meester, Ludolf Erwin}, year = {2005}, publisher = {Springer Science \&amp;amp; Business Media}, isbn = {9781852338961}, series = {Springer Texts in Statistics} }</description></item><item><title>A New distribution-free Quantile Estimator</title><link>https://aakinshin.net/library/papers/harrell1982/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/harrell1982/</guid><description>Reference Frank E Harrell, C E Davis “A new distribution-free quantile estimator” (1982) // Biometrika. Vol. 69. No 3. Pp. 635–640. DOI: 10.1093/biomet/69.3.635
Abstract A new distribution-free estimator Qp of the pth population quantile is formulated, where Qp is a linear combination of order statistics admitting a jackknife variance estimator having excellent properties. The small sample efficiency of Qp is studied under a variety of light and heavy-tailed symmetric and asymmetric distributions. For the distributions and values of p studied, Qp is generally substantially more efficient than the traditional estimator based on one or two order statistics.
Bib @Article{harrell1982, title = {A new distribution-free quantile estimator}, volume = {69}, issn = {0006-3444}, url = {https://academic.oup.com/biomet/article/69/3/635/221346}, doi = {10.1093/biomet/69.3.635}, abstract = {A new distribution-free estimator Qp of the pth population quantile is formulated, where Qp is a linear combination of order statistics admitting a jackknife variance estimator having excellent properties. The small sample efficiency of Qp is studied under a variety of light and heavy-tailed symmetric and asymmetric distributions. For the distributions and values of p studied, Qp is generally substantially more efficient than the traditional estimator based on one or two order statistics.}, language = {en}, number = {3}, urldate = {2020-07-14}, journal = {Biometrika}, author = {Harrell, Frank E and Davis, C E}, month = {dec}, year = {1982}, note = {Publisher: Oxford Academic}, pages = {635--640} }</description></item><item><title>A New Family of Nonparametric Quantile Estimators</title><link>https://aakinshin.net/library/papers/sfakianakis2008/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/sfakianakis2008/</guid><description>Reference Michael E Sfakianakis, Dimitris G Verginis “A new family of nonparametric quantile estimators” (2008) // Communications in Statistics—Simulation and Computation\textregistered. Publisher: Taylor &amp;amp; Francis. Vol. 37. No 2. Pp. 337–345. DOI: 10.1080/03610910701790491
Bib @Article{sfakianakis2008, title = {A new family of nonparametric quantile estimators}, author = {Sfakianakis, Michael E and Verginis, Dimitris G}, journal = {Communications in Statistics—Simulation and Computation\textregistered}, volume = {37}, number = {2}, pages = {337--345}, year = {2008}, publisher = {Taylor \&amp;amp; Francis}, doi = {10.1080/03610910701790491} }</description></item><item><title>A New Quantile Estimator with Weights Based on a Subsampling Approach</title><link>https://aakinshin.net/library/papers/navruz2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/navruz2020/</guid><description>Reference G&amp;quot;ozde Navruz, A F\irat &amp;quot;Ozdemir “A new quantile estimator with weights based on a subsampling approach” (2020) // British Journal of Mathematical and Statistical Psychology. Publisher: Wiley Online Library. Vol. 73. No 3. Pp. 506–521. DOI: 10.1111/bmsp.12198
Bib @Article{navruz2020, title = {A new quantile estimator with weights based on a subsampling approach}, author = {Navruz, G\&amp;#34;ozde and \&amp;#34;Ozdemir, A F\irat}, journal = {British Journal of Mathematical and Statistical Psychology}, volume = {73}, number = {3}, pages = {506--521}, year = {2020}, publisher = {Wiley Online Library}, doi = {10.1111/bmsp.12198} }</description></item><item><title>A Note on Estimating the Variance of the Sample Median</title><link>https://aakinshin.net/library/papers/maritz1978/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/maritz1978/</guid><description>Reference JS Maritz, RG Jarrett “A note on estimating the variance of the sample median” (1978) // Journal of the American Statistical Association. Publisher: Taylor &amp;amp; Francis. Vol. 73. No 361. Pp. 194–196. DOI: 10.2307/2286545
Bib @Article{maritz1978, title = {A note on estimating the variance of the sample median}, author = {Maritz, JS and Jarrett, RG}, journal = {Journal of the American Statistical Association}, volume = {73}, number = {361}, pages = {194--196}, year = {1978}, publisher = {Taylor \&amp;amp; Francis}, doi = {10.2307/2286545} }</description></item><item><title>A Note on the Hodges–Lehmann Estimator</title><link>https://aakinshin.net/library/papers/rosenkranz2010/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/rosenkranz2010/</guid><description>Reference Gerd K Rosenkranz “A note on the Hodges–Lehmann estimator” (2010) // Pharmaceutical Statistics. Vol. 9. No 2. Pp. 162–167. DOI: 10.1002/pst.387
Abstract Abstract
Bib @Article{rosenkranz2010, title = {A note on the Hodges–Lehmann estimator}, volume = {9}, issn = {1539-1604, 1539-1612}, url = {https://onlinelibrary.wiley.com/doi/10.1002/pst.387}, doi = {10.1002/pst.387}, abstract = {Abstract}, language = {en}, number = {2}, urldate = {2023-12-10}, journal = {Pharmaceutical Statistics}, author = {Rosenkranz, Gerd K}, month = {apr}, year = {2010}, pages = {162--167} }</description></item><item><title>A Power Primer</title><link>https://aakinshin.net/library/papers/cohen1992/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/cohen1992/</guid><description>Reference Jacob Cohen “A power primer” (1992) // Psychological Bulletin. Publisher: American Psychological Association (APA). Vol. 112. No 1. Pp. 155–159. DOI: 10.1037/0033-2909.112.1.155
Bib @Article{cohen1992, title = {A power primer}, volume = {112}, issn = {0033-2909}, url = {http://dx.doi.org/10.1037/0033-2909.112.1.155}, doi = {10.1037/0033-2909.112.1.155}, number = {1}, journal = {Psychological Bulletin}, publisher = {American Psychological Association (APA)}, author = {Cohen, Jacob}, year = {1992}, pages = {155–159} }</description></item><item><title>A Practical Implementation of Weighted Kernel Density Estimation for Handling Shape Constraints</title><link>https://aakinshin.net/library/papers/wolters2018/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/wolters2018/</guid><description>Reference Mark Anthony Wolters, Willard John Braun “A practical implementation of weighted kernel density estimation for handling shape constraints” (2018) // Stat. Publisher: Wiley. Vol. 7. No 1. Pp. e202. DOI: 10.1002/sta4.202
Bib @Article{wolters2018, doi = {10.1002/sta4.202}, year = {2018}, publisher = {Wiley}, volume = {7}, number = {1}, pages = {e202}, author = {Mark Anthony Wolters and Willard John Braun}, title = {A practical implementation of weighted kernel density estimation for handling shape constraints}, journal = {Stat} }</description></item><item><title>A Practical Solution to the Pervasive Problems of P Values</title><link>https://aakinshin.net/library/papers/wagenmakers2007/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/wagenmakers2007/</guid><description>Reference Eric-Jan Wagenmakers “A practical solution to the pervasive problems of p values” (2007) // Psychonomic Bulletin &amp;amp; Review. Publisher: Springer Science and Business Media LLC. Vol. 14. No 5. Pp. 779–804. DOI: 10.3758/bf03194105
Bib @Article{wagenmakers2007, title = {A practical solution to the pervasive problems of p values}, volume = {14}, issn = {1531-5320}, url = {http://dx.doi.org/10.3758/BF03194105}, doi = {10.3758/bf03194105}, number = {5}, journal = {Psychonomic Bulletin &amp;amp;amp; Review}, publisher = {Springer Science and Business Media LLC}, author = {Wagenmakers, Eric-Jan}, year = {2007}, month = {oct}, pages = {779–804} }</description></item><item><title>A Reliable data-based Bandwidth Selection Method for Kernel Density Estimation</title><link>https://aakinshin.net/library/papers/sheather1991/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/sheather1991/</guid><description>Reference Simon J Sheather, Michael C Jones “A reliable data-based bandwidth selection method for kernel density estimation” (1991) // Journal of the Royal Statistical Society: Series B (Methodological). Publisher: Wiley Online Library. Vol. 53. No 3. Pp. 683–690. DOI: 10.1111/j.2517-6161.1991.tb01857.x
Bib @Article{sheather1991, title = {A reliable data-based bandwidth selection method for kernel density estimation}, author = {Sheather, Simon J and Jones, Michael C}, journal = {Journal of the Royal Statistical Society: Series B (Methodological)}, volume = {53}, number = {3}, pages = {683--690}, year = {1991}, publisher = {Wiley Online Library}, doi = {10.1111/j.2517-6161.1991.tb01857.x} }</description></item><item><title>A Robust Nonparametric Measure of Effect Size Based on an Analog of Cohen's d, Plus Inferences about the Median of the Typical Difference</title><link>https://aakinshin.net/library/papers/wilcox2019/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/wilcox2019/</guid><description>Reference Rand Wilcox “A Robust Nonparametric Measure of Effect Size Based on an Analog of Cohen&amp;rsquo;s d, Plus Inferences About the Median of the Typical Difference” (2019) // Journal of Modern Applied Statistical Methods. Vol. 17. No 2. Pp. jmasm.eP2726. DOI: 10.22237/jmasm/1551905677
Abstract The paper describes a nonparametric analog of Cohen&amp;rsquo;s d, Q. It is established that a confidence interval for Q can be computed via a method for computing a confidence interval for the median of D = X1 − X2, which in turn is related to making inferences about P(X1 \textless X2).
Bib @Article{wilcox2019, title = {A Robust Nonparametric Measure of Effect Size Based on an Analog of Cohen&amp;#39;s d, Plus Inferences About the Median of the Typical Difference}, volume = {17}, issn = {1538-9472}, url = {https://digitalcommons.wayne.edu/jmasm/vol17/iss2/1}, doi = {10.22237/jmasm/1551905677}, abstract = {The paper describes a nonparametric analog of Cohen&amp;#39;s d, Q. It is established that a confidence interval for Q can be computed via a method for computing a confidence interval for the median of D = X1 − X2, which in turn is related to making inferences about P(X1 \textless X2).}, language = {en}, number = {2}, urldate = {2020-01-07}, journal = {Journal of Modern Applied Statistical Methods}, author = {Wilcox, Rand}, month = {mar}, year = {2019}, pages = {jmasm.eP2726}, custom-url-pdf = {https://digitalcommons.wayne.edu/cgi/viewcontent.cgi?article=2726&amp;amp;context=jmasm} }</description></item><item><title>A Robust Scale Estimator Based on Pairwise Means</title><link>https://aakinshin.net/library/papers/tarr2012/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/tarr2012/</guid><description>Reference Garth Tarr, Samuel Müller, Neville Weber “A robust scale estimator based on pairwise means” (2012) // Journal of Nonparametric Statistics. Vol. 24. No 1. Pp. 187–199. DOI: 10.1080/10485252.2011.621424
Bib @Article{tarr2012, title = {A robust scale estimator based on pairwise means}, volume = {24}, issn = {1048-5252, 1029-0311}, url = {http://www.tandfonline.com/doi/abs/10.1080/10485252.2011.621424}, doi = {10.1080/10485252.2011.621424}, language = {en}, number = {1}, urldate = {2022-08-02}, journal = {Journal of Nonparametric Statistics}, author = {Tarr, Garth and Müller, Samuel and Weber, Neville}, month = {mar}, year = {2012}, pages = {187--199} }</description></item><item><title>A Selected History of Expectation Bias in Physics</title><link>https://aakinshin.net/library/papers/jeng2006/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/jeng2006/</guid><description>Reference Monwhea Jeng “A selected history of expectation bias in physics” (2006) // American Journal of Physics. Publisher: American Association of Physics Teachers (AAPT). Vol. 74. No 7. Pp. 578–583. DOI: 10.1119/1.2186333
Bib @Article{jeng2006, title = {A selected history of expectation bias in physics}, volume = {74}, issn = {1943-2909}, url = {http://dx.doi.org/10.1119/1.2186333}, doi = {10.1119/1.2186333}, number = {7}, journal = {American Journal of Physics}, publisher = {American Association of Physics Teachers (AAPT)}, author = {Jeng, Monwhea}, year = {2006}, month = {jul}, pages = {578–583} }</description></item><item><title>A Simple General Approach to Inference about the Tail of a Distribution</title><link>https://aakinshin.net/library/papers/hill1975/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/hill1975/</guid><description>Reference Bruce M Hill “A Simple General Approach to Inference About the Tail of a Distribution” (1975) // Annals of Statistics. Vol. 3. No 5. Pp. 1163–1174. DOI: 10.1214/aos/1176343247
Abstract A simple general approach to inference about the tail behavior of a distribution is proposed. It is not required to assume any global form for the distribution function, but merely the form of behavior in the tail where it is desired to draw inference. Results are particularly simple for distributions of the Zipf type, i.e., where G(y)=1−Cy−αG(y)=1−Cy−αG(y) = 1 - Cy\textasciicircum-\textbackslashalpha\ for large yyy. The methods of inference are based upon an evaluation of the conditional likelihood for the parameters describing the tail behavior, given the values of the extreme order statistics, and can be implemented from both Bayesian and frequentist viewpoints.
Bib @Article{hill1975, title = {A Simple General Approach to Inference About the Tail of a Distribution}, volume = {3}, issn = {0090-5364, 2168-8966}, url = {https://projecteuclid.org/euclid.aos/1176343247}, doi = {10.1214/aos/1176343247}, abstract = {A simple general approach to inference about the tail behavior of a distribution is proposed. It is not required to assume any global form for the distribution function, but merely the form of behavior in the tail where it is desired to draw inference. Results are particularly simple for distributions of the Zipf type, i.e., where G(y)=1−Cy−αG(y)=1−Cy−αG(y) = 1 - Cy\textasciicircum\-\textbackslashalpha\ for large yyy. The methods of inference are based upon an evaluation of the conditional likelihood for the parameters describing the tail behavior, given the values of the extreme order statistics, and can be implemented from both Bayesian and frequentist viewpoints.}, language = {EN}, number = {5}, urldate = {2020-06-27}, journal = {Annals of Statistics}, author = {Hill, Bruce M}, month = {sep}, year = {1975}, mrnumber = {MR378204}, zmnumber = {0323.62033}, note = {Publisher: Institute of Mathematical Statistics}, keywords = {Bayesian inference, order statistics, Tail of distribution}, pages = {1163--1174} }</description></item><item><title>A Simple Generalisation of the Hill Estimator</title><link>https://aakinshin.net/library/papers/fatima2013/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/fatima2013/</guid><description>Reference M Fátima Brilhante, M Ivette Gomes, Dinis Pestana “A simple generalisation of the Hill estimator” (2013) // Computational Statistics &amp;amp; Data Analysis. Vol. 57. No 1. Pp. 518–535. DOI: 10.1016/j.csda.2012.07.019
Abstract The classical Hill estimator of a positive extreme value index (EVI) can be regarded as the logarithm of the geometric mean, or equivalently the logarithm of the mean of order p=0, of a set of adequate statistics. A simple generalisation of the Hill estimator is now proposed, considering a more general mean of order p≥0 of the same statistics. Apart from the derivation of the asymptotic behaviour of this new class of EVI-estimators, an asymptotic comparison, at optimal levels, of the members of such class and other known EVI-estimators is undertaken. An algorithm for an adaptive estimation of the tuning parameters under play is also provided. A large-scale simulation study and an application to simulated and real data are developed.
Bib @Article{fatima2013, title = {A simple generalisation of the Hill estimator}, volume = {57}, issn = {0167-9473}, url = {http://www.sciencedirect.com/science/article/pii/S0167947312002939}, doi = {10.1016/j.csda.2012.07.019}, abstract = {The classical Hill estimator of a positive extreme value index (EVI) can be regarded as the logarithm of the geometric mean, or equivalently the logarithm of the mean of order p=0, of a set of adequate statistics. A simple generalisation of the Hill estimator is now proposed, considering a more general mean of order p≥0 of the same statistics. Apart from the derivation of the asymptotic behaviour of this new class of EVI-estimators, an asymptotic comparison, at optimal levels, of the members of such class and other known EVI-estimators is undertaken. An algorithm for an adaptive estimation of the tuning parameters under play is also provided. A large-scale simulation study and an application to simulated and real data are developed.}, language = {en}, number = {1}, urldate = {2020-06-27}, journal = {Computational Statistics \&amp;amp; Data Analysis}, author = {Fátima Brilhante, M and Ivette Gomes, M and Pestana, Dinis}, month = {jan}, year = {2013}, keywords = {Bias estimation, Bootstrap methodology, Heavy tails, Optimal levels, Semi-parametric estimation, Statistics of extremes}, pages = {518--535} }</description></item><item><title>A Statistical Distribution Function of Wide Applicability</title><link>https://aakinshin.net/library/papers/weibull1951/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/weibull1951/</guid><description>Reference Weibull W “A statistical distribution function of wide applicability” (1951) // ASME J. Appl. Mech., Trans. Am. Soc. Mech. Eng.. Vol. 18. Pp. 293.
Bib @Article{weibull1951, title = {A statistical distribution function of wide applicability}, volume = {18}, journal = {ASME J. Appl. Mech., Trans. Am. Soc. Mech. Eng.}, author = {W, Weibull}, year = {1951}, pages = {293}, custom-url-pdf = {https://hal.science/hal-03112318/document} }</description></item><item><title>A Survey of Outlier Detection Methodologies</title><link>https://aakinshin.net/library/papers/hodge2004/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/hodge2004/</guid><description>Reference Victoria Hodge, Jim Austin “A Survey of Outlier Detection Methodologies” (2004) // Artificial Intelligence Review. Vol. 22. No 2. Pp. 85–126. DOI: 10.1023/B:AIRE.0000045502.10941.a9
Bib @Article{hodge2004, title = {A Survey of Outlier Detection Methodologies}, volume = {22}, issn = {0269-2821}, url = {http://link.springer.com/10.1023/B:AIRE.0000045502.10941.a9}, doi = {10.1023/B:AIRE.0000045502.10941.a9}, language = {en}, number = {2}, urldate = {2022-08-08}, journal = {Artificial Intelligence Review}, author = {Hodge, Victoria and Austin, Jim}, month = {oct}, year = {2004}, pages = {85--126} }</description></item><item><title>A Tutorial on Fisher Information</title><link>https://aakinshin.net/library/papers/ly2017/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/ly2017/</guid><description>Reference Alexander Ly, Maarten Marsman, Josine Verhagen, Raoul Grasman, Eric-Jan Wagenmakers “A Tutorial on Fisher Information” (2017) // arXiv.
Abstract In many statistical applications that concern mathematical psychologists, the concept of Fisher information plays an important role. In this tutorial we clarify the concept of Fisher information as it manifests itself across three different statistical paradigms. First, in the frequentist paradigm, Fisher information is used to construct hypothesis tests and confidence intervals using maximum likelihood estimators; second, in the Bayesian paradigm, Fisher information is used to define a default prior; lastly, in the minimum description length paradigm, Fisher information is used to measure model complexity.
Bib @Misc{ly2017, title = {A Tutorial on Fisher Information}, url = {http://arxiv.org/abs/1705.01064}, abstract = {In many statistical applications that concern mathematical psychologists, the concept of Fisher information plays an important role. In this tutorial we clarify the concept of Fisher information as it manifests itself across three different statistical paradigms. First, in the frequentist paradigm, Fisher information is used to construct hypothesis tests and confidence intervals using maximum likelihood estimators; second, in the Bayesian paradigm, Fisher information is used to define a default prior; lastly, in the minimum description length paradigm, Fisher information is used to measure model complexity.}, urldate = {2023-11-05}, publisher = {arXiv}, author = {Ly, Alexander and Marsman, Maarten and Verhagen, Josine and Grasman, Raoul and Wagenmakers, Eric-Jan}, month = {oct}, year = {2017}, note = {arXiv:1705.01064 [math, stat]}, arxiv = {1705.01064}, keywords = {Mathematics - Statistics Theory, 62-01, 62B10 (Primary), 62F03, 62F12, 62F15, 62B10 (Secondary)} }</description></item><item><title>A Uniform Saddlepoint Expansion for the Null-Distribution of the Wilcoxon-Mann-Whitney Statistic</title><link>https://aakinshin.net/library/papers/froda2000/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/froda2000/</guid><description>Reference Sorana Froda, Constance Van Eeden “A Uniform Saddlepoint Expansion for the Null-Distribution of the Wilcoxon-Mann-Whitney Statistic” (2000) // The Canadian Journal of Statistics / La Revue Canadienne de Statistique. Vol. 28. No 1. Pp. 137. DOI: 10.2307/3315887
Bib @Article{froda2000, title = {A Uniform Saddlepoint Expansion for the Null-Distribution of the Wilcoxon-Mann-Whitney Statistic}, volume = {28}, issn = {03195724}, url = {https://www.jstor.org/stable/3315887?origin=crossref}, doi = {10.2307/3315887}, number = {1}, urldate = {2023-05-31}, journal = {The Canadian Journal of Statistics / La Revue Canadienne de Statistique}, author = {Froda, Sorana and Van Eeden, Constance}, month = {mar}, year = {2000}, pages = {137} }</description></item><item><title>Abandon Statistical Significance</title><link>https://aakinshin.net/library/papers/mcshane2019/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/mcshane2019/</guid><description>Reference Blakeley B. McShane, David Gal, Andrew Gelman, Christian Robert, Jennifer L. Tackett “Abandon Statistical Significance” (2019) // The American Statistician. Publisher: Informa UK Limited. Vol. 73. No sup1. Pp. 235–245. DOI: 10.1080/00031305.2018.1527253
Bib @Article{mcshane2019, title = {Abandon Statistical Significance}, volume = {73}, issn = {1537-2731}, url = {http://dx.doi.org/10.1080/00031305.2018.1527253}, doi = {10.1080/00031305.2018.1527253}, number = {sup1}, arxiv = {1709.07588}, journal = {The American Statistician}, publisher = {Informa UK Limited}, author = {McShane, Blakeley B. and Gal, David and Gelman, Andrew and Robert, Christian and Tackett, Jennifer L.}, year = {2019}, month = {mar}, pages = {235–245} }</description></item><item><title>Addressing False Positives in Self-Report Surveys</title><link>https://aakinshin.net/library/quotes/6c23bac3-f06b-4234-8b0d-eb4c29388360/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/6c23bac3-f06b-4234-8b0d-eb4c29388360/</guid><description>Self-report surveys of rare events easily lead to huge overestimates of the true incidence of such events, particularly if the event in question has some potential social desirability. Researchers who claim that such survey incidence data are accurate must show how they have eliminated the enormous problem of false positives.</description></item><item><title>Addressing Pseudoreplication in Experimental Studies</title><link>https://aakinshin.net/library/quotes/4c2a9774-48bc-42db-a035-c416e710ed01/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/4c2a9774-48bc-42db-a035-c416e710ed01/</guid><description>We believe that good investigators who are aware of the issue will find that eliminating pseudoreplication from their experiments is a relatively straightforward matter. The problems of pseudoreplication that we typically encounter in published studies are easily solvable, and we see no reason that reviewers and editors should accept studies that fail to eliminate pseudoreplication. We certainly do not believe that absence of pseudoreplication should be the sole, or even the main, criterion for evaluating experiments. Rather, we see the absence of pseudoreplication as representing a minimum requirement that should be met before the merits of an experiment are evaluated.</description></item><item><title>Algorithm 616: Fast Computation of the Hodges-Lehmann Location Estimator</title><link>https://aakinshin.net/library/papers/monahan1984/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/monahan1984/</guid><description>Relevant discussion in DescTools: https://github.com/AndriSignorell/DescTools/issues/97 The algorithm was implemented in v0.99.52.
Reference John F Monahan “Algorithm 616: fast computation of the Hodges-Lehmann location estimator” (1984) // ACM Transactions on Mathematical Software. Vol. 10. No 3. Pp. 265–270. DOI: 10.1145/1271.319414
Bib @Article{monahan1984, title = {Algorithm 616: fast computation of the Hodges-Lehmann location estimator}, volume = {10}, issn = {0098-3500, 1557-7295}, shorttitle = {Algorithm 616}, url = {https://dl.acm.org/doi/10.1145/1271.319414}, doi = {10.1145/1271.319414}, language = {en}, number = {3}, urldate = {2023-12-10}, journal = {ACM Transactions on Mathematical Software}, author = {Monahan, John F}, month = {aug}, year = {1984}, pages = {265--270} }</description></item><item><title>All Maps of Parameter Estimates Are Misleading</title><link>https://aakinshin.net/library/papers/gelman1999/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/gelman1999/</guid><description>Reference Andrew Gelman, Phillip N Price “All maps of parameter estimates are misleading” (1999) // Statistics in Medicine. Publisher: Wiley. Vol. 18. No 23. Pp. 3221–3234. DOI: 10.1002/(sici)1097-0258(19991215)18:23&amp;lt;3221::aid-sim312&amp;gt;3.0.co;2-m
Bib @Article{gelman1999, title = {All maps of parameter estimates are misleading}, volume = {18}, issn = {1097-0258}, url = {http://dx.doi.org/10.1002/(sici)1097-0258(19991215)18:23&amp;lt;3221::aid-sim312&amp;gt;3.0.co;2-m}, doi = {10.1002/(sici)1097-0258(19991215)18:23&amp;lt;3221::aid-sim312&amp;gt;3.0.co;2-m}, number = {23}, journal = {Statistics in Medicine}, publisher = {Wiley}, author = {Gelman, Andrew and Price, Phillip N}, year = {1999}, month = {dec}, pages = {3221–3234} }</description></item><item><title>Alternatives to the Median Absolute Deviation</title><link>https://aakinshin.net/library/papers/rousseeuw1993/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/rousseeuw1993/</guid><description>Reference Peter J Rousseeuw, Christophe Croux “Alternatives to the Median Absolute Deviation” (1993) // Journal of the American Statistical Association. Vol. 88. No 424. Pp. 1273–1283. DOI: 10.1080/01621459.1993.10476408
Abstract In robust estimation one frequently needs an initial or auxiliary estimate of scale. For this one usually takes the median absolute deviation MAD n = 1.4826 med, \textbarxi − med j x j \textbar, because it has a simple explicit formula, needs little computation time, and is very robust as witnessed by its bounded influence function and its 50% breakdown point. But there is still room for improvement in two areas: the fact that MAD n is aimed at symmetric distributions and its low (37%) Gaussian efficiency. In this article we set out to construct explicit and 50% breakdown scale estimators that are more efficient. We consider the estimator Sn = 1.1926 med, med j \textbar xi − xj \textbar and the estimator Qn given by the .25 quantile of the distances \textbarxi − x j \textbar; i \textless j. Note that Sn and Qn do not need any location estimate. Both Sn and Qn can be computed using O(n log n) time and O(n) storage. The Gaussian efficiency of Sn is 58%, whereas Qn attains 82%. We study Sn and Qn by means of their influence functions, their bias curves (for implosion as well as explosion), and their finite-sample performance. Their behavior is also compared at non-Gaussian models, including the negative exponential model where Sn has a lower gross-error sensitivity than the MAD.
Bib @Article{rousseeuw1993, title = {Alternatives to the Median Absolute Deviation}, volume = {88}, issn = {0162-1459}, url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1993.10476408}, doi = {10.1080/01621459.1993.10476408}, abstract = {In robust estimation one frequently needs an initial or auxiliary estimate of scale. For this one usually takes the median absolute deviation MAD n = 1.</description></item><item><title>An Alternative to Cohen's Standardized Mean Difference Effect size: A Robust Parameter and Confidence Interval in the Two Independent Groups Case</title><link>https://aakinshin.net/library/papers/algina2005/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/algina2005/</guid><description>Reference Algina J, Keselman H J, Penfield R D “An alternative to Cohen&amp;amp;#039;s standardized mean difference effect size: A robust parameter and confidence interval in the two independent groups case” (2005) // Psychol. Methods. Vol. 10. Pp. 317. DOI: 10.1037/1082-989X.10.3.317
Bib @Article{algina2005, title = {An alternative to Cohen\&amp;amp;\#039;s standardized mean difference effect size: A robust parameter and confidence interval in the two independent groups case}, volume = {10}, journal = {Psychol. Methods}, author = {J, Algina and J, Keselman H and D, Penfield R}, year = {2005}, pages = {317}, doi = {10.1037/1082-989X.10.3.317} }</description></item><item><title>An Introduction to Second-Generation P -Values</title><link>https://aakinshin.net/library/papers/blume2019/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/blume2019/</guid><description>Reference Jeffrey D Blume, Robert A Greevy, Valerie F Welty, Jeffrey R Smith, William D Dupont “An Introduction to Second-Generation \textitp -Values” (2019) // The American Statistician. Vol. 73. No sup1. Pp. 157–167. DOI: 10.1080/00031305.2018.1537893
Bib @Article{blume2019, title = {An Introduction to Second-Generation \textitp -Values}, volume = {73}, issn = {0003-1305, 1537-2731}, url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1537893}, doi = {10.1080/00031305.2018.1537893}, language = {en}, number = {sup1}, urldate = {2020-01-12}, journal = {The American Statistician}, author = {Blume, Jeffrey D and Greevy, Robert A and Welty, Valerie F and Smith, Jeffrey R and Dupont, William D}, month = {mar}, year = {2019}, note = {ZSCC: NoCitationData[s0]}, pages = {157--167} }</description></item><item><title>Analysis of Variance in Genetic Associations and Health Care Interventions</title><link>https://aakinshin.net/library/quotes/c84cec6e-c9dd-4ea2-b87f-516d09824fbf/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/c84cec6e-c9dd-4ea2-b87f-516d09824fbf/</guid><description>The maximal between-study variance was more likely to be recorded early in the 44 eligible meta-analyses of genetic associations than in the 37 meta-analyses of health care interventions (P = .013). At the time of the first heterogeneity assessment, the most favorable-ever result in support of a specific association was more likely to appear than the least favorable-ever result (22 vs. 10, P = .017); the opposite was seen at the second heterogeneity assessment (15 vs. 5, P = .031). Such a sequence of extreme opposite results was not seen in the clinical trials meta-analyses. The estimated between-study variance decreased over time in genetic association studies (P = .010), but not in clinical trials (P = .30).</description></item><item><title>Analyzing data: Sanctification or Detective work?</title><link>https://aakinshin.net/library/papers/tukey1969/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/tukey1969/</guid><description>Reference John W Tukey “Analyzing data: Sanctification or detective work?” (1969) // American Psychologist. Publisher: American Psychological Association (APA). Vol. 24. No 2. Pp. 83–91. DOI: 10.1037/h0027108
Bib @Article{tukey1969, title = {Analyzing data: Sanctification or detective work?}, volume = {24}, issn = {0003-066X}, url = {http://dx.doi.org/10.1037/h0027108}, doi = {10.1037/h0027108}, number = {2}, journal = {American Psychologist}, publisher = {American Psychological Association (APA)}, author = {Tukey, John W}, year = {1969}, month = {feb}, pages = {83–91} }</description></item><item><title>Asymptotic Equivalence of the Harrell-Davis Median Estimator and the Sample Median</title><link>https://aakinshin.net/library/papers/yoshizawa1985/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/yoshizawa1985/</guid><description>Reference Carl N Yoshizawa, Pranab K Sen, C Edward Davis “Asymptotic equivalence of the Harrell-Davis median estimator and the sample median” (1985) // Communications in Statistics-Theory and Methods. Publisher: Taylor &amp;amp; Francis. Vol. 14. No 9. Pp. 2129–2136. DOI: 10.1080/03610928508829034
Bib @Article{yoshizawa1985, title = {Asymptotic equivalence of the Harrell-Davis median estimator and the sample median}, author = {Yoshizawa, Carl N and Sen, Pranab K and Davis, C Edward}, journal = {Communications in Statistics-Theory and Methods}, volume = {14}, number = {9}, pages = {2129--2136}, year = {1985}, publisher = {Taylor \&amp;amp; Francis}, doi = {10.1080/03610928508829034} }</description></item><item><title>Balancing Realism and Purity</title><link>https://aakinshin.net/library/quotes/c940f25b-3f02-40ea-8f2c-8934efe03226/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/c940f25b-3f02-40ea-8f2c-8934efe03226/</guid><description>It is difficult to give an objective assessment of the validity of a statistical analysis. Rather like medicine, statistics is an art, and there is rarely a unique correct approach. Rather judgement is necessary to select one of a number of possible analyses, each with their own advantages and limitations. In my review I encountered many analyses which I would have tackled differently, but where in my judgement the analysis as presented was perfectly acceptable. In writing this article I have attempted to confine my criticisms to points where I believe that the vast majority of statisticians would agree that the approach adopted was not acceptable, and indeed many statisticians would probably take a harder line than I have. My statistical philosophy leans towards being a realist rather than a purist, and my research interests lie in the area of how to obtain the least biased results possible in areas where perhaps for ethical or practical reasons randomization is not possible, or where missing data abound.</description></item><item><title>Bandwidth Selection for Weighted Kernel Density Estimation</title><link>https://aakinshin.net/library/papers/wang2007/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/wang2007/</guid><description>This paper has been withdrawn by Bin Wang.
Reference Bin Wang, Xiaofeng Wang “Bandwidth Selection for Weighted Kernel Density Estimation” (2007) // arXiv. DOI: 10.48550/ARXIV.0709.1616
Bib @Misc{wang2007, author = {Wang, Bin and Wang, Xiaofeng}, title = {Bandwidth Selection for Weighted Kernel Density Estimation}, publisher = {arXiv}, year = {2007}, doi = {10.48550/ARXIV.0709.1616} }</description></item><item><title>Bayesian Statistics the Fun Way: Understanding Statistics and Probability with Star Wars, LEGO, and Rubber Ducks</title><link>https://aakinshin.net/library/books/kurt-bayesian-statistics-the-fun-way/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/kurt-bayesian-statistics-the-fun-way/</guid><description/></item><item><title>Believability of Relative Risks and Odds Ratios in abstracts: Cross Sectional Study</title><link>https://aakinshin.net/library/papers/g%C3%B8tzsche2006/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/g%C3%B8tzsche2006/</guid><description>Reference Peter C Gøtzsche “Believability of relative risks and odds ratios in abstracts: cross sectional study” (2006) // BMJ. Publisher: BMJ. Vol. 333. No 7561. Pp. 231–234. DOI: 10.1136/bmj.38895.410451.79
Bib @Article{gøtzsche2006, title = {Believability of relative risks and odds ratios in abstracts: cross sectional study}, volume = {333}, issn = {1468-5833}, url = {http://dx.doi.org/10.1136/bmj.38895.410451.79}, doi = {10.1136/bmj.38895.410451.79}, number = {7561}, journal = {BMJ}, publisher = {BMJ}, author = {Gøtzsche, Peter C}, year = {2006}, month = {jul}, pages = {231–234} }</description></item><item><title>Bestimmung Der Genauigkeit Der Beobachtungen</title><link>https://aakinshin.net/library/papers/gauss1816/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/gauss1816/</guid><description>Reference Carl Friedrich Gauss “Bestimmung der genauigkeit der beobachtungen” (1816) // Abhandlungen zur Methode der kleinsten Quadrate, 1887.
Bib @Article{gauss1816, title = {Bestimmung der genauigkeit der beobachtungen}, author = {Gauss, Carl Friedrich}, journal = {Abhandlungen zur Methode der kleinsten Quadrate, 1887}, year = {1816} }</description></item><item><title>Beyond ‘significance’: Principles and Practice of the Analysis of Credibility</title><link>https://aakinshin.net/library/papers/matthews2018/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/matthews2018/</guid><description>Reference Robert A J Matthews “Beyond ‘significance’: principles and practice of the Analysis of Credibility” (2018) // Royal Society Open Science. Vol. 5. No 1. Pp. 171047. DOI: 10.1098/rsos.171047
Bib @Article{matthews2018, title = {Beyond ‘significance’: principles and practice of the Analysis of Credibility}, volume = {5}, issn = {2054-5703, 2054-5703}, shorttitle = {Beyond ‘significance’}, url = {https://royalsocietypublishing.org/doi/10.1098/rsos.171047}, doi = {10.1098/rsos.171047}, language = {en}, number = {1}, urldate = {2020-01-07}, journal = {Royal Society Open Science}, author = {Matthews, Robert A J}, month = {jan}, year = {2018}, note = {ZSCC: 0000017}, pages = {171047} }</description></item><item><title>Beyond Cohen's d: Alternative Effect Size Measures for Between-Subject Designs</title><link>https://aakinshin.net/library/papers/peng2014/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/peng2014/</guid><description>Reference Chao-Ying Joanne Peng, Li-Ting Chen “Beyond Cohen&amp;rsquo;s d: Alternative Effect Size Measures for Between-Subject Designs” (2014) // The Journal of Experimental Education. Vol. 82. No 1. Pp. 22–50. DOI: 10.1080/00220973.2012.745471
Bib @Article{peng2014, title = {Beyond Cohen&amp;#39;s d: Alternative Effect Size Measures for Between-Subject Designs}, volume = {82}, issn = {0022-0973, 1940-0683}, shorttitle = {Beyond Cohen&amp;#39;s \textitd}, url = {http://www.tandfonline.com/doi/abs/10.1080/00220973.2012.745471}, doi = {10.1080/00220973.2012.745471}, language = {en}, number = {1}, urldate = {2020-01-07}, journal = {The Journal of Experimental Education}, author = {Peng, Chao-Ying Joanne and Chen, Li-Ting}, month = {jan}, year = {2014}, pages = {22--50} }</description></item><item><title>Beyond Power Calculations: Assessing Type S (Sign) And Type M (Magnitude) Errors</title><link>https://aakinshin.net/library/papers/gelman2014/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/gelman2014/</guid><description>Reference Andrew Gelman, John Carlin “Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors” (2014) // Perspectives on Psychological Science. Publisher: SAGE Publications. Vol. 9. No 6. Pp. 641–651. DOI: 10.1177/1745691614551642
Bib @Article{gelman2014, title = {Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors}, volume = {9}, issn = {1745-6924}, url = {http://dx.doi.org/10.1177/1745691614551642}, doi = {10.1177/1745691614551642}, number = {6}, journal = {Perspectives on Psychological Science}, publisher = {SAGE Publications}, author = {Gelman, Andrew and Carlin, John}, year = {2014}, month = {nov}, pages = {641–651} }</description></item><item><title>Bias &amp; Bootstrap Bias Correction</title><link>https://aakinshin.net/library/web/90f8c11ef0e36de8b8ab187243860f31/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/web/90f8c11ef0e36de8b8ab187243860f31/</guid><description/></item><item><title>Biological Versus Nonbiological Older Brothers and men’s Sexual Orientation</title><link>https://aakinshin.net/library/papers/bogaert2006/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/bogaert2006/</guid><description>Critisized in: gelman2006 (page 329, Section 3)
Reference Anthony F Bogaert “Biological versus nonbiological older brothers and men’s sexual orientation” (2006) // Proceedings of the National Academy of Sciences. Publisher: Proceedings of the National Academy of Sciences. Vol. 103. No 28. Pp. 10771–10774. DOI: 10.1073/pnas.0511152103
Bib @Article{bogaert2006, title = {Biological versus nonbiological older brothers and men’s sexual orientation}, volume = {103}, issn = {1091-6490}, url = {http://dx.doi.org/10.1073/pnas.0511152103}, doi = {10.1073/pnas.0511152103}, number = {28}, journal = {Proceedings of the National Academy of Sciences}, publisher = {Proceedings of the National Academy of Sciences}, author = {Bogaert, Anthony F}, year = {2006}, month = {jul}, pages = {10771–10774} }</description></item><item><title>Bivariate Median Splits and Spurious Statistical Significance</title><link>https://aakinshin.net/library/papers/maxwell1993/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/maxwell1993/</guid><description>Reference Scott E Maxwell, Harold D Delaney “Bivariate median splits and spurious statistical significance” (1993) // Psychological Bulletin. Publisher: American Psychological Association (APA). Vol. 113. No 1. Pp. 181–190. DOI: 10.1037/0033-2909.113.1.181
Bib @Article{maxwell1993, title = {Bivariate median splits and spurious statistical significance}, volume = {113}, issn = {0033-2909}, url = {http://dx.doi.org/10.1037/0033-2909.113.1.181}, doi = {10.1037/0033-2909.113.1.181}, number = {1}, journal = {Psychological Bulletin}, publisher = {American Psychological Association (APA)}, author = {Maxwell, Scott E and Delaney, Harold D}, year = {1993}, month = {jan}, pages = {181–190} }</description></item><item><title>Black and White Medical Conclusions</title><link>https://aakinshin.net/library/quotes/61d2c118-762a-4f38-8710-231759813a08/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/61d2c118-762a-4f38-8710-231759813a08/</guid><description>It appears that medical authors feel the need to make black and white conclusions when their data almost never allows for such dichotomous statements. This is particularly true when comparing results to similar studies with largely overlapping CIs. Virtually all of the conclusion confusion discussed in this paper can be linked to slavish adherence to an arbitrary threshold for statistical significance. Even if the threshold is reasonable, it still cannot be used to make dichotomous conclusions.</description></item><item><title>Blind Analysis in Nuclear and Particle Physics</title><link>https://aakinshin.net/library/papers/klein2005/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/klein2005/</guid><description>Reference Joshua R Klein, Aaron Roodman “Blind analysis in nuclear and particle physics” (2005) // Annual Review of Nuclear and Particle Science. Publisher: Annual Reviews. Vol. 55. No 1. Pp. 141–163. DOI: 10.1146/annurev.nucl.55.090704.151521
Bib @Article{klein2005, title = {Blind analysis in nuclear and particle physics}, volume = {55}, issn = {1545-4134}, url = {http://dx.doi.org/10.1146/annurev.nucl.55.090704.151521}, doi = {10.1146/annurev.nucl.55.090704.151521}, number = {1}, journal = {Annual Review of Nuclear and Particle Science}, publisher = {Annual Reviews}, author = {Klein, Joshua R and Roodman, Aaron}, year = {2005}, month = {dec}, pages = {141–163} }</description></item><item><title>Book Review. Gina Perry. Behind the Shock Machine: The Untold Story of the Notorious Milgram Psychology Experiments</title><link>https://aakinshin.net/library/papers/russell2013/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/russell2013/</guid><description>Reference Nestar Russell “Book Review. Gina Perry. Behind the Shock Machine: The Untold Story of the Notorious Milgram Psychology Experiments” (2013) // Journal of the History of the Behavioral Sciences. Publisher: Wiley. Vol. 49. No 2. Pp. 221–223. DOI: 10.1002/jhbs.21599
Bib @Article{russell2013, title = {Book Review. Gina Perry. Behind the Shock Machine: The Untold Story of the Notorious Milgram Psychology Experiments}, volume = {49}, issn = {1520-6696}, url = {http://dx.doi.org/10.1002/jhbs.21599}, doi = {10.1002/jhbs.21599}, number = {2}, journal = {Journal of the History of the Behavioral Sciences}, publisher = {Wiley}, author = {Russell, Nestar}, year = {2013}, month = {mar}, pages = {221–223} }</description></item><item><title>Case for Omitting Tied Observations in the two-sample t-test and the Wilcoxon-Mann-Whitney Test</title><link>https://aakinshin.net/library/papers/mcgee2018/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/mcgee2018/</guid><description>Reference Monnie McGee, David Fardo “Case for omitting tied observations in the two-sample t-test and the Wilcoxon-Mann-Whitney Test” (2018) // PLOS ONE. Vol. 13. No 7. Pp. e0200837. DOI: 10.1371/journal.pone.0200837
Bib @Article{mcgee2018, title = {Case for omitting tied observations in the two-sample t-test and the Wilcoxon-Mann-Whitney Test}, volume = {13}, issn = {1932-6203}, url = {https://dx.plos.org/10.1371/journal.pone.0200837}, doi = {10.1371/journal.pone.0200837}, language = {en}, number = {7}, urldate = {2023-05-04}, journal = {PLOS ONE}, author = {McGee, Monnie}, editor = {Fardo, David}, month = {jul}, year = {2018}, pages = {e0200837} }</description></item><item><title>Challenges and Pitfalls in Spatial Data Mapping</title><link>https://aakinshin.net/library/quotes/454084e3-99c3-415b-8a06-25a8b5318e21/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/454084e3-99c3-415b-8a06-25a8b5318e21/</guid><description>Mapping raw data can lead to spurious spatial features. For example, regions can appear highly variable because of small sample sizes in spatial sub-units (as in the radon example) or small populations (as in the cancer example), and these apparently variable regions contain a disproportionate number of very high (or low) observed parameter values. Mapping posterior means leads to the reverse problems: areas that appear too uniform because of small sample sizes or populations.</description></item><item><title>Cohen’s d is Biased</title><link>https://aakinshin.net/library/web/f374b09ad2b7d40966766511c2618784/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/web/f374b09ad2b7d40966766511c2618784/</guid><description/></item><item><title>Comparing Two Groups by Simple Graphs</title><link>https://aakinshin.net/library/papers/darlington1973/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/darlington1973/</guid><description>Reference Darlington R B “Comparing two groups by simple graphs” (1973) // Psychol. Bull.. Vol. 79. Pp. 110. DOI: 10.1037/h0033854
Bib @Article{darlington1973, title = {Comparing two groups by simple graphs}, volume = {79}, journal = {Psychol. Bull.}, author = {B, Darlington R}, year = {1973}, pages = {110}, doi = {10.1037/h0033854} }</description></item><item><title>Comparing Two Independent Groups via the Lower and Upper Quantiles</title><link>https://aakinshin.net/library/papers/wilcox2014/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/wilcox2014/</guid><description>Reference Rand R Wilcox, David M Erceg-Hurn, Florence Clark, Michael Carlson “Comparing two independent groups via the lower and upper quantiles” (2014) // Journal of Statistical Computation and Simulation. Vol. 84. No 7. Pp. 1543–1551. DOI: 10.1080/00949655.2012.754026
Bib @Article{wilcox2014, title = {Comparing two independent groups via the lower and upper quantiles}, volume = {84}, issn = {0094-9655, 1563-5163}, url = {http://www.tandfonline.com/doi/abs/10.1080/00949655.2012.754026}, doi = {10.1080/00949655.2012.754026}, language = {en}, number = {7}, urldate = {2022-06-21}, journal = {Journal of Statistical Computation and Simulation}, author = {Wilcox, Rand R and Erceg-Hurn, David M and Clark, Florence and Carlson, Michael}, month = {jul}, year = {2014}, pages = {1543--1551} }</description></item><item><title>Computing Effect Size Measures with Vista</title><link>https://aakinshin.net/library/papers/ledesma2009/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/ledesma2009/</guid><description>Reference Ledesma R D, Macbeth G, Cortada de Kohan N “Computing effect size measures with vista” (2009) // Tutor. Quant. Methods Psychol.. Vol. 5. Pp. 25.
Bib @Article{ledesma2009, title = {Computing effect size measures with vista}, volume = {5}, journal = {Tutor. Quant. Methods Psychol.}, author = {D, Ledesma R and G, Macbeth and N, Cortada de Kohan}, year = {2009}, pages = {25}, custom-url-pdf = {https://www.tqmp.org/RegularArticles/vol05-1/p025/p025.pdf} }</description></item><item><title>Conclusions on Journal Impact Factor</title><link>https://aakinshin.net/library/quotes/2526af27-e9d4-4a82-a5d3-e95b8af58146/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/2526af27-e9d4-4a82-a5d3-e95b8af58146/</guid><description> While at this point it seems impossible to quantify the relative contributions of the different factors influencing the reliability of scientific publications, the current empirical literature on the effects of journal rank provides evidence supporting the following four conclusions:
Journal rank is a weak to moderate predictor of utility and perceived importance; Journal rank is a moderate to strong predictor of both intentional and unintentional scientific unreliability Journal rank is expensive, delays science and frustrates researchers; Journal rank as established by IF violates even the most basic scientific standards, but predicts subjective judgments of journal quality.</description></item><item><title>Confidence Intervals</title><link>https://aakinshin.net/library/quotes/8a403d69-3240-4581-9710-cde46af21603/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/8a403d69-3240-4581-9710-cde46af21603/</guid><description>We have argued that the excessive use of hypothesis testing at the expense of more informative approaches to data interpretation is an unsatisfactory way of assessing and presenting statistical findings from medical studies. We prefer the use of confidence intervals, which present the results directly on the scale of data measurement. We have also suggested a notation for confidence intervals which is intended to force clarity of meaning. Confidence intervals, which also have a link to the outcome of hypothesis tests, should become the standard method for presenting the statistical results of major findings.</description></item><item><title>Confidence Intervals for Median Absolute Deviations</title><link>https://aakinshin.net/library/papers/arachchige2019/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/arachchige2019/</guid><description>Reference Chandima N P G Arachchige, Luke A Prendergast “Confidence intervals for median absolute deviations” (2019) // arXiv:1910.00229 [math, stat].
Abstract The median absolute deviation (MAD) is a robust measure of scale that is simple to implement and easy to interpret. Motivated by this, we introduce interval estimators of the MAD to make reliable inferences for dispersion for a single population and ratios and differences of MADs for comparing two populations. Our simulation results show that the coverage probabilities of the intervals are very close to the nominal coverage for a variety of distributions. We have used partial influence functions to investigate the robustness properties of the difference and ratios of independent MADs.
Bib @Article{arachchige2019, title = {Confidence intervals for median absolute deviations}, url = {http://arxiv.org/abs/1910.00229}, abstract = {The median absolute deviation (MAD) is a robust measure of scale that is simple to implement and easy to interpret. Motivated by this, we introduce interval estimators of the MAD to make reliable inferences for dispersion for a single population and ratios and differences of MADs for comparing two populations. Our simulation results show that the coverage probabilities of the intervals are very close to the nominal coverage for a variety of distributions. We have used partial influence functions to investigate the robustness properties of the difference and ratios of independent MADs.}, urldate = {2020-07-14}, journal = {arXiv:1910.00229 [math, stat]}, author = {Arachchige, Chandima N P G and Prendergast, Luke A}, month = {nov}, year = {2019}, note = {arXiv: 1910.00229}, arxiv = {1910.00229}, keywords = {Mathematics - Statistics Theory} }</description></item><item><title>Confidence Intervals Rather Than P values: Estimation Rather Than Hypothesis Testing</title><link>https://aakinshin.net/library/papers/gardner1986/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/gardner1986/</guid><description>Reference M J Gardner, D G Altman “Confidence intervals rather than P values: estimation rather than hypothesis testing” (1986) // BMJ. Publisher: BMJ. Vol. 292. No 6522. Pp. 746–750. DOI: 10.1136/bmj.292.6522.746
Bib @Article{gardner1986, title = {Confidence intervals rather than P values: estimation rather than hypothesis testing}, volume = {292}, issn = {1468-5833}, url = {http://dx.doi.org/10.1136/bmj.292.6522.746}, doi = {10.1136/bmj.292.6522.746}, number = {6522}, journal = {BMJ}, publisher = {BMJ}, author = {Gardner, M J and Altman, D G}, year = {1986}, month = {mar}, pages = {746–750} }</description></item><item><title>Confidence Regions for High Quantiles of a Heavy Tailed Distribution</title><link>https://aakinshin.net/library/papers/peng2006/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/peng2006/</guid><description>Reference Liang Peng, Yongcheng Qi “Confidence regions for high quantiles of a heavy tailed distribution” (2006) // Annals of Statistics. Vol. 34. No 4. Pp. 1964–1986. DOI: 10.1214/009053606000000416
Abstract Estimating high quantiles plays an important role in the context of risk management. This involves extrapolation of an unknown distribution function. In this paper we propose three methods, namely, the normal approximation method, the likelihood ratio method and the data tilting method, to construct confidence regions for high quantiles of a heavy tailed distribution. A simulation study prefers the data tilting method.
Bib @Article{peng2006, title = {Confidence regions for high quantiles of a heavy tailed distribution}, volume = {34}, issn = {0090-5364, 2168-8966}, url = {https://projecteuclid.org/euclid.aos/1162567639}, doi = {10.1214/009053606000000416}, abstract = {Estimating high quantiles plays an important role in the context of risk management. This involves extrapolation of an unknown distribution function. In this paper we propose three methods, namely, the normal approximation method, the likelihood ratio method and the data tilting method, to construct confidence regions for high quantiles of a heavy tailed distribution. A simulation study prefers the data tilting method.}, language = {en}, number = {4}, urldate = {2020-06-27}, journal = {Annals of Statistics}, author = {Peng, Liang and Qi, Yongcheng}, month = {aug}, year = {2006}, mrnumber = {MR2283723}, zmnumber = {1246.62125}, note = {Publisher: Institute of Mathematical Statistics}, keywords = {Confidence region, data tilting, empirical likelihood method, heavy tail, high quantile}, pages = {1964--1986}, custom-url-pdf = {https://projecteuclid.org/journalArticle/Download?urlId=10.1214%2F009053606000000416} }</description></item><item><title>Confounding and Simpson’s Paradox</title><link>https://aakinshin.net/library/papers/julious1994/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/julious1994/</guid><description>Reference SA Julious, MA Mullee “Confounding and Simpson’s paradox” (1994) // BMJ. Publisher: BMJ. Vol. 309. No 6967. Pp. 1480–1481. DOI: 10.1136/bmj.309.6967.1480
Abstract A common problem when analysing clinical data is that of confounding. This occurs when the association between an exposure and an outcome is investigated but the exposure and outcome are strongly associated with a third variable. An extreme example of this is Simpson&amp;rsquo;s paradox, in which this third factor reverses the effect first observed.1 This phenomenon has long been recognised as a theoretical possibility but few real examples have been presented.
Bib @Article{julious1994, title = {Confounding and Simpson’s paradox}, abstract = {A common problem when analysing clinical data is that of confounding. This occurs when the association between an exposure and an outcome is investigated but the exposure and outcome are strongly associated with a third variable. An extreme example of this is Simpson&amp;#39;s paradox, in which this third factor reverses the effect first observed.1 This phenomenon has long been recognised as a theoretical possibility but few real examples have been presented.}, volume = {309}, issn = {1468-5833}, url = {http://dx.doi.org/10.1136/bmj.309.6967.1480}, doi = {10.1136/bmj.309.6967.1480}, number = {6967}, journal = {BMJ}, publisher = {BMJ}, author = {Julious, SA and Mullee, MA}, year = {1994}, month = {dec}, pages = {1480–1481}, custom-url-pdf = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2541623/pdf/bmj00468-0032.pdf} }</description></item><item><title>Confusion Over Measures of Evidence (p's) Versus Errors (alpha's) In Classical Statistical Testing</title><link>https://aakinshin.net/library/papers/hubbard2003/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/hubbard2003/</guid><description>Reference Raymond Hubbard, Mar'\ia Jes'us Bayarri “Confusion over measures of evidence (p&amp;rsquo;s) versus errors (alpha&amp;rsquo;s) in classical statistical testing” (2003) // The American Statistician. Publisher: Taylor &amp;amp; Francis. Vol. 57. No 3. Pp. 171–178. DOI: 10.1198/0003130031856
Bib @Article{hubbard2003, title = {Confusion over measures of evidence (p&amp;#39;s) versus errors (alpha&amp;#39;s) in classical statistical testing}, author = {Hubbard, Raymond and Bayarri, Mar\&amp;#39;\ia Jes\&amp;#39;us}, journal = {The American Statistician}, volume = {57}, number = {3}, pages = {171--178}, year = {2003}, publisher = {Taylor \&amp;amp; Francis}, doi = {10.1198/0003130031856} }</description></item><item><title>Consequences of Dichotomization</title><link>https://aakinshin.net/library/papers/fedorov2008/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/fedorov2008/</guid><description>Reference Valerii Fedorov, Frank Mannino, Rongmei Zhang “Consequences of dichotomization” (2008) // Pharmaceutical Statistics. Publisher: Wiley. Vol. 8. No 1. Pp. 50–61. DOI: 10.1002/pst.331
Bib @Article{fedorov2008, title = {Consequences of dichotomization}, volume = {8}, issn = {1539-1612}, url = {http://dx.doi.org/10.1002/pst.331}, doi = {10.1002/pst.331}, number = {1}, journal = {Pharmaceutical Statistics}, publisher = {Wiley}, author = {Fedorov, Valerii and Mannino, Frank and Zhang, Rongmei}, year = {2008}, month = {apr}, pages = {50–61} }</description></item><item><title>Contradicted and Initially Stronger Effects in Highly Cited Clinical Research</title><link>https://aakinshin.net/library/papers/ioannidis2005a/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/ioannidis2005a/</guid><description>Reference John PA Ioannidis “Contradicted and Initially Stronger Effects in Highly Cited Clinical Research” (2005) // JAMA. Publisher: American Medical Association (AMA). Vol. 294. No 2. Pp. 218. DOI: 10.1001/jama.294.2.218
Bib @Article{ioannidis2005a, title = {Contradicted and Initially Stronger Effects in Highly Cited Clinical Research}, volume = {294}, issn = {0098-7484}, url = {http://dx.doi.org/10.1001/jama.294.2.218}, doi = {10.1001/jama.294.2.218}, number = {2}, journal = {JAMA}, publisher = {American Medical Association (AMA)}, author = {Ioannidis, John PA}, year = {2005}, month = {jul}, pages = {218} }</description></item><item><title>Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing</title><link>https://aakinshin.net/library/papers/benjamini1995/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/benjamini1995/</guid><description>Reference Yoav Benjamini, Yosef Hochberg “Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing” (1995) // Journal of the Royal Statistical Society: Series B (Methodological). Publisher: Wiley. Vol. 57. No 1. Pp. 289–300. DOI: 10.1111/j.2517-6161.1995.tb02031.x
Bib @Article{benjamini1995, title = {Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing}, volume = {57}, issn = {2517-6161}, url = {http://dx.doi.org/10.1111/j.2517-6161.1995.tb02031.x}, doi = {10.1111/j.2517-6161.1995.tb02031.x}, number = {1}, journal = {Journal of the Royal Statistical Society: Series B (Methodological)}, publisher = {Wiley}, author = {Benjamini, Yoav and Hochberg, Yosef}, year = {1995}, month = {jan}, pages = {289–300} }</description></item><item><title>Convenient p=0.05</title><link>https://aakinshin.net/library/quotes/9306030d-dc0f-42cd-ae4f-8c77d9dbd656/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/9306030d-dc0f-42cd-ae4f-8c77d9dbd656/</guid><description>The value for which P = 0.05, or 1 in 20, is 1'96 or nearly 2; it is convenient to take this point as a limit in judging whether a deviation is to be considered significant or not. Deviations exceeding twice the standard deviation are thus formally regarded as significant.</description></item><item><title>Correcting a Significance Test for Clustering</title><link>https://aakinshin.net/library/papers/hedges2007/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/hedges2007/</guid><description>Reference Larry V Hedges “Correcting a Significance Test for Clustering” (2007) // Journal of Educational and Behavioral Statistics. Publisher: American Educational Research Association (AERA). Vol. 32. No 2. Pp. 151–179. DOI: 10.3102/1076998606298040
Bib @Article{hedges2007, title = {Correcting a Significance Test for Clustering}, volume = {32}, issn = {1935-1054}, url = {http://dx.doi.org/10.3102/1076998606298040}, doi = {10.3102/1076998606298040}, number = {2}, journal = {Journal of Educational and Behavioral Statistics}, publisher = {American Educational Research Association (AERA)}, author = {Hedges, Larry V}, year = {2007}, month = {jun}, pages = {151–179} }</description></item><item><title>Correspondence Between Confidence Intervals and Hypothesis Tests</title><link>https://aakinshin.net/library/quotes/426c7b3f-1b39-443c-9f6f-25dfaa973005/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/426c7b3f-1b39-443c-9f6f-25dfaa973005/</guid><description>Although for quantitative data and means there is a direct correspondence between the confidence interval approach and a t test ofthe null hypothesis at the associated level of statistical significance, this is not exactly so for qualitative data and proportions. The reason is related to the use of different estimates of the standard error for the usual tests of the null hypothesis from those given here for constructing confidence intervals. The lack of direct correspondence is small and should not result in changes of interpretation. In addition, more accurate confidence intervals can sometimes be obtained by using estimates of the standard error of the sample statistic at the confidence limits themselves-such as derived by Cornfield for relative risks.</description></item><item><title>Data Analysis and regression. A Second Course in Statistics</title><link>https://aakinshin.net/library/papers/mosteller1977/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/mosteller1977/</guid><description>Reference Frederick Mosteller, John W Tukey “Data analysis and regression. A second course in statistics” (1977) // Addison-Wesley series in behavioral science: quantitative methods.
Bib @Book{mosteller1977, title = {Data analysis and regression. A second course in statistics}, author = {Mosteller, Frederick and Tukey, John W}, journal = {Addison-Wesley series in behavioral science: quantitative methods}, year = {1977} }</description></item><item><title>Decline of Power in Psychology (1962..1984)</title><link>https://aakinshin.net/library/quotes/9eaab253-ea71-4eb4-add2-fc061c448725/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/9eaab253-ea71-4eb4-add2-fc061c448725/</guid><description>The long-term impact of studies of statistical power is investigated using J. Cohen&amp;rsquo;s (1962) pioneering work as an example. We argue that the impact is nil; the power of studies in the same journal that Cohen reviewed (now the Journal of Abnormal Psychology) has not increased over the past 24 years. In 1960 the median power (i.e., the probability that a significant result will be obtained if there is a true effect) was .46 for a medium size effect, whereas in 1984 it was only .37. The decline of power is a result of alpha-adjusted procedures. Low power seems to go unnoticed: only 2 out of 64 experiments mentioned power, and it was never estimated. Nonsignificance was generally interpreted as confirmation of the null hypothesis (if this was the research hypothesis), although the median power was as low as .25 in these cases.</description></item><item><title>Deep impact: Unintended Consequences of Journal Rank</title><link>https://aakinshin.net/library/papers/brembs2013/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/brembs2013/</guid><description>Reference Björn Brembs, Katherine Button, Marcus Munafò “Deep impact: unintended consequences of journal rank” (2013) // Frontiers in Human Neuroscience. Publisher: Frontiers Media SA. Vol. 7. DOI: 10.3389/fnhum.2013.00291
Bib @Article{brembs2013, title = {Deep impact: unintended consequences of journal rank}, volume = {7}, issn = {1662-5161}, url = {http://dx.doi.org/10.3389/fnhum.2013.00291}, doi = {10.3389/fnhum.2013.00291}, journal = {Frontiers in Human Neuroscience}, publisher = {Frontiers Media SA}, author = {Brembs, Björn and Button, Katherine and Munafò, Marcus}, year = {2013} }</description></item><item><title>Descriptive Statistics for Nonparametric Models III: Dispersion</title><link>https://aakinshin.net/library/papers/bickel1976/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/bickel1976/</guid><description>Reference Peter J Bickel, Erich L Lehmann “Descriptive statistics for nonparametric models III: Dispersion” (1976) // The Annals of Statistics. Vol. 4. Pp. 1139–1158. DOI: 10.1007/978-1-4614-1412-4_44
Bib @Incollection{bickel1976, title = {Descriptive statistics for nonparametric models III: Dispersion}, author = {Bickel, Peter J and Lehmann, Erich L}, booktitle = {The Annals of Statistics}, volume = {4}, pages = {1139--1158}, year = {1976}, doi = {10.1007/978-1-4614-1412-4_44} }</description></item><item><title>DescTools: Tools for Descriptive Statistics</title><link>https://aakinshin.net/library/papers/andri2022/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/andri2022/</guid><description>Reference Signorell Andri, others “DescTools: Tools for Descriptive Statistics” (2022)
Bib @Manual{andri2022, title = {DescTools: Tools for Descriptive Statistics}, author = {Signorell Andri and others}, year = {2022}, note = {R package version 0.99.46}, url = {https://cran.r-project.org/web/packages/DescTools/index.html}, custom-url-pdf = {https://cran.r-project.org/web/packages/DescTools/DescTools.pdf} }</description></item><item><title>Detecting and Avoiding Likely false‐positive findings – a Practical Guide</title><link>https://aakinshin.net/library/papers/forstmeier2016/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/forstmeier2016/</guid><description>Reference Wolfgang Forstmeier, Eric‐Jan Wagenmakers, Timothy H. Parker “Detecting and avoiding likely false‐positive findings – a practical guide” (2016) // Biological Reviews. Publisher: Wiley. Vol. 92. No 4. Pp. 1941–1968. DOI: 10.1111/brv.12315
Bib @Article{forstmeier2016, title = {Detecting and avoiding likely false‐positive findings – a practical guide}, volume = {92}, issn = {1469-185X}, url = {http://dx.doi.org/10.1111/brv.12315}, doi = {10.1111/brv.12315}, number = {4}, journal = {Biological Reviews}, publisher = {Wiley}, author = {Forstmeier, Wolfgang and Wagenmakers, Eric‐Jan and Parker, Timothy H.}, year = {2016}, month = {nov}, pages = {1941–1968} }</description></item><item><title>Developing Effect Sizes for Non-Normal Data in Two-SampleComparison Studies</title><link>https://aakinshin.net/library/papers/jamalzadeh2010/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/jamalzadeh2010/</guid><description>Reference Amin Jamalzadeh “Developing Effect Sizes for Non-Normal Data in Two-SampleComparison Studies” (2010) // DOI: https://doi.org/10.1080/02664763.2013.818625
Bib @Article{jamalzadeh2010, title = {Developing Effect Sizes for Non-Normal Data in Two-SampleComparison Studies}, doi = {https://doi.org/10.1080/02664763.2013.818625}, author = {Jamalzadeh, Amin}, month = {apr}, year = {2010} }</description></item><item><title>Dichotomization of 2 Continuous Independent Variables</title><link>https://aakinshin.net/library/quotes/ac013725-23bd-4d83-b98c-4b791a382e70/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/ac013725-23bd-4d83-b98c-4b791a382e70/</guid><description>Despite pleas from methodologists, researchers often continue to dichotomize continuous predictor variables. The primary argument against this practice has been that it underestimates the strength of relationships and reduces statistical power. Although this argument is correct for relationships involving a single predictor, a different problem can arise when multiple predictors are involved. Specifically, dichotomizing 2 continuous independent variables can lead to false statistical significance. As a result, the typical justification for using a median split as long as results continue to be statistically significant is invalid, because such results may in fact be spurious. Thus, researchers who dichotomize multiple continuous predictor variables not only may lose power to detect true predictor-criterion relationships in some situations but also may dramatically increase the probability of Type I errors in other situations.</description></item><item><title>Dichotomization Should Be Avoided in Most Cases</title><link>https://aakinshin.net/library/quotes/8cb30d74-c4bb-470b-b52f-eab706477a22/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/8cb30d74-c4bb-470b-b52f-eab706477a22/</guid><description>The knowledge of losing information from dichotomizing a continuous outcome is nothing new. However, many previous writings report on the optimal choice of cut points, which depends upon the parameters we wish to estimate. If we are lucky, the chosen cut point is near the optimal point, but the consequences of dichotomizing become more dire as we deviate from the optimal point. We focus our study on the evaluation of losses caused by dichotomization given cut points. While the analysis of dichotomized outcomes may be easier, there are no benefits to this approach when the true outcomes can be observed and the ‘working’ model is flexible enough to describe the population at hand. Thus, dichotomization should be avoided in most cases. Only when we wish to estimate a CDF value, our working model poorly approximates reality, and our sample size is large will the biasedness of model-based estimators overpower the improvement in variance. In this case, the dichotomized estimator may lead to better results, but further study-specific consideration is needed. We also want to emphasize that while analysis should be done using actual outcomes, some aspects of this analysis can be reported on a dichotomized scale.</description></item><item><title>Different Outcomes of the Wilcoxon-Mann-Whitney Test from Different Statistics Packages</title><link>https://aakinshin.net/library/papers/bergmann2000/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/bergmann2000/</guid><description>Reference Reinhard Bergmann, John Ludbrook, Will P J M Spooren “Different Outcomes of the Wilcoxon-Mann-Whitney Test from Different Statistics Packages” (2000) // The American Statistician. Vol. 54. No 1. Pp. 72. DOI: 10.2307/2685616
Bib @Article{bergmann2000, title = {Different Outcomes of the Wilcoxon-Mann-Whitney Test from Different Statistics Packages}, volume = {54}, issn = {00031305}, url = {https://www.jstor.org/stable/2685616?origin=crossref}, doi = {10.2307/2685616}, number = {1}, urldate = {2023-05-03}, journal = {The American Statistician}, author = {Bergmann, Reinhard and Ludbrook, John and Spooren, Will P J M}, month = {feb}, year = {2000}, pages = {72} }</description></item><item><title>Discrepancies in Sample Size Calculations and Data Analyses Reported in Randomised trials: Comparison of Publications with Protocols</title><link>https://aakinshin.net/library/papers/chan2008/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/chan2008/</guid><description>Reference A.-W. Chan, A. Hrobjartsson, K. J Jorgensen, P. C Gotzsche, D. G Altman “Discrepancies in sample size calculations and data analyses reported in randomised trials: comparison of publications with protocols” (2008) // BMJ. Publisher: BMJ. Vol. 337. No dec04 1. Pp. a2299–a2299. DOI: 10.1136/bmj.a2299
Bib @Article{chan2008, title = {Discrepancies in sample size calculations and data analyses reported in randomised trials: comparison of publications with protocols}, volume = {337}, issn = {1468-5833}, url = {http://dx.doi.org/10.1136/bmj.a2299}, doi = {10.1136/bmj.a2299}, number = {dec04 1}, journal = {BMJ}, publisher = {BMJ}, author = {Chan, A.-W. and Hrobjartsson, A. and Jorgensen, K. J and Gotzsche, P. C and Altman, D. G}, year = {2008}, month = {dec}, pages = {a2299–a2299} }</description></item><item><title>Distributions Are Never Normal</title><link>https://aakinshin.net/library/quotes/8c71defc-488a-4b1e-a360-f0b37f77de12/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/8c71defc-488a-4b1e-a360-f0b37f77de12/</guid><description>To begin, distributions are never normal. For some this seems obvious, hardly worth mentioning, but an aphorism given by Cramér (1946) and attributed to the mathematician Poincaré remains relevant: “Everyone believes in the [normal] law of errors, the experimenters because they think it is a mathematical theorem, the mathematicians because they think it is an experimental fact.”</description></item><item><title>Do Studies of Statistical Power Have an Effect on the Power of studies?</title><link>https://aakinshin.net/library/papers/sedlmeier1989/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/sedlmeier1989/</guid><description>Reference Peter Sedlmeier, Gerd Gigerenzer “Do studies of statistical power have an effect on the power of studies?” (1989) // Psychological Bulletin. Publisher: American Psychological Association (APA). Vol. 105. No 2. Pp. 309–316. DOI: 10.1037/0033-2909.105.2.309
Bib @Article{sedlmeier1989, title = {Do studies of statistical power have an effect on the power of studies?}, volume = {105}, issn = {0033-2909}, url = {http://dx.doi.org/10.1037/0033-2909.105.2.309}, doi = {10.1037/0033-2909.105.2.309}, number = {2}, journal = {Psychological Bulletin}, publisher = {American Psychological Association (APA)}, author = {Sedlmeier, Peter and Gigerenzer, Gerd}, year = {1989}, month = {mar}, pages = {309–316} }</description></item><item><title>Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan</title><link>https://aakinshin.net/library/books/kruschke-doing-bayesian-data-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/kruschke-doing-bayesian-data-analysis/</guid><description/></item><item><title>Dominance statistics: Ordinal Analyses to Answer Ordinal Questions</title><link>https://aakinshin.net/library/papers/cliff1993/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/cliff1993/</guid><description>Reference Cliff N “Dominance statistics: Ordinal analyses to answer ordinal questions” (1993) // Psychol. Bull.. Vol. 114. Pp. 494. DOI: 10.1037/0033-2909.114.3.494
Bib @Article{cliff1993, title = {Dominance statistics: Ordinal analyses to answer ordinal questions}, volume = {114}, journal = {Psychol. Bull.}, author = {N, Cliff}, year = {1993}, pages = {494}, doi = {10.1037/0033-2909.114.3.494} }</description></item><item><title>Dos and don'ts of Reduced chi-squared</title><link>https://aakinshin.net/library/papers/andrae2010/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/andrae2010/</guid><description>Reference Rene Andrae, Tim Schulze-Hartung, Peter Melchior “Dos and don&amp;rsquo;ts of reduced chi-squared” (2010) // arXiv preprint arXiv:1012.3754.
Bib @Article{andrae2010, title = {Dos and don&amp;#39;ts of reduced chi-squared}, author = {Andrae, Rene and Schulze-Hartung, Tim and Melchior, Peter}, journal = {arXiv preprint arXiv:1012.3754}, arxiv = {1012.3754}, year = {2010} }</description></item><item><title>Eager-Beaver Researchers</title><link>https://aakinshin.net/library/quotes/5a3b8f36-edc5-4e56-bd51-d6fe8c1e0fee/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/5a3b8f36-edc5-4e56-bd51-d6fe8c1e0fee/</guid><description>Meanwhile our eager-beaver researcher, undismayed by logic-of-science considerations and relying blissfully on the “exactitude” of modem statistical hypothesis-testing, has produced a long publication list and been promoted to a full professorship. In terms of his contribution to the enduring body of psychological knowledge, he has done hardly anything. His true position is that of a potent-but-sterile intellectual rake, who leaves in his merry path a long train of ravished maidens but no viable scientific offspring.
First, I found this quote in the paper itself, next rediscovered it in Statistics Done Wrong.</description></item><item><title>Early Extreme Contradictory Estimates May Appear in Published research: The Proteus Phenomenon in Molecular Genetics Research and Randomized Trials</title><link>https://aakinshin.net/library/papers/ioannidis2005b/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/ioannidis2005b/</guid><description>Reference John PA Ioannidis, Thomas A Trikalinos “Early extreme contradictory estimates may appear in published research: The Proteus phenomenon in molecular genetics research and randomized trials” (2005) // Journal of Clinical Epidemiology. Publisher: Elsevier BV. Vol. 58. No 6. Pp. 543–549. DOI: 10.1016/j.jclinepi.2004.10.019
Bib @Article{ioannidis2005b, title = {Early extreme contradictory estimates may appear in published research: The Proteus phenomenon in molecular genetics research and randomized trials}, volume = {58}, issn = {0895-4356}, url = {http://dx.doi.org/10.1016/j.jclinepi.2004.10.019}, doi = {10.1016/j.jclinepi.2004.10.019}, number = {6}, journal = {Journal of Clinical Epidemiology}, publisher = {Elsevier BV}, author = {Ioannidis, John PA and Trikalinos, Thomas A}, year = {2005}, month = {jun}, pages = {543–549} }</description></item><item><title>Early Stopping of Rcts</title><link>https://aakinshin.net/library/quotes/7c744647-3299-4d41-b73f-85556e2d6e91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/7c744647-3299-4d41-b73f-85556e2d6e91/</guid><description>RCTs stopped early for benefit are becoming more common, often fail to adequately report relevant information about the decision to stop early, and show implausibly large treatment effects, particularly when the number of events is small. These findings suggest clinicians should view the results of such trials with skepticism.</description></item><item><title>Easy to Publish</title><link>https://aakinshin.net/library/quotes/9ef2c0c7-a5da-4d76-8169-2d2d97aae36a/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/9ef2c0c7-a5da-4d76-8169-2d2d97aae36a/</guid><description>Our job as scientists is to discover truths about the world. We generate hypotheses, collect data, and examine whether or not the data are consistent with those hypotheses. Although we aspire to always be accurate, errors are inevitable. Perhaps the most costly error is a false positive, the incorrect rejection of a null hypothesis. First, once they appear in the literature, false positives are particularly persistent. Because null results have many possible causes, failures to replicate previous findings are never conclusive. Furthermore, because it is uncommon for prestigious journals to publish null findings or exact replications, researchers have little incentive to even attempt them. Second, false positives waste resources: They inspire investment in fruitless research programs and can lead to ineffective policy changes. Finally, a field known for publishing false positives risks losing its credibility. In this article, we show that despite the nominal endorsement of a maximum false-positive rate of 5% (i.e., p ≤ .05), current standards for disclosing details of data collection and analyses make false positives vastly more likely. In fact, it is unacceptably easy to publish “statistically significant” evidence consistent with any hypothesis.
(Emphasis is mine.)</description></item><item><title>Editorial: Some Remarks from the Outgoing Editor</title><link>https://aakinshin.net/library/papers/campbell1982/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/campbell1982/</guid><description>Reference J. P. Campbell “Editorial: Some Remarks From the Outgoing Editor” (1982) // Journal of Applied Psychology. Publisher: American Psychological Association (APA). Vol. 67. No 6. Pp. 691–700. DOI: 10.1037/h0077946
Bib @Article{campbell1982, title = {Editorial: Some Remarks From the Outgoing Editor}, volume = {67}, issn = {0021-9010}, url = {http://dx.doi.org/10.1037/h0077946}, doi = {10.1037/h0077946}, number = {6}, journal = {Journal of Applied Psychology}, publisher = {American Psychological Association (APA)}, editor = {Campbell, J. P.}, year = {1982}, month = {dec}, pages = {691–700} }</description></item><item><title>Editors Can Lead Researchers to Confidence Intervals</title><link>https://aakinshin.net/library/papers/fidler2004/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/fidler2004/</guid><description>Reference Fiona Fidler, Neil Thomason, Geoff Cumming, Sue Finch, Joanna Leeman “Editors Can Lead Researchers to Confidence Intervals” (2004) // Psychological Science. Publisher: SAGE Publications. Vol. 15. No 2. Pp. 119–126. DOI: 10.1111/j.0963-7214.2004.01502008.x
Bib @Article{fidler2004, title = {Editors Can Lead Researchers to Confidence Intervals}, volume = {15}, issn = {1467-9280}, url = {http://dx.doi.org/10.1111/j.0963-7214.2004.01502008.x}, doi = {10.1111/j.0963-7214.2004.01502008.x}, number = {2}, journal = {Psychological Science}, publisher = {SAGE Publications}, author = {Fidler, Fiona and Thomason, Neil and Cumming, Geoff and Finch, Sue and Leeman, Joanna}, year = {2004}, month = {feb}, pages = {119–126} }</description></item><item><title>Effect Sizes for research: Univariate and Multivariate Applications</title><link>https://aakinshin.net/library/papers/grissom2012/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/grissom2012/</guid><description>Reference Robert J Grissom, John J Kim “Effect sizes for research: Univariate and multivariate applications” (2012) // Publisher: Routledge Academic. ISBN: 0805850147. DOI: 10.4324/9781410612915
Bib @Book{grissom2012, title = {Effect sizes for research: Univariate and multivariate applications}, author = {Grissom, Robert J and Kim, John J}, year = {2012}, ed = {1}, publisher = {Routledge Academic}, isbn = {0805850147}, doi = {10.4324/9781410612915} }</description></item><item><title>Efficiency Loss of Dichotomization</title><link>https://aakinshin.net/library/quotes/834262d6-ba81-46ea-a08a-952fafecc22c/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/834262d6-ba81-46ea-a08a-952fafecc22c/</guid><description>Dichotomization is the transformation of a continuous outcome (response) to a binary outcome. This approach, while somewhat common, is harmful from the viewpoint of statistical estimation and hypothesis testing. We show that this leads to loss of information, which can be large. For normally distributed data, this loss in terms of Fisher’s information is at least $1-2/\pi$ (or 36%). In other words, 100 continuous observations are statistically equivalent to 158 dichotomized observations. The amount of information lost depends greatly on the prior choice of cut points, with the optimal cut point depending upon the unknown parameters. The loss of information leads to loss of power or conversely a sample size increase to maintain power. Only in certain cases, for instance, in estimating a value of the cumulative distribution function and when the assumed model is very different from the true model, can the use of dichotomized outcomes be considered a reasonable approach.</description></item><item><title>Embarrassignly Large Confidence Intervals</title><link>https://aakinshin.net/library/quotes/a2e73f66-cacd-4065-94d2-b541952903ab/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/a2e73f66-cacd-4065-94d2-b541952903ab/</guid><description>&amp;ldquo;Everyone knows&amp;rdquo; that confidence intervals contain all the information to be found in significance tests and much more. They not only reveal the status of the trivial nil hypothesis but also about the status of non-nil null hypotheses and thus help remind researchers about the possible operation of the crud factor. Yet they are rarely to be found in the literature. I suspect that the main reason they are not reported is that they are so embarrassingly large!</description></item><item><title>Empirical Evidence for Selective Reporting of Outcomes in Randomized Trials: Comparison of Protocols to Published Articles</title><link>https://aakinshin.net/library/papers/chan2004/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/chan2004/</guid><description>Reference An-Wen Chan, Asbjørn Hróbjartsson, Mette T. Haahr, Peter C. Gøtzsche, Douglas G. Altman “Empirical Evidence for Selective Reporting of Outcomes in Randomized Trials: Comparison of Protocols to Published Articles” (2004) // JAMA. Publisher: American Medical Association (AMA). Vol. 291. No 20. Pp. 2457. DOI: 10.1001/jama.291.20.2457
Bib @Article{chan2004, title = {Empirical Evidence for Selective Reporting of Outcomes in Randomized Trials: Comparison of Protocols to Published Articles}, volume = {291}, issn = {0098-7484}, url = {http://dx.doi.org/10.1001/jama.291.20.2457}, doi = {10.1001/jama.291.20.2457}, number = {20}, journal = {JAMA}, publisher = {American Medical Association (AMA)}, author = {Chan, An-Wen and Hróbjartsson, Asbjørn and Haahr, Mette T. and Gøtzsche, Peter C. and Altman, Douglas G.}, year = {2004}, month = {may}, pages = {2457} }</description></item><item><title>Empirical Probability Plots and Statistical Inference for Nonlinear Models in the Two-Sample Case</title><link>https://aakinshin.net/library/papers/doksum1974/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/doksum1974/</guid><description>Reference Kjell Doksum “Empirical Probability Plots and Statistical Inference for Nonlinear Models in the Two-Sample Case” (1974) // The Annals of Statistics. Publisher: Institute of Mathematical Statistics. Vol. 2. No 2. DOI: 10.1214/aos/1176342662
Bib @Article{doksum1974, doi = {10.1214/aos/1176342662}, year = {1974}, month = {3}, publisher = {Institute of Mathematical Statistics}, volume = {2}, number = {2}, author = {Kjell Doksum}, title = {Empirical Probability Plots and Statistical Inference for Nonlinear Models in the Two-Sample Case}, journal = {The Annals of Statistics} }</description></item><item><title>Erroneous Analyses of Interactions in neuroscience: A Problem of Significance</title><link>https://aakinshin.net/library/papers/nieuwenhuis2011/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/nieuwenhuis2011/</guid><description>Reference Sander Nieuwenhuis, Birte U Forstmann, Eric-Jan Wagenmakers “Erroneous analyses of interactions in neuroscience: a problem of significance” (2011) // Nature Neuroscience. Publisher: Springer Science and Business Media LLC. Vol. 14. No 9. Pp. 1105–1107. DOI: 10.1038/nn.2886
Bib @Article{nieuwenhuis2011, title = {Erroneous analyses of interactions in neuroscience: a problem of significance}, volume = {14}, issn = {1546-1726}, url = {http://dx.doi.org/10.1038/nn.2886}, doi = {10.1038/nn.2886}, number = {9}, journal = {Nature Neuroscience}, publisher = {Springer Science and Business Media LLC}, author = {Nieuwenhuis, Sander and Forstmann, Birte U and Wagenmakers, Eric-Jan}, year = {2011}, month = {aug}, pages = {1105–1107} }</description></item><item><title>Estimates of Location Based on Rank Tests</title><link>https://aakinshin.net/library/papers/hodges1963/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/hodges1963/</guid><description>Reference J L Hodges, E L Lehmann “Estimates of Location Based on Rank Tests” (1963) // The Annals of Mathematical Statistics. Vol. 34. No 2. Pp. 598–611. DOI: 10.1214/aoms/1177704172
Bib @Article{hodges1963, title = {Estimates of Location Based on Rank Tests}, volume = {34}, issn = {0003-4851}, url = {http://projecteuclid.org/euclid.aoms/1177704172}, doi = {10.1214/aoms/1177704172}, language = {en}, number = {2}, urldate = {2022-05-31}, journal = {The Annals of Mathematical Statistics}, author = {Hodges, J L and Lehmann, E L}, month = {jun}, year = {1963}, pages = {598--611} }</description></item><item><title>Estimating the Impact of State Policies and Institutions with Mixed-Level Data</title><link>https://aakinshin.net/library/papers/primo2007/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/primo2007/</guid><description>Reference David M Primo, Matthew L Jacobsmeier, Jeffrey Milyo “Estimating the Impact of State Policies and Institutions with Mixed-Level Data” (2007) // State Politics &amp;amp; Policy Quarterly. Publisher: Cambridge University Press (CUP). Vol. 7. No 4. Pp. 446–459. DOI: 10.1177/153244000700700405
Bib @Article{primo2007, title = {Estimating the Impact of State Policies and Institutions with Mixed-Level Data}, volume = {7}, issn = {1946-1607}, url = {http://dx.doi.org/10.1177/153244000700700405}, doi = {10.1177/153244000700700405}, number = {4}, journal = {State Politics &amp;amp;amp; Policy Quarterly}, publisher = {Cambridge University Press (CUP)}, author = {Primo, David M and Jacobsmeier, Matthew L and Milyo, Jeffrey}, year = {2007}, pages = {446–459} }</description></item><item><title>Estimating the Ratio of medians: Theory and Applications</title><link>https://aakinshin.net/library/papers/price1996/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/price1996/</guid><description>Reference Robert Martin Jr Price “Estimating the ratio of medians: Theory and applications” (1996)
Bib @PhdThesis{price1996, title = {Estimating the ratio of medians: Theory and applications}, school = {University of Wyoming}, author = {Price, Robert Martin Jr}, year = {1996} }</description></item><item><title>Estimation of Social Exclusion Indicators from Complex Surveys: The R Package Laeken</title><link>https://aakinshin.net/library/papers/alfons2013/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/alfons2013/</guid><description>Reference Andreas Alfons, Matthias Templ “Estimation of Social Exclusion Indicators from Complex Surveys: The R Package laeken” (2013) // Journal of Statistical Software. Vol. 54. No 15. Pp. 1–25. DOI: 10.18637/jss.v054.i15
Bib @Article{alfons2013, title = {Estimation of Social Exclusion Indicators from Complex Surveys: The R Package laeken}, author = {Andreas Alfons and Matthias Templ}, journal = {Journal of Statistical Software}, year = {2013}, volume = {54}, number = {15}, pages = {1--25}, doi = {10.18637/jss.v054.i15}, url = {https://cran.r-project.org/web//packages//laeken/vignettes/laeken-intro.pdf} }</description></item><item><title>Estimation of the Ratio of Scale Parameters in the Two Sample Problem with Arbitrary Right Censorship</title><link>https://aakinshin.net/library/papers/padgett1982/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/padgett1982/</guid><description>Reference W J Padgett, L J Wei “Estimation of the ratio of scale parameters in the two sample problem with arbitrary right censorship” (1982) // Biometrika. Vol. 69. No 1. Pp. 252–256. DOI: 10.1093/biomet/69.1.252
Bib @Article{padgett1982, title = {Estimation of the ratio of scale parameters in the two sample problem with arbitrary right censorship}, volume = {69}, issn = {0006-3444, 1464-3510}, url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/69.1.252}, doi = {10.1093/biomet/69.1.252}, language = {en}, number = {1}, urldate = {2023-12-10}, journal = {Biometrika}, author = {Padgett, W J and Wei, L J}, year = {1982}, pages = {252--256} }</description></item><item><title>Evaluating the Reliability of Highly Cited Clinical Research Studies</title><link>https://aakinshin.net/library/quotes/3862f143-7b54-472a-b201-83407f62ac6c/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/3862f143-7b54-472a-b201-83407f62ac6c/</guid><description>Of 49 highly cited original clinical research studies, 45 claimed that the intervention was effective. Of these, 7 (16%) were contradicted by subsequent studies, 7 others (16%) had found effects that were stronger than those of subsequent studies, 20 (44%) were replicated, and 11 (24%) remained largely unchallenged. Five of 6 highlycited nonrandomized studies had been contradicted or had found stronger effects vs 9 of 39 randomized controlled trials (P=.008). Among randomized trials, studies with contradicted or stronger effects were smaller (P=.009) than replicated or unchallenged studies although there was no statistically significant difference in their early or overall citation impact. Matched control studies did not have a significantly different share of refuted results than highly cited studies, but they included more studies with “negative” results.</description></item><item><title>Evaluation of Watermelons Texture Using Their Vibration Responses</title><link>https://aakinshin.net/library/papers/abbaszadeh2013/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/abbaszadeh2013/</guid><description>Fabulous research! Four scientists took 43 watermelons (Crimson sweet), measured their vibration response, rated them using a five-point ripeness scale, built a regression model to predict ripeness from vibration response, checked the model on the same 43 watermelons, got R² = 0.9998, published the results in a peer-reviewed journal.
Debunked in Statistics Done Wrong.
Reference Rouzbeh Abbaszadeh, Ali Rajabipour, Mohammad Mahjoob, Mojtaba Delshad, Hojjat Ahmadi “Evaluation of watermelons texture using their vibration responses” (2013) // Biosystems Engineering. Publisher: Elsevier BV. Vol. 115. No 1. Pp. 102–105. DOI: 10.1016/j.biosystemseng.2013.01.001
Bib @Article{abbaszadeh2013, title = {Evaluation of watermelons texture using their vibration responses}, volume = {115}, issn = {1537-5110}, url = {http://dx.doi.org/10.1016/j.biosystemseng.2013.01.001}, doi = {10.1016/j.biosystemseng.2013.01.001}, number = {1}, journal = {Biosystems Engineering}, publisher = {Elsevier BV}, author = {Abbaszadeh, Rouzbeh and Rajabipour, Ali and Mahjoob, Mohammad and Delshad, Mojtaba and Ahmadi, Hojjat}, year = {2013}, month = {may}, pages = {102–105} }</description></item><item><title>Exploratory Data Analysis</title><link>https://aakinshin.net/library/papers/tukey1977/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/tukey1977/</guid><description>Reference John W Tukey, others “Exploratory data analysis” (1977) // Publisher: Reading, MA. Vol. 2.
Bib @Book{tukey1977, title = {Exploratory data analysis}, author = {Tukey, John W and others}, volume = {2}, year = {1977}, publisher = {Reading, MA} }</description></item><item><title>Fake Science: Exposing the Left's Skewed Statistics, Fuzzy Facts, and Dodgy Data</title><link>https://aakinshin.net/library/books/ruse-fake-science/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/ruse-fake-science/</guid><description/></item><item><title>False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant</title><link>https://aakinshin.net/library/papers/simmons2011/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/simmons2011/</guid><description>Reference Joseph P Simmons, Leif D Nelson, Uri Simonsohn “False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant” (2011) // Psychological Science. Publisher: SAGE Publications. Vol. 22. No 11. Pp. 1359–1366. DOI: 10.1177/0956797611417632
Bib @Article{simmons2011, title = {False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant}, volume = {22}, issn = {1467-9280}, url = {http://dx.doi.org/10.1177/0956797611417632}, doi = {10.1177/0956797611417632}, number = {11}, journal = {Psychological Science}, publisher = {SAGE Publications}, author = {Simmons, Joseph P and Nelson, Leif D and Simonsohn, Uri}, year = {2011}, month = {oct}, pages = {1359–1366} }</description></item><item><title>Fast Deterministic Selection</title><link>https://aakinshin.net/library/papers/alexandrescu2017/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/alexandrescu2017/</guid><description>Reference Andrei Alexandrescu, Costas S. Iliopoulos, Solon P. Pissis, Simon J. Puglisi, Rajeev Raman “Fast Deterministic Selection” (2017) // 16th International Symposium on Experimental Algorithms (SEA 2017). Publisher: Schloss Dagstuhl&amp;ndash;Leibniz-Zentrum fuer Informatik. Dagstuhl, Germany. ISBN: 978-3-95977-036-1. Vol. 75. Pp. 24:1–24:19. DOI: 10.4230/LIPIcs.SEA.2017.24
Bib @Inproceedings{alexandrescu2017, author = {Andrei Alexandrescu}, title = {Fast Deterministic Selection}, booktitle = {16th International Symposium on Experimental Algorithms (SEA 2017)}, pages = {24:1--24:19}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, isbn = {978-3-95977-036-1}, issn = {1868-8969}, year = {2017}, volume = {75}, editor = {Costas S. Iliopoulos and Solon P. Pissis and Simon J. Puglisi and Rajeev Raman}, publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik}, address = {Dagstuhl, Germany}, url = {http://drops.dagstuhl.de/opus/volltexte/2017/7612}, urn = {urn:nbn:de:0030-drops-76122}, doi = {10.4230/LIPIcs.SEA.2017.24}, arxiv = {1606.00484}, annote = {Keywords: Selection Problem, Quickselect, Median of Medians, Algorithm Engineering, Algorithmic Libraries} }</description></item><item><title>Fast Highly Efficient and Robust one-step M-estimators of Scale Based on Qn</title><link>https://aakinshin.net/library/papers/smirnov2014/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/smirnov2014/</guid><description>Reference Pavel O Smirnov, Georgy L Shevlyakov “Fast highly efficient and robust one-step M-estimators of scale based on Qn” (2014) // Computational Statistics and Data Analysis. Publisher: Elsevier BV. Vol. 78. Pp. 153–158. DOI: 10.1016/j.csda.2014.04.013
Bib @Article{smirnov2014, doi = {10.1016/j.csda.2014.04.013}, year = {2014}, month = {oct}, publisher = {Elsevier BV}, volume = {78}, pages = {153--158}, author = {Pavel O Smirnov and Georgy L Shevlyakov}, title = {Fast highly efficient and robust one-step M-estimators of scale based on Qn}, journal = {Computational Statistics and Data Analysis} }</description></item><item><title>Fast Online Computation of the Q N Estimator with Applications to the Detection of Outliers in Data Streams</title><link>https://aakinshin.net/library/papers/cafaro2021/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/cafaro2021/</guid><description>Reference Massimo Cafaro, Catiuscia Melle, Marco Pulimeno, Italo Epicoco “Fast online computation of the Q n estimator with applications to the detection of outliers in data streams” (2021) // Expert Systems with Applications. Vol. 164. Pp. 113831. DOI: 10.1016/j.eswa.2020.113831
Bib @Article{cafaro2021, title = {Fast online computation of the Q n estimator with applications to the detection of outliers in data streams}, volume = {164}, issn = {09574174}, url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417420306424}, doi = {10.1016/j.eswa.2020.113831}, language = {en}, urldate = {2022-08-05}, journal = {Expert Systems with Applications}, author = {Cafaro, Massimo and Melle, Catiuscia and Pulimeno, Marco and Epicoco, Italo}, month = {feb}, year = {2021}, pages = {113831} }</description></item><item><title>Finite Sample Correction Factors for Several Simple Robust Estimators of Normal Standard Deviation</title><link>https://aakinshin.net/library/papers/williams2011/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/williams2011/</guid><description>Reference Dennis C Williams “Finite sample correction factors for several simple robust estimators of normal standard deviation” (2011) // Journal of Statistical Computation and Simulation. Vol. 81. No 11. Pp. 1697–1702. DOI: 10.1080/00949655.2010.499516
Bib @Article{williams2011, title = {Finite sample correction factors for several simple robust estimators of normal standard deviation}, volume = {81}, issn = {0094-9655, 1563-5163}, url = {http://www.tandfonline.com/doi/abs/10.1080/00949655.2010.499516}, doi = {10.1080/00949655.2010.499516}, language = {en}, number = {11}, urldate = {2022-08-02}, journal = {Journal of Statistical Computation and Simulation}, author = {Williams, Dennis C}, month = {nov}, year = {2011}, pages = {1697--1702} }</description></item><item><title>Finite-Sample Bias-Correction Factors for the Median Absolute Deviation</title><link>https://aakinshin.net/library/papers/hayes2014/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/hayes2014/</guid><description>Reference Kevin Hayes “Finite-Sample Bias-Correction Factors for the Median Absolute Deviation” (2014) // Communications in Statistics - Simulation and Computation. Vol. 43. No 10. Pp. 2205–2212. DOI: 10.1080/03610918.2012.748913
Bib @Article{hayes2014, title = {Finite-Sample Bias-Correction Factors for the Median Absolute Deviation}, volume = {43}, issn = {0361-0918, 1532-4141}, url = {http://www.tandfonline.com/doi/abs/10.1080/03610918.2012.748913}, doi = {10.1080/03610918.2012.748913}, language = {en}, number = {10}, urldate = {2022-08-02}, journal = {Communications in Statistics - Simulation and Computation}, author = {Hayes, Kevin}, month = {nov}, year = {2014}, pages = {2205--2212} }</description></item><item><title>First (?) Occurrence of Common Terms in Mathematical Statistics</title><link>https://aakinshin.net/library/papers/david1995/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/david1995/</guid><description>Reference H A David “First (?) Occurrence of Common Terms in Mathematical Statistics” (1995) // The American Statistician. Vol. 49. No 2. Pp. 121. DOI: 10.2307/2684625
Bib @Article{david1995, title = {First (?) Occurrence of Common Terms in Mathematical Statistics}, volume = {49}, issn = {00031305}, shorttitle = {First (?}, url = {https://www.jstor.org/stable/2684625?origin=crossref}, doi = {10.2307/2684625}, number = {2}, urldate = {2020-01-07}, journal = {The American Statistician}, author = {David, H A}, month = {may}, year = {1995}, note = {ZSCC: 0000090}, pages = {121} }</description></item><item><title>First Among others? Cohen's D vs. Alternative Standardized Mean Group Difference Measures</title><link>https://aakinshin.net/library/papers/cahan2011/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/cahan2011/</guid><description>Reference Cahan S, Gamliel E “First among others? Cohen&amp;amp;#039;s d vs. alternative standardized mean group difference measures” (2011) // Pract. Assess. Res. Eval.. Vol. 16. Pp. 1.
Bib @Article{cahan2011, title = {First among others? Cohen\&amp;amp;\#039;s d vs. alternative standardized mean group difference measures}, volume = {16}, journal = {Pract. Assess. Res. Eval.}, author = {S, Cahan and E, Gamliel}, year = {2011}, pages = {1}, custom-url-pdf = {https://openpublishing.library.umass.edu/pare/article/1451/galley/1402/view/} }</description></item><item><title>Fisher, Neyman-Pearson or NHST? A Tutorial for Teaching Data Testing</title><link>https://aakinshin.net/library/papers/perezgonzalez2015/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/perezgonzalez2015/</guid><description>Reference Jose D Perezgonzalez “Fisher, Neyman-Pearson or NHST? A tutorial for teaching data testing” (2015) // Frontiers in Psychology. Vol. 6. DOI: 10.3389/fpsyg.2015.00223
Bib @Article{perezgonzalez2015, title = {Fisher, Neyman-Pearson or NHST? A tutorial for teaching data testing}, volume = {6}, issn = {1664-1078}, shorttitle = {Fisher, Neyman-Pearson or NHST?}, url = {http://journal.frontiersin.org/Article/10.3389/fpsyg.2015.00223/abstract}, doi = {10.3389/fpsyg.2015.00223}, urldate = {2020-01-07}, journal = {Frontiers in Psychology}, author = {Perezgonzalez, Jose D}, month = {mar}, year = {2015}, note = {ZSCC: 0000068} }</description></item><item><title>Five Percieved Probability Values</title><link>https://aakinshin.net/library/quotes/68b00b34-b893-406a-963c-6775b11a9147/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/68b00b34-b893-406a-963c-6775b11a9147/</guid><description>There are only five probabilities the average human can handle: 99 percent, one percent, 100 percent, zero, and 50-50. That’s it.
Source: https://twitter.com/ProbFact/status/1559569468979908608</description></item><item><title>Fraud Analytics Using Descriptive, Predictive, and Social Network Techniques: A Guide to Data Science for Fraud Detection</title><link>https://aakinshin.net/library/books/baesens-fraud-analytics-using-descriptive-predictive-and-social-network-techniques/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/baesens-fraud-analytics-using-descriptive-predictive-and-social-network-techniques/</guid><description/></item><item><title>Gender Differences in Variability in Intellectual abilities: A Reanalysis of Feingold's Results</title><link>https://aakinshin.net/library/papers/hedges1993/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/hedges1993/</guid><description>Reference Hedges L V, Friedman L “Gender differences in variability in intellectual abilities: A reanalysis of Feingold&amp;amp;#039;s results” (1993) // Rev. Educ. Res.. Vol. 63. Pp. 94. DOI: 10.2307/1170561
Bib @Article{hedges1993, title = {Gender differences in variability in intellectual abilities: A reanalysis of Feingold\&amp;amp;\#039;s results}, volume = {63}, journal = {Rev. Educ. Res.}, author = {V, Hedges L and L, Friedman}, year = {1993}, pages = {94}, doi = {10.2307/1170561} }</description></item><item><title>Geometry and Statistics: Problems at the Interface</title><link>https://aakinshin.net/library/papers/shamos1976/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/shamos1976/</guid><description>Reference Michael Ian Shamos “Geometry and Statistics: Problems at the Interface” (1976) // In Algorithms and Complexity: New directions and recent results. Citeseer.
Bib @Book{shamos1976, title = {Geometry and Statistics: Problems at the Interface}, author = {Shamos, Michael Ian}, booktitle = {In Algorithms and Complexity: New directions and recent results}, year = {1976}, organization = {Citeseer} }</description></item><item><title>Ggplot2: Elegant Graphics for Data Analysis (Use R!)</title><link>https://aakinshin.net/library/books/wickham-ggplot2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/wickham-ggplot2/</guid><description/></item><item><title>Graphical Methods for Data Analysis</title><link>https://aakinshin.net/library/papers/chambers1983/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/chambers1983/</guid><description>Reference John M Chambers, William S Cleveland, Paul A Tukey, Beat Kleiner “Graphical methods for data analysis” (1983) // Publisher: Duxbury Press. ISBN: 053498052X.
Bib @Book{chambers1983, title = {Graphical methods for data analysis}, author = {John M Chambers and William S Cleveland and Paul A Tukey and Beat Kleiner}, publisher = {Duxbury Press}, isbn = {053498052X}, year = {1983}, series = {Wadsworth \&amp;amp; Brooks/Cole Statistics/Probability Series} }</description></item><item><title>Guide to Effect Sizes and Confidence Intervals</title><link>https://aakinshin.net/library/papers/jan%C3%A92024/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/jan%C3%A92024/</guid><description>Reference Matthew B Jané, Qinyu Xiao, Siu Kit Yeung, Mattan S *Ben-Shachar, Aaron R Caldwell, Denis Cousineau, Daniel J Dunleavy, Mahmoud M Elsherif, Blair T Johnson, David Moreau, Paul Riesthuis, Lukas Röseler, James Steele, Felipe F Vieira, Mircea Zloteanu, Gilad Feldman “Guide to Effect Sizes and Confidence Intervals” (2024) // Publisher: OSF. DOI: 10.17605/OSF.IO/D8C4G
Bib @Misc{jané2024, title = {Guide to Effect Sizes and Confidence Intervals}, url = {https://matthewbjane.quarto.pub/}, doi = {10.17605/OSF.IO/D8C4G}, publisher = {OSF}, author = {Jané, Matthew B and Xiao, Qinyu and Yeung, Siu Kit and *Ben-Shachar, Mattan S and Caldwell, Aaron R and Cousineau, Denis and Dunleavy, Daniel J and Elsherif, Mahmoud M and Johnson, Blair T and Moreau, David and Riesthuis, Paul and Röseler, Lukas and Steele, James and Vieira, Felipe F and Zloteanu, Mircea and Feldman, Gilad}, custom-url-pdf = {https://osf.io/download/87vke/}, year = {2024} }</description></item><item><title>Guidelines for Reviewers</title><link>https://aakinshin.net/library/quotes/1d8a5c7b-087b-4a6e-b60e-f144dd8a0f0b/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/1d8a5c7b-087b-4a6e-b60e-f144dd8a0f0b/</guid><description>We propose the following four guidelines for reviewers.
Reviewers should ensure that authors follow the requirements. Review teams are the gatekeepers of the scientific community, and they should encourage authors not only to rule out alternative explanations, but also to more convincingly demonstrate that their findings are not due to chance alone. This means prioritizing transparency over tidiness; if a wonderful study is partially marred by a peculiar exclusion or an inconsistent condition, those imperfections should be retained. If reviewers require authors to follow these requirements, they will. Reviewers should be more tolerant of imperfections in results. One reason researchers exploit researcher degrees of freedom is the unreasonable expectation we often impose as reviewers for every data pattern to be (significantly) as predicted. Underpowered studies with perfect results are the ones that should invite extra scrutiny. Reviewers should require authors to demonstrate that their results do not hinge on arbitrary analytic decisions. Even if authors follow all of our guidelines, they will necessarily still face arbitrary decisions. For example, should they subtract the baseline measure of the dependent variable from the final result or should they use the baseline measure as a covariate? When there is no obviously correct way to answer questions like this, the reviewer should ask for alternatives. For example, reviewer reports might include questions such as, “Do the results also hold if the baseline measure is instead used as a covariate?” Similarly, reviewers should ensure that arbitrary decisions are used consistently across studies (e.g., “Do the results hold for Study 3 if gender is entered as a covariate, as was done in Study 2?”).5 If a result holds only for one arbitrary specification, then everyone involved has learned a great deal about the robustness (or lack thereof) of the effect. If justifications of data collection or analysis are not compelling, reviewers should require the authors to conduct an exact replication.</description></item><item><title>High Impact = High Statistical Standards? Not Necessarily so</title><link>https://aakinshin.net/library/papers/tressoldi2013/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/tressoldi2013/</guid><description>Reference Patrizio E Tressoldi, David Giofré, Francesco Sella, Geoff Cumming, Hills “High Impact = High Statistical Standards? Not Necessarily So” (2013) // PLoS ONE. Publisher: Public Library of Science (PLoS). Vol. 8. No 2. Pp. e56180. DOI: 10.1371/journal.pone.0056180
Bib @Article{tressoldi2013, title = {High Impact = High Statistical Standards? Not Necessarily So}, volume = {8}, issn = {1932-6203}, url = {http://dx.doi.org/10.1371/journal.pone.0056180}, doi = {10.1371/journal.pone.0056180}, number = {2}, journal = {PLoS ONE}, publisher = {Public Library of Science (PLoS)}, author = {Tressoldi, Patrizio E and Giofré, David and Sella, Francesco and Cumming, Geoff}, editor = {Hills}, year = {2013}, month = {feb}, pages = {e56180} }</description></item><item><title>How Confidence Intervals Become Confusion Intervals</title><link>https://aakinshin.net/library/papers/mccormack2013/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/mccormack2013/</guid><description>Reference James McCormack, Ben Vandermeer, G Michael Allan “How confidence intervals become confusion intervals” (2013) // BMC Medical Research Methodology. Publisher: Springer Science and Business Media LLC. Vol. 13. No 1. DOI: 10.1186/1471-2288-13-134
Abstract In this paper, we review how researchers can look at very similar data yet have completely different conclusions based purely on an over-reliance of statistical significance and an unclear understanding of confidence intervals. The dogmatic adherence to statistical significant thresholds can lead authors to write dichotomized absolute conclusions while ignoring the broader interpretations of very consistent findings. We describe three examples of controversy around the potential benefit of a medication, a comparison between new medications, and a medication with a potential harm. The examples include the highest levels of evidence, both meta-analyses and randomized controlled trials. We will show how in each case the confidence intervals and point estimates were very similar. The only identifiable differences to account for the contrasting conclusions arise from the serendipitous finding of confidence intervals that either marginally cross or just fail to cross the line of statistical significance.
Bib @Article{mccormack2013, title = {How confidence intervals become confusion intervals}, abstract = {In this paper, we review how researchers can look at very similar data yet have completely different conclusions based purely on an over-reliance of statistical significance and an unclear understanding of confidence intervals. The dogmatic adherence to statistical significant thresholds can lead authors to write dichotomized absolute conclusions while ignoring the broader interpretations of very consistent findings. We describe three examples of controversy around the potential benefit of a medication, a comparison between new medications, and a medication with a potential harm. The examples include the highest levels of evidence, both meta-analyses and randomized controlled trials. We will show how in each case the confidence intervals and point estimates were very similar.</description></item><item><title>How to Lie with Statistics</title><link>https://aakinshin.net/library/books/huff-how-to-lie-with-statistics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/huff-how-to-lie-with-statistics/</guid><description/></item><item><title>How to Test Hypotheses If You Must</title><link>https://aakinshin.net/library/papers/grieve2015/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/grieve2015/</guid><description>Reference Andrew P Grieve “How to test hypotheses if you must” (2015) // Pharmaceutical Statistics. Vol. 14. No 2. Pp. 139–150. DOI: 10.1002/pst.1667
Bib @Article{grieve2015, title = {How to test hypotheses if you must}, volume = {14}, issn = {15391604}, url = {http://doi.wiley.com/10.1002/pst.1667}, doi = {10.1002/pst.1667}, language = {en}, number = {2}, urldate = {2020-01-07}, journal = {Pharmaceutical Statistics}, author = {Grieve, Andrew P}, month = {mar}, year = {2015}, note = {ZSCC: 0000012}, pages = {139--150} }</description></item><item><title>Huff and Puff</title><link>https://aakinshin.net/library/papers/reinhart2014/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/reinhart2014/</guid><description>Reference Alex Reinhart “Huff and Puff” (2014) // Significance. Publisher: Oxford University Press (OUP). Vol. 11. No 4. Pp. 28–33. DOI: 10.1111/j.1740-9713.2014.00765.x
Bib @Article{reinhart2014, title = {Huff and Puff}, volume = {11}, issn = {1740-9713}, url = {http://dx.doi.org/10.1111/j.1740-9713.2014.00765.x}, doi = {10.1111/j.1740-9713.2014.00765.x}, number = {4}, journal = {Significance}, publisher = {Oxford University Press (OUP)}, author = {Reinhart, Alex}, year = {2014}, month = {oct}, pages = {28–33} }</description></item><item><title>Impact of Multiple Comparisons in Randomized Clinical Trials</title><link>https://aakinshin.net/library/papers/smith1987/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/smith1987/</guid><description>Reference David Gary Smith, John Clemens, William Crede, Mary Harvey, Edward J Gracely “Impact of multiple comparisons in randomized clinical trials” (1987) // The American Journal of Medicine. Publisher: Elsevier BV. Vol. 83. No 3. Pp. 545–550. DOI: 10.1016/0002-9343(87)90768-6
Bib @Article{smith1987, title = {Impact of multiple comparisons in randomized clinical trials}, volume = {83}, issn = {0002-9343}, url = {http://dx.doi.org/10.1016/0002-9343(87)90768-6}, doi = {10.1016/0002-9343(87)90768-6}, number = {3}, journal = {The American Journal of Medicine}, publisher = {Elsevier BV}, author = {Smith, David Gary and Clemens, John and Crede, William and Harvey, Mary and Gracely, Edward J}, year = {1987}, month = {sep}, pages = {545–550} }</description></item><item><title>Improving Your Statistical Inferences</title><link>https://aakinshin.net/library/books/lakens-improving-your-statistical-inferences/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/lakens-improving-your-statistical-inferences/</guid><description/></item><item><title>Inadequate Statistical Power to Detect Clinically Significant Differences in Adverse Event Rates in Randomized Controlled Trials</title><link>https://aakinshin.net/library/papers/tsang2009/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/tsang2009/</guid><description>Reference Ruth Tsang, Lindsey Colley, Larry D Lynd “Inadequate statistical power to detect clinically significant differences in adverse event rates in randomized controlled trials” (2009) // Journal of Clinical Epidemiology. Publisher: Elsevier BV. Vol. 62. No 6. Pp. 609–616. DOI: 10.1016/j.jclinepi.2008.08.005
Bib @Article{tsang2009, title = {Inadequate statistical power to detect clinically significant differences in adverse event rates in randomized controlled trials}, volume = {62}, issn = {0895-4356}, url = {http://dx.doi.org/10.1016/j.jclinepi.2008.08.005}, doi = {10.1016/j.jclinepi.2008.08.005}, number = {6}, journal = {Journal of Clinical Epidemiology}, publisher = {Elsevier BV}, author = {Tsang, Ruth and Colley, Lindsey and Lynd, Larry D}, year = {2009}, month = {jun}, pages = {609–616} }</description></item><item><title>Incongruence Between Test Statistics and P Values in Medical Papers</title><link>https://aakinshin.net/library/papers/garc%C3%ADa-berthou2004/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/garc%C3%ADa-berthou2004/</guid><description>Reference Emili García-Berthou, Carles Alcaraz “Incongruence between test statistics and P values in medical papers” (2004) // BMC Medical Research Methodology. Publisher: Springer Science and Business Media LLC. Vol. 4. No 1. DOI: 10.1186/1471-2288-4-13
Bib @Article{garcía-berthou2004, title = {Incongruence between test statistics and P values in medical papers}, volume = {4}, issn = {1471-2288}, url = {http://dx.doi.org/10.1186/1471-2288-4-13}, doi = {10.1186/1471-2288-4-13}, number = {1}, journal = {BMC Medical Research Methodology}, publisher = {Springer Science and Business Media LLC}, author = {García-Berthou, Emili and Alcaraz, Carles}, year = {2004}, month = {may} }</description></item><item><title>Incorrect Statistical Procedures in Neuroscience</title><link>https://aakinshin.net/library/quotes/4e6b0a2d-9a6c-4b97-9c15-b7009ef063a5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/4e6b0a2d-9a6c-4b97-9c15-b7009ef063a5/</guid><description>In theory, a comparison of two experimental effects requires a statistical test on their difference. In practice, this comparison is often based on an incorrect procedure involving two separate tests in which researchers conclude that effects differ when one effect is significant (P &amp;lt; 0.05) but the other is not (P &amp;gt; 0.05). We reviewed 513 behavioral, systems and cognitive neuroscience articles in five top-ranking journals (Science, Nature, Nature Neuroscience, Neuron and The Journal of Neuroscience) and found that 78 used the correct procedure and 79 used the incorrect procedure. An additional analysis suggests that incorrect analyses of interactions are even more common in cellular and molecular neuroscience.</description></item><item><title>Inferential Statistics as Descriptive Statistics: There is No Replication Crisis If We Don’t Expect Replication</title><link>https://aakinshin.net/library/papers/amrhein2019/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/amrhein2019/</guid><description>Reference Valentin Amrhein, David Trafimow, Sander Greenland “Inferential Statistics as Descriptive Statistics: There Is No Replication Crisis if We Don’t Expect Replication” (2019) // The American Statistician. Publisher: Informa UK Limited. Vol. 73. No sup1. Pp. 262–270. DOI: 10.1080/00031305.2018.1543137
Bib @Article{amrhein2019, title = {Inferential Statistics as Descriptive Statistics: There Is No Replication Crisis if We Don’t Expect Replication}, volume = {73}, issn = {1537-2731}, url = {http://dx.doi.org/10.1080/00031305.2018.1543137}, doi = {10.1080/00031305.2018.1543137}, number = {sup1}, journal = {The American Statistician}, publisher = {Informa UK Limited}, author = {Amrhein, Valentin and Trafimow, David and Greenland, Sander}, year = {2019}, month = {mar}, pages = {262–270} }</description></item><item><title>Interim Analyses and Sequential Designs in Phase III Studies</title><link>https://aakinshin.net/library/papers/todd2001/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/todd2001/</guid><description>Reference Susan Todd, Anne Whitehead, Nigel Stallard, John Whitehead “Interim analyses and sequential designs in phase III studies” (2001) // British Journal of Clinical Pharmacology. Publisher: Wiley. Vol. 51. No 5. Pp. 394–399. DOI: 10.1046/j.1365-2125.2001.01382.x
Bib @Article{todd2001, title = {Interim analyses and sequential designs in phase III studies}, volume = {51}, issn = {1365-2125}, url = {http://dx.doi.org/10.1046/j.1365-2125.2001.01382.x}, doi = {10.1046/j.1365-2125.2001.01382.x}, number = {5}, journal = {British Journal of Clinical Pharmacology}, publisher = {Wiley}, author = {Todd, Susan and Whitehead, Anne and Stallard, Nigel and Whitehead, John}, year = {2001}, month = {may}, pages = {394–399} }</description></item><item><title>Interval Estimates of Weighted Effect Sizes in the one-way Heteroscedastic ANOVA</title><link>https://aakinshin.net/library/papers/kulinskaya2006/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/kulinskaya2006/</guid><description>Reference Kulinskaya E, Staudte R G “Interval estimates of weighted effect sizes in the one-way heteroscedastic ANOVA” (2006) // Br. J. Math. Statist. Psychol.. Vol. 59. Pp. 97. DOI: 10.1348/000711005X68174
Bib @Article{kulinskaya2006, title = {Interval estimates of weighted effect sizes in the one-way heteroscedastic ANOVA}, volume = {59}, journal = {Br. J. Math. Statist. Psychol.}, author = {E, Kulinskaya and G, Staudte R}, year = {2006}, pages = {97}, doi = {10.1348/000711005X68174} }</description></item><item><title>Introduction to Empirical Bayes: Examples from Baseball Statistics</title><link>https://aakinshin.net/library/books/robinson-introduction-to-empirical-bayes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/robinson-introduction-to-empirical-bayes/</guid><description/></item><item><title>Introduction to Robust Estimation and Hypothesis Testing</title><link>https://aakinshin.net/library/books/wilcox-introduction-to-robust-estimation-and-hypothesis-testing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/wilcox-introduction-to-robust-estimation-and-hypothesis-testing/</guid><description>The topic of robust statistics claims to be practical. However, the three previous books may look too theoretical. While they discuss how to adapt mathematical tools to bizarre real-life data, they are too focused on the theoretical aspects of the suggested approaches. Sometimes, another reading session of another chapter leaves me in a confusing state. I think: &amp;ldquo;OK, all of this sounds fascinating and marvelous, but how do I solve my particular problem? Which method/approach/estimator/etc should I choose?&amp;rdquo;
At this moment, I open &amp;ldquo;Introduction to Robust Estimation and Hypothesis Testing&amp;rdquo; by Rand R. Wilcox. This is the most practical book about robust statistics. The theoretical part is reduced to the minimum: only the essential equations are presented. Instead of presenting the advanced stuff, references to relevant books and papers are provided. Such a format may be challenging for beginners: the knowledge of theoretical basis significantly simplifies the reading process.
However, if you know the basics, this is a wonderful handbook. It contains a broad overview of robust statistical tools. And it is not just a plain enumeration. For me, the most precious feature of this book is a plethora of small remarks regarding the real-life experience of suggested approaches. What kinds of pitfalls should we expect, what are the corner cases, which estimator is more efficient and when, and so on. The second most precious feature of this book is a set of reference R implementations for almost all the presented methods. If I&amp;rsquo;m curious about the actual behavior of the suggested estimator, I should not spend time implementing it from scratch: I can just take the ready implementation and start my experiments. In most cases, I use this book to get a brief overview of available approaches for the task I am working on.
Conclusion: recommended to engineers who are using robust statistics in real life.</description></item><item><title>Introduction to the New Statistics: Estimation, Open Science, and Beyond</title><link>https://aakinshin.net/library/books/cumming-introduction-to-the-new-statistics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/cumming-introduction-to-the-new-statistics/</guid><description>The second edition was published in 2024. Announcement: Brian Nosek Weighs in on the 2nd Edition of ITNS.</description></item><item><title>Investigating the Probability of Rejecting Null Hypotheses in Abnormal-Social Research</title><link>https://aakinshin.net/library/quotes/fcecf1bc-d282-46ec-b32a-86dc4b053695/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/fcecf1bc-d282-46ec-b32a-86dc4b053695/</guid><description>The results indicate that the investigators contributing to Volume 61 of the Journal of Abnormal and Social Psychology had, on the average, a relatively (or even absolutely) poor chance of rejecting their major null hypotheses, unless the effect they sought was large. This surprising (and discouraging) finding needs some further consideration to be seen in full perspective.
First, it may be noted that with few exceptions, the 70 studies did have significant results. This may then suggest that perhaps the definitions of size of effect were too severe, or perhaps, accepting the definitions, one might seek to conclude that the investigators were operating under circumstances wherein the effects were actually large, hence their success. Perhaps, then, research in the abnormal-social area is not as &amp;ldquo;weak&amp;rdquo; as the above results suggest. But this argument rests on the implicit assumption that the research which is published is representative of the research undertaken in this area. It seems obvious that investigators are less likely to submit for publication unsuccessful than successful research, to say nothing of a similar editorial bias in accepting research for publication. Consider this paradigm: 100 investigations are undertaken in which, in fact, there is actually a medium population effect. From the above findings, about SO get positive results and are likely to come to publication; the other SO fail to reject their (assumed false) null hypotheses and are unlikely to come to publication. Thus, the general success of the articles in the volume under review does not successfully argue for their antecedent probabilities of success being any higher than the results of the analysis suggest, or, equivalently, that the criteria for size of effect used were overly stringent.&amp;quot;</description></item><item><title>Investigation of finite-sample Properties of Robust Location and Scale Estimators</title><link>https://aakinshin.net/library/papers/park2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/park2020/</guid><description>Reference Chanseok Park, Haewon Kim, Min Wang “Investigation of finite-sample properties of robust location and scale estimators” (2020) // Communications in Statistics - Simulation and Computation. Vol. 51. No 5. Pp. 2619–2645. DOI: 10.1080/03610918.2019.1699114
Bib @Article{park2020, title = {Investigation of finite-sample properties of robust location and scale estimators}, volume = {51}, issn = {0361-0918, 1532-4141}, url = {https://www.tandfonline.com/doi/full/10.1080/03610918.2019.1699114}, doi = {10.1080/03610918.2019.1699114}, language = {en}, number = {5}, urldate = {2022-06-23}, journal = {Communications in Statistics - Simulation and Computation}, author = {Park, Chanseok and Kim, Haewon and Wang, Min}, year = {2020}, pages = {2619--2645} }</description></item><item><title>Joint P and E Usage</title><link>https://aakinshin.net/library/quotes/80ed236b-ff1e-4214-9995-6e5f12948167/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/80ed236b-ff1e-4214-9995-6e5f12948167/</guid><description>Consider the P value and the E value jointly; if the P value is small and the E value is substantial, then a real effect is obtained.</description></item><item><title>Justify Your Alpha</title><link>https://aakinshin.net/library/papers/lakens2018/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/lakens2018/</guid><description>Reference Daniel Lakens, Federico G Adolfi, Casper J Albers, Farid Anvari, Matthew A J Apps, Shlomo E Argamon, Thom Baguley, Raymond B Becker, Stephen D Benning, Daniel E Bradford, Erin M Buchanan, Aaron R Caldwell, Ben Van Calster, Rickard Carlsson, Sau-Chin Chen, Bryan Chung, Lincoln J Colling, Gary S Collins, Zander Crook, Emily S Cross, Sameera Daniels, Henrik Danielsson, Lisa DeBruine, Daniel J Dunleavy, Brian D Earp, Michele I Feist, Jason D Ferrell, James G Field, Nicholas W Fox, Amanda Friesen, Caio Gomes, Monica Gonzalez-Marquez, James A Grange, Andrew P Grieve, Robert Guggenberger, James Grist, Anne-Laura van Harmelen, Fred Hasselman, Kevin D Hochard, Mark R Hoffarth, Nicholas P Holmes, Michael Ingre, Peder M Isager, Hanna K Isotalus, Christer Johansson, Konrad Juszczyk, David A Kenny, Ahmed A Khalil, Barbara Konat, Junpeng Lao, Erik Gahner Larsen, Gerine M A Lodder, Jiří Lukavský, Christopher R Madan, David Manheim, Stephen R Martin, Andrea E Martin, Deborah G Mayo, Randy J McCarthy, Kevin McConway, Colin McFarland, Amanda Q X Nio, Gustav Nilsonne, Cilene Lino de Oliveira, Jean-Jacques Orban de Xivry, Sam Parsons, Gerit Pfuhl, Kimberly A Quinn, John J Sakon, S Adil Saribay, Iris K Schneider, Manojkumar Selvaraju, Zsuzsika Sjoerds, Samuel G Smith, Tim Smits, Jeffrey R Spies, Vishnu Sreekumar, Crystal N Steltenpohl, Neil Stenhouse, Wojciech Świątkowski, Miguel A Vadillo, Marcel A L M Van Assen, Matt N Williams, Samantha E Williams, Donald R Williams, Tal Yarkoni, Ignazio Ziano, Rolf A Zwaan “Justify your alpha” (2018) // Nature Human Behaviour. Vol. 2. No 3. Pp. 168–171. DOI: 10.1038/s41562-018-0311-x
Abstract In response to recommendations to redefine statistical significance to P ≤ 0.005, we propose that researchers should transparently report and justify all choices they make when designing a study, including the alpha level.
Bib @Article{lakens2018, title = {Justify your alpha}, volume = {2}, copyright = {2018 The Publisher}, issn = {2397-3374}, url = {https://www.</description></item><item><title>Kernel Density Estimation Using Weighted Data</title><link>https://aakinshin.net/library/papers/guillamon1998/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/guillamon1998/</guid><description>Reference A Guillamon, J Navarro, JM Ruiz “Kernel density estimation using weighted data” (1998) // Communications in Statistics - Theory and Methods. Publisher: Informa UK Limited. Vol. 27. No 9. Pp. 2123–2135. DOI: 10.1080/03610929808832217
Bib @Article{guillamon1998, doi = {10.1080/03610929808832217}, year = {1998}, month = {jan}, publisher = {Informa UK Limited}, volume = {27}, number = {9}, pages = {2123--2135}, author = {Guillamon, A and Navarro, J and Ruiz, JM}, title = {Kernel density estimation using weighted data}, journal = {Communications in Statistics - Theory and Methods} }</description></item><item><title>Laeken: Estimation of Indicators on Social Exclusion and Poverty</title><link>https://aakinshin.net/library/papers/alfons2021/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/alfons2021/</guid><description>Reference Andreas Alfons, Josef Holzer, Matthias Templ, Alexander Haider “laeken: Estimation of Indicators on Social Exclusion and Poverty” (2021)
Bib @Manual{alfons2021, title = {laeken: Estimation of Indicators on Social Exclusion and Poverty}, author = {Andreas Alfons and Josef Holzer and Matthias Templ and Alexander Haider}, year = {2021}, note = {R package version 0.5.2}, url = {https://cran.r-project.org/web/packages/laeken/index.html} }</description></item><item><title>Look Elsewhere Effect in Physics</title><link>https://aakinshin.net/library/quotes/ce332bef-224c-42b5-8235-9a412e36de23/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/ce332bef-224c-42b5-8235-9a412e36de23/</guid><description>When searching for a new resonance somewhere in a possible mass range, the significance of observing a local excess of events must take into account the probability of observing such an excess anywhere in the range. This is the so called “look elsewhere effect”. The effect can be quantified in terms of a trial factor, which is the ratio between the probability of observing the excess at some fixed mass point, to the probability of observing it anywhere in the range.</description></item><item><title>Low Statistical Power</title><link>https://aakinshin.net/library/quotes/982229dc-9c49-4800-8039-c08ca40858e3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/982229dc-9c49-4800-8039-c08ca40858e3/</guid><description>Objective. To describe the pattern over time in the level of statistical power and the reporting of sample size calculations in published randomized controlled trials (RCTs) with negative results.
Design. Ourstudy was a descriptive survey. Power to detect 25% and 50% relative differences was calculated for the subset of trials with negative results in which a simple two-group parallel design was used. Criteria were developed both to classify trial results as positive or negative and to identify the primary outcomes. Power calculations were based on results from the primary outcomes reported in the trials.
Population. We reviewed all 383 RCTs published in JAMA, Lancet, and the New England Journal of Medicine in 1975, 1980, 1985, and 1990.
Results. Twenty-sevenpercent of the 383 RCTs (n=102) were classified as having negative results. The number of published RCTs more than doubled from 1975 to 1990, with the proportion of trials with negative results remaining fairly stable. Of the simple two-group parallel design trials having negative results with dichotomous or continuous primary outcomes (n=70), only 16% and 36% had sufficient statistical power (80%) to detect a 25% or 50% relative difference, respectively. These percentages did not consistently increase overtime. Overall, only 32% of the trials with negative results reported sample size calculations, but the percentage doing so has improved over time from 0% in 1975 to 43% in 1990. Only 20 of the 102 reports made any statement related to the clinical significance of the observed differences.
Conclusions. Most trials with negative results did not have large enough sample sizes to detect a 25% or a 50% relative difference. This result has not changed over time. Few trials discussed whether the observed differences were clinically important. There are important reasons to change this practice. The reporting of statistical power and sample size also needs to be improved.</description></item><item><title>Magnitude of Effects in Clinical Trials Published in high-impact General Medical Journals</title><link>https://aakinshin.net/library/papers/siontis2011/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/siontis2011/</guid><description>Reference Konstantinos CM Siontis, Evangelos Evangelou, John PA Ioannidis “Magnitude of effects in clinical trials published in high-impact general medical journals” (2011) // International Journal of Epidemiology. Publisher: Oxford University Press (OUP). Vol. 40. No 5. Pp. 1280–1291. DOI: 10.1093/ije/dyr095
Bib @Article{siontis2011, title = {Magnitude of effects in clinical trials published in high-impact general medical journals}, volume = {40}, issn = {0300-5771}, url = {http://dx.doi.org/10.1093/ije/dyr095}, doi = {10.1093/ije/dyr095}, number = {5}, journal = {International Journal of Epidemiology}, publisher = {Oxford University Press (OUP)}, author = {Siontis, Konstantinos CM and Evangelou, Evangelos and Ioannidis, John PA}, year = {2011}, month = {sep}, pages = {1280–1291} }</description></item><item><title>Making the Study Positive</title><link>https://aakinshin.net/library/quotes/613be7e4-c3fd-405a-be24-1874a4c93a26/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/613be7e4-c3fd-405a-be24-1874a4c93a26/</guid><description>Believing there is a difference between groups, a well-intentioned clinician researcher addresses unexpected values. We tested how much removal, remeasurement, or reclassification of patients would be needed in most cases to turn an otherwise-neutral study positive. Remeasurement of 19 patients out of 200 per group was required to make most studies positive. Removal was more powerful: just 9 out of 200 was enough. Reclassification was most powerful, with 5 out of 200 enough. The larger the study, the smaller the proportion of patients needing to be manipulated to make the study positive: the percentages needed to be remeasured, removed, or reclassified fell from 45%, 20%, and 10% respectively for a 20 patient-per-group study, to 4%, 2%, and 1% for an 800 patient-per-group study. Dot-plots, but not bar-charts, make the perhaps-inadvertent manipulations visible.</description></item><item><title>Mann-Whitney Test is Not Just a Test of medians: Differences in Spread Can Be Important</title><link>https://aakinshin.net/library/papers/hart2001/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/hart2001/</guid><description>Reference A Hart “Mann-Whitney test is not just a test of medians: differences in spread can be important” (2001) // BMJ. Vol. 323. No 7309. Pp. 391–393. DOI: 10.1136/bmj.323.7309.391
Bib @Article{hart2001, title = {Mann-Whitney test is not just a test of medians: differences in spread can be important}, volume = {323}, issn = {09598138}, shorttitle = {Mann-Whitney test is not just a test of medians}, url = {https://www.bmj.com/lookup/doi/10.1136/bmj.323.7309.391}, doi = {10.1136/bmj.323.7309.391}, number = {7309}, urldate = {2023-10-22}, journal = {BMJ}, author = {Hart, A}, month = {aug}, year = {2001}, pages = {391--393} }</description></item><item><title>Mann–Whitney U Test When Variances Are Unequal</title><link>https://aakinshin.net/library/papers/kasuya2001/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/kasuya2001/</guid><description>Reference Eiiti Kasuya “Mann–Whitney U test when variances are unequal” (2001) // Animal Behaviour. Vol. 61. No 6. Pp. 1247–1249. DOI: 10.1006/anbe.2001.1691
Bib @Article{kasuya2001, title = {Mann–Whitney U test when variances are unequal}, volume = {61}, issn = {00033472}, url = {https://linkinghub.elsevier.com/retrieve/pii/S0003347201916914}, doi = {10.1006/anbe.2001.1691}, language = {en}, number = {6}, urldate = {2023-10-22}, journal = {Animal Behaviour}, author = {Kasuya, Eiiti}, month = {jun}, year = {2001}, pages = {1247--1249} }</description></item><item><title>matrixStats: Functions that Apply to Rows and Columns of Matrices (and to Vectors)</title><link>https://aakinshin.net/library/papers/bengtsson2022/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/bengtsson2022/</guid><description>Reference Henrik Bengtsson, others “matrixStats: Functions that Apply to Rows and Columns of Matrices (and to Vectors)” (2022)
Bib @Manual{bengtsson2022, title = {matrixStats: Functions that Apply to Rows and Columns of Matrices (and to Vectors)}, author = {Henrik Bengtsson and others}, year = {2022}, note = {R package version 0.62.0}, url = {https://cran.r-project.org/web/packages/matrixStats/index.html} }</description></item><item><title>Measuring Effect size: A Robust Heteroscedastic Approach for Two or More Groups</title><link>https://aakinshin.net/library/papers/wilcox2011/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/wilcox2011/</guid><description>Reference Wilcox R R, Tian T S “Measuring effect size: A robust heteroscedastic approach for two or more groups” (2011) // J. Appl. Stat.. Vol. 38. Pp. 1359. DOI: 10.1080/02664763.2010.498507
Bib @Article{wilcox2011, title = {Measuring effect size: A robust heteroscedastic approach for two or more groups}, volume = {38}, journal = {J. Appl. Stat.}, author = {R, Wilcox R and S, Tian T}, year = {2011}, pages = {1359}, doi = {10.1080/02664763.2010.498507} }</description></item><item><title>Measuring the Prevalence of Questionable Research Practices with Incentives for Truth Telling</title><link>https://aakinshin.net/library/papers/john2012/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/john2012/</guid><description>Reference Leslie K John, George Loewenstein, Drazen Prelec “Measuring the Prevalence of Questionable Research Practices With Incentives for Truth Telling” (2012) // Psychological Science. Publisher: SAGE Publications. Vol. 23. No 5. Pp. 524–532. DOI: 10.1177/0956797611430953
Bib @Article{john2012, title = {Measuring the Prevalence of Questionable Research Practices With Incentives for Truth Telling}, volume = {23}, issn = {1467-9280}, url = {http://dx.doi.org/10.1177/0956797611430953}, doi = {10.1177/0956797611430953}, number = {5}, journal = {Psychological Science}, publisher = {SAGE Publications}, author = {John, Leslie K and Loewenstein, George and Prelec, Drazen}, year = {2012}, month = {apr}, pages = {524–532} }</description></item><item><title>Medicine residents' Understanding of the Biostatistics and Results in the Medical Literature</title><link>https://aakinshin.net/library/papers/windish2007/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/windish2007/</guid><description>Reference Donna M Windish, Stephen J Huot, Michael L Green “Medicine residents&amp;rsquo; understanding of the biostatistics and results in the medical literature” (2007) // Jama. Publisher: American Medical Association. Vol. 298. No 9. Pp. 1010–1022. DOI: 10.1001/jama.298.9.1010
Bib @Article{windish2007, title = {Medicine residents&amp;#39; understanding of the biostatistics and results in the medical literature}, author = {Windish, Donna M and Huot, Stephen J and Green, Michael L}, journal = {Jama}, volume = {298}, number = {9}, pages = {1010--1022}, year = {2007}, publisher = {American Medical Association}, doi = {10.1001/jama.298.9.1010} }</description></item><item><title>Menstrual Synchrony and Suppression</title><link>https://aakinshin.net/library/papers/mcclintock1971/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/mcclintock1971/</guid><description>Critisism:
Critique of McClintock&amp;#39;s Study of Human Menstrual Cycles wilson1992 yang2006 Reference Martha K McClintock “Menstrual Synchrony and Suppression” (1971) // Nature. Publisher: Springer Science and Business Media LLC. Vol. 229. No 5282. Pp. 244–245. DOI: 10.1038/229244a0
Bib @Article{mcclintock1971, title = {Menstrual Synchrony and Suppression}, volume = {229}, issn = {1476-4687}, url = {http://dx.doi.org/10.1038/229244a0}, doi = {10.1038/229244a0}, number = {5282}, journal = {Nature}, publisher = {Springer Science and Business Media LLC}, author = {Martha K McClintock}, year = {1971}, month = {jan}, pages = {244–245} }</description></item><item><title>MetricsWeighted: Weighted Metrics, Scoring Functions and Performance Measures for Machine Learning</title><link>https://aakinshin.net/library/papers/mayer2022/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/mayer2022/</guid><description>Reference Michael Mayer, Christian Lorentzen “MetricsWeighted: Weighted Metrics, Scoring Functions and Performance Measures for Machine Learning” (2022)
Bib @Manual{mayer2022, title = {MetricsWeighted: Weighted Metrics, Scoring Functions and Performance Measures for Machine Learning}, author = {Michael Mayer and Christian Lorentzen}, year = {2022}, note = {R package version 0.5.4}, url = {https://cran.r-project.org/web/packages/MetricsWeighted/index.html} }</description></item><item><title>Mindless Statistics</title><link>https://aakinshin.net/library/papers/gigerenzer2004/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/gigerenzer2004/</guid><description>Reference Gerd Gigerenzer “Mindless statistics” (2004) // The Journal of Socio-Economics. Vol. 33. No 5. Pp. 587–606. DOI: 10.1016/j.socec.2004.09.033
Bib @Article{gigerenzer2004, title = {Mindless statistics}, volume = {33}, issn = {10535357}, url = {https://linkinghub.elsevier.com/retrieve/pii/S1053535704000927}, doi = {10.1016/j.socec.2004.09.033}, language = {en}, number = {5}, urldate = {2020-01-07}, journal = {The Journal of Socio-Economics}, author = {Gigerenzer, Gerd}, month = {nov}, year = {2004}, note = {ZSCC: 0000819}, pages = {587--606} }</description></item><item><title>Misunderstanding of Confidence Intervals and Standard Error Bars</title><link>https://aakinshin.net/library/quotes/22a80e19-4456-4510-8a14-7415b537a7da/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/22a80e19-4456-4510-8a14-7415b537a7da/</guid><description>Little is known about researchers’ understanding of confidence intervals (CIs) and standard error (SE) bars. Authors of journal articles in psychology, behavioral neuroscience, and medicine were invited to visit a Web site where they adjusted a figure until they judged 2 means, with error bars, to be just statistically significantly different (p &amp;lt; .05). Results from 473 respondents suggest that many leading researchers have severe misconceptions about how error bars relate to statistical significance, do not adequately distinguish CIs and SE bars, and do not appreciate the importance of whether the 2 means are independent or come from a repeated measures design. Better guidelines for researchers and less ambiguous graphical conventions are needed before the advantages of CIs for research communication can be realized.</description></item><item><title>Modi: Multivariate Outlier Detection and Imputation for Incomplete Survey Data</title><link>https://aakinshin.net/library/papers/hulliger2018/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/hulliger2018/</guid><description>Reference Beat Hulliger “modi: Multivariate outlier detection and imputation for incomplete survey data” (2018)
Bib @Manual{hulliger2018, title = {modi: Multivariate outlier detection and imputation for incomplete survey data}, author = {Beat Hulliger}, year = {2018}, note = {R package version 0.1.0}, url = {https://cran.r-project.org/web/packages/modi/index.html} }</description></item><item><title>Modified Kolmogorov–Smirnov Test Procedures with Applications to Arbitrarily right-censored Data</title><link>https://aakinshin.net/library/papers/fleming1980/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/fleming1980/</guid><description>Reference Fleming T R, O&amp;rsquo;Fallon J R, O’ Brien P C, Harrington D P “Modified Kolmogorov–Smirnov test procedures with applications to arbitrarily right-censored data” (1980) // Biometrics. Vol. 36. Pp. 607. DOI: 10.2307/2556114
Bib @Article{fleming1980, title = {Modified Kolmogorov–Smirnov test procedures with applications to arbitrarily right-censored data}, volume = {36}, journal = {Biometrics}, author = {R, Fleming T and R, O&amp;#39;Fallon J and C, O’ Brien P and P, Harrington D}, year = {1980}, pages = {607}, doi = {10.2307/2556114} }</description></item><item><title>Monte Carlo Methods</title><link>https://aakinshin.net/library/quotes/cdce4d2e-fb19-44fb-997f-4d1981e471a2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/cdce4d2e-fb19-44fb-997f-4d1981e471a2/</guid><description>Monte Carlo is an extremely bad method; it should only be used when all alternative methods are worse.</description></item><item><title>Monte Carlo Methods in Statistical mechanics: Foundations and New Algorithms</title><link>https://aakinshin.net/library/papers/sokal1997/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/sokal1997/</guid><description>Reference Alan Sokal “Monte Carlo methods in statistical mechanics: foundations and new algorithms” (1997) // Functional integration: Basics and applications. Publisher: Springer. Pp. 131–192. DOI: 10.1007/978-1-4899-0319-8_6
Bib @Incollection{sokal1997, title = {Monte Carlo methods in statistical mechanics: foundations and new algorithms}, author = {Sokal, Alan}, booktitle = {Functional integration: Basics and applications}, url = {https://citeseerx.ist.psu.edu/document?repid=rep1&amp;amp;type=pdf&amp;amp;doi=0bfe9e3db30605fe2d4d26e1a288a5e2997e7225}, doi = {10.1007/978-1-4899-0319-8_6}, pages = {131--192}, year = {1997}, publisher = {Springer} }</description></item><item><title>Moving to a World Beyond “p&lt;0.05”</title><link>https://aakinshin.net/library/papers/wasserstein2019/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/wasserstein2019/</guid><description>Reference Ronald L Wasserstein, Allen L Schirm, Nicole A Lazar “Moving to a World Beyond “p\textless0.05”” (2019) // The American Statistician. Vol. 73. No sup1. Pp. 1–19. DOI: 10.1080/00031305.2019.1583913
Bib @Article{wasserstein2019, title = {Moving to a World Beyond “p\textless0.05”}, volume = {73}, issn = {0003-1305, 1537-2731}, url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2019.1583913}, doi = {10.1080/00031305.2019.1583913}, language = {en}, number = {sup1}, urldate = {2020-01-07}, journal = {The American Statistician}, author = {Wasserstein, Ronald L and Schirm, Allen L and Lazar, Nicole A}, month = {mar}, year = {2019}, note = {ZSCC: NoCitationData[s0]}, pages = {1--19} }</description></item><item><title>Moving Towards the Post p&lt;0.05 Era via the Analysis of Credibility</title><link>https://aakinshin.net/library/papers/matthews2019/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/matthews2019/</guid><description>Reference Robert A J Matthews “Moving Towards the Post p\textless0.05 Era via the Analysis of Credibility” (2019) // The American Statistician. Vol. 73. No sup1. Pp. 202–212. DOI: 10.1080/00031305.2018.1543136
Bib @Article{matthews2019, title = {Moving Towards the Post p\textless0.05 Era via the Analysis of Credibility}, volume = {73}, issn = {0003-1305, 1537-2731}, url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1543136}, doi = {10.1080/00031305.2018.1543136}, language = {en}, number = {sup1}, urldate = {2020-01-07}, journal = {The American Statistician}, author = {Matthews, Robert A J}, month = {mar}, year = {2019}, note = {ZSCC: 0000014}, pages = {202--212} }</description></item><item><title>Neural Correlates of Interspecies Perspective Taking in the post-mortem Atlantic Salmon: An Argument for Multiple Comparisons Correction</title><link>https://aakinshin.net/library/papers/bennett2009/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/bennett2009/</guid><description>One of my favorite examples of statistics misuse.
Reference Craig M Bennett, Michael B Miller, George L Wolford “Neural correlates of interspecies perspective taking in the post-mortem Atlantic Salmon: an argument for multiple comparisons correction” (2009) // NeuroImage. Publisher: Elsevier BV. Vol. 47. Pp. S125. DOI: 10.1016/s1053-8119(09)71202-9
Bib @Article{bennett2009, title = {Neural correlates of interspecies perspective taking in the post-mortem Atlantic Salmon: an argument for multiple comparisons correction}, volume = {47}, issn = {1053-8119}, url = {http://dx.doi.org/10.1016/S1053-8119(09)71202-9}, doi = {10.1016/s1053-8119(09)71202-9}, journal = {NeuroImage}, publisher = {Elsevier BV}, author = {Bennett, Craig M and Miller, Michael B and Wolford, George L}, year = {2009}, month = {jul}, pages = {S125} }</description></item><item><title>Neyman-Pearson vs. Fisher</title><link>https://aakinshin.net/library/quotes/e9011bc6-0eaf-4e76-8090-0331bd513617/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/e9011bc6-0eaf-4e76-8090-0331bd513617/</guid><description>It is not generally appreciated that the p value, as conceived by R. A. Fisher, is not compatible with the Neyman-Pearson hypothesis test in which it has become embedded. The p value was meant to be a flexible inferential measure, whereas the hypothesis test was a rule for behavior, not inference. The combination of the two methods has led to a reinterpretation of the p value simultaneously as an &amp;ldquo;observed error rate&amp;rdquo; and as a measure of evidence. Both of these interpretations are problematic, and their combination has obscured the important differences between Neyman and Fisher on the nature of the scientific method and inhibited our understanding of the philosophic implications of the basic methods in use today. An analysis using another method promoted by Fisher, mathematical likelihood, shows that the p value substantially overstates the evidence against the null hypothesis. Likelihood makes clearer the distinction between error rates and inferential evidence and is a quantitative tool for expressing evidential strength that is more appropriate for the purposes of epidemiology than the p value.</description></item><item><title>Neyman–pearson vs. Fisher</title><link>https://aakinshin.net/library/quotes/510b2ea5-0e1c-4aa9-8e13-28240daf157a/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/510b2ea5-0e1c-4aa9-8e13-28240daf157a/</guid><description>Confusion surrounding the reporting and interpretation of results of classical statistical tests is widespread among applied researchers, most of whom erroneously believe that such tests are prescribed by a single coherent theory of statistical inference. This is not the case: Classical statistical testing is an anonymous hybrid of the competing and frequently contradictory approaches formulated by R. A. Fisher on the one hand, and Jerzy Neyman and Egon Pearson on the other. In particular, there is a widespread failure to appreciate the incompatibility of Fisher’s evidential p value with the Type I error rate, α, of Neyman–Pearson statistical orthodoxy. The distinction between evidence (p’s) and error (α ’s) is not trivial. Instead, it reflects the fundamental differences between Fisher’s ideas on significance testing and inductive inference, and Neyman–Pearson’s views on hypothesis testing and inductive behavior. The emphasis of the article is to expose this incompatibility, but we also briefly note a possible reconciliation.</description></item><item><title>NHST</title><link>https://aakinshin.net/library/quotes/0dff54f2-c974-483a-a6b6-81eb944d4882/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/0dff54f2-c974-483a-a6b6-81eb944d4882/</guid><description>What&amp;rsquo;s wrong with NHST? Well, among many other things, it does not tell us what we want to know, and we so much want to know what we want to know that, out of desperation, we nevertheless believe that it does!</description></item><item><title>NHST</title><link>https://aakinshin.net/library/quotes/f75b2f1f-b183-45f5-a015-f0cf16344a19/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/f75b2f1f-b183-45f5-a015-f0cf16344a19/</guid><description>We are inclined to think that as far as a particular hypothesis is concerned, no test based upon the theory of probability can by itself provide any valuable evidence of the truth or falsehood of that hypothesis.
But we may look at the purpose of tests from another view-point. Without hoping to know whether each separate hypothesis is true or false, we may search for rules to govern our behaviour with regard to them, in following which we insure that, in the long run of experience, we shall not be too often wrong.</description></item><item><title>Nonlinear Dynamics and chaos: With Applications to physics, Biology, Chemistry, and Engineering</title><link>https://aakinshin.net/library/papers/strogatz2015/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/strogatz2015/</guid><description>Reference Steven H Strogatz “Nonlinear dynamics and chaos: with applications to physics, biology, chemistry, and engineering” (2015) // Publisher: Westview Press, a member of the Perseus Books Group. Boulder, CO. ISBN: 978-0-8133-4910-7.
Bib @Book{strogatz2015, address = {Boulder, CO}, edition = {Second edition}, title = {Nonlinear dynamics and chaos: with applications to physics, biology, chemistry, and engineering}, isbn = {978-0-8133-4910-7}, shorttitle = {Nonlinear dynamics and chaos}, publisher = {Westview Press, a member of the Perseus Books Group}, author = {Strogatz, Steven H}, year = {2015}, note = {OCLC: ocn842877119}, keywords = {Chaotic behavior in systems, Dynamics, Nonlinear theories} }</description></item><item><title>Nonparametric Estimation of Global Functionals and a Measure of the Explanatory Power of Covariates in Regression</title><link>https://aakinshin.net/library/papers/doksum1995/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/doksum1995/</guid><description>Reference Doksum K A, Samarov A “Nonparametric estimation of global functionals and a measure of the explanatory power of covariates in regression” (1995) // Ann. Statist.. Vol. 23. Pp. 1443.
Bib @Article{doksum1995, title = {Nonparametric estimation of global functionals and a measure of the explanatory power of covariates in regression}, volume = {23}, journal = {Ann. Statist.}, author = {A, Doksum K and A, Samarov}, year = {1995}, pages = {1443}, custom-url-pdf = {https://projecteuclid.org/journalArticle/Download?urlId=10.1214%2Faos%2F1176324307} }</description></item><item><title>Nonparametric Estimation of Ratio of Scale Parameters</title><link>https://aakinshin.net/library/papers/bhattacharyya1977/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/bhattacharyya1977/</guid><description>Reference Helen T Bhattacharyya “Nonparametric Estimation of Ratio of Scale Parameters” (1977) // Journal of the American Statistical Association. Vol. 72. No 358. Pp. 459–463. DOI: 10.1080/01621459.1977.10481021
Bib @Article{bhattacharyya1977, title = {Nonparametric Estimation of Ratio of Scale Parameters}, volume = {72}, issn = {0162-1459, 1537-274X}, url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1977.10481021}, doi = {10.1080/01621459.1977.10481021}, language = {en}, number = {358}, urldate = {2023-12-10}, journal = {Journal of the American Statistical Association}, author = {Bhattacharyya, Helen T}, month = {jun}, year = {1977}, pages = {459--463} }</description></item><item><title>Nonparametric Statistical Inference</title><link>https://aakinshin.net/library/papers/gibbons2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/gibbons2020/</guid><description>Reference Jean Dickinson Gibbons, Subhabrata Chakraborti “Nonparametric statistical inference” (2020) // Publisher: CRC press. ISBN: 9781138087446. DOI: 10.1201/9781315110479
Bib @Book{gibbons2020, title = {Nonparametric statistical inference}, author = {Gibbons, Jean Dickinson and Chakraborti, Subhabrata}, year = {2020}, ed = {6}, publisher = {CRC press}, isbn = {9781138087446}, doi = {10.1201/9781315110479} }</description></item><item><title>Nonparametric Statistical tests: A Computational Approach</title><link>https://aakinshin.net/library/papers/neuh%C3%A4user2012/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/neuh%C3%A4user2012/</guid><description>Reference Markus Neuhäuser “Nonparametric statistical tests: a computational approach” (2012) // Publisher: CRC Press. Boca Raton, Fla.. ISBN: 978-1-138-11410-4 978-1-4398-6703-7.
Bib @Book{neuhäuser2012, address = {Boca Raton, Fla.}, series = {A Chapman \&amp;amp; Hall Book}, title = {Nonparametric statistical tests: a computational approach}, isbn = {978-1-138-11410-4 978-1-4398-6703-7}, shorttitle = {Nonparametric statistical tests}, language = {eng}, publisher = {CRC Press}, author = {Neuhäuser, Markus}, year = {2012} }</description></item><item><title>Nonparametric statistics: Theory and Methods</title><link>https://aakinshin.net/library/papers/deshpande2018/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/deshpande2018/</guid><description>Reference J V Deshpande, Uttara Naik-Nimbalkar, Isha Dewan “Nonparametric statistics: theory and methods” (2018) // Publisher: World Scientific. New Jersey. ISBN: 978-981-4663-57-1.
Bib @Book{deshpande2018, address = {New Jersey}, title = {Nonparametric statistics: theory and methods}, isbn = {978-981-4663-57-1}, shorttitle = {Nonparametric statistics}, publisher = {World Scientific}, author = {Deshpande, J V and Naik-Nimbalkar, Uttara and Dewan, Isha}, year = {2018}, keywords = {Distribution (Probability theory), Nonparametric statistics} }</description></item><item><title>Nonparametrics: Statistical Methods Based on Ranks</title><link>https://aakinshin.net/library/papers/lehmann1975/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/lehmann1975/</guid><description>Reference Erich L Lehmann, H J M D&amp;rsquo;Abrera “Nonparametrics: statistical methods based on ranks” (1975) // Publisher: Holden-Day [u.a.]. San Francisco. ISBN: 978-0-07-037073-9.
Bib @Book{lehmann1975, address = {San Francisco}, series = {Holden-Day series in probability and statistics}, title = {Nonparametrics: statistical methods based on ranks}, isbn = {978-0-07-037073-9}, shorttitle = {Nonparametrics}, language = {eng}, publisher = {Holden-Day [u.a.]}, author = {Lehmann, Erich L and D&amp;#39;Abrera, H J M}, year = {1975} }</description></item><item><title>Null Hypothesis Significance Testing on the Survival of a Flawed Method</title><link>https://aakinshin.net/library/papers/krueger2001/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/krueger2001/</guid><description>Reference Krueger J “Null hypothesis significance testing on the survival of a flawed method” (2001) // Am. Psychol.. Vol. 56. Pp. 16. DOI: 10.1037/0003-066x.56.1.16
Bib @Article{krueger2001, title = {Null hypothesis significance testing on the survival of a flawed method}, volume = {56}, journal = {Am. Psychol.}, author = {J, Krueger}, year = {2001}, pages = {16}, doi = {10.1037/0003-066x.56.1.16}, custom-url-pdf = {http://files.clps.brown.edu/jkrueger/journal_articles/krueger-2001-null.pdf} }</description></item><item><title>Observations Weighted According to Order</title><link>https://aakinshin.net/library/papers/daniell1920/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/daniell1920/</guid><description>Reference PJ Daniell “Observations weighted according to order” (1920) // American Journal of Mathematics. Publisher: JSTOR. Vol. 42. No 4. Pp. 222–236. DOI: 10.2307/2370465
Bib @Article{daniell1920, title = {Observations weighted according to order}, author = {Daniell, PJ}, journal = {American Journal of Mathematics}, volume = {42}, number = {4}, pages = {222--236}, year = {1920}, publisher = {JSTOR}, doi = {10.2307/2370465} }</description></item><item><title>Of beauty, Sex, and power: Statistical Challenges in Estimating Small Effects</title><link>https://aakinshin.net/library/papers/gelman2009/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/gelman2009/</guid><description>Reference A Gelman, D Weakliem “Of beauty, sex, and power: statistical challenges in estimating small effects” (2009) // American Scientist. Publisher: Sigma Xi. Vol. 97. No 4. Pp. 310. DOI: 10.1511/2009.79.310
Bib @Article{gelman2009, title = {Of beauty, sex, and power: statistical challenges in estimating small effects}, volume = {97}, issn = {1545-2786}, url = {http://dx.doi.org/10.1511/2009.79.310}, doi = {10.1511/2009.79.310}, number = {4}, journal = {American Scientist}, publisher = {Sigma Xi}, author = {A Gelman and D Weakliem}, year = {2009}, pages = {310}, custom-url-pdf = {http://www.stat.columbia.edu/~gelman/research/unpublished/power.pdf} }</description></item><item><title>On a Simple Measure of Dominance</title><link>https://aakinshin.net/library/papers/anderson2009/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/anderson2009/</guid><description>Reference Anderson C L, Berry J C “On a simple measure of dominance” (2009) // J. Statist. Plann. Inference. Vol. 139. Pp. 1098. DOI: 10.1016/j.jspi.2008.07.001
Bib @Article{anderson2009, title = {On a simple measure of dominance}, volume = {139}, journal = {J. Statist. Plann. Inference}, author = {L, Anderson C and C, Berry J}, year = {2009}, pages = {1098}, doi = {10.1016/j.jspi.2008.07.001} }</description></item><item><title>On a Test of Whether One of Two Random Variables is Stochastically Larger Than the Other</title><link>https://aakinshin.net/library/papers/mann1947/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/mann1947/</guid><description>Reference H B Mann, D R Whitney “On a Test of Whether one of Two Random Variables is Stochastically Larger than the Other” (1947) // The Annals of Mathematical Statistics. Vol. 18. No 1. Pp. 50–60. DOI: 10.1214/aoms/1177730491
Bib @Article{mann1947, title = {On a Test of Whether one of Two Random Variables is Stochastically Larger than the Other}, volume = {18}, issn = {0003-4851}, url = {http://projecteuclid.org/euclid.aoms/1177730491}, doi = {10.1214/aoms/1177730491}, language = {en}, number = {1}, urldate = {2023-10-22}, journal = {The Annals of Mathematical Statistics}, author = {Mann, H B and Whitney, D R}, month = {mar}, year = {1947}, pages = {50--60} }</description></item><item><title>On Judging the Significance of Differences by Examining the Overlap Between Confidence Intervals</title><link>https://aakinshin.net/library/papers/schenker2001/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/schenker2001/</guid><description>Reference Nathaniel Schenker, Jane F Gentleman “On Judging the Significance of Differences by Examining the Overlap Between Confidence Intervals” (2001) // The American Statistician. Publisher: Informa UK Limited. Vol. 55. No 3. Pp. 182–186. DOI: 10.1198/000313001317097960
Abstract To judge whether the difference between two point estimates is statistically significant, data analysts often examine the overlap between the two associated con dence intervals. We compare this technique to the standard method of testing signi cance under the common assumptions of consistency, asymptotic normality, and asymptoticindependenceof the estimates. Rejection of the null hypothesis by the method of examining overlap implies rejection by the standard method, whereas failure to reject by the method of examining overlap does not imply failure to reject by the standard method. As a consequence, the method of examining overlap is more conservative (i.e., rejects the null hypothesis less often) than the standard method when the null hypothesis is true, and it mistakenly fails to reject the null hypothesis more frequently than does the standard method when the null hypothesis is false. Although the method of examining overlap is simple and especially convenient when lists or graphs of confidence intervals have been presented, we conclude that it should not be used for formal significance testing unless the data analyst is aware of its deficiencies and unless the information needed to carry out a more appropriate procedure is unavailable.
Bib @Article{schenker2001, title = {On Judging the Significance of Differences by Examining the Overlap Between Confidence Intervals}, abstract = {To judge whether the difference between two point estimates is statistically significant, data analysts often examine the overlap between the two associated con dence intervals. We compare this technique to the standard method of testing signi cance under the common assumptions of consistency, asymptotic normality, and asymptoticindependenceof the estimates. Rejection of the null hypothesis by the method of examining overlap implies rejection by the standard method, whereas failure to reject by the method of examining overlap does not imply failure to reject by the standard method.</description></item><item><title>On Robust Procedures</title><link>https://aakinshin.net/library/papers/gastwirth1966/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/gastwirth1966/</guid><description>Reference Joseph L Gastwirth “On Robust Procedures” (1966) // Journal of the American Statistical Association. Publisher: Taylor &amp;amp; Francis. Vol. 61. No 316. Pp. 929-948. DOI: 10.1080/01621459.1966.10482185
Bib @Article{gastwirth1966, author = {Joseph L Gastwirth}, title = {On Robust Procedures}, journal = {Journal of the American Statistical Association}, volume = {61}, number = {316}, pages = {929-948}, year = {1966}, publisher = {Taylor &amp;amp; Francis}, doi = {10.1080/01621459.1966.10482185} }</description></item><item><title>On Some Non Parametric Estimators of the Quantile Density Function for a Stationary Associated Process</title><link>https://aakinshin.net/library/papers/chaubey2023/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/chaubey2023/</guid><description>Reference Yogendra P Chaubey, Isha Dewan, Jun Li “On some non parametric estimators of the quantile density function for a stationary associated process” (2023) // Communications in Statistics - Theory and Methods. Publisher: Informa UK Limited. Pp. 1–21. DOI: 10.1080/03610926.2023.2222922
Bib @Article{chaubey2023, title = {On some non parametric estimators of the quantile density function for a stationary associated process}, issn = {1532-415X}, url = {http://dx.doi.org/10.1080/03610926.2023.2222922}, doi = {10.1080/03610926.2023.2222922}, journal = {Communications in Statistics - Theory and Methods}, publisher = {Informa UK Limited}, author = {Chaubey, Yogendra P and Dewan, Isha and Li, Jun}, year = {2023}, month = {jun}, pages = {1–21} }</description></item><item><title>On Testing the Equality Between Interquartile Ranges</title><link>https://aakinshin.net/library/papers/greco2023/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/greco2023/</guid><description>Reference Luca Greco, George Luta, Rand Wilcox “On testing the equality between interquartile ranges” (2023) // DOI: 10.1007/s00180-023-01415-8
Bib @Article{greco2023, title = {On testing the equality between interquartile ranges}, author = {Greco, Luca and Luta, George and Wilcox, Rand}, year = {2023}, doi = {10.1007/s00180-023-01415-8} }</description></item><item><title>On the Estimation of Relative Potency in Dilution (-Direct) Assays by Distribution-Free Methods</title><link>https://aakinshin.net/library/papers/sen1963/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/sen1963/</guid><description>Reference Pranab Kumar Sen “On the Estimation of Relative Potency in Dilution (-Direct) Assays by Distribution-Free Methods” (1963) // Biometrics. Vol. 19. No 4. Pp. 532. DOI: 10.2307/2527532
Bib @Article{sen1963, title = {On the Estimation of Relative Potency in Dilution (-Direct) Assays by Distribution-Free Methods}, volume = {19}, issn = {0006341X}, url = {https://www.jstor.org/stable/2527532?origin=crossref}, doi = {10.2307/2527532}, number = {4}, urldate = {2022-05-31}, journal = {Biometrics}, author = {Sen, Pranab Kumar}, month = {dec}, year = {1963}, pages = {532} }</description></item><item><title>On the Mathematical Foundations of Theoretical Statistics</title><link>https://aakinshin.net/library/papers/fisher1922/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/fisher1922/</guid><description>Reference Ronald A Fisher “On the mathematical foundations of theoretical statistics” (1922) // Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character. Vol. 222. No 594-604. Pp. 309–368. DOI: 10.1098/rsta.1922.0009
Abstract Several reasons have contributed to the prolonged neglect into which the study of statistics, in its theoretical aspects, has fallen. In spite of the immense amount of fruitful labour which has been expended in its practical applications, the basic principles of this organ of science are still in a state of obscurity, and it cannot be denied that, during the recent rapid development of practical methods, fundamental problems have been ignored and fundamental paradoxes left unresolved. This anomalous state of statistical science is strikingly exemplified by a recent paper entitled &amp;ldquo;The Fundamental Problem of Practical Statistics,&amp;rdquo; in which one of the most eminent of modern statisticians presents what purports to be a general proof of BAYES&amp;rsquo; postulate, a proof which, in the opinion of a second statistician of equal eminence, &amp;ldquo;seems to rest upon a very peculiar &amp;ndash; not to say hardly supposable &amp;ndash; relation.&amp;rdquo;
Bib @Article{fisher1922, title = {On the mathematical foundations of theoretical statistics}, volume = {222}, issn = {0264-3952, 2053-9258}, url = {https://royalsocietypublishing.org/doi/10.1098/rsta.1922.0009}, doi = {10.1098/rsta.1922.0009}, abstract = {Several reasons have contributed to the prolonged neglect into which the study of statistics, in its theoretical aspects, has fallen. In spite of the immense amount of fruitful labour which has been expended in its practical applications, the basic principles of this organ of science are still in a state of obscurity, and it cannot be denied that, during the recent rapid development of practical methods, fundamental problems have been ignored and fundamental paradoxes left unresolved. This anomalous state of statistical science is strikingly exemplified by a recent paper entitled &amp;#34;The Fundamental Problem of Practical Statistics,&amp;#34; in which one of the most eminent of modern statisticians presents what purports to be a general proof of BAYES&amp;#39; postulate, a proof which, in the opinion of a second statistician of equal eminence, &amp;#34;seems to rest upon a very peculiar -- not to say hardly supposable -- relation.</description></item><item><title>On the Medians of Gamma Distributions and an Equation of Ramanujan</title><link>https://aakinshin.net/library/papers/choi1994/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/choi1994/</guid><description>Reference Kwok Pui Choi “On the medians of gamma distributions and an equation of Ramanujan” (1994) // Proceedings of the American Mathematical Society. Vol. 121. No 1. Pp. 245–251. DOI: 10.2307/2160389
Bib @Article{choi1994, title = {On the medians of gamma distributions and an equation of Ramanujan}, author = {Choi, Kwok Pui}, journal = {Proceedings of the American Mathematical Society}, volume = {121}, number = {1}, pages = {245--251}, year = {1994}, doi = {10.2307/2160389} }</description></item><item><title>On the Problem of the Most Efficient Tests of Statistical Hypotheses</title><link>https://aakinshin.net/library/papers/neyman1933/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/neyman1933/</guid><description>Reference Jerzy Neyman, Egon Sharpe Pearson “On the problem of the most efficient tests of statistical hypotheses” (1933) // Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character. Publisher: The Royal Society London. Vol. 231. No 694-706. Pp. 289–337. DOI: 10.1098/rsta.1933.0009
Bib @Article{neyman1933, title = {On the problem of the most efficient tests of statistical hypotheses}, author = {Neyman, Jerzy and Pearson, Egon Sharpe}, journal = {Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character}, volume = {231}, number = {694-706}, pages = {289--337}, year = {1933}, publisher = {The Royal Society London}, doi = {10.1098/rsta.1933.0009} }</description></item><item><title>On the Ratio of Two Correlated Normal Random Variables</title><link>https://aakinshin.net/library/papers/hinkley1969/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/hinkley1969/</guid><description>Reference Hinkley D V “On the ratio of two correlated normal random variables” (1969) // Biometrika. Vol. 56. Pp. 635. DOI: 10.2307/2334671
Bib @Article{hinkley1969, title = {On the ratio of two correlated normal random variables}, volume = {56}, journal = {Biometrika}, author = {V, Hinkley D}, year = {1969}, pages = {635}, doi = {10.2307/2334671} }</description></item><item><title>Order Statistics</title><link>https://aakinshin.net/library/papers/david2003/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/david2003/</guid><description>Reference Herbert A David, Haikady N Nagaraja “Order statistics” (2003) // Publisher: John Wiley &amp;amp; Sons. ISBN: 9780471389262. DOI: 10.1002/0471722162
Bib @Book{david2003, title = {Order statistics}, author = {David, Herbert A and Nagaraja, Haikady N}, year = {2003}, ed = {3}, doi = {10.1002/0471722162}, isbn = {9780471389262}, publisher = {John Wiley \&amp;amp; Sons} }</description></item><item><title>Outlier Detection and a tail-adjusted Boxplot Based on Extreme Value Theory</title><link>https://aakinshin.net/library/papers/bhattacharya2019/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/bhattacharya2019/</guid><description>Reference Shrijita Bhattacharya, Jan Beirlant “Outlier detection and a tail-adjusted boxplot based on extreme value theory” (2019) // arXiv:1912.02595 [math, stat].
Abstract Whether an extreme observation is an outlier or not, depends strongly on the corresponding tail behaviour of the underlying distribution. We develop an automatic, data-driven method to identify extreme tail behaviour that deviates from the intermediate and central characteristics. This allows for detecting extreme outliers or sets of extreme data that show less spread than the bulk of the data. To this end we extend a testing method proposed in Bhattacharya et al 2019 for the specific case of heavy tailed models, to all max-domains of attraction. Consequently we propose a tail-adjusted boxplot which yields a more accurate representation of possible outliers. Several examples and simulation results illustrate the finite sample behaviour of this approach.
Bib @Article{bhattacharya2019, title = {Outlier detection and a tail-adjusted boxplot based on extreme value theory}, url = {http://arxiv.org/abs/1912.02595}, abstract = {Whether an extreme observation is an outlier or not, depends strongly on the corresponding tail behaviour of the underlying distribution. We develop an automatic, data-driven method to identify extreme tail behaviour that deviates from the intermediate and central characteristics. This allows for detecting extreme outliers or sets of extreme data that show less spread than the bulk of the data. To this end we extend a testing method proposed in Bhattacharya et al 2019 for the specific case of heavy tailed models, to all max-domains of attraction. Consequently we propose a tail-adjusted boxplot which yields a more accurate representation of possible outliers. Several examples and simulation results illustrate the finite sample behaviour of this approach.}, urldate = {2020-06-27}, journal = {arXiv:1912.02595 [math, stat]}, author = {Bhattacharya, Shrijita and Beirlant, Jan}, month = {dec}, year = {2019}, note = {arXiv: 1912.02595}, arxiv = {1912.02595}, keywords = {Mathematics - Statistics Theory, Statistics - Methodology} }</description></item><item><title>P Values Like Mosquitos</title><link>https://aakinshin.net/library/quotes/5b71be63-c543-4d94-8c3a-aafff77ca666/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/5b71be63-c543-4d94-8c3a-aafff77ca666/</guid><description>Perhaps p values are like mosquitos. They have an evolutionary niche somewhere and no amount of scratching, swatting, or spraying will dislodge them</description></item><item><title>P values, Hypothesis tests, and likelihood: Implications for Epidemiology of a Neglected Historical Debate</title><link>https://aakinshin.net/library/papers/goodman1993/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/goodman1993/</guid><description>Reference Steven N Goodman “P values, hypothesis tests, and likelihood: implications for epidemiology of a neglected historical debate” (1993) // American Journal of Epidemiology. Publisher: Oxford University Press. Vol. 137. No 5. Pp. 485–496. DOI: 10.1093/oxfordjournals.aje.a116700
Bib @Article{goodman1993, title = {P values, hypothesis tests, and likelihood: implications for epidemiology of a neglected historical debate}, author = {Goodman, Steven N}, journal = {American Journal of Epidemiology}, volume = {137}, number = {5}, pages = {485--496}, year = {1993}, publisher = {Oxford University Press}, doi = {10.1093/oxfordjournals.aje.a116700} }</description></item><item><title>Penalized Power Approach to Compare the Power of the Tests When Type I Error Probabilities Are Different</title><link>https://aakinshin.net/library/papers/cavus2021/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/cavus2021/</guid><description>Reference Mustafa Cavus, Berna Yazici, Ahmet Sezer “Penalized power approach to compare the power of the tests when Type I error probabilities are different” (2021) // Communications in Statistics - Simulation and Computation. Vol. 50. No 7. Pp. 1912–1926. DOI: 10.1080/03610918.2019.1588310
Bib @Article{cavus2021, title = {Penalized power approach to compare the power of the tests when Type I error probabilities are different}, volume = {50}, issn = {0361-0918, 1532-4141}, url = {https://www.tandfonline.com/doi/full/10.1080/03610918.2019.1588310}, doi = {10.1080/03610918.2019.1588310}, language = {en}, number = {7}, urldate = {2023-04-11}, journal = {Communications in Statistics - Simulation and Computation}, author = {Cavus, Mustafa and Yazici, Berna and Sezer, Ahmet}, month = {jul}, year = {2021}, pages = {1912--1926} }</description></item><item><title>Performance of Some Estimators of Relative Variability</title><link>https://aakinshin.net/library/papers/ospina2019/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/ospina2019/</guid><description>Reference Raydonal Ospina, Fernando Marmolejo-Ramos “Performance of Some Estimators of Relative Variability” (2019) // Frontiers in Applied Mathematics and Statistics. Vol. 5. DOI: 10.3389/fams.2019.00043
Abstract The classic coefficient of variation (CV) is the ratio of the standard deviation to the mean and can be used to compare normally distributed data with respect to their variability, this measure has been widely used in many fields. In the Social Sciences, the CV is used to evaluate demographic heterogeneity and social aggregates such as race, sex, education and others. Data of this nature are usually not normally distributed, and the distributional characteristics can vary widely. In this sense, more accurate and robust estimator variations of the classic CV are needed to give a more realistic picture of the behavior of collected data. In this work, we empirically evaluate five measures of relative variability, including the classic CV, of finite sample sizes via Monte Carlo simulations. Our purpose is to give an insight into the behavior of these estimators, as their performance has not previously been systematically investigated. To represent different behaviors of the data, we considered some statistical distributions—which are frequently used to model data across various research fields. To enable comparisons, we consider parameters of these distributions that lead to a similar range of values for the CV. Our results indicate that CV estimators based on robust statistics of scale and location are more accurate and give the highest measure of efficiency. Finally, we study the stability of a robust CV estimator in psychological and genetic data and compare the results with the traditional CV.
Bib @Article{ospina2019, title = {Performance of Some Estimators of Relative Variability}, volume = {5}, issn = {2297-4687}, url = {https://www.frontiersin.org/articles/10.3389/fams.2019.00043}, abstract = {The classic coefficient of variation (CV) is the ratio of the standard deviation to the mean and can be used to compare normally distributed data with respect to their variability, this measure has been widely used in many fields.</description></item><item><title>Performing high-powered Studies Efficiently with Sequential analyses: Sequential Analyses</title><link>https://aakinshin.net/library/papers/lakens2014/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/lakens2014/</guid><description>Reference Daniël Lakens “Performing high-powered studies efficiently with sequential analyses: Sequential analyses” (2014) // European Journal of Social Psychology. Vol. 44. No 7. Pp. 701–710. DOI: 10.1002/ejsp.2023
Bib @Article{lakens2014, title = {Performing high-powered studies efficiently with sequential analyses: Sequential analyses}, volume = {44}, issn = {00462772}, shorttitle = {Performing high-powered studies efficiently with sequential analyses}, url = {http://doi.wiley.com/10.1002/ejsp.2023}, doi = {10.1002/ejsp.2023}, language = {en}, number = {7}, urldate = {2020-01-08}, journal = {European Journal of Social Psychology}, author = {Lakens, Daniël}, month = {dec}, year = {2014}, note = {ZSCC: 0000167}, pages = {701--710} }</description></item><item><title>Plot and Eye</title><link>https://aakinshin.net/library/quotes/5277cbcc-0a1a-4094-8dab-5360a6876aa6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/5277cbcc-0a1a-4094-8dab-5360a6876aa6/</guid><description>It may well be true that &amp;ldquo;plot and eye&amp;rdquo; is the most diverse channel to the human mind. Not that it transmits more bits per second, but rather that it will transmit a greater variety of messages on unexpected topics easily and rapidly. There really seems to be no substitute for &amp;ldquo;looking at the data.&amp;rdquo;</description></item><item><title>Plotting with Confidence – Graphical Comparisons of 2 Populations</title><link>https://aakinshin.net/library/papers/doksum1976/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/doksum1976/</guid><description>Reference Doksum K A, Sievers G L “Plotting with confidence – Graphical comparisons of 2 populations” (1976) // Biometrika. Vol. 63. Pp. 421. DOI: 10.1093/biomet/63.3.421
Bib @Article{doksum1976, title = {Plotting with confidence – Graphical comparisons of 2 populations}, volume = {63}, journal = {Biometrika}, author = {A, Doksum K and L, Sievers G}, year = {1976}, pages = {421}, doi = {10.1093/biomet/63.3.421} }</description></item><item><title>Post Mortem Examination</title><link>https://aakinshin.net/library/quotes/e361cd8b-796d-4edd-8b8a-1f5325c9801c/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/e361cd8b-796d-4edd-8b8a-1f5325c9801c/</guid><description>To consult the statistician after an experiment is fnished is often merely to ask him to conduct a post mortem examination. He can perhaps say what the experiment died of.</description></item><item><title>Power failure: Why Small Sample Size Undermines the Reliability of Neuroscience</title><link>https://aakinshin.net/library/papers/button2013/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/button2013/</guid><description>Reference Katherine S Button, John P A Ioannidis, Claire Mokrysz, Brian A Nosek, Jonathan Flint, Emma S J Robinson, Marcus R Munafò “Power failure: why small sample size undermines the reliability of neuroscience” (2013) // Nature Reviews Neuroscience. Publisher: Springer Science and Business Media LLC. Vol. 14. No 5. Pp. 365–376. DOI: 10.1038/nrn3475
Bib @Article{button2013, title = {Power failure: why small sample size undermines the reliability of neuroscience}, volume = {14}, issn = {1471-0048}, url = {http://dx.doi.org/10.1038/nrn3475}, doi = {10.1038/nrn3475}, number = {5}, journal = {Nature Reviews Neuroscience}, publisher = {Springer Science and Business Media LLC}, author = {Button, Katherine S and Ioannidis, John P A and Mokrysz, Claire and Nosek, Brian A and Flint, Jonathan and Robinson, Emma S J and Munafò, Marcus R}, year = {2013}, month = {apr}, pages = {365–376} }</description></item><item><title>Presidential Address by Professor R.A. Fisher</title><link>https://aakinshin.net/library/papers/fisher1938/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/fisher1938/</guid><description>Reference RA Fisher “Presidential Address by Professor R.A. Fisher” (1938) // Sankhya. Vol. 4. No 1. Pp. 14–17. DOI: 10.2307/40383882
Bib @Article{fisher1938, title = {Presidential Address by Professor R.A. Fisher}, author = {Fisher, RA}, url = {https://www.jstor.org/stable/40383882}, journal = {Sankhya}, volume = {4}, number = {1}, pages = {14--17}, year = {1938}, doi = {10.2307/40383882} }</description></item><item><title>Probabilistic Evaluation of Quantile Estimators</title><link>https://aakinshin.net/library/papers/pajari2021/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/pajari2021/</guid><description>Reference Matti Pajari, Maria Tikanmäki, Lasse Makkonen “Probabilistic evaluation of quantile estimators” (2021) // Communications in Statistics - Theory and Methods. Vol. 50. No 14. Pp. 3319–3337. DOI: 10.1080/03610926.2019.1696975
Bib @Article{pajari2021, title = {Probabilistic evaluation of quantile estimators}, volume = {50}, issn = {0361-0926, 1532-415X}, url = {https://www.tandfonline.com/doi/full/10.1080/03610926.2019.1696975}, doi = {10.1080/03610926.2019.1696975}, language = {en}, number = {14}, urldate = {2022-08-02}, journal = {Communications in Statistics - Theory and Methods}, author = {Pajari, Matti and Tikanmäki, Maria and Makkonen, Lasse}, month = {jul}, year = {2021}, pages = {3319--3337} }</description></item><item><title>Probability of the Superior Outcome of One Treatment Over Another</title><link>https://aakinshin.net/library/papers/grissom1994/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/grissom1994/</guid><description>Reference Grissom R J “Probability of the superior outcome of one treatment over another” (1994) // J. Appl. Psychol.. Vol. 79. Pp. 314. DOI: 10.1037/0021-9010.79.2.314
Bib @Article{grissom1994, title = {Probability of the superior outcome of one treatment over another}, volume = {79}, journal = {J. Appl. Psychol.}, author = {J, Grissom R}, year = {1994}, pages = {314}, doi = {10.1037/0021-9010.79.2.314} }</description></item><item><title>Probability Plotting Methods for the Analysis of Data</title><link>https://aakinshin.net/library/papers/wilk1968/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/wilk1968/</guid><description>Reference Wilk M B, Gnanadesikan R “Probability plotting methods for the analysis of data” (1968) // Biometrika. Vol. 55. Pp. 1. DOI: 10.2307/2334448
Bib @Article{wilk1968, title = {Probability plotting methods for the analysis of data}, volume = {55}, journal = {Biometrika}, author = {B, Wilk M and R, Gnanadesikan}, year = {1968}, pages = {1}, doi = {10.2307/2334448} }</description></item><item><title>Pseudoreplication and the Design of Ecological Field Experiments</title><link>https://aakinshin.net/library/papers/hurlbert1984/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/hurlbert1984/</guid><description>Reference Stuart H Hurlbert “Pseudoreplication and the Design of Ecological Field Experiments” (1984) // Ecological Monographs. Publisher: Wiley. Vol. 54. No 2. Pp. 187–211. DOI: 10.2307/1942661
Bib @Article{hurlbert1984, title = {Pseudoreplication and the Design of Ecological Field Experiments}, volume = {54}, issn = {1557-7015}, url = {http://dx.doi.org/10.2307/1942661}, doi = {10.2307/1942661}, number = {2}, journal = {Ecological Monographs}, publisher = {Wiley}, author = {Hurlbert, Stuart H}, year = {1984}, month = {jun}, pages = {187–211} }</description></item><item><title>Pseudoreplication in Experimental Studies</title><link>https://aakinshin.net/library/quotes/c5d9190f-aaaa-4d7b-96f6-84186076c145/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/c5d9190f-aaaa-4d7b-96f6-84186076c145/</guid><description>Pseudoreplication is defined as the use of inferential statistics to test for treatment effects with data from experiments where either treatments are not replicated (though samples may be) or replicates are not statistically independent. In ANOVA terminology, it is the testing for treatment effects with an error term inappropriate to the hypothesis being considered. Scrutiny of 176 experimental studies published between 1960 and the present revealed that pseudoreplication occurred in 27% of them, or 48% of all such studies that applied inferential statistics. The incidence of pseudoreplication is especially high in studies of marine benthos and small mammals.</description></item><item><title>Pseudoreplication in Neuroscience Research:</title><link>https://aakinshin.net/library/quotes/e9ebe56a-db58-4982-9d18-d15926814ecc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/e9ebe56a-db58-4982-9d18-d15926814ecc/</guid><description>Of the nineteen papers published in the August 2008 issue of Nature Neuroscience, seventeen papers (89%) used inferential statistics; of these, only three (18%) had sufficient information to assess whether there was pseudoreplication. Of these three, two appeared to have pseudoreplication. Of the fourteen papers that used inferential statistics but did not provide sufficient information, five (36%) were suspected of having pseudoreplication, but it was not possible to determine for certain.</description></item><item><title>Pseudoreplication in Playback Experiments</title><link>https://aakinshin.net/library/papers/kroodsma2001/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/kroodsma2001/</guid><description>Reference Donald E Kroodsma, Bruce E Byers, Eben Goodale, Steven Johnson, Wan-Chun Liu “Pseudoreplication in playback experiments” (2001) // Animal Behaviour. Publisher: Elsevier BV. Vol. 61. No 5. Pp. 1029–1033. DOI: 10.1006/anbe.2000.1676
Bib @Article{kroodsma2001, title = {Pseudoreplication in playback experiments}, volume = {61}, issn = {0003-3472}, url = {http://dx.doi.org/10.1006/anbe.2000.1676}, doi = {10.1006/anbe.2000.1676}, number = {5}, journal = {Animal Behaviour}, publisher = {Elsevier BV}, author = {Kroodsma, Donald E and Byers, Bruce E and Goodale, Eben and Johnson, Steven and Liu, Wan-Chun}, year = {2001}, month = {may}, pages = {1029–1033} }</description></item><item><title>Pseudoreplication Revisited</title><link>https://aakinshin.net/library/papers/heffner1996/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/heffner1996/</guid><description>Reference Robert A Heffner, Mark J Butler, Colleen Keelan Reilly “Pseudoreplication Revisited” (1996) // Ecology. Publisher: Wiley. Vol. 77. No 8. Pp. 2558–2562. DOI: 10.2307/2265754
Bib @Article{heffner1996, title = {Pseudoreplication Revisited}, volume = {77}, issn = {1939-9170}, url = {http://dx.doi.org/10.2307/2265754}, doi = {10.2307/2265754}, number = {8}, journal = {Ecology}, publisher = {Wiley}, author = {Heffner, Robert A and Butler, Mark J and Reilly, Colleen Keelan}, year = {1996}, month = {dec}, pages = {2558–2562} }</description></item><item><title>Puzzlingly High Correlations in fMRI Studies of Emotion, Personality, and Social Cognition</title><link>https://aakinshin.net/library/papers/vul2009/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/vul2009/</guid><description>Reference Edward Vul, Christine Harris, Piotr Winkielman, Harold Pashler “Puzzlingly High Correlations in fMRI Studies of Emotion, Personality, and Social Cognition” (2009) // Perspectives on Psychological Science. Publisher: SAGE Publications. Vol. 4. No 3. Pp. 274–290. DOI: 10.1111/j.1745-6924.2009.01125.x
Bib @Article{vul2009, title = {Puzzlingly High Correlations in fMRI Studies of Emotion, Personality, and Social Cognition}, volume = {4}, issn = {1745-6924}, url = {http://dx.doi.org/10.1111/j.1745-6924.2009.01125.x}, doi = {10.1111/j.1745-6924.2009.01125.x}, number = {3}, journal = {Perspectives on Psychological Science}, publisher = {SAGE Publications}, author = {Vul, Edward and Harris, Christine and Winkielman, Piotr and Pashler, Harold}, year = {2009}, month = {may}, pages = {274–290} }</description></item><item><title>Quantile Comparison Functions in two-sample problems, with Application to Comparisons of Diagnostic Markers</title><link>https://aakinshin.net/library/papers/li1996/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/li1996/</guid><description>Reference Gang Li, C R Tiwari, T M Wells “Quantile comparison functions in two-sample problems, with application to comparisons of diagnostic markers” (1996) // J. Am. Statist. Assoc.. Vol. 91. Pp. 689. DOI: 10.2307/2291664
Bib @Article{li1996, title = {Quantile comparison functions in two-sample problems, with application to comparisons of diagnostic markers}, volume = {91}, journal = {J. Am. Statist. Assoc.}, author = {Li, Gang and Tiwari, C R and Wells, T M}, year = {1996}, pages = {689}, doi = {10.2307/2291664} }</description></item><item><title>Questionable Practices</title><link>https://aakinshin.net/library/quotes/a40b9984-ae39-4f04-821b-42f8fabf5719/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/a40b9984-ae39-4f04-821b-42f8fabf5719/</guid><description>Cases of clear scientific misconduct have received significant media attention recently, but less flagrantly questionable research practices may be more prevalent and, ultimately, more damaging to the academic enterprise. Using an anonymous elicitation format supplemented by incentives for honest reporting, we surveyed over 2,000 psychologists about their involvement in questionable research practices. The impact of truth-telling incentives on self-admissions of questionable research practices was positive, and this impact was greater for practices that respondents judged to be less defensible. Combining three different estimation methods, we found that the percentage of respondents who have engaged in questionable practices was surprisingly high. This finding suggests that some questionable practices may constitute the prevailing research norm.</description></item><item><title>Randomized Trials Stopped Early for Benefit: A Systematic Review</title><link>https://aakinshin.net/library/papers/montori2005/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/montori2005/</guid><description>Reference Victor M Montori, P J Devereaux, Neill K J Adhikari, Karen E A Burns, Christoph H Eggert, Matthias Briel, Christina Lacchetti, Teresa W Leung, Elizabeth Darling, Dianne M Bryant, Heiner C Bucher, Holger J Schünemann, Maureen O Meade, Deborah J Cook, Patricia J Erwin, Amit Sood, Richa Sood, Benjamin Lo, Carly A Thompson, Qi Zhou, Edward Mills, Gordon H Guyatt “Randomized Trials Stopped Early for Benefit: A Systematic Review” (2005) // JAMA. Publisher: American Medical Association (AMA). Vol. 294. No 17. Pp. 2203. DOI: 10.1001/jama.294.17.2203
Bib @Article{montori2005, title = {Randomized Trials Stopped Early for Benefit: A Systematic Review}, volume = {294}, issn = {0098-7484}, url = {http://dx.doi.org/10.1001/jama.294.17.2203}, doi = {10.1001/jama.294.17.2203}, number = {17}, journal = {JAMA}, publisher = {American Medical Association (AMA)}, author = {Montori, Victor M and Devereaux, P J and Adhikari, Neill K J and Burns, Karen E A and Eggert, Christoph H and Briel, Matthias and Lacchetti, Christina and Leung, Teresa W and Darling, Elizabeth and Bryant, Dianne M and Bucher, Heiner C and Schünemann, Holger J and Meade, Maureen O and Cook, Deborah J and Erwin, Patricia J and Sood, Amit and Sood, Richa and Lo, Benjamin and Thompson, Carly A and Zhou, Qi and Mills, Edward and Guyatt, Gordon H}, year = {2005}, month = {nov}, pages = {2203} }</description></item><item><title>Recommendations on Presenting of Statistical Results in Medical Literature</title><link>https://aakinshin.net/library/quotes/10d26f39-ca23-4d67-8a99-baa4b9c0211f/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/10d26f39-ca23-4d67-8a99-baa4b9c0211f/</guid><description>We encourage authors to avoid statements like “X has no effect on mortality” as they are likely to be both untrue and misleading. This is especially true as results get “close” to being statistically significant. Results should speak for themselves. For that to happen, readers (clinicians and science reporters) need to understand the language of statistics and approach authors’ conclusions with a critical eye. We are not trying to say that the reader should not review the abstract but when authors’ conclusions differ from others, readers must examine and compare the actual results. In fact, all but one of the meta-analyses provided point estimates and CIs in the abstracts. This facilitates quick comparisons to other studies reported to be “completely different,” and to determine if the CIs demonstrate clinically important differences. The problem lies in the authors’ conclusions, which often have little to do with their results but rather what they want the results to show. We encourage journal editors to challenge authors’ conclusions, particularly when they argue they have found something unique or different than other researchers but the difference is based solely on tiny variations in CIs or p-value (statistically significant or not).
We are not suggesting the elimination of statistical testing or statistical significance, but rather that all people (authors, publishers, regulators etc.) who write about medical interventions use common sense and good judgment when presenting results that differ from others and not be so beholden to the “magical” statistical significance level of 0.05. We urge them to consider the degree to which the results of the “differing” study overlap with their own, the true difference in the point estimates and range of possible effects, where the preponderance of the effect lies and how clinicians might apply the evidence.
It appears that readers of the papers discussed here would be better served by reviewing the actual results than reading the authors’ conclusions.</description></item><item><title>Reldist: Relative Distribution Methods</title><link>https://aakinshin.net/library/papers/handcock2022/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/handcock2022/</guid><description>Reference Mark S Handcock “reldist: Relative Distribution Methods” (2022)
Bib @Manual{handcock2022, title = {reldist: Relative Distribution Methods}, author = {Mark S Handcock}, year = {2022}, note = {R package version 1.7-1}, url = {https://cran.r-project.org/web/packages/reldist/index.html} }</description></item><item><title>Requirements for Authors</title><link>https://aakinshin.net/library/quotes/2915ea66-476d-46bc-a79a-43ebe0c730e2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/2915ea66-476d-46bc-a79a-43ebe0c730e2/</guid><description>We propose the following six requirements for authors.
Authors must decide the rule for terminating data collection before data collection begins and report this rule in the article. Following this requirement may mean reporting the outcome of power calculations or disclosing arbitrary rules, such as “we decided to collect 100 observations” or “we decided to collect as many observations as we could before the end of the semester.” The rule itself is secondary, but it must be determined ex ante and be reported. Authors must collect at least 20 observations per cell or else provide a compelling cost-of-data-collection justification. This requirement offers extra protection for the first requirement. Samples smaller than 20 per cell are simply not powerful enough to detect most effects, and so there is usually no good reason to decide in advance to collect such a small number of observations. Smaller samples, it follows, are much more likely to reflect interim data analysis and a flexible termination rule. In addition, as Figure 1 shows, larger minimum sample sizes can lessen the impact of violating Requirement 1. Authors must list all variables collected in a study. This requirement prevents researchers from reporting only a convenient subset of the many measures that were collected, allowing readers and reviewers to easily identify possible researcher degrees of freedom. Because authors are required to just list those variables rather than describe them in detail, this requirement increases the length of an article by only a few words per otherwise shrouded variable. We encourage authors to begin the list with “only,” to assure readers that the list is exhaustive (e.g., “participants reported only their age and gender”). Authors must report all experimental conditions, including failed manipulations. This requirement prevents authors from selectively choosing only to report the condition comparisons that yield results that are consistent with their hypothesis.</description></item><item><title>Researchers Misunderstand Confidence Intervals and Standard Error Bars</title><link>https://aakinshin.net/library/papers/belia2005/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/belia2005/</guid><description>Reference Sarah Belia, Fiona Fidler, Jennifer Williams, Geoff Cumming “Researchers Misunderstand Confidence Intervals and Standard Error Bars” (2005) // Psychological Methods. Publisher: American Psychological Association (APA). Vol. 10. No 4. Pp. 389–396. DOI: 10.1037/1082-989x.10.4.389
Bib @Article{belia2005, title = {Researchers Misunderstand Confidence Intervals and Standard Error Bars}, volume = {10}, issn = {1082-989X}, url = {http://dx.doi.org/10.1037/1082-989X.10.4.389}, doi = {10.1037/1082-989x.10.4.389}, number = {4}, journal = {Psychological Methods}, publisher = {American Psychological Association (APA)}, author = {Belia, Sarah and Fidler, Fiona and Williams, Jennifer and Cumming, Geoff}, year = {2005}, pages = {389–396} }</description></item><item><title>Rethinking the Effective Sample Size</title><link>https://aakinshin.net/library/papers/elvira2022/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/elvira2022/</guid><description>Reference V Elvira, L Martino, C Robert “Rethinking the Effective Sample Size” (2022) // International Statistical Review. Publisher: Wiley Online Library. DOI: 10.1111/insr.12500
Bib @Article{elvira2022, author = {Elvira, V and Martino, L and Robert, C}, title = {Rethinking the Effective Sample Size}, journal = {International Statistical Review}, year = {2022}, doi = {10.1111/insr.12500}, publisher = {Wiley Online Library}, arxiv = {1809.04129} }</description></item><item><title>Risk Reduction in Truncated Rcts</title><link>https://aakinshin.net/library/quotes/cfcf0003-6df7-4c36-a140-1297e5f8954f/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/cfcf0003-6df7-4c36-a140-1297e5f8954f/</guid><description>Nontruncated RCTs with no evidence of benefit &amp;hellip; would on average be associated with a 29% relative risk reduction in truncated RCTs addressing the same question.</description></item><item><title>Robust Analogs to the Coefficient of Variation</title><link>https://aakinshin.net/library/papers/arachchige2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/arachchige2020/</guid><description>Reference Chandima N P G Arachchige, Luke A Prendergast, Robert G Staudte “Robust analogs to the Coefficient of Variation” (2020) // Journal of Applied Statistics. Vol. 49. No 2. Pp. 268–290. DOI: 10.1080/02664763.2020.1808599
Abstract The coefficient of variation (CV) is commonly used to measure relative dispersion. However, since it is based on the sample mean and standard deviation, outliers can adversely affect the CV. Additionally, for skewed distributions the mean and standard deviation do not have natural interpretations and, consequently, neither does the CV. Here we investigate the extent to which quantile-based measures of relative dispersion can provide appropriate summary information as an alternative to the CV. In particular, we investigate two measures, the first being the interquartile range (in lieu of the standard deviation), divided by the median (in lieu of the mean), and the second being the median absolute deviation (MAD), divided by the median, as robust estimators of relative dispersion. In addition to comparing the influence functions of the competing estimators and their asymptotic biases and variances, we compare interval estimators using simulation studies to assess coverage.
Bib @Article{arachchige2020, title = {Robust analogs to the Coefficient of Variation}, volume = {49}, issn = {0266-4763, 1360-0532}, url = {http://arxiv.org/abs/1907.01110}, doi = {10.1080/02664763.2020.1808599}, abstract = {The coefficient of variation (CV) is commonly used to measure relative dispersion. However, since it is based on the sample mean and standard deviation, outliers can adversely affect the CV. Additionally, for skewed distributions the mean and standard deviation do not have natural interpretations and, consequently, neither does the CV. Here we investigate the extent to which quantile-based measures of relative dispersion can provide appropriate summary information as an alternative to the CV. In particular, we investigate two measures, the first being the interquartile range (in lieu of the standard deviation), divided by the median (in lieu of the mean), and the second being the median absolute deviation (MAD), divided by the median, as robust estimators of relative dispersion.</description></item><item><title>Robust and scale-free Effect Sizes for non-Normal two-sample comparisons, with Applications in e-commerce</title><link>https://aakinshin.net/library/papers/wooff2013/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/wooff2013/</guid><description>Reference David A Wooff, Amin Jamalzadeh “Robust and scale-free effect sizes for non-Normal two-sample comparisons, with applications in e-commerce” (2013) // Journal of Applied Statistics. Vol. 40. No 11. Pp. 2495–2515. DOI: 10.1080/02664763.2013.818625
Abstract The effect size (ES) has been mainly introduced and investigated for changes in location under an assumption of Normality for the underlying population. However, there are many circumstances where populations are non-Normal, or depend on scale and shape and not just a location parameter. Our motivating application from e-commerce requires an ES which is appropriate for long-tailed distributions. We review some common ES measures. We then introduce two novel alternative ES for two-sample comparisons, one scale-free and one on the original scale of measurement, and analyse some theoretical properties. We examine these ES for two-sample comparison studies under an assumption of Normality and investigate what happens when both location and scale parameters differ. We explore ES for phenomena for non-Normal situations, using the Weibull family for illustration. Finally, for an application, we assess differences in customer behaviour when browsing E-commerce websites.
Bib @Article{wooff2013, title = {Robust and scale-free effect sizes for non-Normal two-sample comparisons, with applications in e-commerce}, volume = {40}, issn = {0266-4763}, url = {https://doi.org/10.1080/02664763.2013.818625}, doi = {10.1080/02664763.2013.818625}, abstract = {The effect size (ES) has been mainly introduced and investigated for changes in location under an assumption of Normality for the underlying population. However, there are many circumstances where populations are non-Normal, or depend on scale and shape and not just a location parameter. Our motivating application from e-commerce requires an ES which is appropriate for long-tailed distributions. We review some common ES measures. We then introduce two novel alternative ES for two-sample comparisons, one scale-free and one on the original scale of measurement, and analyse some theoretical properties. We examine these ES for two-sample comparison studies under an assumption of Normality and investigate what happens when both location and scale parameters differ.</description></item><item><title>Robust Effect Sizes for 2 Independent Groups</title><link>https://aakinshin.net/library/web/61f968693aa9f03dd1c1e21aca7c0cd5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/web/61f968693aa9f03dd1c1e21aca7c0cd5/</guid><description/></item><item><title>Robust Estimates of Location Survey and Advances</title><link>https://aakinshin.net/library/papers/andrews2016/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/andrews2016/</guid><description>Reference David F Andrews, Frank R Hampel “Robust Estimates of Location Survey and Advances” (2016) // Publisher: Princeton University Press California Princeton Fulfillment Services [Distributor. Princeton; Ewing. ISBN: 978-0-691-64663-3.
Abstract Annotation
Bib @Book{andrews2016, address = {Princeton; Ewing}, title = {Robust Estimates of Location Survey and Advances}, isbn = {978-0-691-64663-3}, url = {http://ezproxy.canterbury.ac.nz/login?url=https://www.jstor.org/stable/10.2307/j.ctt13x12sw}, abstract = {Annotation}, language = {English}, urldate = {2022-06-21}, publisher = {Princeton University Press California Princeton Fulfillment Services [Distributor}, author = {Andrews, David F and Hampel, Frank R}, year = {2016}, note = {OCLC: 1175632478} }</description></item><item><title>Robust Estimators of scale: Finite-Sample Performance in long-tailed Symmetric Distributions</title><link>https://aakinshin.net/library/papers/lax1985/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/lax1985/</guid><description>Reference David A Lax “Robust estimators of scale: Finite-sample performance in long-tailed symmetric distributions” (1985) // Journal of the American Statistical Association. Publisher: Taylor &amp;amp; Francis. Vol. 80. No 391. Pp. 736–741. DOI: 10.2307/2288493
Bib @Article{lax1985, title = {Robust estimators of scale: Finite-sample performance in long-tailed symmetric distributions}, author = {Lax, David A}, journal = {Journal of the American Statistical Association}, volume = {80}, number = {391}, pages = {736--741}, year = {1985}, publisher = {Taylor \&amp;amp; Francis}, doi = {10.2307/2288493} }</description></item><item><title>Robust Regression and Outlier Detection</title><link>https://aakinshin.net/library/papers/rousseeuw1987/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/rousseeuw1987/</guid><description>Reference Peter J Rousseeuw, Annick M Leroy “Robust Regression and Outlier Detection” (1987) // Publisher: John Wiley &amp;amp; Sons, Inc.. DOI: 10.1002/0471725382
Bib @Book{rousseeuw1987, doi = {10.1002/0471725382}, year = {1987}, month = {oct}, publisher = {John Wiley \&amp;amp; Sons, Inc.}, author = {Peter J Rousseeuw and Annick M Leroy}, title = {Robust Regression and Outlier Detection} }</description></item><item><title>Robust Statistical Methods with R</title><link>https://aakinshin.net/library/papers/jureckova2019/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/jureckova2019/</guid><description>Reference Jana Jureckova, Jan Picek, Martin Schindler “Robust statistical methods with R” (2019) // Publisher: Taylor &amp;amp; Francis. ISBN: 978-1-1380-3536-2.
Bib @Book{jureckova2019, title = {Robust statistical methods with R}, author = {Jureckova, Jana and Picek, Jan and Schindler, Martin}, year = {2019}, edition = {2}, publisher = {Taylor \&amp;amp; Francis}, isbn = {978-1-1380-3536-2} }</description></item><item><title>Robust Statistics</title><link>https://aakinshin.net/library/books/huber-robust-statistics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/huber-robust-statistics/</guid><description>It is one of the pioneer books in the field: the first edition was published in 1981. In this book (and his multiple other works), Peter J. Huber created a foundation for the further development of robust methods.
While I definitely recommend this book to everyone who wants to become an expert in robust statistics, I do not recommend it as the first book on this topic. The book is quite advanced and written for people with a strong mathematical background. For example, the first topic that is discussed just right after the introduction chapter is &amp;ldquo;The Weak Topology and its Metrization&amp;rdquo; (Levy, Prohorov, and the bounded Lipschitz metrics; Frechet and Gateaux derivatives; Hampel&amp;rsquo;s Theorem). This is an interesting and peculiar way to start discussing robust statistics. Most of the terms and notation symbols are assumed to be known by the reader, so the author doesn&amp;rsquo;t disturb you by providing definitions and explanations. The second edition has multiple improvements, but the book structure and style are the same.
Conclusion: the book is great but only for advanced readers; not for beginners.</description></item><item><title>Robust Statistics</title><link>https://aakinshin.net/library/papers/huber2009/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/huber2009/</guid><description>Reference Peter J Huber, Elvezio M Ronchetti “Robust statistics” (2009) // Publisher: John Wiley &amp;amp; Sons. ISBN: 9780470129906. DOI: 10.1002/9780470434697
Bib @Book{huber2009, title = {Robust statistics}, author = {Huber, Peter J and Ronchetti, Elvezio M}, year = {2009}, edition = {2}, publisher = {John Wiley \&amp;amp; Sons}, series = {Wiley Series in Probability and Statistics}, isbn = {9780470129906}, doi = {10.1002/9780470434697} }</description></item><item><title>Robust statistics: The Approach Based on Influence Functions</title><link>https://aakinshin.net/library/papers/hampel1986/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/hampel1986/</guid><description>Reference Frank R. Hampel, Elevezio M. Ronchetti, Peter J. Rousseeuw, Werner A. Stahel “Robust statistics: the approach based on influence functions” (1986) // Publisher: Wiley. New York. ISBN: 978-0-471-73577-9.
Bib @Book{hampel1986, address = {New York}, edition = {Digital print}, series = {Wiley series in probability and mathematical statistics Probability and mathematical statistics}, title = {Robust statistics: the approach based on influence functions}, isbn = {978-0-471-73577-9}, shorttitle = {Robust statistics}, language = {eng}, publisher = {Wiley}, editor = {Hampel, Frank R. and Ronchetti, Elevezio M. and Rousseeuw, Peter J. and Stahel, Werner A.}, year = {1986} }</description></item><item><title>Robust Statistics: Theory and Methods (With R)</title><link>https://aakinshin.net/library/papers/maronna2019/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/maronna2019/</guid><description>Reference Ricardo A Maronna, R Douglas Martin, Victor J Yohai, Mat'\ias Salibi'an-Barrera “Robust Statistics: Theory and Methods (With R)” (2019) // Publisher: John Wiley &amp;amp; Sons. ISBN: 978-1-119-21468-7.
Bib @Book{maronna2019, title = {Robust Statistics: Theory and Methods (With R)}, author = {Maronna, Ricardo A and Martin, R Douglas and Yohai, Victor J and Salibi\&amp;#39;an-Barrera, Mat\&amp;#39;\ias}, publisher = {John Wiley \&amp;amp; Sons}, isbn = {978-1-119-21468-7}, year = {2019}, series = {Wiley Series in Probability and Statistics}, edition = {2} }</description></item><item><title>Robustbase: Basic Robust Statistics</title><link>https://aakinshin.net/library/papers/maechler2022/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/maechler2022/</guid><description>Reference Martin Maechler, Peter Rousseeuw, Christophe Croux “robustbase: Basic Robust Statistics” (2022)
Bib @Manual{maechler2022, title = {robustbase: Basic Robust Statistics}, author = {Martin Maechler and Peter Rousseeuw and Christophe Croux}, year = {2022}, month = {4}, day = {2}, note = {R package version 0.95-0}, url = {https://cran.r-project.org/web/packages/robustbase/index.html} }</description></item><item><title>Rules of Smaple Size Planning</title><link>https://aakinshin.net/library/quotes/63edb163-442a-4336-a5c4-fc51eb0e94e7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/63edb163-442a-4336-a5c4-fc51eb0e94e7/</guid><description> Sample size planning is important to enhance cumulative knowledge in the discipline as well as for the individual researcher. Sample size planning can be based on a goal of achieving adequate statistical power, or accurate parameter estimates, or both. Researchers are actively involved in developing methods for sample size planning, especially for complex designs and analyses. Sample sizes necessary to achieve accurate parameter estimates will often be larger than sample sizes necessary to detect even a small effect. Sample sizes necessary to obtain accurate parameter estimates or power to detect small effects may often require resources prohibitive to the individual researcher, thus suggesting the desirability of study registries accompanied by meta-analytic methods.</description></item><item><title>Same Data, Different Results</title><link>https://aakinshin.net/library/quotes/6e3a83e1-2574-4f7f-a436-579ec133c468/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/6e3a83e1-2574-4f7f-a436-579ec133c468/</guid><description>Most published reports of clinical studies begin with an abstract – likely the first and perhaps only thing many clinicians, the media and patients will read. Within that abstract, authors/investigators typically provide a brief summary of the results and a 1–2 sentence conclusion. At times, the conclusion of one study will be different, even diametrically opposed, to another despite the authors looking at similar data. In these cases, readers may assume that these individual authors somehow found dramatically different results. While these reported differences may be true some of the time, radically diverse conclusions and ensuing controversies may simply be due to tiny differences in confidence intervals combined with an over-reliance and misunderstanding of a “statistically significant difference.” Unfortunately, this misunderstanding can lead to therapeutic uncertainty for front-line clinicians when in fact the overall data on a particular issue is remarkably consistent.</description></item><item><title>Sample Quantiles in Statistical Packages</title><link>https://aakinshin.net/library/papers/hyndman1996/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/hyndman1996/</guid><description>Reference Rob J Hyndman, Yanan Fan “Sample Quantiles in Statistical Packages” (1996) // The American Statistician. Vol. 50. No 4. Pp. 361. DOI: 10.2307/2684934
Bib @Article{hyndman1996, title = {Sample Quantiles in Statistical Packages}, volume = {50}, issn = {00031305}, url = {https://www.jstor.org/stable/2684934?origin=crossref}, doi = {10.2307/2684934}, number = {4}, urldate = {2022-08-09}, journal = {The American Statistician}, author = {Hyndman, Rob J and Fan, Yanan}, month = {nov}, year = {1996}, pages = {361} }</description></item><item><title>Sample Size Planning for Statistical Power and Accuracy in Parameter Estimation</title><link>https://aakinshin.net/library/papers/maxwell2008/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/maxwell2008/</guid><description>Reference Scott E Maxwell, Ken Kelley, Joseph R Rausch “Sample Size Planning for Statistical Power and Accuracy in Parameter Estimation” (2008) // Annual Review of Psychology. Publisher: Annual Reviews. Vol. 59. No 1. Pp. 537–563. DOI: 10.1146/annurev.psych.59.103006.093735
Bib @Article{maxwell2008, title = {Sample Size Planning for Statistical Power and Accuracy in Parameter Estimation}, volume = {59}, issn = {1545-2085}, url = {http://dx.doi.org/10.1146/annurev.psych.59.103006.093735}, doi = {10.1146/annurev.psych.59.103006.093735}, number = {1}, journal = {Annual Review of Psychology}, publisher = {Annual Reviews}, author = {Maxwell, Scott E and Kelley, Ken and Rausch, Joseph R}, year = {2008}, month = {jan}, pages = {537–563} }</description></item><item><title>Scientific Method</title><link>https://aakinshin.net/library/quotes/cd4d7cb3-1f80-4fa7-be94-9cb8181e7851/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/cd4d7cb3-1f80-4fa7-be94-9cb8181e7851/</guid><description>The originators of the statistical frameworks that underlie modern epidemiologic studies recognized that their methods could not be interpreted properly without an understanding of their philosophical underpinnings. Neyman held that inductive reasoning was an illusion and that the only meaningful parameters of importance in an experiment were constraints on the number of statistical &amp;ldquo;errors&amp;rdquo; we would make, defined before an experiment. Fisher rejected mechanistic approaches to inference, believing in a more flexible, inductive approach to science. One of Fisher&amp;rsquo;s developments, mathematical likelihood, fit into such an approach. The p value, which Fisher wanted used in a similar manner, invited misinterpretation because it occupied a peculiar middle ground. Because of its resemblance to the pretrial a error, it was absorbed into the hypothesis test framework. This created two illusions: that an &amp;ldquo;error rate&amp;rdquo; could be measured after an experiment and that this posttrial &amp;ldquo;error rate&amp;rdquo; could be regarded as a measure of inductive evidence. Even though Fisher, Neyman, and many others have recognized these as fallacies, their perpetuation has been encouraged by the manner in which we use the p value today. One consequence is that we overestimate the evidence for associations, particularly with p values in the range of 0.001-0.05, creating misleading impressions of their plausibility. Another result is that we minimize the importance of judgment in inference, because its role is unclear when postexperiment evidential strength is thought to be measurable with preexperiment &amp;ldquo;error-rates.&amp;rdquo; Many experienced epidemiologists have tried to correct these problems by offering guidelines about how p values should be used. We may be more effective if, in the spirts of Fisher and Neyman, we instead focus on clarifying what p values mean, and on what we mean by the &amp;ldquo;scientific method.&amp;rdquo;</description></item><item><title>Second-Generation p-values: Improved rigor, Reproducibility, &amp; Transparency in Statistical Analyses</title><link>https://aakinshin.net/library/papers/blume2018/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/blume2018/</guid><description>Reference Jeffrey D Blume, Lucy D’Agostino McGowan, William D Dupont, Robert A Greevy, Neil R. Smalheiser “Second-generation p-values: Improved rigor, reproducibility, &amp;amp; transparency in statistical analyses” (2018) // PLOS ONE. Vol. 13. No 3. Pp. e0188299. DOI: 10.1371/journal.pone.0188299
Bib @Article{blume2018, title = {Second-generation p-values: Improved rigor, reproducibility, \&amp;amp; transparency in statistical analyses}, volume = {13}, issn = {1932-6203}, shorttitle = {Second-generation p-values}, url = {https://dx.plos.org/10.1371/journal.pone.0188299}, doi = {10.1371/journal.pone.0188299}, language = {en}, number = {3}, urldate = {2020-01-12}, journal = {PLOS ONE}, author = {Blume, Jeffrey D and D’Agostino McGowan, Lucy and Dupont, William D and Greevy, Robert A}, editor = {Smalheiser, Neil R.}, month = {mar}, year = {2018}, note = {ZSCC: NoCitationData[s0]}, pages = {e0188299} }</description></item><item><title>Selected Methods of Interval Estimation of the median. The Analysis of Accuracy of Estimation</title><link>https://aakinshin.net/library/papers/baszczynska2010/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/baszczynska2010/</guid><description>Reference Aleksandra Baszczyńska, Dorota Pekasiewicz “Selected methods of interval estimation of the median. The analysis of accuracy of estimation” (2010)
Abstract Mediana z próby jest jednym z estymatorów parametru położenia i może być stosowana
Bib @Article{baszczynska2010, title = {Selected methods of interval estimation of the median. The analysis of accuracy of estimation}, issn = {0208-6018}, url = {http://dspace.uni.lodz.pl:8080/xmlui/handle/11089/335}, abstract = {Mediana z próby jest jednym z estymatorów parametru położenia i może być stosowana}, language = {en}, urldate = {2020-06-27}, author = {Baszczyńska, Aleksandra and Pekasiewicz, Dorota}, year = {2010}, note = {Accepted: 2012-04-16T12:16:11Z}, custom-url-pdf = {https://dspace.uni.lodz.pl:8443/xmlui/bitstream/handle/11089/335/21-30.pdf?sequence=1&amp;amp;isAllowed=y} }</description></item><item><title>Selective Review of Offline Change Point Detection Methods</title><link>https://aakinshin.net/library/papers/truong2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/truong2020/</guid><description>As of 2020, the best change point detection overview I found.
Reference Charles Truong, Laurent Oudre, Nicolas Vayatis “Selective review of offline change point detection methods” (2020) // Signal Processing. Vol. 167. Pp. 107299. DOI: 10.1016/j.sigpro.2019.107299
Abstract This article presents a selective survey of algorithms for the offline detection of multiple change points in multivariate time series. A general yet structuring methodological strategy is adopted to organize this vast body of work. More precisely, detection algorithms considered in this review are characterized by three elements: a cost function, a search method and a constraint on the number of changes. Each of those elements is described, reviewed and discussed separately. Implementations of the main algorithms described in this article are provided within a Python package called ruptures.
Bib @Article{truong2020, title = {Selective review of offline change point detection methods}, volume = {167}, issn = {01651684}, url = {http://arxiv.org/abs/1801.00718}, doi = {10.1016/j.sigpro.2019.107299}, abstract = {This article presents a selective survey of algorithms for the offline detection of multiple change points in multivariate time series. A general yet structuring methodological strategy is adopted to organize this vast body of work. More precisely, detection algorithms considered in this review are characterized by three elements: a cost function, a search method and a constraint on the number of changes. Each of those elements is described, reviewed and discussed separately. Implementations of the main algorithms described in this article are provided within a Python package called ruptures.}, urldate = {2020-06-30}, journal = {Signal Processing}, author = {Truong, Charles and Oudre, Laurent and Vayatis, Nicolas}, month = {feb}, year = {2020}, note = {arXiv: 1801.00718}, arxiv = {1801.00718}, keywords = {overview}, pages = {107299} }</description></item><item><title>Sequential Monte Carlo as Approximate sampling: Bounds, Adaptive Resampling via infinity-ESS, and an Application to Particle Gibbs</title><link>https://aakinshin.net/library/papers/huggins2019/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/huggins2019/</guid><description>Reference Jonathan H Huggins, Daniel M Roy “Sequential Monte Carlo as approximate sampling: bounds, adaptive resampling via infinity-ESS, and an application to particle Gibbs” (2019) // Bernoulli. Publisher: Bernoulli Society for Mathematical Statistics and Probability. Vol. 25. No 1. Pp. 584–622.
Bib @Article{huggins2019, title = {Sequential Monte Carlo as approximate sampling: bounds, adaptive resampling via infinity-ESS, and an application to particle Gibbs}, author = {Huggins, Jonathan H and Roy, Daniel M}, journal = {Bernoulli}, volume = {25}, number = {1}, pages = {584--622}, year = {2019}, publisher = {Bernoulli Society for Mathematical Statistics and Probability}, arxiv = {1503.00966} }</description></item><item><title>Sex Bias in Graduate Admissions: Data from Berkeley: Measuring Bias is Harder Than is Usually assumed, and the Evidence is Sometimes Contrary to Expectation</title><link>https://aakinshin.net/library/papers/bickel1975/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/bickel1975/</guid><description>Reference P. J. Bickel, E. A. Hammel, J. W. O’Connell “Sex Bias in Graduate Admissions: Data from Berkeley: Measuring bias is harder than is usually assumed, and the evidence is sometimes contrary to expectation” (1975) // Science. Publisher: American Association for the Advancement of Science (AAAS). Vol. 187. No 4175. Pp. 398–404. DOI: 10.1126/science.187.4175.398
Abstract Examination of aggregate data on graduate admissions to the University of California, Berkeley, for fall 1973 shows a clear but misleading pattern of bias against female applicants. Examination of the disaggregated data reveals few decision-making units that show statistically significant departures from expected frequencies of female admissions, and about as many units appear to favor women as to favor men. If the data are properly pooled, taking into account the autonomy of departmental decision making, thus correcting for the tendency of women to apply to graduate departments that are more difficult for applicants of either sex to enter, there is a small but statistically significant bias in favor of women. The graduate departments that are easier to enter tend to be those that require more mathematics in the undergraduate preparatory curriculum. The bias in the aggregated data stems not from any pattern of discrimination on the part of admissions committees, which seem quite fair on the whole, but apparently from prior screening at earlier levels of the educational system. Women are shunted by their socialization and education toward fields of graduate study that are generally more crowded, less productive of completed degrees, and less well funded, and that frequently offer poorer professional employment prospects.
Bib @Article{bickel1975, title = {Sex Bias in Graduate Admissions: Data from Berkeley: Measuring bias is harder than is usually assumed, and the evidence is sometimes contrary to expectation}, abstract = {Examination of aggregate data on graduate admissions to the University of California, Berkeley, for fall 1973 shows a clear but misleading pattern of bias against female applicants.</description></item><item><title>Simultaneous Estimation of Several Percentiles</title><link>https://aakinshin.net/library/papers/raatikainen1987/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/raatikainen1987/</guid><description>Reference Kimmo E E Raatikainen “Simultaneous estimation of several percentiles” (1987) // SIMULATION. Publisher: SAGE Publications. Vol. 49. No 4. Pp. 159–163. DOI: 10.1177/003754978704900405
Bib @Article{raatikainen1987, title = {Simultaneous estimation of several percentiles}, volume = {49}, issn = {1741-3133}, url = {http://dx.doi.org/10.1177/003754978704900405}, doi = {10.1177/003754978704900405}, number = {4}, journal = {SIMULATION}, publisher = {SAGE Publications}, author = {Raatikainen, Kimmo E E}, year = {1987}, month = {oct}, pages = {159–163} }</description></item><item><title>Sir. Ronald Fisher</title><link>https://aakinshin.net/library/quotes/01015429-2154-45e1-b36d-9e11757643ca/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/01015429-2154-45e1-b36d-9e11757643ca/</guid><description>You may say, “But, Meehl, R. A. Fisher was a genius, and we all know how valuable his stuff has been in agronomy. Why shouldn’t it work for soft psychology?” Well, I am not intimidated by Fisher’s genius, because my complaint is not in the field of mathematical statistics, and as regards inductive logic and philosophy of science, it is well-known that Sir Ronald permitted himself a great deal of dogmatism. I remember my amazement when the late Rudolf Carnap said to me, the first time I met him, “But, of course, on this subject Fisher is just mistaken: surely you must know that.” My statistician friends tell me that it is not clear just how useful the significance test has been in biological science either, but I set that aside as beyond my competence to discuss.</description></item><item><title>Some Graphical Methods in statistics: A Review and Some Extensions</title><link>https://aakinshin.net/library/papers/doksum1977/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/doksum1977/</guid><description>Reference Doksum K A “Some graphical methods in statistics: A review and some extensions” (1977) // Statist. Neerlandica. Vol. 31. Pp. 53. DOI: 10.1111/j.1467-9574.1977.tb00752.x
Bib @Article{doksum1977, title = {Some graphical methods in statistics: A review and some extensions}, volume = {31}, journal = {Statist. Neerlandica}, author = {A, Doksum K}, year = {1977}, pages = {53}, doi = {10.1111/j.1467-9574.1977.tb00752.x} }</description></item><item><title>Some Practical Guidelines for Effective sample-size Determination</title><link>https://aakinshin.net/library/papers/lenth2001/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/lenth2001/</guid><description>Reference Lenth R V “Some practical guidelines for effective sample-size determination” (2001) // Am. Stat.. Vol. 55. Pp. 187.
Bib @Article{lenth2001, title = {Some practical guidelines for effective sample-size determination}, volume = {55}, journal = {Am. Stat.}, author = {V, Lenth R}, year = {2001}, pages = {187}, custom-url-pdf = {https://stat.uiowa.edu/sites/stat.uiowa.edu/files/techrep/tr303.pdf} }</description></item><item><title>Spatstat.geom: Geometrical Functionality of the 'spatstat' Family</title><link>https://aakinshin.net/library/papers/baddeley2022/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/baddeley2022/</guid><description>Reference Adrian Baddeley, Rolf Turner, others “spatstat.geom: Geometrical Functionality of the &amp;lsquo;spatstat&amp;rsquo; Family” (2022)
Bib @Manual{baddeley2022, title = {spatstat.geom: Geometrical Functionality of the &amp;#39;spatstat&amp;#39; Family}, author = {Adrian Baddeley and Rolf Turner and others}, year = {2022}, note = {R package version 2.4-0}, url = {https://cran.r-project.org/web/packages/spatstat.geom/index.html} }</description></item><item><title>Standard Methods for Point Estimation of Indicators on Social Exclusion and Poverty Using the R Package Laeken</title><link>https://aakinshin.net/library/papers/templ2011/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/templ2011/</guid><description>Reference Matthias Templ, Andreas Alfons “Standard Methods for Point Estimation of Indicators on Social Exclusion and Poverty using the R Package laeken” (2011)
Bib @Article{templ2011, title = {Standard Methods for Point Estimation of Indicators on Social Exclusion and Poverty using the R Package laeken}, author = {Templ, Matthias and Alfons, Andreas}, year = {2011}, custom-url-pdf = {https://cran.r-project.org/web/packages/laeken/vignettes/laeken-standard.pdf} }</description></item><item><title>Stat 5102 Notes: Nonparametric Tests and Confidence Intervals</title><link>https://aakinshin.net/library/papers/geyer2007/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/geyer2007/</guid><description>Reference Charles J Geyer “Stat 5102 Notes: Nonparametric Tests and Confidence Intervals” (2007)
Bib @Misc{geyer2007, title = {Stat 5102 Notes: Nonparametric Tests and Confidence Intervals}, url = {https://www.stat.umn.edu/geyer/s06/5102/notes/rank.pdf}, language = {English}, author = {Geyer, Charles J}, month = {apr}, year = {2007} }</description></item><item><title>Statistical Analysis of Extreme Values: With Applications to Insurance, Finance, Hydrology and Other Fields</title><link>https://aakinshin.net/library/books/reiss-statistical-analysis-of-extreme-values/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/reiss-statistical-analysis-of-extreme-values/</guid><description/></item><item><title>Statistical Consequences of Fat Tails: Real World Preasymptotics, Epistemology, and Applications</title><link>https://aakinshin.net/library/books/taleb-statistical-consequences-of-fat-tails/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/taleb-statistical-consequences-of-fat-tails/</guid><description/></item><item><title>Statistical Consequences of Fat Tails: Real World Preasymptotics, Epistemology, and Applications</title><link>https://aakinshin.net/library/papers/taleb2020/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/taleb2020/</guid><description>Reference Nassim Nicholas Taleb “Statistical Consequences of Fat Tails: Real World Preasymptotics, Epistemology, and Applications” (2020) // DOI: 10.48550/ARXIV.2001.10488
Abstract The monograph investigates the misapplication of conventional statistical techniques to fat tailed distributions and looks for remedies, when possible. Switching from thin tailed to fat tailed distributions requires more than &amp;ldquo;changing the color of the dress&amp;rdquo;. Traditional asymptotics deal mainly with either n=1 or $n=\textbackslashinfty$, and the real world is in between, under of the &amp;ldquo;laws of the medium numbers&amp;rdquo; &amp;ndash;which vary widely across specific distributions. Both the law of large numbers and the generalized central limit mechanisms operate in highly idiosyncratic ways outside the standard Gaussian or Levy-Stable basins of convergence. A few examples: + The sample mean is rarely in line with the population mean, with effect on &amp;ldquo;naive empiricism&amp;rdquo;, but can be sometimes be estimated via parametric methods. + The &amp;ldquo;empirical distribution&amp;rdquo; is rarely empirical. + Parameter uncertainty has compounding effects on statistical metrics. + Dimension reduction (principal components) fails. + Inequality estimators (GINI or quantile contributions) are not additive and produce wrong results. + Many &amp;ldquo;biases&amp;rdquo; found in psychology become entirely rational under more sophisticated probability distributions + Most of the failures of financial economics, econometrics, and behavioral economics can be attributed to using the wrong distributions. This book, the first volume of the Technical Incerto, weaves a narrative around published journal articles.
Bib @Article{taleb2020, title = {Statistical Consequences of Fat Tails: Real World Preasymptotics, Epistemology, and Applications}, copyright = {arXiv.org perpetual, non-exclusive license}, shorttitle = {Statistical Consequences of Fat Tails}, url = {https://arxiv.org/abs/2001.10488}, doi = {10.48550/ARXIV.2001.10488}, abstract = {The monograph investigates the misapplication of conventional statistical techniques to fat tailed distributions and looks for remedies, when possible. Switching from thin tailed to fat tailed distributions requires more than &amp;#34;changing the color of the dress&amp;#34;. Traditional asymptotics deal mainly with either n=1 or \$n=\textbackslashinfty\$, and the real world is in between, under of the &amp;#34;laws of the medium numbers&amp;#34; --which vary widely across specific distributions.</description></item><item><title>Statistical Evidence: A Likelihood Paradigm</title><link>https://aakinshin.net/library/books/royall-statistical-evidence/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/royall-statistical-evidence/</guid><description/></item><item><title>Statistical Inference Using Extreme Order Statistics</title><link>https://aakinshin.net/library/papers/iii1975/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/iii1975/</guid><description>Reference James Pickands Iii “Statistical Inference Using Extreme Order Statistics” (1975) // The Annals of Statistics. Vol. 3. No 1. DOI: 10.1214/aos/1176343003
Bib @Article{iii1975, title = {Statistical Inference Using Extreme Order Statistics}, volume = {3}, issn = {0090-5364}, url = {https://projecteuclid.org/journals/annals-of-statistics/volume-3/issue-1/Statistical-Inference-Using-Extreme-Order-Statistics/10.1214/aos/1176343003.full}, doi = {10.1214/aos/1176343003}, number = {1}, urldate = {2022-08-08}, journal = {The Annals of Statistics}, author = {Iii, James Pickands}, month = {jan}, year = {1975} }</description></item><item><title>Statistical Literacy of obstetrics-gynecology Residents</title><link>https://aakinshin.net/library/papers/anderson2013/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/anderson2013/</guid><description>Reference Britta L Anderson, Sterling Williams, Jay Schulkin “Statistical literacy of obstetrics-gynecology residents” (2013) // Journal of graduate medical education. Publisher: The Accreditation Council for Graduate Medical Education Suite 2000, 515~…. Vol. 5. No 2. Pp. 272–275. DOI: 10.4300/jgme-d-12-00161.1
Bib @Article{anderson2013, title = {Statistical literacy of obstetrics-gynecology residents}, author = {Anderson, Britta L and Williams, Sterling and Schulkin, Jay}, journal = {Journal of graduate medical education}, volume = {5}, number = {2}, pages = {272--275}, year = {2013}, publisher = {The Accreditation Council for Graduate Medical Education Suite 2000, 515~…}, doi = {10.4300/jgme-d-12-00161.1} }</description></item><item><title>Statistical Literacy Training for obstetrics-gynecology Residents</title><link>https://aakinshin.net/library/quotes/58d4e333-4344-4fef-be8a-61e319433780/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/58d4e333-4344-4fef-be8a-61e319433780/</guid><description>Methods In 2011 we surveyed US obstetrics-gynecology residents participating in the Council for Resident Education in Obstetrics and Gynecology In-Training Examination about their statistical literacy and statistical literacy training.
Results Our response rate was 95% (4713 of 4961). About two-thirds (2980 of 4713) of the residents rated their statistical literacy training as adequate. Female respondents were more likely to rate their statistical literacy training poorly, with 25% (897 of 3575) indicating inadequate literacy compared with 17% (141 of 806) of the male respondents (P &amp;lt; .001). Respondents performed poorly on 2 statistical literacy questions, with only 26% (1222 of 4713) correctly answering a positive predictive value question and 42% (1989 of 4173) correctly defining a P value. A total of 51% (2391 of 4713) of respondents reported receiving statistical literacy training through a journal club, 29% (1359 of 4713) said they had informal training, 15% (711 of 4713) said that they had statistical literacy training as part of a course, and 11% (527 of 4713) said that they had no training.</description></item><item><title>Statistical Methods and Scientific Inference</title><link>https://aakinshin.net/library/papers/fisher1956/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/fisher1956/</guid><description>Reference Ronald A Fisher “Statistical methods and scientific inference” (1956) // Publisher: Hafner Publishing Co.. Oxford, England.
Abstract An explicit statement of the logical nature of statistical reasoning that has been implicitly required in the development and use of statistical techniques in the making of uncertain inferences and in the design of experiments. Included is a consideration of the concept of mathematical probability; a comparison of fiducial and confidence intervals; a comparison of the logic of tests of significance with the acceptance decision approach; and a discussion of the principles of prediction and estimation. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
Bib @Book{fisher1956, address = {Oxford, England}, series = {Statistical methods and scientific inference}, title = {Statistical methods and scientific inference}, abstract = {An explicit statement of the logical nature of statistical reasoning that has been implicitly required in the development and use of statistical techniques in the making of uncertain inferences and in the design of experiments. Included is a consideration of the concept of mathematical probability; a comparison of fiducial and confidence intervals; a comparison of the logic of tests of significance with the acceptance decision approach; and a discussion of the principles of prediction and estimation. (PsycINFO Database Record (c) 2016 APA, all rights reserved)}, publisher = {Hafner Publishing Co.}, author = {Fisher, Ronald A}, year = {1956}, note = {ZSCC: 0002421} }</description></item><item><title>Statistical Methods for Research Workers</title><link>https://aakinshin.net/library/papers/fisher1950/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/fisher1950/</guid><description>Reference Ronald Aylmer Fisher “Statistical methods for research workers” (1950) // Publisher: Springer. DOI: 10.1007/978-1-4612-4380-9_6
Bib @Book{fisher1950, title = {Statistical methods for research workers}, author = {Fisher, Ronald Aylmer}, year = {1950}, publisher = {Springer}, doi = {10.1007/978-1-4612-4380-9_6} }</description></item><item><title>Statistical Methods in the Journal</title><link>https://aakinshin.net/library/papers/horton2005/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/horton2005/</guid><description>Reference Nicholas J Horton, Suzanne S Switzer “Statistical methods in the journal” (2005) // New England Journal of Medicine. Publisher: Mass Medical Soc. Vol. 353. No 18. Pp. 1977–1979. DOI: 10.1056/NEJM200511033531823
Bib @Article{horton2005, title = {Statistical methods in the journal}, author = {Horton, Nicholas J and Switzer, Suzanne S}, journal = {New England Journal of Medicine}, volume = {353}, number = {18}, pages = {1977--1979}, year = {2005}, publisher = {Mass Medical Soc}, doi = {10.1056/NEJM200511033531823} }</description></item><item><title>Statistical Misleadingness of Error Bars</title><link>https://aakinshin.net/library/quotes/e42a2cde-94ae-44f9-b9bf-3f2c1eee39c9/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/e42a2cde-94ae-44f9-b9bf-3f2c1eee39c9/</guid><description>Climate studies often involve comparisons between estimates of some parameter derived from different observed and/or model-generated datasets. It is common practice to present estimates of two or more statistical quantities with error bars about each representing a confidence interval. If the error bars do not overlap, it is presumed that there is a statistically significant difference between them. In general, such a procedure is not valid and usually results in declaring statistical significance too infrequently. Simple examples that demonstrate the nature of this pitfall, along with some formulations, are presented. It is recommended that practitioners use standard hypothesis testing techniques that have been derived from statistical theory rather than the ad hoc approach involving error bars.</description></item><item><title>Statistical Power Analysis for the Behavioral Sciences</title><link>https://aakinshin.net/library/books/cohen-statistical-power-analysis-for-the-behavioral-sciences/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/cohen-statistical-power-analysis-for-the-behavioral-sciences/</guid><description/></item><item><title>Statistical Power of Negative Randomized Controlled Trials Presented at American Society for Clinical Oncology Annual Meetings</title><link>https://aakinshin.net/library/papers/bedard2007/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/bedard2007/</guid><description>Reference Philippe L Bedard, Monika K Krzyzanowska, Melania Pintilie, Ian F Tannock “Statistical Power of Negative Randomized Controlled Trials Presented at American Society for Clinical Oncology Annual Meetings” (2007) // Journal of Clinical Oncology. Publisher: American Society of Clinical Oncology (ASCO). Vol. 25. No 23. Pp. 3482–3487. DOI: 10.1200/jco.2007.11.3670
Bib @Article{bedard2007, title = {Statistical Power of Negative Randomized Controlled Trials Presented at American Society for Clinical Oncology Annual Meetings}, volume = {25}, issn = {1527-7755}, url = {http://dx.doi.org/10.1200/JCO.2007.11.3670}, doi = {10.1200/jco.2007.11.3670}, number = {23}, journal = {Journal of Clinical Oncology}, publisher = {American Society of Clinical Oncology (ASCO)}, author = {Bedard, Philippe L and Krzyzanowska, Monika K and Pintilie, Melania and Tannock, Ian F}, year = {2007}, month = {aug}, pages = {3482–3487} }</description></item><item><title>Statistical power, Sample size, and Their Reporting in Randomized Controlled Trials</title><link>https://aakinshin.net/library/papers/moher1994/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/moher1994/</guid><description>Reference D Moher, C Dulberg, G Wells “Statistical power, sample size, and their reporting in randomized controlled trials” (1994) // JAMA: The Journal of the American Medical Association. Publisher: American Medical Association (AMA). Vol. 272. No 2. Pp. 122. DOI: 10.1001/jama.1994.03520020048013
Bib @Article{moher1994, title = {Statistical power, sample size, and their reporting in randomized controlled trials}, volume = {272}, issn = {0098-7484}, url = {http://dx.doi.org/10.1001/jama.1994.03520020048013}, doi = {10.1001/jama.1994.03520020048013}, number = {2}, journal = {JAMA: The Journal of the American Medical Association}, publisher = {American Medical Association (AMA)}, author = {D Moher and C Dulberg and G Wells}, year = {1994}, month = {jul}, pages = {122} }</description></item><item><title>Statistical power: An Historical Introduction</title><link>https://aakinshin.net/library/papers/descoteaux2007/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/descoteaux2007/</guid><description>Reference Descôteaux J “Statistical power: An historical introduction” (2007) // Tutor. Quant. Methods Psychol.. Vol. 3. Pp. 28.
Bib @Article{descoteaux2007, title = {Statistical power: An historical introduction}, volume = {3}, journal = {Tutor. Quant. Methods Psychol.}, author = {J, Descôteaux}, year = {2007}, pages = {28}, custom-url-pdf = {https://www.tqmp.org/RegularArticles/vol03-2/p028/p028.pdf} }</description></item><item><title>Statistical Practices in high-impact Journals</title><link>https://aakinshin.net/library/quotes/8120cd40-f648-47d8-ac65-45509e4262af/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/8120cd40-f648-47d8-ac65-45509e4262af/</guid><description>What are the statistical practices of articles published in journals with a high impact factor? Are there differences compared with articles published in journals with a somewhat lower impact factor that have adopted editorial policies to reduce the impact of limitations of Null Hypothesis Significance Testing? To investigate these questions, the current study analyzed all articles related to psychological, neuropsychological and medical issues, published in 2011 in four journals with high impact factors: Science, Nature, The New England Journal of Medicine and The Lancet, and three journals with relatively lower impact factors: Neuropsychology, Journal of Experimental Psychology-Applied and the American Journal of Public Health. Results show that Null Hypothesis Significance Testing without any use of confidence intervals, effect size, prospective power and model estimation, is the prevalent statistical practice used in articles published in Nature, 89%, followed by articles published in Science, 42%.</description></item><item><title>Statistical Practices of Educational researchers: An Analysis of Their ANOVA, MANOVA, and ANCOVA Analyses</title><link>https://aakinshin.net/library/papers/keselman1998/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/keselman1998/</guid><description>Reference Keselman H J, Huberty C J, Lix L M, Olejnik S, Cribbie R A, Donahue B, Kowalchuk R K, Lowman L L, Petoskey M D, Keselman J C, Levin J R “Statistical practices of educational researchers: An analysis of their ANOVA, MANOVA, and ANCOVA analyses” (1998) // Rev. Educ. Res.. Vol. 68. Pp. 350. DOI: 10.2307/1170601
Bib @Article{keselman1998, title = {Statistical practices of educational researchers: An analysis of their ANOVA, MANOVA, and ANCOVA analyses}, volume = {68}, journal = {Rev. Educ. Res.}, author = {J, Keselman H and J, Huberty C and M, Lix L and S, Olejnik and A, Cribbie R and B, Donahue and K, Kowalchuk R and L, Lowman L and D, Petoskey M and C, Keselman J and R, Levin J}, year = {1998}, pages = {350}, doi = {10.2307/1170601} }</description></item><item><title>Statistical Reform in Psychology: Is Anything Changing?</title><link>https://aakinshin.net/library/papers/cumming2007/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/cumming2007/</guid><description>Reference Geoff Cumming, Fiona Fidler, Martine Leonard, Pavel Kalinowski, Ashton Christiansen, Anita Kleinig, Jessica Lo, Natalie McMenamin, Sarah Wilson “Statistical Reform in Psychology: Is Anything Changing?” (2007) // Psychological Science. Publisher: SAGE Publications. Vol. 18. No 3. Pp. 230–232. DOI: 10.1111/j.1467-9280.2007.01881.x
Bib @Article{cumming2007, title = {Statistical Reform in Psychology: Is Anything Changing?}, volume = {18}, issn = {1467-9280}, url = {http://dx.doi.org/10.1111/j.1467-9280.2007.01881.x}, doi = {10.1111/j.1467-9280.2007.01881.x}, number = {3}, journal = {Psychological Science}, publisher = {SAGE Publications}, author = {Cumming, Geoff and Fidler, Fiona and Leonard, Martine and Kalinowski, Pavel and Christiansen, Ashton and Kleinig, Anita and Lo, Jessica and McMenamin, Natalie and Wilson, Sarah}, year = {2007}, month = {mar}, pages = {230–232} }</description></item><item><title>Statistical Rethinking: A Bayesian Course with Examples in R and Stan</title><link>https://aakinshin.net/library/books/mcelreath-statistical-rethinking/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/mcelreath-statistical-rethinking/</guid><description/></item><item><title>Statistical Significance and Effect Size reporting: Portrait of a Possible Future</title><link>https://aakinshin.net/library/papers/thompson1998/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/thompson1998/</guid><description>Reference Thompson B “Statistical significance and effect size reporting: Portrait of a possible future” (1998) // Res. Schools. Vol. 5. Pp. 33.
Bib @Article{thompson1998, title = {Statistical significance and effect size reporting: Portrait of a possible future}, volume = {5}, journal = {Res. Schools}, author = {B, Thompson}, year = {1998}, pages = {33} }</description></item><item><title>Statistical tests, P values, Confidence intervals, and power: A Guide to Misinterpretations</title><link>https://aakinshin.net/library/papers/greenland2016/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/greenland2016/</guid><description>Reference Sander Greenland, Stephen J Senn, Kenneth J Rothman, John B Carlin, Charles Poole, Steven N Goodman, Douglas G Altman “Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations” (2016) // European Journal of Epidemiology. Vol. 31. No 4. Pp. 337–350. DOI: 10.1007/s10654-016-0149-3
Bib @Article{greenland2016, title = {Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations}, volume = {31}, issn = {0393-2990, 1573-7284}, shorttitle = {Statistical tests, P values, confidence intervals, and power}, url = {http://link.springer.com/10.1007/s10654-016-0149-3}, doi = {10.1007/s10654-016-0149-3}, language = {en}, number = {4}, urldate = {2020-01-08}, journal = {European Journal of Epidemiology}, author = {Greenland, Sander and Senn, Stephen J and Rothman, Kenneth J and Carlin, John B and Poole, Charles and Goodman, Steven N and Altman, Douglas G}, month = {apr}, year = {2016}, note = {ZSCC: 0000855}, pages = {337--350} }</description></item><item><title>Statistics</title><link>https://aakinshin.net/library/books/freedman-statistics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/freedman-statistics/</guid><description/></item><item><title>Statistics and Death from Meningococcal Disease in Children</title><link>https://aakinshin.net/library/papers/perera2006/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/perera2006/</guid><description>Reference Rafael Perera “Statistics and death from meningococcal disease in children” (2006) // BMJ. Publisher: BMJ. Vol. 332. No 7553. Pp. 1297–1298. DOI: 10.1136/bmj.332.7553.1297
Bib @Article{perera2006, title = {Statistics and death from meningococcal disease in children}, volume = {332}, issn = {1468-5833}, url = {http://dx.doi.org/10.1136/bmj.332.7553.1297}, doi = {10.1136/bmj.332.7553.1297}, number = {7553}, journal = {BMJ}, publisher = {BMJ}, author = {Perera, Rafael}, year = {2006}, month = {jun}, pages = {1297–1298} }</description></item><item><title>Statistics Done Wrong: The Woefully Complete Guide</title><link>https://aakinshin.net/library/books/reinhart-statistics-done-wrong/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/reinhart-statistics-done-wrong/</guid><description/></item><item><title>Stopping Randomized Trials Early for Benefit and Estimation of Treatment Effects Systematic Review and Meta-regression Analysis</title><link>https://aakinshin.net/library/papers/bassler2010/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/bassler2010/</guid><description>Reference Dirk Bassler “Stopping Randomized Trials Early for Benefit and Estimation of Treatment Effects Systematic Review and Meta-regression Analysis” (2010) // JAMA. Publisher: American Medical Association (AMA). Vol. 303. No 12. Pp. 1180. DOI: 10.1001/jama.2010.310
Bib @Article{bassler2010, title = {Stopping Randomized Trials Early for Benefit and Estimation of Treatment Effects Systematic Review and Meta-regression Analysis}, volume = {303}, issn = {0098-7484}, url = {http://dx.doi.org/10.1001/jama.2010.310}, doi = {10.1001/jama.2010.310}, number = {12}, journal = {JAMA}, publisher = {American Medical Association (AMA)}, author = {Bassler, Dirk}, year = {2010}, month = {mar}, pages = {1180} }</description></item><item><title>Studies in the History of Probability and Statistics. XXXII: Laplace, Fisher and the Discovery of the Concept of Sufficiency</title><link>https://aakinshin.net/library/papers/stigler1973/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/stigler1973/</guid><description>Reference Stephen M Stigler “Studies in the History of Probability and Statistics. XXXII: Laplace, Fisher and the Discovery of the Concept of Sufficiency” (1973) // Biometrika. Publisher: Oxford University Press. Vol. 60. No 3. Pp. 439–445. DOI: 10.1093/biomet/60.3.439
Bib @Article{stigler1973, title = {Studies in the History of Probability and Statistics. XXXII: Laplace, Fisher and the Discovery of the Concept of Sufficiency}, author = {Stigler, Stephen M}, journal = {Biometrika}, volume = {60}, number = {3}, pages = {439--445}, year = {1973}, publisher = {Oxford University Press}, doi = {10.1093/biomet/60.3.439} }</description></item><item><title>Surely God Loves 51 km/h Nearly as Much as 49 km/h?</title><link>https://aakinshin.net/library/web/6847d5ff77f9ca7d5903f1bd2cc122a5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/web/6847d5ff77f9ca7d5903f1bd2cc122a5/</guid><description/></item><item><title>Survey Research and Self-Defense Gun Use: An Explanation of Extreme Overestimates</title><link>https://aakinshin.net/library/papers/hemenway1997/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/hemenway1997/</guid><description>Reference David Hemenway “Survey Research and Self-Defense Gun Use: An Explanation of Extreme Overestimates” (1997) // The Journal of Criminal Law and Criminology (1973-). Publisher: JSTOR. Vol. 87. No 4. Pp. 1430. DOI: 10.2307/1144020
Abstract Gary Kleck and Marc Gertz conducted a survey of civilian defensive gun use in 1992. In 1993, Kleck began publicizing the estimate that civilians use guns in self-defense against offenders up to 2.5 million times each year.&amp;rsquo; This figure has been widely used by the National Rifle Association and by gun advocates. It is also often cited in the media and even in Congress. The Kleck and Gertz (K-G) paper has now been published. It is clear, however, that its conclusions cannot be accepted as valid.
Bib @Article{hemenway1997, title = {Survey Research and Self-Defense Gun Use: An Explanation of Extreme Overestimates}, abstract = {Gary Kleck and Marc Gertz conducted a survey of civilian defensive gun use in 1992. In 1993, Kleck began publicizing the estimate that civilians use guns in self-defense against offenders up to 2.5 million times each year.&amp;#39; This figure has been widely used by the National Rifle Association and by gun advocates. It is also often cited in the media and even in Congress. The Kleck and Gertz (K-G) paper has now been published. It is clear, however, that its conclusions cannot be accepted as valid.}, volume = {87}, issn = {0091-4169}, url = {http://dx.doi.org/10.2307/1144020}, doi = {10.2307/1144020}, number = {4}, journal = {The Journal of Criminal Law and Criminology (1973-)}, publisher = {JSTOR}, author = {Hemenway, David}, year = {1997}, pages = {1430} }</description></item><item><title>Survey Sampling</title><link>https://aakinshin.net/library/papers/kish1965/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/kish1965/</guid><description>Reference L Kish “Survey sampling” (1965) // Publisher: John Wiley &amp;amp; Sons, Inc., New York, London. ISBN: 0-471-10949-5.
Bib @Book{kish1965, title = {Survey sampling}, author = {Kish, L}, year = {1965}, publisher = {John Wiley \&amp;amp; Sons, Inc., New York, London}, isbn = {0-471-10949-5} }</description></item><item><title>Swaying an Entire Study</title><link>https://aakinshin.net/library/quotes/c81a5510-8273-4df8-aaef-aeadc928b20f/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/c81a5510-8273-4df8-aaef-aeadc928b20f/</guid><description>In medical practice, clinically unexpected measurements might be quite properly handled by the remeasurement, removal, or reclassification of patients. If these habits are not prevented during clinical research, how much of each is needed to sway an entire study?</description></item><item><title>The (mis)reporting of Statistical Results in Psychology Journals</title><link>https://aakinshin.net/library/papers/bakker2011/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/bakker2011/</guid><description>Reference Marjan Bakker, Jelte M. Wicherts “The (mis)reporting of statistical results in psychology journals” (2011) // Behavior Research Methods. Publisher: Springer Science and Business Media LLC. Vol. 43. No 3. Pp. 666–678. DOI: 10.3758/s13428-011-0089-5
Bib @Article{bakker2011, title = {The (mis)reporting of statistical results in psychology journals}, volume = {43}, issn = {1554-3528}, url = {http://dx.doi.org/10.3758/s13428-011-0089-5}, doi = {10.3758/s13428-011-0089-5}, number = {3}, journal = {Behavior Research Methods}, publisher = {Springer Science and Business Media LLC}, author = {Bakker, Marjan and Wicherts, Jelte M.}, year = {2011}, month = {apr}, pages = {666–678} }</description></item><item><title>The 3% Usage of Power Analysis</title><link>https://aakinshin.net/library/quotes/b6157da6-8408-4226-a073-c1a0ac73fdb4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/b6157da6-8408-4226-a073-c1a0ac73fdb4/</guid><description>Over-reliance on significance testing has been heavily criticized in psychology. Therefore the American Psychological Association recommended supplementing the p value with additional elements such as effect sizes, confidence intervals, and considering statistical power seriously. This article elaborates the conclusions that can be drawn when these measures accompany the p value. An analysis of over 30 summary papers (including over 6,000 articles) reveals that, if at all, only effect sizes are reported in addition to p’s (38%). Only every 10th article provides a confidence interval and statistical power is reported in only 3% of articles.</description></item><item><title>The ASA Statement on p-Values: Context, Process, and Purpose</title><link>https://aakinshin.net/library/papers/wasserstein2016/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/wasserstein2016/</guid><description>Reference Ronald L. Wasserstein, Nicole A. Lazar “The ASA Statement on p-Values: Context, Process, and Purpose” (2016) // The American Statistician. Publisher: Informa UK Limited. Vol. 70. No 2. Pp. 129–133. DOI: 10.1080/00031305.2016.1154108
Bib @Article{wasserstein2016, title = {The ASA Statement on p-Values: Context, Process, and Purpose}, volume = {70}, issn = {1537-2731}, url = {http://dx.doi.org/10.1080/00031305.2016.1154108}, doi = {10.1080/00031305.2016.1154108}, number = {2}, journal = {The American Statistician}, publisher = {Informa UK Limited}, author = {Wasserstein, Ronald L. and Lazar, Nicole A.}, year = {2016}, month = {apr}, pages = {129–133} }</description></item><item><title>The Bayesian New Statistics: Hypothesis testing, Estimation, Meta-Analysis, and Power Analysis from a Bayesian Perspective</title><link>https://aakinshin.net/library/papers/kruschke2018/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/kruschke2018/</guid><description>Reference John K Kruschke, Torrin M Liddell “The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective” (2018) // Psychonomic Bulletin &amp;amp; Review. Vol. 25. No 1. Pp. 178–206. DOI: 10.3758/s13423-016-1221-4
Abstract In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed “the New Statistics” (Cumming 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequentist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis.
Bib @Article{kruschke2018, title = {The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective}, volume = {25}, issn = {1531-5320}, shorttitle = {The Bayesian New Statistics}, url = {https://doi.org/10.3758/s13423-016-1221-4}, doi = {10.3758/s13423-016-1221-4}, abstract = {In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed “the New Statistics” (Cumming 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequentist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis.</description></item><item><title>The Beta Error and Sample Size Determination in Clinical Trials in Emergency Medicine</title><link>https://aakinshin.net/library/papers/brown1987/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/brown1987/</guid><description>Reference Charles G Brown, Gabor D Kelen, James J Ashton, Howard A Werman “The beta error and sample size determination in clinical trials in emergency medicine” (1987) // Annals of Emergency Medicine. Publisher: Elsevier BV. Vol. 16. No 2. Pp. 183–187. DOI: 10.1016/s0196-0644(87)80013-6
Bib @Article{brown1987, title = {The beta error and sample size determination in clinical trials in emergency medicine}, volume = {16}, issn = {0196-0644}, url = {http://dx.doi.org/10.1016/S0196-0644(87)80013-6}, doi = {10.1016/s0196-0644(87)80013-6}, number = {2}, journal = {Annals of Emergency Medicine}, publisher = {Elsevier BV}, author = {Brown, Charles G and Kelen, Gabor D and Ashton, James J and Werman, Howard A}, year = {1987}, month = {feb}, pages = {183–187} }</description></item><item><title>The Difference Between “Significant” And “Not Significant” Is Not Itself Statistically Significant</title><link>https://aakinshin.net/library/papers/gelman2006/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/gelman2006/</guid><description>Reference Andrew Gelman, Hal Stern “The Difference Between “Significant” and “Not Significant” is not Itself Statistically Significant” (2006) // The American Statistician. Publisher: Informa UK Limited. Vol. 60. No 4. Pp. 328–331. DOI: 10.1198/000313006x152649
Abstract It is common to summarize statistical comparisons by declarations of statistical significance or nonsignificance. Here we discuss one problem with such declarations, namely that changes in statistical significance are often not themselves statistically significant. By this, we are not merely making the commonplace observation that any particular threshold is arbitrary—for example, only a small change is required to move an estimate from a 5.1% significance level to 4.9%, thus moving it into statistical significance. Rather, we are pointing out that even large changes in significance levels can correspond to small, nonsignificant changes in the underlying quantities. The error we describe is conceptually different from other oftcited problems—that statistical significance is not the same as practical importance, that dichotomization into significant and nonsignificant results encourages the dismissal of observed differences in favor of the usually less interesting null hypothesis of no difference, and that any particular threshold for declaring significance is arbitrary. We are troubled by all of these concerns and do not intend to minimize their importance. Rather, our goal is to bring attention to this additional error of interpretation. We illustrate with a theoretical example and two applied examples. The ubiquity of this statistical error leads us to suggest that students and practitioners be made more aware that the difference between &amp;ldquo;significant&amp;rdquo; and &amp;ldquo;not significant&amp;rdquo; is not itself statistically significant.
Bib @Article{gelman2006, title = {The Difference Between “Significant” and “Not Significant” is not Itself Statistically Significant}, abstract = {It is common to summarize statistical comparisons by declarations of statistical significance or nonsignificance. Here we discuss one problem with such declarations, namely that changes in statistical significance are often not themselves statistically significant.</description></item><item><title>The Earth is Flat (p>0.05): Significance Thresholds and the Crisis of Unreplicable Research</title><link>https://aakinshin.net/library/papers/amrhein2017/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/amrhein2017/</guid><description>Reference Valentin Amrhein, Fränzi Korner-Nievergelt, Tobias Roth “The earth is flat (p\textgreater0.05): significance thresholds and the crisis of unreplicable research” (2017) // PeerJ. Vol. 5. Pp. e3544. DOI: 10.7717/peerj.3544
Abstract The widespread use of ‘statistical significance’ as a license for making a claim of a scientific finding leads to considerable distortion of the scientific process (according to the American Statistical Association). We review why degrading
Bib @Article{amrhein2017, title = {The earth is flat (p\textgreater0.05): significance thresholds and the crisis of unreplicable research}, volume = {5}, issn = {2167-8359}, shorttitle = {The earth is flat (p\textgreater0.05)}, url = {https://peerj.com/articles/3544}, doi = {10.7717/peerj.3544}, abstract = {The widespread use of ‘statistical significance’ as a license for making a claim of a scientific finding leads to considerable distortion of the scientific process (according to the American Statistical Association). We review why degrading}, language = {en}, urldate = {2020-01-07}, journal = {PeerJ}, author = {Amrhein, Valentin and Korner-Nievergelt, Fränzi and Roth, Tobias}, month = {jul}, year = {2017}, note = {ZSCC: 0000098}, pages = {e3544} }</description></item><item><title>The Earth is Round (p &lt; .05)</title><link>https://aakinshin.net/library/papers/cohen1994/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/cohen1994/</guid><description>Reference Jacob Cohen “The earth is round (p &amp;lt; .05)” (1994) // American Psychologist. Publisher: American Psychological Association (APA). Vol. 49. No 12. Pp. 997–1003. DOI: 10.1037/0003-066x.49.12.997
Bib @Article{cohen1994, title = {The earth is round (p &amp;amp;lt; .05)}, volume = {49}, issn = {0003-066X}, url = {http://dx.doi.org/10.1037/0003-066X.49.12.997}, doi = {10.1037/0003-066x.49.12.997}, number = {12}, journal = {American Psychologist}, publisher = {American Psychological Association (APA)}, author = {Cohen, Jacob}, year = {1994}, month = {dec}, pages = {997–1003} }</description></item><item><title>The Essential Guide to Effect Sizes: Statistical Power, Meta-Analysis, and the Interpretation of Research Results</title><link>https://aakinshin.net/library/books/ellis-the-essential-guide-to-effect-sizes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/ellis-the-essential-guide-to-effect-sizes/</guid><description/></item><item><title>The Failure of Null Hypothesis Significance Testing When Studying Incremental Changes, and What to Do about It</title><link>https://aakinshin.net/library/papers/gelman2017/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/gelman2017/</guid><description>Reference Andrew Gelman “The Failure of Null Hypothesis Significance Testing When Studying Incremental Changes, and What to Do About It” (2017) // Personality and Social Psychology Bulletin. Publisher: SAGE Publications. Vol. 44. No 1. Pp. 16–23. DOI: 10.1177/0146167217729162
Bib @Article{gelman2017, title = {The Failure of Null Hypothesis Significance Testing When Studying Incremental Changes, and What to Do About It}, volume = {44}, issn = {1552-7433}, url = {http://dx.doi.org/10.1177/0146167217729162}, doi = {10.1177/0146167217729162}, number = {1}, journal = {Personality and Social Psychology Bulletin}, publisher = {SAGE Publications}, author = {Gelman, Andrew}, year = {2017}, month = {sep}, pages = {16–23} }</description></item><item><title>The Fallacy of Placing Confidence in Confidence Intervals</title><link>https://aakinshin.net/library/papers/morey2015/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/morey2015/</guid><description>Reference Richard D. Morey, Rink Hoekstra, Jeffrey N. Rouder, Michael D. Lee, Eric-Jan Wagenmakers “The fallacy of placing confidence in confidence intervals” (2015) // Psychonomic Bulletin &amp;amp; Review. Publisher: Springer Science and Business Media LLC. Vol. 23. No 1. Pp. 103–123. DOI: 10.3758/s13423-015-0947-8
Abstract Interval estimates – estimates of parameters that include an allowance for sampling uncertainty – have long been touted as a key component of statistical analyses. There are several kinds of interval estimates, but the most popular are confidence intervals (CIs): intervals that contain the true parameter value in some known proportion of repeated samples, on average. The width of confidence intervals is thought to index the precision of an estimate; CIs are thought to be a guide to which parameter values are plausible or reasonable; and the confidence coefficient of the interval (e.g., 95 %) is thought to index the plausibility that the true parameter is included in the interval. We show in a number of examples that CIs do not necessarily have any of these properties, and can lead to unjustified or arbitrary inferences. For this reason, we caution against relying upon confidence interval theory to justify interval estimates, and suggest that other theories of interval estimation should be used instead.
Bib @Article{morey2015, title = {The fallacy of placing confidence in confidence intervals}, abstract = {Interval estimates – estimates of parameters that include an allowance for sampling uncertainty – have long been touted as a key component of statistical analyses. There are several kinds of interval estimates, but the most popular are confidence intervals (CIs): intervals that contain the true parameter value in some known proportion of repeated samples, on average. The width of confidence intervals is thought to index the precision of an estimate; CIs are thought to be a guide to which parameter values are plausible or reasonable; and the confidence coefficient of the interval (e.</description></item><item><title>The Fluctuating Female Vote: Politics, Religion, and the Ovulatory Cycle</title><link>https://aakinshin.net/library/papers/durante2013/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/durante2013/</guid><description>Reference Kristina M. Durante, Ashley Rae, Vladas Griskevicius “The Fluctuating Female Vote: Politics, Religion, and the Ovulatory Cycle” (2013) // Psychological Science. Publisher: SAGE Publications. Vol. 24. No 6. Pp. 1007–1016. DOI: 10.1177/0956797612466416
Bib @Article{durante2013, title = {The Fluctuating Female Vote: Politics, Religion, and the Ovulatory Cycle}, volume = {24}, issn = {1467-9280}, url = {http://dx.doi.org/10.1177/0956797612466416}, doi = {10.1177/0956797612466416}, number = {6}, journal = {Psychological Science}, publisher = {SAGE Publications}, author = {Durante, Kristina M. and Rae, Ashley and Griskevicius, Vladas}, year = {2013}, month = {apr}, pages = {1007–1016} }</description></item><item><title>The Harm Done by Tests of Significance</title><link>https://aakinshin.net/library/papers/hauer2004/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/hauer2004/</guid><description>Reference Ezra Hauer “The harm done by tests of significance” (2004) // Accident Analysis &amp;amp; Prevention. Publisher: Elsevier BV. Vol. 36. No 3. Pp. 495–500. DOI: 10.1016/s0001-4575(03)00036-8
Abstract Three historical episodes in which the application of null hypothesis significance testing (NHST) led to the mis-interpretation of data are described. It is argued that the pervasive use of this statistical ritual impedes the accumulation of knowledge and is unfit for use.
Bib @Article{hauer2004, title = {The harm done by tests of significance}, volume = {36}, issn = {0001-4575}, url = {http://dx.doi.org/10.1016/S0001-4575(03)00036-8}, abstract = {Three historical episodes in which the application of null hypothesis significance testing (NHST) led to the mis-interpretation of data are described. It is argued that the pervasive use of this statistical ritual impedes the accumulation of knowledge and is unfit for use.}, doi = {10.1016/s0001-4575(03)00036-8}, number = {3}, journal = {Accident Analysis &amp;amp;amp; Prevention}, publisher = {Elsevier BV}, author = {Hauer, Ezra}, year = {2004}, month = {may}, pages = {495–500} }</description></item><item><title>The Illusion of Attaining Improbability</title><link>https://aakinshin.net/library/quotes/7a038512-b3c5-496a-b7ac-e5c900fca23b/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/7a038512-b3c5-496a-b7ac-e5c900fca23b/</guid><description>One problem arises from a misapplication of deductive syllogistic reasoning. Falk and Greenbaum (in press) called this the &amp;ldquo;illusion of probabilistic proof by contradiction&amp;rdquo; or the &amp;ldquo;illusion of attaining improbability.&amp;rdquo; Gigerenzer (1993) called it the &amp;ldquo;permanent illusion&amp;rdquo; and the &amp;ldquo;Bayesian Id&amp;rsquo;s wishful thinking,&amp;rdquo; part of the &amp;ldquo;hybrid logic&amp;rdquo; of contemporary statistical inference—a mishmash of Fisher and Neyman-Pearson, with invalid Bayesian interpretation.</description></item><item><title>The Importance of Effect Magnitude Over Statistical Hypotheses</title><link>https://aakinshin.net/library/quotes/c6000a61-924a-47b7-805c-2fc024a131bb/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/c6000a61-924a-47b7-805c-2fc024a131bb/</guid><description>Instead of asking “how many more crashes?” and the authors chose to ask “are we sufficiently sure that the effect was not zero?” This substitution of questions led to all the subsequent entanglements. These can all be avoided by not testing statistical hypotheses when the research question is about the effect of some treatment; by returning to common sense and the mainstream of science and providing estimates of effect magnitude and its standard error instead.</description></item><item><title>The Inappropriateness of Significance Tests</title><link>https://aakinshin.net/library/quotes/441a516a-9f37-46bc-afb1-fd6165503b80/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/441a516a-9f37-46bc-afb1-fd6165503b80/</guid><description>All references to statistical hypothesis testing and statistical significance should be removed from the paper. I ask that you delete p values as well as comments about statistical significance. If you do not agree with my standards (concerning the inappropriateness of significance tests), you should feel free to argue the point, or simply ignore what you may consider to be my misguided view, by publishing elsewher.</description></item><item><title>The Influence Curve and Its Role in Robust Estimation</title><link>https://aakinshin.net/library/papers/hampel1974/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/hampel1974/</guid><description>Reference Frank R Hampel “The influence curve and its role in robust estimation” (1974) // Journal of the american statistical association. Publisher: Taylor &amp;amp; Francis. Vol. 69. No 346. Pp. 383–393. DOI: 10.2307/2285666
Bib @Article{hampel1974, title = {The influence curve and its role in robust estimation}, author = {Hampel, Frank R}, journal = {Journal of the american statistical association}, volume = {69}, number = {346}, pages = {383--393}, year = {1974}, publisher = {Taylor \&amp;amp; Francis}, doi = {10.2307/2285666} }</description></item><item><title>The Influence of Journal Prestige on the Inflation of Effect Sizes in Small Trials</title><link>https://aakinshin.net/library/quotes/79991435-cde7-4963-8f62-2bf812a39fda/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/79991435-cde7-4963-8f62-2bf812a39fda/</guid><description>We found that small trials published in NEJM, JAMA and Lancet were more likely to display more favourable results for experimental interventions compared with trials in other publication venues. Inflated effect sizes were seen primarily for early small trials in these prominent journals. Therefore, the results of small trials with spectacular early promises for large treatment effects should be seen with great caution. Conversely, for large trials, effect estimates are likely to be more reliable. Small-study effects have been previously documented in the randomized trials literature. However, the results of our study provide further insight suggesting the possibility of a specific interaction with further exaggerated effects when the limited evidence from small trials appears in the most prestigious journals. Also, the inflation of effects in early randomized trials on particular interventions appears to be quite specific to these most prestigious journals. Some modest heterogeneity was seen in the two tertiles with higher events, but heterogeneity is difficult to determine in the tertile with lower events, because of the wide uncertainty in the ROR for single topics, when there is limited evidence.</description></item><item><title>The Lady Tasting Tea: How Statistics Revolutionized Science in the Twentieth Century</title><link>https://aakinshin.net/library/books/salsburg-the-lady-tasting-tea/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/salsburg-the-lady-tasting-tea/</guid><description/></item><item><title>The Median of the Poisson Distribution</title><link>https://aakinshin.net/library/papers/adell2005/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/adell2005/</guid><description>Reference Jos'e A Adell, P Jodr'a “The median of the Poisson distribution” (2005) // Metrika. Publisher: Springer. Vol. 61. No 3. Pp. 337–346. DOI: 10.1007/s001840400350
Bib @Article{adell2005, title = {The median of the Poisson distribution}, author = {Adell, Jos\&amp;#39;e A and Jodr\&amp;#39;a, P}, journal = {Metrika}, volume = {61}, number = {3}, pages = {337--346}, year = {2005}, publisher = {Springer}, doi = {10.1007/s001840400350} }</description></item><item><title>The Most Dangerous Equation</title><link>https://aakinshin.net/library/papers/wainer2007/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/wainer2007/</guid><description>Reference Howard Wainer “The Most Dangerous Equation” (2007) // American Scientist. Publisher: Sigma Xi. Vol. 95. No 3. Pp. 249. DOI: 10.1511/2007.65.249
Bib @Article{wainer2007, title = {The Most Dangerous Equation}, volume = {95}, issn = {1545-2786}, url = {https://www.americanscientist.org/article/the-most-dangerous-equation}, doi = {10.1511/2007.65.249}, number = {3}, journal = {American Scientist}, publisher = {Sigma Xi}, author = {Wainer, Howard}, year = {2007}, pages = {249}, custom-url-pdf = {http://nsmn1.uh.edu/dgraur/niv/TheMostDangerousEquation.pdf} }</description></item><item><title>The Neuroscience of Low Statistical Power</title><link>https://aakinshin.net/library/quotes/76c951e9-c936-4b30-919f-d3d3fd7f7227/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/76c951e9-c936-4b30-919f-d3d3fd7f7227/</guid><description>A study with low statistical power has a reduced chance of detecting a true effect, but it is less well appreciated that low power also reduces the likelihood that a statistically significant result reflects a true effect. Here, we show that the average statistical power of studies in the neurosciences is very low. The consequences of this include overestimates of effect size and low reproducibility of results. There are also ethical dimensions to this problem, as unreliable research is inefficient and wasteful. Improving reproducibility in neuroscience is a key priority and requires attention to well-established but often ignored methodological principles.</description></item><item><title>The normal, Edgeworth, Saddlepoint and Uniform Approximations to the Wilcoxon–Mann–Whitney null-distribution: A Numerical Comparison</title><link>https://aakinshin.net/library/papers/bean2004/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/bean2004/</guid><description>Reference Raphaël Bean, Sorana Froda, Constance Van Eeden “The normal, Edgeworth, saddlepoint and uniform approximations to the Wilcoxon–Mann–Whitney null-distribution: a numerical comparison” (2004) // Journal of Nonparametric Statistics. Vol. 16. No 1-2. Pp. 279–288. DOI: 10.1080/10485250310001622677
Bib @Article{bean2004, title = {The normal, Edgeworth, saddlepoint and uniform approximations to the Wilcoxon–Mann–Whitney null-distribution: a numerical comparison}, volume = {16}, issn = {1048-5252, 1029-0311}, shorttitle = {The normal, Edgeworth, saddlepoint and uniform approximations to the Wilcoxon–Mann–Whitney null-distribution}, url = {http://www.tandfonline.com/doi/abs/10.1080/10485250310001622677}, doi = {10.1080/10485250310001622677}, language = {en}, number = {1-2}, urldate = {2023-05-04}, journal = {Journal of Nonparametric Statistics}, author = {Bean, Raphaël and Froda, Sorana and Van Eeden, Constance}, month = {feb}, year = {2004}, pages = {279--288} }</description></item><item><title>The Null Field</title><link>https://aakinshin.net/library/quotes/f05e3cd0-fb35-4654-b121-421c58c5f5e4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/f05e3cd0-fb35-4654-b121-421c58c5f5e4/</guid><description>Let us suppose that in a research field there are no true findings at all to be discovered. History of science teaches us that scientific endeavor has often in the past wasted effort in fields with absolutely no yield of true scientific information, at least based on our current understanding. In such a “null field,” one would ideally expect all observed effect sizes to vary by chance around the null in the absence of bias. The extent that observed findings deviate from what is expected by chance alone would be simply a pure measure of the prevailing bias.</description></item><item><title>The Null Hypothesis is Always False</title><link>https://aakinshin.net/library/quotes/9d1c1cff-0bdb-4fd7-b146-da704a7caa82/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/9d1c1cff-0bdb-4fd7-b146-da704a7caa82/</guid><description>I believe is generally recognized by statisticians today and by thoughtful social scientists, the null hypothesis, taken literally, is always false.</description></item><item><title>The Null Hypothesis Ritual</title><link>https://aakinshin.net/library/quotes/af7c74d8-e8ac-4736-958a-ef3bd67c4385/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/af7c74d8-e8ac-4736-958a-ef3bd67c4385/</guid><description>After 4 decades of severe criticism, the ritual of null hypothesis significance testing — mechanical dichotomous decisions around a sacred .05 criterion — still persists.</description></item><item><title>The Overlap Method</title><link>https://aakinshin.net/library/quotes/eb3039e9-e45a-411d-ac91-4885d0049c0b/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/eb3039e9-e45a-411d-ac91-4885d0049c0b/</guid><description>The overlap method is simple, and it is convenient when lists or graphs of confidence intervals are presented. It can be useful as a quick and relatively rough method for exploratory data analysis. It should not be regarded as an optimal method for significance testing, however, given its conservatism and low power relative to the standard method in the common situation that we have considered. Thus, the overlap method should not be used for formal significance testing unless the data analyst is aware of its deficiencies and unless the information needed to carry out a more appropriate procedure is unavailable.</description></item><item><title>The P Value and Statistical significance: Misunderstandings, Explanations, Challenges, and Alternatives</title><link>https://aakinshin.net/library/papers/andrade2019/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/andrade2019/</guid><description>Reference Chittaranjan Andrade “The P value and statistical significance: Misunderstandings, explanations, challenges, and alternatives” (2019) // Indian Journal of Psychological Medicine. Vol. 41. No 3. Pp. 210. DOI: 10.4103/IJPSYM.IJPSYM_193_19
Bib @Article{andrade2019, title = {The P value and statistical significance: Misunderstandings, explanations, challenges, and alternatives}, volume = {41}, issn = {0253-7176}, shorttitle = {The P value and statistical significance}, url = {http://www.ijpm.info/text.asp?2019/41/3/210/258415}, doi = {10.4103/IJPSYM.IJPSYM_193_19}, language = {en}, number = {3}, urldate = {2020-01-07}, journal = {Indian Journal of Psychological Medicine}, author = {Andrade, Chittaranjan}, year = {2019}, note = {ZSCC: 0000004}, pages = {210} }</description></item><item><title>The P Value Fallacy</title><link>https://aakinshin.net/library/quotes/aeb58f62-484b-49a5-853c-8f72e49c82e3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/aeb58f62-484b-49a5-853c-8f72e49c82e3/</guid><description>An important problem exists in the interpretation of modern medical research data: Biological understanding and previous research play little formal role in the interpretation of quantitative results. This phenomenon is manifest in the discussion sections of research articles and ultimately can affect the reliability of conclusions. The standard statistical approach has created this situation by promoting the illusion that conclusions can be produced with certain “error rates,” without consideration of information from outside the experiment. This statistical approach, the key components of which are P values and hypothesis tests, is widely perceived as a mathematically coherent approach to inference. There is little appreciation in the medical community that the methodology is an amalgam of incompatible elements, whose utility for scientific inference has been the subject of intense debate among statisticians for almost 70 years. This article introduces some of the key elements of that debate and traces the appeal and adverse impact of this methodology to the P value fallacy, the mistaken idea that a single number can capture both the long-run outcomes of an experiment and the evidential meaning of a single result. This argument is made as a prelude to the suggestion that another measure of evidence should be used—the Bayes factor, which properly separates issues of long-run behavior from evidential strength and allows the integration of background knowledge with statistical findings.</description></item><item><title>The p-p Plot as a Method of Comparing Treatment Effects</title><link>https://aakinshin.net/library/papers/holmgren1995/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/holmgren1995/</guid><description>Reference Holmgren E C “The p-p plot as a method of comparing treatment effects” (1995) // J. Am. Statist. Assoc.. Vol. 90. Pp. 360. DOI: 10.1080/01621459.1995.10476520
Bib @Article{holmgren1995, title = {The p-p plot as a method of comparing treatment effects}, volume = {90}, journal = {J. Am. Statist. Assoc.}, author = {C, Holmgren E}, year = {1995}, pages = {360}, doi = {10.1080/01621459.1995.10476520} }</description></item><item><title>The P² Algorithm for Dynamic Calculation of Quantiles and Histograms Without Storing Observations</title><link>https://aakinshin.net/library/papers/jain1985/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/jain1985/</guid><description>The P² quantile estimator is a fast sequential estimator that uses $O(1)$ memory. Allows implementing lightweight real-time monitoring of various indicators in software systems.
Reference Raj Jain, Imrich Chlamtac “The P² algorithm for dynamic calculation of quantiles and histograms without storing observations” (1985) // Communications of the ACM. Publisher: Association for Computing Machinery (ACM). Vol. 28. No 10. Pp. 1076–1085. DOI: 10.1145/4372.4378
Abstract What constitutes a dangerous equation? There are two obvious interpretations: Some equations are dangerous if you know them, and others are dangerous if you do not.
Bib @Article{jain1985, title = {The P² algorithm for dynamic calculation of quantiles and histograms without storing observations}, abstract = {What constitutes a dangerous equation? There are two obvious interpretations: Some equations are dangerous if you know them, and others are dangerous if you do not.}, volume = {28}, issn = {1557-7317}, url = {http://dx.doi.org/10.1145/4372.4378}, doi = {10.1145/4372.4378}, number = {10}, journal = {Communications of the ACM}, publisher = {Association for Computing Machinery (ACM)}, author = {Jain, Raj and Chlamtac, Imrich}, year = {1985}, month = {oct}, pages = {1076–1085} }</description></item><item><title>The Philosophy of Multiple Comparisons</title><link>https://aakinshin.net/library/papers/tukey1991/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/tukey1991/</guid><description>Reference John W Tukey “The Philosophy of Multiple Comparisons” (1991) // Statistical Science. Publisher: Institute of Mathematical Statistics. Vol. 6. No 1. DOI: 10.1214/ss/1177011945
Bib @Article{tukey1991, title = {The Philosophy of Multiple Comparisons}, volume = {6}, issn = {0883-4237}, url = {http://dx.doi.org/10.1214/ss/1177011945}, doi = {10.1214/ss/1177011945}, number = {1}, journal = {Statistical Science}, publisher = {Institute of Mathematical Statistics}, author = {Tukey, John W}, year = {1991}, month = {feb} }</description></item><item><title>The Problem of Pseudoreplication in Neuroscientific studies: Is It Affecting Your analysis?</title><link>https://aakinshin.net/library/papers/lazic2010/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/lazic2010/</guid><description>Reference Stanley E Lazic “The problem of pseudoreplication in neuroscientific studies: is it affecting your analysis?” (2010) // BMC Neuroscience. Publisher: Springer Science and Business Media LLC. Vol. 11. No 1. DOI: 10.1186/1471-2202-11-5
Bib @Article{lazic2010, title = {The problem of pseudoreplication in neuroscientific studies: is it affecting your analysis?}, volume = {11}, issn = {1471-2202}, url = {http://dx.doi.org/10.1186/1471-2202-11-5}, doi = {10.1186/1471-2202-11-5}, number = {1}, journal = {BMC Neuroscience}, publisher = {Springer Science and Business Media LLC}, author = {Lazic, Stanley E}, year = {2010}, month = {jan} }</description></item><item><title>The Rectified Gaussian Distribution</title><link>https://aakinshin.net/library/papers/socci1997/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/socci1997/</guid><description>Reference Nicholas Socci, Daniel Lee, H Sebastian Seung “The rectified Gaussian distribution” (1997) // Advances in neural information processing systems. Vol. 10.
Bib @Article{socci1997, title = {The rectified Gaussian distribution}, author = {Socci, Nicholas and Lee, Daniel and Seung, H Sebastian}, journal = {Advances in neural information processing systems}, volume = {10}, year = {1997}, custom-url-pdf = {https://proceedings.neurips.cc/paper/1997/file/28fc2782ea7ef51c1104ccf7b9bea13d-Paper.pdf} }</description></item><item><title>The Russian Roulette: An Unbiased Estimator of the Limit</title><link>https://aakinshin.net/library/web/55741543b493252df4a3ea921467d847/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/web/55741543b493252df4a3ea921467d847/</guid><description/></item><item><title>The Search for Significance: A Few Peculiarities in the Distribution of P Values in Experimental Psychology Literature</title><link>https://aakinshin.net/library/papers/krawczyk2015/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/krawczyk2015/</guid><description>Reference Michał Krawczyk, Daniele Fanelli “The Search for Significance: A Few Peculiarities in the Distribution of P Values in Experimental Psychology Literature” (2015) // PLOS ONE. Vol. 10. No 6. Pp. e0127872. DOI: 10.1371/journal.pone.0127872
Bib @Article{krawczyk2015, title = {The Search for Significance: A Few Peculiarities in the Distribution of P Values in Experimental Psychology Literature}, volume = {10}, issn = {1932-6203}, shorttitle = {The Search for Significance}, url = {https://dx.plos.org/10.1371/journal.pone.0127872}, doi = {10.1371/journal.pone.0127872}, language = {en}, number = {6}, urldate = {2020-01-08}, journal = {PLOS ONE}, author = {Krawczyk, Michał}, editor = {Fanelli, Daniele}, month = {jun}, year = {2015}, note = {ZSCC: NoCitationData[s0]}, pages = {e0127872} }</description></item><item><title>The Statistical Accessibility of Medical Papers</title><link>https://aakinshin.net/library/quotes/cca63eb6-34c7-451e-baaf-1c35e7c1d7d8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/cca63eb6-34c7-451e-baaf-1c35e7c1d7d8/</guid><description>Similarly, if a reader had knowledge of t-tests, contingency tables, nonparametric tests, epidemiologic statistics, Pearson’s correlation, simple linear regression, analysis of variance, transformations, and nonparametric correlation (topics typically included in introductory statistics courses), then 21 percent of the articles would be accessible.</description></item><item><title>The Statistical Power of abnormal-social Psychological research: A Review</title><link>https://aakinshin.net/library/papers/cohen1962/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/cohen1962/</guid><description>Reference Jacob Cohen “The statistical power of abnormal-social psychological research: A review” (1962) // The Journal of Abnormal and Social Psychology. Publisher: American Psychological Association (APA). Vol. 65. No 3. Pp. 145–153. DOI: 10.1037/h0045186
Bib @Article{cohen1962, title = {The statistical power of abnormal-social psychological research: A review}, volume = {65}, issn = {0096-851X}, url = {http://dx.doi.org/10.1037/h0045186}, doi = {10.1037/h0045186}, number = {3}, journal = {The Journal of Abnormal and Social Psychology}, publisher = {American Psychological Association (APA)}, author = {Cohen, Jacob}, year = {1962}, month = {sep}, pages = {145–153} }</description></item><item><title>The Task of a Statistical Referee</title><link>https://aakinshin.net/library/papers/murray1988/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/murray1988/</guid><description>Reference G D Murray “The task of a statistical referee” (1988) // British Journal of Surgery. Publisher: Oxford University Press (OUP). Vol. 75. No 7. Pp. 664–667. DOI: 10.1002/bjs.1800750714
Bib @Article{murray1988, title = {The task of a statistical referee}, volume = {75}, issn = {1365-2168}, url = {http://dx.doi.org/10.1002/bjs.1800750714}, doi = {10.1002/bjs.1800750714}, number = {7}, journal = {British Journal of Surgery}, publisher = {Oxford University Press (OUP)}, author = {Murray, G D}, year = {1988}, month = {jul}, pages = {664–667} }</description></item><item><title>The Wilcoxon–Mann–Whitney Procedure Fails as a Test of Medians</title><link>https://aakinshin.net/library/papers/divine2018/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/divine2018/</guid><description>Reference George W Divine, H James Norton, Anna E Barón, Elizabeth Juarez-Colunga “The Wilcoxon–Mann–Whitney Procedure Fails as a Test of Medians” (2018) // The American Statistician. Vol. 72. No 3. Pp. 278–286. DOI: 10.1080/00031305.2017.1305291
Bib @Article{divine2018, title = {The Wilcoxon–Mann–Whitney Procedure Fails as a Test of Medians}, volume = {72}, issn = {0003-1305, 1537-2731}, url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2017.1305291}, doi = {10.1080/00031305.2017.1305291}, language = {en}, number = {3}, urldate = {2023-10-22}, journal = {The American Statistician}, author = {Divine, George W and Norton, H James and Barón, Anna E and Juarez-Colunga, Elizabeth}, month = {jul}, year = {2018}, pages = {278--286} }</description></item><item><title>The Wrong Question</title><link>https://aakinshin.net/library/quotes/7566960c-ae77-4add-9c00-b9865d8f1cac/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/7566960c-ae77-4add-9c00-b9865d8f1cac/</guid><description>Statisticians classically asked the wrong question — and were willing to answer with a lie, one that was often a downright lie. They asked &amp;ldquo;Are the effects of A and B different?&amp;rdquo; and they were willing to answer &amp;ldquo;no.&amp;rdquo;
All we know about the world teaches us that the effects of A and B are always difference — in some decimal place — for any A and B. Thus asking &amp;ldquo;Are the effects different?&amp;rdquo; is foolish.
What we should be answering first is &amp;ldquo;Can we tell the direction in which the effects of A differ from the effects of B?&amp;rdquo; In other words, can we be confident about the direction from A to B? Is it &amp;ldquo;up,&amp;rdquo; &amp;ldquo;down&amp;rdquo; or &amp;ldquo;uncertain&amp;rdquo;?
The third answer to this first question is that we are &amp;ldquo;uncertain about the direction&amp;rdquo; — it is not, and never should be, that we &amp;ldquo;accept the null hypothesis.&amp;rdquo;</description></item><item><title>Theoretical Risks and Tabular asterisks: Sir Karl, Sir Ronald, and the Slow Progress of Soft Psychology</title><link>https://aakinshin.net/library/papers/meehl1978/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/meehl1978/</guid><description>Reference Paul E Meehl “Theoretical risks and tabular asterisks: Sir Karl, Sir Ronald, and the slow progress of soft psychology” (1978) // Publisher: American Psychological Association. DOI: 10.1037/0022-006X.46.4.806
Bib @Article{meehl1978, title = {Theoretical risks and tabular asterisks: Sir Karl, Sir Ronald, and the slow progress of soft psychology}, author = {Meehl, Paul E}, year = {1978}, publisher = {American Psychological Association}, doi = {10.1037/0022-006X.46.4.806} }</description></item><item><title>Theory-Testing in Psychology and physics: A Methodological Paradox</title><link>https://aakinshin.net/library/papers/meehl1967/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/meehl1967/</guid><description>Reference Paul E Meehl “Theory-testing in psychology and physics: A methodological paradox” (1967) // Philosophy of science. Publisher: Cambridge University Press. Vol. 34. No 2. Pp. 103–115.
Bib @Article{meehl1967, title = {Theory-testing in psychology and physics: A methodological paradox}, author = {Meehl, Paul E}, url = {https://meehl.umn.edu/sites/meehl.umn.edu/files/files/074theorytestingparadox.pdf}, journal = {Philosophy of science}, volume = {34}, number = {2}, pages = {103--115}, year = {1967}, publisher = {Cambridge University Press} }</description></item><item><title>Things I Have Learned (so far)</title><link>https://aakinshin.net/library/papers/cohen1990/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/cohen1990/</guid><description>Reference Jacob Cohen “Things I have learned (so far)” (1990) // American Psychologist. Vol. 45. No 12. Pp. 1304–1312. DOI: 10.1037/0003-066X.45.12.1304
Bib @Article{cohen1990, title = {Things I have learned (so far)}, volume = {45}, issn = {1935-990X, 0003-066X}, url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0003-066X.45.12.1304}, doi = {10.1037/0003-066X.45.12.1304}, language = {en}, number = {12}, urldate = {2023-01-30}, journal = {American Psychologist}, author = {Cohen, Jacob}, month = {dec}, year = {1990}, pages = {1304--1312} }</description></item><item><title>Three Dangerous Statistical Equations</title><link>https://aakinshin.net/library/quotes/9d9f8cca-5477-4108-9b60-6520cd897505/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/9d9f8cca-5477-4108-9b60-6520cd897505/</guid><description>Supporting ignorance is not, however, the direction I wish to pursue—indeed it is quite the antithesis of my message. Instead I am interested in equations that unleash their danger not when we know about them, but rather when we do not. Kept close at hand, these equations allow us to understand things clearly, but their absence leaves us dangerously ignorant.
There are many plausible candidates, and I have identified three prime examples: Kelley&amp;rsquo;s equation, which indicates that the truth is estimated best when its observed value is regressed toward the mean of the group that it came from; the standard linear regression equation; and the equation that provides us with the standard deviation of the sampling distribution of the mean—what might be called de Moivre&amp;rsquo;s equation: $\sigma_{\bar{x}} = \sigma/\sqrt{n}$, where $\sigma_{\bar{x}}$ is the standard error of the mean, $s$ is the standard deviation of the sample and $n$ is the size of the sample. (Note the square root symbol, which will be a key to at least one of the misunderstandings of variation.) De Moivre&amp;rsquo;s equation was derived by the French mathematician Abraham de Moivre, who described it in his 1730 exploration of the binomial distribution, Miscellanea Analytica.</description></item><item><title>Time-Efficient Algorithms for Robust Estimators of Location, Scale, Symmetry, and Tail Heaviness</title><link>https://aakinshin.net/library/papers/gelade2015/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/gelade2015/</guid><description>Reference Wouter Gelade, Vincenzo Verardi, Catherine Vermandele “Time-Efficient Algorithms for Robust Estimators of Location, Scale, Symmetry, and Tail heaviness” (2015) // The Stata Journal: Promoting communications on statistics and Stata. Vol. 15. No 1. Pp. 77–94. DOI: 10.1177/1536867X1501500105
Abstract The analysis of the empirical distribution of univariate data often includes the computation of location, scale, skewness, and tail-heaviness measures, which are estimates of specific parameters of the underlying population distribution. Several measures are available, but they differ by Gaussian efficiency, robustness regarding outliers, and meaning in the case of asymmetric distributions. In this article, we briefly compare, for each type of parameter (location, scale, skewness, and tail heaviness), the “classical” estimator based on (centered) moments of the empirical distribution, an estimator based on specific quantiles of the distribution, and an estimator based on pairwise comparisons of the observations. This last one always performs better than the other estimators, particularly in terms of robustness, but it requires a heavy computation time of an order of n
Bib @Article{gelade2015, title = {Time-Efficient Algorithms for Robust Estimators of Location, Scale, Symmetry, and Tail heaviness}, volume = {15}, issn = {1536-867X, 1536-8734}, url = {http://journals.sagepub.com/doi/10.1177/1536867X1501500105}, doi = {10.1177/1536867X1501500105}, abstract = {The analysis of the empirical distribution of univariate data often includes the computation of location, scale, skewness, and tail-heaviness measures, which are estimates of specific parameters of the underlying population distribution. Several measures are available, but they differ by Gaussian efficiency, robustness regarding outliers, and meaning in the case of asymmetric distributions. In this article, we briefly compare, for each type of parameter (location, scale, skewness, and tail heaviness), the “classical” estimator based on (centered) moments of the empirical distribution, an estimator based on specific quantiles of the distribution, and an estimator based on pairwise comparisons of the observations. This last one always performs better than the other estimators, particularly in terms of robustness, but it requires a heavy computation time of an order of n}, language = {en}, number = {1}, urldate = {2022-08-02}, journal = {The Stata Journal: Promoting communications on statistics and Stata}, author = {Gelade, Wouter and Verardi, Vincenzo and Vermandele, Catherine}, month = {apr}, year = {2015}, pages = {77--94} }</description></item><item><title>Time-Efficient Algorithms for Two Highly Robust Estimators of Scale</title><link>https://aakinshin.net/library/papers/croux1992/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/croux1992/</guid><description>Reference Christophe Croux, Peter J Rousseeuw, Yadolah Dodge, Joe Whittaker “Time-Efficient Algorithms for Two Highly Robust Estimators of Scale” (1992) // Computational Statistics. Publisher: Physica-Verlag HD. Heidelberg. ISBN: 978-3-662-26813-1 978-3-662-26811-7. Pp. 411–428. DOI: 10.1007/978-3-662-26811-7_58
Bib @Incollection{croux1992, address = {Heidelberg}, title = {Time-Efficient Algorithms for Two Highly Robust Estimators of Scale}, isbn = {978-3-662-26813-1 978-3-662-26811-7}, url = {http://link.springer.com/10.1007/978-3-662-26811-7_58}, language = {en}, urldate = {2022-08-02}, booktitle = {Computational Statistics}, publisher = {Physica-Verlag HD}, author = {Croux, Christophe and Rousseeuw, Peter J}, editor = {Dodge, Yadolah and Whittaker, Joe}, year = {1992}, doi = {10.1007/978-3-662-26811-7_58}, pages = {411--428} }</description></item><item><title>To Explain or to Predict?</title><link>https://aakinshin.net/library/papers/shmueli2010/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/shmueli2010/</guid><description>Reference Galit Shmueli “To Explain or to Predict?” (2010) // Statistical Science. Publisher: Institute of Mathematical Statistics. Vol. 25. No 3. DOI: 10.1214/10-sts330
Bib @Article{shmueli2010, title = {To Explain or to Predict?}, volume = {25}, issn = {0883-4237}, url = {http://dx.doi.org/10.1214/10-STS330}, doi = {10.1214/10-sts330}, number = {3}, journal = {Statistical Science}, publisher = {Institute of Mathematical Statistics}, author = {Shmueli, Galit}, year = {2010}, month = {aug} }</description></item><item><title>Toward evidence-based Medical statistics. 1: The P Value Fallacy</title><link>https://aakinshin.net/library/papers/goodman1999/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/goodman1999/</guid><description>Reference Steven N Goodman “Toward evidence-based medical statistics. 1: The P value fallacy” (1999) // Annals of internal medicine. Publisher: American College of Physicians. Vol. 130. No 12. Pp. 995–1004. DOI: 10.7326/0003-4819-130-12-199906150-00008
Bib @Article{goodman1999, title = {Toward evidence-based medical statistics. 1: The P value fallacy}, author = {Goodman, Steven N}, journal = {Annals of internal medicine}, volume = {130}, number = {12}, pages = {995--1004}, year = {1999}, doi = {10.7326/0003-4819-130-12-199906150-00008}, publisher = {American College of Physicians} }</description></item><item><title>Trial Factors for the Look Elsewhere Effect in High Energy Physics</title><link>https://aakinshin.net/library/papers/gross2010/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/gross2010/</guid><description>Reference Eilam Gross, Ofer Vitells “Trial factors for the look elsewhere effect in high energy physics” (2010) // The European Physical Journal C. Publisher: Springer Science and Business Media LLC. Vol. 70. No 1–2. Pp. 525–530. DOI: 10.1140/epjc/s10052-010-1470-8
Bib @Article{gross2010, title = {Trial factors for the look elsewhere effect in high energy physics}, volume = {70}, issn = {1434-6052}, url = {http://dx.doi.org/10.1140/epjc/s10052-010-1470-8}, doi = {10.1140/epjc/s10052-010-1470-8}, number = {1–2}, journal = {The European Physical Journal C}, publisher = {Springer Science and Business Media LLC}, author = {Gross, Eilam and Vitells, Ofer}, year = {2010}, month = {oct}, pages = {525–530} }</description></item><item><title>Truth, Damn Truth, and Statistics</title><link>https://aakinshin.net/library/papers/velleman2008/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/velleman2008/</guid><description>Reference Paul F Velleman “Truth, Damn Truth, and Statistics” (2008) // Journal of Statistics Education. Vol. 16. No 2. Pp. 7. DOI: 10.1080/10691898.2008.11889565
Bib @Article{velleman2008, title = {Truth, Damn Truth, and Statistics}, volume = {16}, issn = {1069-1898}, url = {https://www.tandfonline.com/doi/full/10.1080/10691898.2008.11889565}, doi = {10.1080/10691898.2008.11889565}, language = {en}, number = {2}, urldate = {2023-02-04}, journal = {Journal of Statistics Education}, author = {Velleman, Paul F}, month = {jul}, year = {2008}, pages = {7} }</description></item><item><title>Twelve P-Value Misconceptions</title><link>https://aakinshin.net/library/quotes/ac262184-cdb6-46f8-b7ac-5107d66d8314/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/ac262184-cdb6-46f8-b7ac-5107d66d8314/</guid><description> Twelve P-Value Misconceptions:
If P =.05, the null hypothesis has only a 5% chance of being true. A nonsignificant difference (eg, P &amp;gt; .05) means there is no difference between groups. A statistically significant finding is clinically important. Studies with P values on opposite sides of .05 are conflicting. Studies with the same P value provide the same evidence against the null hypothesis. P = .05 means that we have observed data that would occur only 5% of the time under the null hypothesis. P = .05 and P &amp;lt;= .05 mean the same thing. P values are properly written as inequalities (eg, “P &amp;lt; .02” when P = .015) P = .05 means that if you reject the null hypothesis, the probability of a type I error is only 5%. With a P = .05 threshold for significance, the chance of a type I error will be 5%. You should use a one-sided P value when you don’t care about a result in one direction, or a difference in that direction is impossible. A scientific conclusion or treatment policy should be based on whether or not the P value is significant.</description></item><item><title>Type II Error Should Be as Essential a Requirement for Publication</title><link>https://aakinshin.net/library/quotes/c7ba1497-c183-41ab-9d9e-a4cffb4d2c84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/c7ba1497-c183-41ab-9d9e-a4cffb4d2c84/</guid><description>Failure to achieve statistical significance between interventions does not prove the absence of any difference. Proper planning of a clinical trial with attention to beta error and sample size determination allows the critical investigator to acknowledge the probability of a type II error and therefore the probability of detecting a clinically meaningful difference if one exists. The reader and clinician must be aware that negative trials may in fact be falsely negative, and should look for specific reporting of alpha, beta, and $\Delta_c$ error to provide the details of the reliability of such conclusions. Type II error should be as essential a requirement for publication, and as rigorously analyzed, as the traditional and far more common type I (alpha) error.</description></item><item><title>Type M and Type S Errors</title><link>https://aakinshin.net/library/quotes/8359ad42-cd60-4f97-b32a-1f81df61f486/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/8359ad42-cd60-4f97-b32a-1f81df61f486/</guid><description>This is a Type M (magnitude) error (Gelman and Tuerlinckx, 2000): the study is constructed in such a way that any statistically-significant finding will almost certainly be a huge overestimate of the true effect. In addition there will be Type S (sign) errors, in which the estimate will be in the opposite direction as the true effect.</description></item><item><title>Über Eine Partition Der nat. Zahlen Und Ihre Anwendung Beim U-Test</title><link>https://aakinshin.net/library/papers/loeffler1982/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/loeffler1982/</guid><description>Original | English Version
Reference Andreas Löffler “Über eine Partition der nat. Zahlen und ihre Anwendung beim U-Test” (1982)
Bib @Article{loeffler1982, title = {Über eine Partition der nat. Zahlen und ihre Anwendung beim U-Test}, year = {1982}, url = {https://upload.wikimedia.org/wikipedia/de/1/19/MannWhitney_151102.pdf}, language = {german}, author = {Löffler, Andreas} }</description></item><item><title>Underpowered Negative Clinical Trials</title><link>https://aakinshin.net/library/quotes/10189519-eb48-41f5-a1ca-adac8092bf8e/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/10189519-eb48-41f5-a1ca-adac8092bf8e/</guid><description>Our survey of 423 negative clinical trials indicates that 55% of trials had too few participants to detect a medium effect size in favor of the experimental over the standard treatment arm for their primary end point with at least 80% statistical power. Although underpowered negative clinical trials have been widely reported in the general medical and subspecialty literature, there are few reports relating to trials evaluating treatment of cancer. A review of 22 negative randomized oncology trials published in major general medical or oncology journals during a 1-year period found that 16 trials (73%) lacked adequate statistical power to detect a 50% improvement in median survival in favor of the experimental arm.</description></item><item><title>Understanding Power and Rules of Thumb for Determining Sample Sizes</title><link>https://aakinshin.net/library/papers/wilson2007/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/wilson2007/</guid><description>Reference Wilson Van Voorhis C R, Morgan B L “Understanding power and rules of thumb for determining sample sizes” (2007) // Tutor. Quant. Methods Psychol.. Vol. 3. Pp. 43.
Bib @Article{wilson2007, title = {Understanding power and rules of thumb for determining sample sizes}, volume = {3}, journal = {Tutor. Quant. Methods Psychol.}, author = {R, Wilson Van Voorhis C and L, Morgan B}, year = {2007}, pages = {43}, custom-url-pdf = {https://www.tqmp.org/RegularArticles/vol03-2/p043/p043.pdf} }</description></item><item><title>Understanding the New Statistics (Multivariate Applications Series)</title><link>https://aakinshin.net/library/books/cumming-understanding-the-new-statistics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/cumming-understanding-the-new-statistics/</guid><description/></item><item><title>Unimpressive Theories in Psychology</title><link>https://aakinshin.net/library/quotes/a877a820-1fcb-4944-99ad-5f888320ea8d/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/a877a820-1fcb-4944-99ad-5f888320ea8d/</guid><description>I consider it unnecessary to persuade you that most so-called “theories” in the soft areas of psychology (clinical, counseling, social, personality, community, and school psychology) are scientifically unimpressive and technologically worthless.</description></item><item><title>US Studies May Overestimate Effect Sizes in Softer Research</title><link>https://aakinshin.net/library/papers/fanelli2013/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/fanelli2013/</guid><description>Reference Daniele Fanelli, John PA Ioannidis “US studies may overestimate effect sizes in softer research” (2013) // Proceedings of the National Academy of Sciences. Publisher: National Acad Sciences. Vol. 110. No 37. Pp. 15031–15036. DOI: 10.1073/pnas.1302997110
Abstract Many biases affect scientific research, causing a waste of resources, posing a threat to human health, and hampering scientific progress. These problems are hypothesized to be worsened by lack of consensus on theories and methods, by selective publication processes, and by career systems too heavily oriented toward productivity, such as those adopted in the United States (US). Here, we extracted 1,174 primary outcomes appearing in 82 meta-analyses published in health-related biological and behavioral research sampled from the Web of Science categories Genetics &amp;amp; Heredity and Psychiatry and measured how individual results deviated from the overall summary effect size within their respective meta-analysis. We found that primary studies whose outcome included behavioral parameters were generally more likely to report extreme effects, and those with a corresponding author based in the US were more likely to deviate in the direction predicted by their experimental hypotheses, particularly when their outcome did not include additional biological parameters. Nonbehavioral studies showed no such &amp;ldquo;US effect&amp;rdquo; and were subject mainly to sampling variance and small-study effects, which were stronger for non-US countries. Although this latter finding could be interpreted as a publication bias against non-US authors, the US effect observed in behavioral research is unlikely to be generated by editorial biases. Behavioral studies have lower methodological consensus and higher noise, making US researchers potentially more likely to express an underlying propensity to report strong and significant findings.
Bib @Article{fanelli2013, title = {US studies may overestimate effect sizes in softer research}, author = {Fanelli, Daniele and Ioannidis, John PA}, journal = {Proceedings of the National Academy of Sciences}, abstract = {Many biases affect scientific research, causing a waste of resources, posing a threat to human health, and hampering scientific progress.</description></item><item><title>Variance of the Median of Small Samples from Several Special Populations</title><link>https://aakinshin.net/library/papers/rider1960/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/rider1960/</guid><description>Reference Paul R Rider “Variance of the median of small samples from several special populations” (1960) // Journal of the American Statistical Association. Publisher: Taylor &amp;amp; Francis. Vol. 55. No 289. Pp. 148–150. DOI: 10.1080/01621459.1960.10482056
Bib @Article{rider1960, title = {Variance of the median of small samples from several special populations}, author = {Rider, Paul R}, journal = {Journal of the American Statistical Association}, volume = {55}, number = {289}, pages = {148--150}, year = {1960}, publisher = {Taylor \&amp;amp; Francis}, doi = {10.1080/01621459.1960.10482056} }</description></item><item><title>Voodoo and Circularity Errors</title><link>https://aakinshin.net/library/papers/vul2012/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/vul2012/</guid><description>Reference Edward Vul, Hal Pashler “Voodoo and circularity errors” (2012) // NeuroImage. Publisher: Elsevier BV. Vol. 62. No 2. Pp. 945–948. DOI: 10.1016/j.neuroimage.2012.01.027
Bib @Article{vul2012, title = {Voodoo and circularity errors}, volume = {62}, issn = {1053-8119}, url = {http://dx.doi.org/10.1016/j.neuroimage.2012.01.027}, doi = {10.1016/j.neuroimage.2012.01.027}, number = {2}, journal = {NeuroImage}, publisher = {Elsevier BV}, author = {Vul, Edward and Pashler, Hal}, year = {2012}, month = {aug}, pages = {945–948} }</description></item><item><title>Voodoo Correlations Are Everywhere—Not Only in Neuroscience</title><link>https://aakinshin.net/library/papers/fiedler2011/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/fiedler2011/</guid><description>Reference Klaus Fiedler “Voodoo Correlations Are Everywhere—Not Only in Neuroscience” (2011) // Perspectives on Psychological Science. Publisher: SAGE Publications. Vol. 6. No 2. Pp. 163–171. DOI: 10.1177/1745691611400237
Bib @Article{fiedler2011, title = {Voodoo Correlations Are Everywhere—Not Only in Neuroscience}, volume = {6}, issn = {1745-6924}, url = {http://dx.doi.org/10.1177/1745691611400237}, doi = {10.1177/1745691611400237}, number = {2}, journal = {Perspectives on Psychological Science}, publisher = {SAGE Publications}, author = {Fiedler, Klaus}, year = {2011}, month = {mar}, pages = {163–171} }</description></item><item><title>What Hypotheses Do “Nonparametric” Two-Group Tests Actually Test?</title><link>https://aakinshin.net/library/papers/conroy2012/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/conroy2012/</guid><description>Reference Ronán M Conroy “What Hypotheses do “Nonparametric” Two-Group Tests Actually Test?” (2012) // The Stata Journal: Promoting communications on statistics and Stata. Vol. 12. No 2. Pp. 182–190. DOI: 10.1177/1536867X1201200202
Abstract In this article, I discuss measures of effect size for two-group comparisons where data are not appropriately analyzed by least-squares methods. The Mann–Whitney test calculates a statistic that is a very useful measure of effect size, particularly suited to situations in which differences are measured on scales that either are ordinal or use arbitrary scale units. Both the difference in medians and the median difference between groups are also useful measures of effect size.
Bib @Article{conroy2012, title = {What Hypotheses do “Nonparametric” Two-Group Tests Actually Test?}, volume = {12}, issn = {1536-867X, 1536-8734}, url = {http://journals.sagepub.com/doi/10.1177/1536867X1201200202}, doi = {10.1177/1536867X1201200202}, abstract = {In this article, I discuss measures of effect size for two-group comparisons where data are not appropriately analyzed by least-squares methods. The Mann–Whitney test calculates a statistic that is a very useful measure of effect size, particularly suited to situations in which differences are measured on scales that either are ordinal or use arbitrary scale units. Both the difference in medians and the median difference between groups are also useful measures of effect size.}, language = {en}, number = {2}, urldate = {2023-10-22}, journal = {The Stata Journal: Promoting communications on statistics and Stata}, author = {Conroy, Ronán M}, month = {jun}, year = {2012}, pages = {182--190} }</description></item><item><title>What If There Were No Significance Tests? (Multivariate Applications)</title><link>https://aakinshin.net/library/books/harlow-what-if-there-were-no-significance-tests/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/harlow-what-if-there-were-no-significance-tests/</guid><description/></item><item><title>When is Statistical Significance Not significant?</title><link>https://aakinshin.net/library/papers/figueiredo2013/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/figueiredo2013/</guid><description>Reference Dalson Britto Figueiredo Filho, Ranulfo Paranhos, Enivaldo C da Rocha, Mariana Batista, José Alexandre da Silva Jr, Manoel L Wanderley D Santos, Jacira Guiro Marino “When is statistical significance not significant?” (2013) // Brazilian Political Science Review. Vol. 7. No 1. Pp. 31–55. DOI: 10.1590/S1981-38212013000100002
Bib @Article{figueiredo2013, title = {When is statistical significance not significant?}, volume = {7}, issn = {1981-3821}, url = {http://www.scielo.br/scielo.php?script=sci_arttext&amp;amp;pid=S1981-38212013000100002&amp;amp;lng=en&amp;amp;tlng=en}, doi = {10.1590/S1981-38212013000100002}, number = {1}, urldate = {2020-01-19}, journal = {Brazilian Political Science Review}, author = {Figueiredo Filho, Dalson Britto and Paranhos, Ranulfo and Rocha, Enivaldo C da and Batista, Mariana and Silva Jr, José Alexandre da and Santos, Manoel L Wanderley D and Marino, Jacira Guiro}, year = {2013}, note = {ZSCC: 0000079}, pages = {31--55} }</description></item><item><title>Why “Encouraging” Effect Size Reporting is Not Working: The Etiology of Researcher Resistance to Changing Practices</title><link>https://aakinshin.net/library/papers/thompson1999/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/thompson1999/</guid><description>Reference Bruce Thompson “Why “Encouraging” Effect Size Reporting Is Not Working: The Etiology of Researcher Resistance to Changing Practices” (1999) // The Journal of Psychology. Publisher: Informa UK Limited. Vol. 133. No 2. Pp. 133–140. DOI: 10.1080/00223989909599728
Bib @Article{thompson1999, title = {Why “Encouraging” Effect Size Reporting Is Not Working: The Etiology of Researcher Resistance to Changing Practices}, volume = {133}, issn = {1940-1019}, url = {http://dx.doi.org/10.1080/00223989909599728}, doi = {10.1080/00223989909599728}, number = {2}, journal = {The Journal of Psychology}, publisher = {Informa UK Limited}, author = {Thompson, Bruce}, year = {1999}, month = {mar}, pages = {133–140} }</description></item><item><title>Why Most Discovered True Associations Are Inflated</title><link>https://aakinshin.net/library/papers/ioannidis2008/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/ioannidis2008/</guid><description>Disclaimer The debate on whether research findings are credible is out of the scope. Assumption: considered research findings are true. First example is based on the previous work of the author: ioannidis2007a. While the original study van2002 is based on 117 patients (98 initial + 19 confirmatory), the author highlights only 19 patients from the second trial (to show the small sample size in the pioneer work). On page 645, left column, third line from the bottom, the number 256 should be 461. The same correction should be made in the legend for Figure 2. Reference John PA Ioannidis “Why Most Discovered True Associations Are Inflated” (2008) // Epidemiology. Publisher: Ovid Technologies (Wolters Kluwer Health). Vol. 19. No 5. Pp. 640–648. DOI: 10.1097/ede.0b013e31818131e7
Abstract Newly discovered true (non-null) associations often have inflated effects compared with the true effect sizes. I discuss here the main reasons for this inflation. First, theoretical considerations prove that when true discovery is claimed based on crossing a threshold of statistical significance and the discovery study is underpowered, the observed effects are expected to be inflated. This has been demonstrated in various fields ranging from early stopped clinical trials to genome-wide associations. Second, flexible analyses coupled with selective reporting may inflate the published discovered effects. The vibration ratio (the ratio of the largest vs. smallest effect on the same association approached with different analytic choices) can be very large. Third, effects may be inflated at the stage of interpretation due to diverse conflicts of interest. Discovered effects are not always inflated, and under some circumstances may be deflated-for example, in the setting of late discovery of associations in sequentially accumulated overpowered evidence, in some types of misclassification from measurement error, and in conflicts causing reverse biases. Finally, I discuss potential approaches to this problem. These include being cautious about newly discovered effect sizes, considering some rational down-adjustment, using analytical methods that correct for the anticipated inflation, ignoring the magnitude of the effect (if not necessary), conducting large studies in the discovery phase, using strict protocols for analyses, pursuing complete and transparent reporting of all results, placing emphasis on replication, and being fair with interpretation of results.</description></item><item><title>Why Most Published Research Findings Are False</title><link>https://aakinshin.net/library/papers/ioannidis2005/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/ioannidis2005/</guid><description>Corollaries:
The smaller the studies conducted in a scientific field, the less likely the research findings are to be true. The smaller the effect sizes in a scientific field, the less likely the research findings are to be true. The greater the number and the lesser the selection of tested relationships in a scientific field, the less likely the research findings are to be true. The greater the flexibility in designs, definitions, outcomes, and analytical modes in a scientific field, the less likely the research findings are to be true. The greater the financial and other interests and prejudices in a scientific field, the less likely the research findings are to be true. How Can We Improve the Situation:
Better powered evidence. The totality of the evidence (including all false discoveries). Instead of chasing statistical significance, we should improve our understanding of the pre-study odds. Reference John PA Ioannidis “Why most published research findings are false” (2005) // PLoS medicine. Publisher: Public Library of Science. Vol. 2. No 8. Pp. e124. DOI: 10.1371/journal.pmed.0020124
Abstract There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance.</description></item><item><title>Why Software Projects Take Longer Than You think: A Statistical Model &amp;middot</title><link>https://aakinshin.net/library/web/42c9eb2a42ecff7c5f73ed80b5f60737/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/web/42c9eb2a42ecff7c5f73ed80b5f60737/</guid><description/></item><item><title>Women Are More Likely to Wear Red or Pink at Peak Fertility</title><link>https://aakinshin.net/library/papers/beall2013/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/beall2013/</guid><description>Reference Alec T. Beall, Jessica L. Tracy “Women Are More Likely to Wear Red or Pink at Peak Fertility” (2013) // Psychological Science. Publisher: SAGE Publications. Vol. 24. No 9. Pp. 1837–1841. DOI: 10.1177/0956797613476045
Bib @Article{beall2013, title = {Women Are More Likely to Wear Red or Pink at Peak Fertility}, volume = {24}, issn = {1467-9280}, url = {http://dx.doi.org/10.1177/0956797613476045}, doi = {10.1177/0956797613476045}, number = {9}, journal = {Psychological Science}, publisher = {SAGE Publications}, author = {Beall, Alec T. and Tracy, Jessica L.}, year = {2013}, month = {jul}, pages = {1837–1841} }</description></item><item><title>Women Can Keep the Vote: No Evidence that Hormonal Changes During the Menstrual Cycle Impact Political and Religious Beliefs</title><link>https://aakinshin.net/library/papers/harris2014/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/harris2014/</guid><description>Reference Christine R. Harris, Aimee Chabot, Laura Mickes “Women Can Keep the Vote: No Evidence That Hormonal Changes During the Menstrual Cycle Impact Political and Religious Beliefs” (2014) // Psychological Science. Publisher: SAGE Publications. Vol. 25. No 5. Pp. 1147–1149. DOI: 10.1177/0956797613520236
Bib @Article{harris2014, title = {Women Can Keep the Vote: No Evidence That Hormonal Changes During the Menstrual Cycle Impact Political and Religious Beliefs}, volume = {25}, issn = {1467-9280}, url = {http://dx.doi.org/10.1177/0956797613520236}, doi = {10.1177/0956797613520236}, number = {5}, journal = {Psychological Science}, publisher = {SAGE Publications}, author = {Harris, Christine R. and Chabot, Aimee and Mickes, Laura}, year = {2014}, month = {feb}, pages = {1147–1149} }</description></item></channel></rss>