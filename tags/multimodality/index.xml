<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Multimodality on Andrey Akinshin</title><link>https://aakinshin.net/tags/multimodality/</link><description>Recent content in Multimodality on Andrey Akinshin</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Tue, 18 Jul 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://aakinshin.net/tags/multimodality/index.xml" rel="self" type="application/rss+xml"/><item><title>Multimodal distributions and effect size</title><link>https://aakinshin.net/posts/multimodal-es/</link><pubDate>Tue, 18 Jul 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/multimodal-es/</guid><description>&lt;p>When we want to express the difference between two samples or distributions,
a popular measure family is the effect sizes based on differences between means (difference family).
When the normality assumption is satisfied, this approach works well thanks to classic measures of effect size
like Cohen&amp;rsquo;s d, Glass&amp;rsquo; Î”, or Hedges&amp;rsquo; g.
With slight deviations from normality, &lt;a href="https://aakinshin.net/posts/nonparametric-effect-size2/">robust alternatives&lt;/a> may be considered.
To build such a measure, it&amp;rsquo;s enough to upgrade classic measures by
replacing the sample mean with a robust measure of central tendency and
replacing the standard deviation with a robust measure of dispersion.
However, it might not be enough in the case of large deviations from normality.
In this post, I briefly discuss the problem of effect size evaluation in the context of multimodal distributions.&lt;/p></description></item><item><title>Joining modes of multimodal distributions</title><link>https://aakinshin.net/posts/joining-modes/</link><pubDate>Tue, 27 Jun 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/joining-modes/</guid><description>&lt;p>Multimodality of distributions is a severe issue in statistical analysis.
Comparing two multimodal distributions is a tricky challenge.
The degree of this challenge depends on the number of existing modes.
Switching from unimodal models to multimodal ones
can be a controversial decision, potentially causing more problems than solutions.
Hence, if we dare to increase the complexity of the considering models,
we should be sure that this is an essential necessity.
Even when we confidently detect a truly multimodal distribution,
a unimodal model could be an acceptable approximation if it is sufficiently close to the true distribution.
The simplicity of a unimodal model may make it preferable, even if it is less accurate.
Of course, the research goals should always be taken into account when the particular model choice is being made.&lt;/p></description></item><item><title>Plain-text summary notation for multimodal distributions</title><link>https://aakinshin.net/posts/modality-summary-notation/</link><pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/modality-summary-notation/</guid><description>&lt;p>Let&amp;rsquo;s say you collected a lot of data and want to explore the underlying distributions of collected samples.
If you have only a few distributions, the best way to do that is to look at the density plots
(expressed via histograms, kernel density estimations, or &lt;a href="https://aakinshin.net/posts/qrde-hd/">quantile-respectful density estimations&lt;/a>).
However, it&amp;rsquo;s not always possible.&lt;/p>
&lt;p>Suppose you have to process dozens, hundreds, or even thousands of distributions.
In that case,
it may be extremely time-consuming to manually check visualizations of each distribution.
If you analyze distributions from the command line or send notifications about suspicious samples,
it may be impossible to embed images in the reports.
In these cases, there is a need to present a distribution using plain text.&lt;/p>
&lt;p>One way to do that is plain text histograms.
Unfortunately, this kind of visualization may occupy o lot of space.
In complicated cases, you may need 20 or 30 lines per a single distribution.&lt;/p>
&lt;p>Another way is to present classic &lt;a href="https://en.wikipedia.org/wiki/Summary_statistics">summary statistics&lt;/a>
like mean or median, standard deviation or median absolute deviation, quantiles, skewness, and kurtosis.
There is another problem here:
without experience, it&amp;rsquo;s hard to reconstruct the true distribution shape based on these values.
Even if you are an experienced researcher, the statistical metrics may become misleading in the case of multimodal distributions.
Multimodality is one of the most severe challenges in distribution analysis because it distorts basic summary statistics.
It&amp;rsquo;s important to not only find such distribution but also have a way to present brief information about multimodality effects.&lt;/p>
&lt;p>So, how can we condense the underlying distribution shape of a given sample to a short text line?
I didn&amp;rsquo;t manage to find an approach that works fine in my cases, so I came up with my own notation.
Most of the interpretation problems in my experiments arise from multimodality and outliers,
so I decided to focus on these two things and specifically highlight them.
Let&amp;rsquo;s consider this plot:&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/modality-summary-notation/img/thumbnail-light.svg" target="_blank" alt="thumbnail">
 &lt;img
 src="https://aakinshin.net/posts/modality-summary-notation/img/thumbnail-light.svg" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/modality-summary-notation/img/thumbnail-dark.svg" target="_blank" alt="thumbnail">
 &lt;img
 src="https://aakinshin.net/posts/modality-summary-notation/img/thumbnail-dark.svg" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>I suggest describing it like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="o">{&lt;/span>1.00, 2.00&lt;span class="o">}&lt;/span> + &lt;span class="o">[&lt;/span>7.16&lt;span class="p">;&lt;/span> 13.12&lt;span class="o">]&lt;/span>_100 + &lt;span class="o">{&lt;/span>19.00&lt;span class="o">}&lt;/span> + &lt;span class="o">[&lt;/span>27.69&lt;span class="p">;&lt;/span> 32.34&lt;span class="o">]&lt;/span>_100 + &lt;span class="o">{&lt;/span>37.00..39.00&lt;span class="o">}&lt;/span>_3
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Let me explain the suggested notation in detail.&lt;/p></description></item><item><title>Intermodal outliers</title><link>https://aakinshin.net/posts/intermodal-outliers/</link><pubDate>Tue, 10 Nov 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/intermodal-outliers/</guid><description>&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Outlier">Outlier&lt;/a> analysis is a typical step in distribution exploration.
Usually, we work with the &amp;ldquo;lower outliers&amp;rdquo; (extremely low values) and the &amp;ldquo;upper outliers&amp;rdquo; (extremely high values).
However, outliers are not always extreme values.
In the general case, an outlier is a value that significantly differs from other values in the same sample.
In the case of multimodal distribution, we can also consider outliers in the middle of the distribution.
Let&amp;rsquo;s call such outliers that we found between modes the &amp;ldquo;&lt;em>intermodal outliers&lt;/em>.&amp;rdquo;&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/intermodal-outliers/img/step4-light.svg" target="_blank" alt="step4">
 &lt;img
 src="https://aakinshin.net/posts/intermodal-outliers/img/step4-light.svg" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/intermodal-outliers/img/step4-dark.svg" target="_blank" alt="step4">
 &lt;img
 src="https://aakinshin.net/posts/intermodal-outliers/img/step4-dark.svg" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>Look at the above density plot.
It&amp;rsquo;s a bimodal distribution that is formed as a combination of two unimodal distributions.
Each of the unimodal distributions may have its own lower and upper outliers.
When we merge them, the upper outliers of the first distribution and the lower outliers of the second distribution
stop being lower or upper outliers.
However, if these values don&amp;rsquo;t belong to the modes, they still are a subject of interest.
In this post, I will show you how to detect such intermodal outliers
and how they can be used to form a better distribution description.&lt;/p></description></item><item><title>Lowland multimodality detection</title><link>https://aakinshin.net/posts/lowland-multimodality-detection/</link><pubDate>Tue, 03 Nov 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/lowland-multimodality-detection/</guid><description>&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/lowland-multimodality-detection/img/data5-light.svg" target="_blank" alt="data5">
 &lt;img
 src="https://aakinshin.net/posts/lowland-multimodality-detection/img/data5-light.svg" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/lowland-multimodality-detection/img/data5-dark.svg" target="_blank" alt="data5">
 &lt;img
 src="https://aakinshin.net/posts/lowland-multimodality-detection/img/data5-dark.svg" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>Multimodality is an essential feature of a distribution, which may create many troubles during automatic analysis.
One of the best ways to work with such distributions is to detect all the modes in advance based on the given samples.
Unfortunately, this problem is much harder than it looks like.&lt;/p>
&lt;p>I tried many different approaches for multimodality detection, but none of them was good enough.
During the past several years, my approach of choice was the &lt;a href="http://www.brendangregg.com/FrequencyTrails/modes.html">mvalue-based modal test&lt;/a> by Brendan Gregg.
It works nicely in simple cases, but I was constantly stumbling over noisy samples where this algorithm doesn&amp;rsquo;t produce reliable results.
Also, it has some limitations that make it inapplicable to some corner cases.&lt;/p>
&lt;p>So, I needed a better approach.
Here are my main requirements:&lt;/p>
&lt;ul>
&lt;li>It should detect the exact mode locations and ranges&lt;/li>
&lt;li>It should provide reliable results even on noisy samples&lt;/li>
&lt;li>It should be able to detect multimodality even when some modes are extremely close to each other&lt;/li>
&lt;li>It should work out of the box without tricky parameter tuning for each specific distribution&lt;/li>
&lt;/ul>
&lt;p>I failed to find such an algorithm anywhere, so I came up with my own!
The current working title is &amp;ldquo;the lowland multimodality detector.&amp;rdquo;
It takes an estimation of the probability density function (PDF) and tries to find &amp;ldquo;lowlands&amp;rdquo; (areas that are much lower than neighboring peaks).
Next, it splits the plot by these lowlands and detects modes between them.
For the PDF estimation, it uses the
&lt;a href="https://aakinshin.net/posts/qrde-hd/">quantile-respectful density estimation based on the Harrell-Davis quantile estimator&lt;/a> (QRDE-HD)
(see also &lt;a href="https://aakinshin.net/library/papers/harrell1982/">&lt;svg class="rating-icon">&lt;use xlink:href="https://aakinshin.net/img/fa/all.svg#paper">&lt;/use>&lt;/svg>harrell1982&lt;/a>)
Let me explain how it works in detail.&lt;/p></description></item><item><title>Misleading histograms</title><link>https://aakinshin.net/posts/misleading-histograms/</link><pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/misleading-histograms/</guid><description>&lt;p>Below you see two histograms.
What could you say about them?&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/misleading-histograms/img/hist-riddle-light.svg" target="_blank" alt="hist-riddle">
 &lt;img
 src="https://aakinshin.net/posts/misleading-histograms/img/hist-riddle-light.svg" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/misleading-histograms/img/hist-riddle-dark.svg" target="_blank" alt="hist-riddle">
 &lt;img
 src="https://aakinshin.net/posts/misleading-histograms/img/hist-riddle-dark.svg" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>Most likely, you say that the first histogram is based on a uniform distribution,
and the second one is based on a multimodal distribution with four modes.
Although this is not obvious from the plots,
both histograms are based on the same sample:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-cs" data-lang="cs">&lt;span class="line">&lt;span class="cl">&lt;span class="m">20.13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">19.94&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">20.03&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">20.06&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">20.04&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">19.98&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">20.15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">19.99&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">20.20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">19.99&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">20.13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">20.22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">19.86&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">19.97&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">19.98&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">20.06&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="m">29.97&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">29.73&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">29.75&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">30.13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">29.96&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">29.82&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">29.98&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">30.12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">30.18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">29.95&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">29.97&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">29.82&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">30.04&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">29.93&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">30.04&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">30.07&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="m">40.10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">39.93&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">40.05&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">39.82&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">39.92&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">39.91&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">39.75&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">40.00&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">40.02&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">39.96&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">40.07&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">39.92&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">39.86&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">40.04&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">39.91&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">40.14&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="m">49.95&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.06&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.03&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">49.92&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.06&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.00&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.02&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.06&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.00&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">49.70&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.02&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">49.96&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.01&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.05&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">50.13&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Thus, the only difference between histograms is the offset!&lt;/p>
&lt;p>Visualization is a simple way to understand the shape of your data.
Unfortunately, this way may easily become a slippery slope.
In the &lt;a href="https://aakinshin.net/posts/kde-bw/">previous post&lt;/a>, I have shown how density plots may deceive you when the bandwidth is poorly chosen.
Today, we talk about histograms and why you can&amp;rsquo;t trust them in the general case.&lt;/p></description></item><item><title>Frequency Trails: Modes and Modality</title><link>https://aakinshin.net/library/web/cb5645f7ac4f6f375a7a2cd38b58c4e1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/web/cb5645f7ac4f6f375a7a2cd38b58c4e1/</guid><description/></item></channel></rss>