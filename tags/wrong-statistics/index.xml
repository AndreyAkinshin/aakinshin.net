<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Wrong Statistics on Andrey Akinshin</title><link>https://aakinshin.net/tags/wrong-statistics/</link><description>Recent content in Wrong Statistics on Andrey Akinshin</description><generator>Hugo -- gohugo.io</generator><language>en</language><atom:link href="https://aakinshin.net/tags/wrong-statistics/index.xml" rel="self" type="application/rss+xml"/><item><title>Statistics Done Wrong: The Woefully Complete Guide</title><link>https://aakinshin.net/library/books/reinhart-statistics-done-wrong/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/books/reinhart-statistics-done-wrong/</guid><description/></item><item><title>US studies may overestimate effect sizes in softer research</title><link>https://aakinshin.net/library/papers/fanelli2013/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/fanelli2013/</guid><description>Daniele Fanelli, John PA Ioannidis &amp;lt;span title=&amp;ldquo;Many biases affect scientific research, causing a waste of resources, posing a threat to human health, and hampering scientific progress. These problems are hypothesized to be worsened by lack of consensus on theories and methods, by selective publication processes, and by career systems too heavily oriented toward productivity, such as those adopted in the United States (US). Here, we extracted 1,174 primary outcomes appearing in 82 meta-analyses published in health-related biological and behavioral research sampled from the Web of Science categories Genetics &amp;amp; Heredity and Psychiatry and measured how individual results deviated from the overall summary effect size within their respective meta-analysis. We found that primary studies whose outcome included behavioral parameters were generally more likely to report extreme effects, and those with a corresponding author based in the US were more likely to deviate in the direction predicted by their experimental hypotheses, particularly when their outcome did not include additional biological parameters. Nonbehavioral studies showed no such &amp;ldquo;US effect&amp;rdquo; and were subject mainly to sampling variance and small-study effects, which were stronger for non-US countries. Although this latter finding could be interpreted as a publication bias against non-US authors, the US effect observed in behavioral research is unlikely to be generated by editorial biases. Behavioral studies have lower methodological consensus and higher noise, making US researchers potentially more likely to express an underlying propensity to report strong and significant findings.&amp;quot;&amp;gt;“US studies may overestimate effect sizes in softer research” (2013) // Proceedings of the National Academy of Sciences. Publisher: National Acad Sciences. Vol. 110. No 37. Pp. 15031–15036. DOI: 10.1073/pnas.1302997110
Abstract Many biases affect scientific research, causing a waste of resources, posing a threat to human health, and hampering scientific progress. These problems are hypothesized to be worsened by lack of consensus on theories and methods, by selective publication processes, and by career systems too heavily oriented toward productivity, such as those adopted in the United States (US).</description></item><item><title>Why most published research findings are false</title><link>https://aakinshin.net/library/papers/ioannidis2005/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/ioannidis2005/</guid><description>John PA Ioannidis “Why most published research findings are false” (2005) // PLoS medicine. Publisher: Public Library of Science. Vol. 2. No 8. Pp. e124. DOI: 10.1371/journal.pmed.0020124
Abstract There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research.
Bib @Article{ioannidis2005, title = {Why most published research findings are false}, author = {Ioannidis, John PA}, journal = {PLoS medicine}, abstract = {There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance.</description></item></channel></rss>