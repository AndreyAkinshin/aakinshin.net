<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Effect Size on Andrey Akinshin</title><link>https://aakinshin.net/tags/effect-size/</link><description>Recent content in Effect Size on Andrey Akinshin</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Tue, 12 Mar 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://aakinshin.net/tags/effect-size/index.xml" rel="self" type="application/rss+xml"/><item><title>Effect Sizes and Asymmetry</title><link>https://aakinshin.net/posts/asymmetry-es/</link><pubDate>Tue, 12 Mar 2024 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/asymmetry-es/</guid><description>&lt;p>Cohen&amp;rsquo;s d is one of the most popular measures of the effect size.
Unfortunately, it was designed for the normal distribution,
which may make it a misleading measure in the non-normal case.
And the real distributions are &lt;a href="https://aakinshin.net/tags/normality/">never normal&lt;/a>.
When we discuss &lt;a href="https://aakinshin.net/library/quotes/ca964333-044c-4fec-8d89-145921696525/">deviations from normality&lt;/a>,
we should treat the illusion of normality not as an atomic mental construction,
but rather as a set of independent assumptions, each of which may be violated independently.
In this post, I take a look at what kind of issues we may have when the symmetry assumption is heavily violated.&lt;/p></description></item><item><title>Calculating gamma effect size for samples with zero median absolute deviation</title><link>https://aakinshin.net/posts/zero-mad-gamma-es/</link><pubDate>Tue, 22 Jun 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/zero-mad-gamma-es/</guid><description>&lt;p>In previous posts, I discussed the &lt;a href="https://aakinshin.net/posts/nonparametric-effect-size/">gamma effect size&lt;/a>
which is a Cohen&amp;rsquo;s d-consistent nonparametric and robust measure of the effect size.
Also, I discussed &lt;a href="https://aakinshin.net/posts/nonparametric-effect-size2/">various ways to customize this metric&lt;/a>
and adjust it to different kinds of business requirements.
In this post, I want to briefly cover one more corner case that requires special adjustments.
We are going to discuss the situation when the median absolute deviation is zero.&lt;/p></description></item><item><title>Customization of the nonparametric Cohen's d-consistent effect size</title><link>https://aakinshin.net/posts/nonparametric-effect-size2/</link><pubDate>Tue, 08 Jun 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/nonparametric-effect-size2/</guid><description>&lt;p>One year ago, I publish a post called &lt;a href="https://aakinshin.net/posts/nonparametric-effect-size/">&lt;svg class="rating-icon">&lt;use xlink:href="https://aakinshin.net/img/fa/all.svg#note">&lt;/use>&lt;/svg>Nonparametric Cohen&amp;#39;s d-consistent effect size&lt;/a>.
During this year, I got a lot of internal and external feedback from
my own statistical experiments and
&lt;a href="https://twitter.com/ViljamiSairanen/status/1400457118340108293">people&lt;/a>
&lt;a href="https://sherbold.github.io/autorank/autorank/">who&lt;/a>
&lt;a href="https://github.com/Ramon-Diaz/Thesis-Project/blob/85df6b11050c7e05c4394d873585f701a7e3f32e/_util.py#L100">tried&lt;/a>
to use the suggested approach.
It seems that the nonparametric version of Cohen&amp;rsquo;s d works much better with real-life not-so-normal data.
While the classic Cohen&amp;rsquo;s d based on
the non-robust arithmetic mean and
the &lt;a href="https://aakinshin.net/posts/misleading-stddev/">non-robust standard deviation&lt;/a>
can be easily &lt;a href="https://aakinshin.net/posts/cohend-and-outliers/">corrupted by a single outlier&lt;/a>,
my approach is much more resistant to unexpected extreme values.
Also, it allows exploring
&lt;a href="https://aakinshin.net/posts/comparing-distributions-using-gamma-es/">the difference between specific quantiles of considered samples&lt;/a>,
which can be useful in the non-parametric case.&lt;/p>
&lt;p>However, I wasn&amp;rsquo;t satisfied with the results of all of my experiments.
While I still like the basic idea
(replace the mean with the median; replace the standard deviation with the median absolute deviation),
it turned out that the final results heavily depend on the used quantile estimator.
To be more specific, the original Harrell-Davis quantile estimator is not always optimal;
in most cases, it&amp;rsquo;s better to replace it with its &lt;a href="https://aakinshin.net/posts/trimmed-hdqe/">trimmed&lt;/a> modification.
However, the particular choice of the quantile estimators depends on the situation.
Also, the consistency constant for the median absolute deviation
should be adjusted according to the current sample size and the used quantile estimator.
Of course, it also can be replaced by other dispersion estimators
that can be used as consistent estimators of the standard deviation.&lt;/p>
&lt;p>In this post, I want to get a brief overview of possible customizations of the suggested metrics.&lt;/p></description></item><item><title>Comparing distribution quantiles using gamma effect size</title><link>https://aakinshin.net/posts/comparing-distributions-using-gamma-es/</link><pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/comparing-distributions-using-gamma-es/</guid><description>&lt;p>There are several ways to describe the difference between two distributions.
Here are a few examples:&lt;/p>
&lt;ul>
&lt;li>Effect sizes based on differences between means (e.g., Cohen&amp;rsquo;s d, Glass&amp;rsquo; Δ, Hedges&amp;rsquo; g)&lt;/li>
&lt;li>&lt;a href="https://aakinshin.net/posts/shift-and-ratio-functions/">The shift and ration functions&lt;/a> that
estimate differences between matched quantiles.&lt;/li>
&lt;/ul>
&lt;p>In one of the previous post, I &lt;a href="https://aakinshin.net/posts/nonparametric-effect-size/">described&lt;/a>
the gamma effect size which is defined not for the mean but for quantiles.
In this post, I want to share a few case studies that demonstrate
how the suggested metric combines the advantages of the above approaches.&lt;/p></description></item><item><title>A single outlier could completely distort your Cohen's d value</title><link>https://aakinshin.net/posts/cohend-and-outliers/</link><pubDate>Tue, 26 Jan 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/cohend-and-outliers/</guid><description>&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Effect_size#Cohen's_d">Cohen&amp;rsquo;s d&lt;/a> is a popular way to estimate
the &lt;a href="https://en.wikipedia.org/wiki/Effect_size">effect size&lt;/a> between two samples.
It works excellent for perfectly normal distributions.
Usually, people think that slight deviations from normality
shouldn&amp;rsquo;t produce a noticeable impact on the result.
Unfortunately, it&amp;rsquo;s not always true.
In fact, a single outlier value can completely distort the result even in large samples.&lt;/p>
&lt;p>In this post, I will present some illustrations for this problem and will show how to fix it.&lt;/p></description></item><item><title>Nonparametric Cohen's d-consistent effect size</title><link>https://aakinshin.net/posts/nonparametric-effect-size/</link><pubDate>Thu, 25 Jun 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/nonparametric-effect-size/</guid><description>&lt;p>&lt;strong>Update: the second part of this post is available &lt;a href="https://aakinshin.net/posts/nonparametric-effect-size2/">here&lt;/a>.&lt;/strong>&lt;/p>
&lt;p>The effect size is a common way to describe a difference between two distributions.
When these distributions are normal, one of the most popular approaches to express the effect size is &lt;a href="https://en.wikipedia.org/wiki/Effect_size#Cohen's_d">Cohen&amp;rsquo;s d&lt;/a>.
Unfortunately, it doesn&amp;rsquo;t work great for non-normal distributions.&lt;/p>
&lt;p>In this post, I will show a robust Cohen&amp;rsquo;s d-consistent effect size formula for nonparametric distributions.&lt;/p>





&lt;div class="row">
&lt;div class="mx-auto">
 &lt;a href="https://aakinshin.net/posts/nonparametric-effect-size/img/blackboard.png" target="_blank" alt="blackboard">
 &lt;img
 class="mx-auto d-block img-fluid"
 width='800'
 src="https://aakinshin.net/posts/nonparametric-effect-size/img/blackboard.png" />
 &lt;/a>
&lt;/div>
&lt;/div>
&lt;br /></description></item><item><title>3 Easy Ways to Obtain Cohen’s d and Its CI</title><link>https://aakinshin.net/library/web/3cf11abcafe2b5d16c586dfb1af211bd/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/web/3cf11abcafe2b5d16c586dfb1af211bd/</guid><description/></item><item><title>A Critique and Improvement of the "CL" Common Language Effect Size Statistics of McGraw and Wong</title><link>https://aakinshin.net/library/papers/vargha2000/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/vargha2000/</guid><description>Reference András Vargha, Harold D Delaney, Andras Vargha “A Critique and Improvement of the &amp;ldquo;CL&amp;rdquo; Common Language Effect Size Statistics of McGraw and Wong” (2000) // Journal of Educational and Behavioral Statistics. Vol. 25. No 2. Pp. 101. DOI: 10.2307/1165329
Bib @Article{vargha2000, title = {A Critique and Improvement of the &amp;#34;CL&amp;#34; Common Language Effect Size Statistics of McGraw and Wong}, volume = {25}, issn = {10769986}, url = {http://links.jstor.org/sici?sici=1076-9986%28200022%2925%3A2%3C101%3AACAIOT%3E2.0.CO%3B2-O&amp;amp;origin=crossref}, doi = {10.2307/1165329}, number = {2}, urldate = {2023-10-22}, journal = {Journal of Educational and Behavioral Statistics}, author = {Vargha, András and Delaney, Harold D and Vargha, Andras}, year = {2000}, pages = {101} }</description></item><item><title>A History of Effect Size Indices</title><link>https://aakinshin.net/library/papers/huberty2002/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/huberty2002/</guid><description>Reference Carl J Huberty “A History of Effect Size Indices” (2002) // Educational and Psychological Measurement. Publisher: SAGE Publications. Vol. 62. No 2. Pp. 227–240. DOI: 10.1177/0013164402062002002
Bib @Article{huberty2002, title = {A History of Effect Size Indices}, volume = {62}, issn = {1552-3888}, url = {http://dx.doi.org/10.1177/0013164402062002002}, doi = {10.1177/0013164402062002002}, number = {2}, journal = {Educational and Psychological Measurement}, publisher = {SAGE Publications}, author = {Huberty, Carl J}, year = {2002}, month = {apr}, pages = {227–240} }</description></item><item><title>A Robust Nonparametric Measure of Effect Size Based on an Analog of Cohen's d, Plus Inferences about the Median of the Typical Difference</title><link>https://aakinshin.net/library/papers/wilcox2019/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/wilcox2019/</guid><description>Reference Rand Wilcox “A Robust Nonparametric Measure of Effect Size Based on an Analog of Cohen&amp;rsquo;s d, Plus Inferences About the Median of the Typical Difference” (2019) // Journal of Modern Applied Statistical Methods. Vol. 17. No 2. Pp. jmasm.eP2726. DOI: 10.22237/jmasm/1551905677
Abstract The paper describes a nonparametric analog of Cohen&amp;rsquo;s d, Q. It is established that a confidence interval for Q can be computed via a method for computing a confidence interval for the median of D = X1 − X2, which in turn is related to making inferences about P(X1 \textless X2).
Bib @Article{wilcox2019, title = {A Robust Nonparametric Measure of Effect Size Based on an Analog of Cohen&amp;#39;s d, Plus Inferences About the Median of the Typical Difference}, volume = {17}, issn = {1538-9472}, url = {https://digitalcommons.wayne.edu/jmasm/vol17/iss2/1}, doi = {10.22237/jmasm/1551905677}, abstract = {The paper describes a nonparametric analog of Cohen&amp;#39;s d, Q. It is established that a confidence interval for Q can be computed via a method for computing a confidence interval for the median of D = X1 − X2, which in turn is related to making inferences about P(X1 \textless X2).}, language = {en}, number = {2}, urldate = {2020-01-07}, journal = {Journal of Modern Applied Statistical Methods}, author = {Wilcox, Rand}, month = {mar}, year = {2019}, pages = {jmasm.eP2726}, custom-url-pdf = {https://digitalcommons.wayne.edu/cgi/viewcontent.cgi?article=2726&amp;amp;context=jmasm} }</description></item><item><title>Cohen’s d is Biased</title><link>https://aakinshin.net/library/web/f374b09ad2b7d40966766511c2618784/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/web/f374b09ad2b7d40966766511c2618784/</guid><description/></item><item><title>Computing Effect Size Measures with Vista</title><link>https://aakinshin.net/library/papers/ledesma2009/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/ledesma2009/</guid><description>Reference Ledesma R D, Macbeth G, Cortada de Kohan N “Computing effect size measures with vista” (2009) // Tutor. Quant. Methods Psychol.. Vol. 5. Pp. 25.
Bib @Article{ledesma2009, title = {Computing effect size measures with vista}, volume = {5}, journal = {Tutor. Quant. Methods Psychol.}, author = {D, Ledesma R and G, Macbeth and N, Cortada de Kohan}, year = {2009}, pages = {25}, custom-url-pdf = {https://www.tqmp.org/RegularArticles/vol05-1/p025/p025.pdf} }</description></item><item><title>Effect Sizes for research: Univariate and Multivariate Applications</title><link>https://aakinshin.net/library/papers/grissom2012/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/grissom2012/</guid><description>Reference Robert J Grissom, John J Kim “Effect sizes for research: Univariate and multivariate applications” (2012) // Publisher: Routledge Academic. ISBN: 0805850147. DOI: 10.4324/9781410612915
Bib @Book{grissom2012, title = {Effect sizes for research: Univariate and multivariate applications}, author = {Grissom, Robert J and Kim, John J}, year = {2012}, ed = {1}, publisher = {Routledge Academic}, isbn = {0805850147}, doi = {10.4324/9781410612915} }</description></item><item><title>Guide to Effect Sizes and Confidence Intervals</title><link>https://aakinshin.net/library/papers/jan%C3%A92024/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/jan%C3%A92024/</guid><description>Reference Matthew B Jané, Qinyu Xiao, Siu Kit Yeung, Mattan S *Ben-Shachar, Aaron R Caldwell, Denis Cousineau, Daniel J Dunleavy, Mahmoud M Elsherif, Blair T Johnson, David Moreau, Paul Riesthuis, Lukas Röseler, James Steele, Felipe F Vieira, Mircea Zloteanu, Gilad Feldman “Guide to Effect Sizes and Confidence Intervals” (2024) // Publisher: OSF. DOI: 10.17605/OSF.IO/D8C4G
Bib @Misc{jané2024, title = {Guide to Effect Sizes and Confidence Intervals}, url = {https://matthewbjane.quarto.pub/}, doi = {10.17605/OSF.IO/D8C4G}, publisher = {OSF}, author = {Jané, Matthew B and Xiao, Qinyu and Yeung, Siu Kit and *Ben-Shachar, Mattan S and Caldwell, Aaron R and Cousineau, Denis and Dunleavy, Daniel J and Elsherif, Mahmoud M and Johnson, Blair T and Moreau, David and Riesthuis, Paul and Röseler, Lukas and Steele, James and Vieira, Felipe F and Zloteanu, Mircea and Feldman, Gilad}, custom-url-pdf = {https://osf.io/download/87vke/}, year = {2024} }</description></item><item><title>Interval Estimates of Weighted Effect Sizes in the one-way Heteroscedastic ANOVA</title><link>https://aakinshin.net/library/papers/kulinskaya2006/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/kulinskaya2006/</guid><description>Reference Kulinskaya E, Staudte R G “Interval estimates of weighted effect sizes in the one-way heteroscedastic ANOVA” (2006) // Br. J. Math. Statist. Psychol.. Vol. 59. Pp. 97. DOI: 10.1348/000711005X68174
Bib @Article{kulinskaya2006, title = {Interval estimates of weighted effect sizes in the one-way heteroscedastic ANOVA}, volume = {59}, journal = {Br. J. Math. Statist. Psychol.}, author = {E, Kulinskaya and G, Staudte R}, year = {2006}, pages = {97}, doi = {10.1348/000711005X68174} }</description></item><item><title>Journal’s Impact Factor and Overestimation of Effect Sizes</title><link>https://aakinshin.net/library/quotes/544f89c6-188a-488a-a13a-585caf62ef81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/544f89c6-188a-488a-a13a-585caf62ef81/</guid><description>Some evidence suggests a correlation between a journal’s impact factor (a rough measure of its prominence and importance) and the factor by which its studies overestimate effect sizes. Studies that produce less “exciting” results are closer to the truth but less interesting to a major journal editor.</description></item><item><title>Measuring Effect size: A Robust Heteroscedastic Approach for Two or More Groups</title><link>https://aakinshin.net/library/papers/wilcox2011/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/wilcox2011/</guid><description>Reference Wilcox R R, Tian T S “Measuring effect size: A robust heteroscedastic approach for two or more groups” (2011) // J. Appl. Stat.. Vol. 38. Pp. 1359. DOI: 10.1080/02664763.2010.498507
Bib @Article{wilcox2011, title = {Measuring effect size: A robust heteroscedastic approach for two or more groups}, volume = {38}, journal = {J. Appl. Stat.}, author = {R, Wilcox R and S, Tian T}, year = {2011}, pages = {1359}, doi = {10.1080/02664763.2010.498507} }</description></item><item><title>Robust and scale-free Effect Sizes for non-Normal two-sample comparisons, with Applications in e-commerce</title><link>https://aakinshin.net/library/papers/wooff2013/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/wooff2013/</guid><description>Reference David A Wooff, Amin Jamalzadeh “Robust and scale-free effect sizes for non-Normal two-sample comparisons, with applications in e-commerce” (2013) // Journal of Applied Statistics. Vol. 40. No 11. Pp. 2495–2515. DOI: 10.1080/02664763.2013.818625
Abstract The effect size (ES) has been mainly introduced and investigated for changes in location under an assumption of Normality for the underlying population. However, there are many circumstances where populations are non-Normal, or depend on scale and shape and not just a location parameter. Our motivating application from e-commerce requires an ES which is appropriate for long-tailed distributions. We review some common ES measures. We then introduce two novel alternative ES for two-sample comparisons, one scale-free and one on the original scale of measurement, and analyse some theoretical properties. We examine these ES for two-sample comparison studies under an assumption of Normality and investigate what happens when both location and scale parameters differ. We explore ES for phenomena for non-Normal situations, using the Weibull family for illustration. Finally, for an application, we assess differences in customer behaviour when browsing E-commerce websites.
Bib @Article{wooff2013, title = {Robust and scale-free effect sizes for non-Normal two-sample comparisons, with applications in e-commerce}, volume = {40}, issn = {0266-4763}, url = {https://doi.org/10.1080/02664763.2013.818625}, doi = {10.1080/02664763.2013.818625}, abstract = {The effect size (ES) has been mainly introduced and investigated for changes in location under an assumption of Normality for the underlying population. However, there are many circumstances where populations are non-Normal, or depend on scale and shape and not just a location parameter. Our motivating application from e-commerce requires an ES which is appropriate for long-tailed distributions. We review some common ES measures. We then introduce two novel alternative ES for two-sample comparisons, one scale-free and one on the original scale of measurement, and analyse some theoretical properties. We examine these ES for two-sample comparison studies under an assumption of Normality and investigate what happens when both location and scale parameters differ.</description></item><item><title>Robust Effect Sizes for 2 Independent Groups</title><link>https://aakinshin.net/library/web/61f968693aa9f03dd1c1e21aca7c0cd5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/web/61f968693aa9f03dd1c1e21aca7c0cd5/</guid><description/></item><item><title>Statistical Significance and Effect Size reporting: Portrait of a Possible Future</title><link>https://aakinshin.net/library/papers/thompson1998/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/thompson1998/</guid><description>Reference Thompson B “Statistical significance and effect size reporting: Portrait of a possible future” (1998) // Res. Schools. Vol. 5. Pp. 33.
Bib @Article{thompson1998, title = {Statistical significance and effect size reporting: Portrait of a possible future}, volume = {5}, journal = {Res. Schools}, author = {B, Thompson}, year = {1998}, pages = {33} }</description></item><item><title>The Influence of Journal Prestige on the Inflation of Effect Sizes in Small Trials</title><link>https://aakinshin.net/library/quotes/79991435-cde7-4963-8f62-2bf812a39fda/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/79991435-cde7-4963-8f62-2bf812a39fda/</guid><description>We found that small trials published in NEJM, JAMA and Lancet were more likely to display more favourable results for experimental interventions compared with trials in other publication venues. Inflated effect sizes were seen primarily for early small trials in these prominent journals. Therefore, the results of small trials with spectacular early promises for large treatment effects should be seen with great caution. Conversely, for large trials, effect estimates are likely to be more reliable. Small-study effects have been previously documented in the randomized trials literature. However, the results of our study provide further insight suggesting the possibility of a specific interaction with further exaggerated effects when the limited evidence from small trials appears in the most prestigious journals. Also, the inflation of effects in early randomized trials on particular interventions appears to be quite specific to these most prestigious journals. Some modest heterogeneity was seen in the two tertiles with higher events, but heterogeneity is difficult to determine in the tertile with lower events, because of the wide uncertainty in the ROR for single topics, when there is limited evidence.</description></item><item><title>Truth Inflation and Groundbreaking Effect Sizes in top-ranked Journals</title><link>https://aakinshin.net/library/quotes/3107d5e7-d81b-48f9-926e-591261332ef5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/3107d5e7-d81b-48f9-926e-591261332ef5/</guid><description>Consider also that top-ranked journals, such as Nature and Science, prefer to publish studies with groundbreaking results—meaning large effect sizes in novel fields with little prior research. This is a perfect combination for chronic truth inflation. Some evidence suggests a correlation between a journal’s impact factor (a rough measure of its prominence and importance) and the factor by which its studies overestimate effect sizes. Studies that produce less “exciting” results are closer to the truth but less interesting to a major journal editor. brembs2013 siontis2011</description></item><item><title>US Studies May Overestimate Effect Sizes in Softer Research</title><link>https://aakinshin.net/library/papers/fanelli2013/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/fanelli2013/</guid><description>Reference Daniele Fanelli, John PA Ioannidis “US studies may overestimate effect sizes in softer research” (2013) // Proceedings of the National Academy of Sciences. Publisher: National Acad Sciences. Vol. 110. No 37. Pp. 15031–15036. DOI: 10.1073/pnas.1302997110
Abstract Many biases affect scientific research, causing a waste of resources, posing a threat to human health, and hampering scientific progress. These problems are hypothesized to be worsened by lack of consensus on theories and methods, by selective publication processes, and by career systems too heavily oriented toward productivity, such as those adopted in the United States (US). Here, we extracted 1,174 primary outcomes appearing in 82 meta-analyses published in health-related biological and behavioral research sampled from the Web of Science categories Genetics &amp;amp; Heredity and Psychiatry and measured how individual results deviated from the overall summary effect size within their respective meta-analysis. We found that primary studies whose outcome included behavioral parameters were generally more likely to report extreme effects, and those with a corresponding author based in the US were more likely to deviate in the direction predicted by their experimental hypotheses, particularly when their outcome did not include additional biological parameters. Nonbehavioral studies showed no such &amp;ldquo;US effect&amp;rdquo; and were subject mainly to sampling variance and small-study effects, which were stronger for non-US countries. Although this latter finding could be interpreted as a publication bias against non-US authors, the US effect observed in behavioral research is unlikely to be generated by editorial biases. Behavioral studies have lower methodological consensus and higher noise, making US researchers potentially more likely to express an underlying propensity to report strong and significant findings.
Bib @Article{fanelli2013, title = {US studies may overestimate effect sizes in softer research}, author = {Fanelli, Daniele and Ioannidis, John PA}, journal = {Proceedings of the National Academy of Sciences}, abstract = {Many biases affect scientific research, causing a waste of resources, posing a threat to human health, and hampering scientific progress.</description></item><item><title>Why “Encouraging” Effect Size Reporting is Not Working: The Etiology of Researcher Resistance to Changing Practices</title><link>https://aakinshin.net/library/papers/thompson1999/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/thompson1999/</guid><description>Reference Bruce Thompson “Why “Encouraging” Effect Size Reporting Is Not Working: The Etiology of Researcher Resistance to Changing Practices” (1999) // The Journal of Psychology. Publisher: Informa UK Limited. Vol. 133. No 2. Pp. 133–140. DOI: 10.1080/00223989909599728
Bib @Article{thompson1999, title = {Why “Encouraging” Effect Size Reporting Is Not Working: The Etiology of Researcher Resistance to Changing Practices}, volume = {133}, issn = {1940-1019}, url = {http://dx.doi.org/10.1080/00223989909599728}, doi = {10.1080/00223989909599728}, number = {2}, journal = {The Journal of Psychology}, publisher = {Informa UK Limited}, author = {Thompson, Bruce}, year = {1999}, month = {mar}, pages = {133–140} }</description></item></channel></rss>