<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Research: Weighted quantile estimators on Andrey Akinshin</title><link>https://aakinshin.net/tags/research-wqe/</link><description>Recent content in Research: Weighted quantile estimators on Andrey Akinshin</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Tue, 18 Apr 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://aakinshin.net/tags/research-wqe/index.xml" rel="self" type="application/rss+xml"/><item><title>Preprint announcement: 'Weighted quantile estimators'</title><link>https://aakinshin.net/posts/preprint-wqe/</link><pubDate>Tue, 18 Apr 2023 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/preprint-wqe/</guid><description>&lt;p>I have just published a preprint of a paper &amp;lsquo;Weighted quantile estimators&amp;rsquo;.
It&amp;rsquo;s based on a series of my &lt;a href="https://aakinshin.net/tags/research-wqe/">research notes&lt;/a> that I have been writing since September 2020.&lt;/p>
&lt;p>The paper preprint is available on arXiv:
&lt;a href="https://arxiv.org/abs/2304.07265">arXiv:2304.07265 [stat.ME]&lt;/a>.
The paper source code is available on GitHub:
&lt;a href="https://github.com/AndreyAkinshin/paper-wqe">AndreyAkinshin/paper-wqe&lt;/a>.
You can cite it as follows:&lt;/p>
&lt;ul>
&lt;li>Andrey Akinshin (2023)
&amp;ldquo;Weighted quantile estimators&amp;rdquo;
&lt;a href="https://arxiv.org/abs/2304.07265">arXiv:2304.07265&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Abstract:&lt;/p>
&lt;blockquote>
&lt;p>In this paper, we consider a generic scheme that allows building weighted versions of various quantile estimators,
such as traditional quantile estimators based on linear interpolation of two order statistics,
the Harrell-Davis quantile estimator and its trimmed modification.
The obtained weighted quantile estimators are especially useful
in the problem of estimating a distribution at the tail of a time series using quantile exponential smoothing.
The presented approach can also be applied to other problems,
such as quantile estimation of weighted mixture distributions.&lt;/p>
&lt;/blockquote></description></item><item><title>Weighted quantile estimation for a weighted mixture distribution</title><link>https://aakinshin.net/posts/wqe-mixture/</link><pubDate>Tue, 25 Oct 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/wqe-mixture/</guid><description>&lt;p>Let $\mathbf{x} = \{ x_1, x_2, \ldots, x_n \}$ be a sample of size $n$.
We assign non-negative weight coefficients $w_i$ with a positive sum for all sample elements:&lt;/p>
$$
\mathbf{w} = \{ w_1, w_2, \ldots, w_n \}, \quad w_i \geq 0, \quad \sum_{i=1}^{n} w_i > 0.
$$
&lt;p>For simplification, we also consider normalized (standardized) weights $\overline{\mathbf{w}}$:&lt;/p>
$$
\overline{\mathbf{w}} = \{ \overline{w}_1, \overline{w}_2, \ldots, \overline{w}_n \}, \quad
 \overline{w}_i = \frac{w_i}{\sum_{i=1}^{n} w_i}.
$$
&lt;p>In the non-weighted case, we can consider a quantile estimator $\operatorname{Q}(\mathbf{x}, p)$
that estimates the $p^\textrm{th}$ quantile of the underlying distribution.
We want to build a weighted quantile estimator $\operatorname{Q}(\mathbf{x}, \mathbf{w}, p)$
so that we can estimate the quantiles of a weighed sample.&lt;/p>
&lt;p>In this post, we consider a specific problem of estimating quantiles of a weighted mixture distribution.&lt;/p></description></item><item><title>Weighted quantile estimators for exponential smoothing and mixture distributions</title><link>https://aakinshin.net/posts/wqe-smoothing-mixture/</link><pubDate>Tue, 20 Sep 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/wqe-smoothing-mixture/</guid><description>&lt;p>There are various ways to estimate quantiles of weighted samples.
The proper choice of the most appropriate weighted quantile estimator depends not only on the own estimator properties
but also on the goal.&lt;/p>
&lt;p>Let us consider two problems:&lt;/p>
&lt;ol>
&lt;li>&lt;em>Estimating quantiles of a weighted mixture distribution.&lt;/em>&lt;br />
In this problem, we have a weighted mixture distribution given by $F = \sum_{i=1}^m w_i F_i$.
We collect samples $\mathbf{x_1}, \mathbf{x_2}, \ldots, \mathbf{x_m}$ from $F_1, F_2, \ldots F_m$,
and want to estimate quantile function $F^{-1}$ of the mixture distribution based on the given samples.&lt;/li>
&lt;li>&lt;em>Quantile exponential smoothing.&lt;/em>&lt;br />
In this problem, we have a time series $\mathbf{x} = \{ x_1, x_2, \ldots, x_n \}$.
We want to describe the distribution &amp;ldquo;at the end&amp;rdquo; of this time series.
The latest series element $x_n$ is the most &amp;ldquo;actual&amp;rdquo; one, but we cannot build a distribution based on a single element.
Therefore, we have to consider more elements at the end of $\mathbf{x}$.
However, if we take too many elements, we may corrupt the estimations due to obsolete measurements.
To resolve this problem, we can assign weights to all elements according to the exponential law
and estimate weighted quantiles.&lt;/li>
&lt;/ol>
&lt;p>In both problems, the usage of weighted quantile estimators looks like a reasonable solution.
However, in each problem, we have different expectations of the estimator behavior.
In this post, we provide an example that illustrates the difference in these expectations.&lt;/p></description></item><item><title>The Huggins-Roy family of effective sample sizes</title><link>https://aakinshin.net/posts/huggins-roy-ess/</link><pubDate>Tue, 13 Sep 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/huggins-roy-ess/</guid><description>&lt;p>When we work with weighted samples, it&amp;rsquo;s essential to introduce adjustments for the sample size.
Indeed, let&amp;rsquo;s consider two following weighted samples:&lt;/p>
$$
\mathbf{x}_1 = \{ x_1, x_2, \ldots, x_n \}, \quad \mathbf{w}_1 = \{ w_1, w_2, \ldots, w_n \},
$$
$$
\mathbf{x}_2 = \{ x_1, x_2, \ldots, x_n, x_{n+1} \}, \quad \mathbf{w}_2 = \{ w_1, w_2, \ldots, w_n, 0 \}.
$$
&lt;p>Since the weight of $x_{n+1}$ in the second sample is zero,
it&amp;rsquo;s natural to expect that both samples have the same set of properties.
However, there is a major difference between $\mathbf{x}_1$ and $\mathbf{x}_2$: their sample sizes which are
$n$ and $n+1$.
In order to eliminate this difference, we typically introduce the &lt;em>effective sample size&lt;/em> (ESS)
which is estimated based on the list of weights.&lt;/p>
&lt;p>There are various ways to estimate the ESS.
In this post, we briefly discuss the Huggins-Roy&amp;rsquo;s family of ESS.&lt;/p></description></item><item><title>Weighted trimmed Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/wthdqe/</link><pubDate>Tue, 19 Apr 2022 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/wthdqe/</guid><description>&lt;p>In this post, I combine ideas from two of my previous posts:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aakinshin.net/posts/pub-thdqe/">Trimmed Harrell-Davis quantile estimator&lt;/a>:
quantile estimator that provides an optimal trade-off between statistical efficiency and robustness&lt;/li>
&lt;li>&lt;a href="https://aakinshin.net/posts/weighted-quantiles/">Weighted quantile estimators&lt;/a>:
a general scheme that allows building weighted quantile estimators.
Could be used for &lt;a href="https://aakinshin.net/posts/quantile-exponential-smoothing/">quantile exponential smoothing&lt;/a>
and &lt;a href="https://aakinshin.net/posts/dispersion-exponential-smoothing/">dispersion exponential smoothing&lt;/a>.&lt;/li>
&lt;/ul>
&lt;p>Thus, we are going to build a weighted version of the trimmed Harrell-Davis quantile estimator based on the highest
density interval of the given width.&lt;/p></description></item><item><title>Using Kish's effective sample size with weighted quantiles</title><link>https://aakinshin.net/posts/kish-ess-weighted-quantiles/</link><pubDate>Tue, 06 Jul 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/kish-ess-weighted-quantiles/</guid><description>&lt;p>In my previous posts, I described how to calculate
&lt;a href="https://aakinshin.net/posts/weighted-quantiles/">weighted quantiles&lt;/a> and
their &lt;a href="https://aakinshin.net/posts/weighted-quantiles-ci/">confidence intervals&lt;/a>
using the Harrell-Davis quantile estimator.
This powerful technique allows applying
&lt;a href="https://aakinshin.net/posts/quantile-exponential-smoothing/">quantile exponential smoothing&lt;/a> and
&lt;a href="https://aakinshin.net/posts/dispersion-exponential-smoothing/">dispersion exponential smoothing&lt;/a> for
time series in order to get its moving properties.&lt;/p>
&lt;p>When we work with weighted samples, we need a way to calculate the
&lt;a href="https://en.wikipedia.org/wiki/Effective_sample_size">effective samples size&lt;/a>.
Previously, I used the sum of all weights normalized by the maximum weight.
In most cases, it worked OK.&lt;/p>
&lt;p>Recently, &lt;a href="https://www.soz.unibe.ch/about_us/people/prof_dr_jann_ben/index_eng.html">Ben Jann&lt;/a> pointed out
that it would be better to use the Kish&amp;rsquo;s formula to calculate the effective sample size.
In this post, you find the formula and a few numerical simulations that illustrate the actual impact of
the underlying sample size formula.&lt;/p></description></item><item><title>Quantile confidence intervals for weighted samples</title><link>https://aakinshin.net/posts/weighted-quantiles-ci/</link><pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/weighted-quantiles-ci/</guid><description>&lt;p>&lt;strong>Update 2021-07-06:
the approach was updated using the &lt;a href="https://aakinshin.net/posts/kish-ess-weighted-quantiles/">Kish&amp;rsquo;s effective sample size&lt;/a>.&lt;/strong>&lt;/p>
&lt;p>When you work with non-parametric distributions,
quantile estimations are essential to get the main distribution properties.
Once you get the estimation values, you may be interested in measuring the accuracy of these estimations.
Without it, it&amp;rsquo;s hard to understand how trustable the obtained values are.
One of the most popular ways to evaluate accuracy is confidence interval estimation.&lt;/p>
&lt;p>Now imagine that you collect some measurements every day.
Each day you get a small sample of values that is not enough to get the accurate daily quantile estimations.
However, the full time-series over the last several weeks has a decent size.
You suspect that past measurements should be similar to today measurements,
but you are not 100% sure about it.
You feel a temptation to extend the up-to-date sample by the previously collected values,
but it may spoil the estimation (e.g., in the case of recent change points or positive/negative trends).&lt;/p>
&lt;p>One of the possible approaches in this situation is to use &lt;em>weighted samples&lt;/em>.
This assumes that we add past measurements to the &amp;ldquo;today sample,&amp;rdquo;
but these values should have smaller weight.
The older measurement we take, the smaller weight it gets.
If you have consistent values across the last several days,
this approach works like a charm.
If you have any recent changes, you can detect such situations by huge confidence intervals
due to the sample inconsistency.&lt;/p>
&lt;p>So, how do we estimate confidence intervals around quantiles for the weighted samples?
In one of the previous posts, I have already shown how to &lt;a href="https://aakinshin.net/posts/weighted-quantiles/">estimate quantiles on weighted samples&lt;/a>.
In this post, I will show how to estimate quantile confidence intervals for weighted samples.&lt;/p></description></item><item><title>Weighted quantile estimators</title><link>https://aakinshin.net/posts/weighted-quantiles/</link><pubDate>Tue, 29 Sep 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/weighted-quantiles/</guid><description>&lt;p>&lt;strong>Update 2021-07-06:
the approach was updated using the &lt;a href="https://aakinshin.net/posts/kish-ess-weighted-quantiles/">Kish&amp;rsquo;s effective sample size&lt;/a>.&lt;/strong>&lt;/p>
&lt;p>In this post, I will show how to calculate weighted quantile estimates and how to use them in practice.&lt;/p>
&lt;p>Let&amp;rsquo;s start with a problem from real life.
Imagine that you measure the total duration of a unit test executed daily on a CI server.
Every day you get a single number that corresponds to the test duration from the latest revision for this day:&lt;/p>






&lt;div class="row">
&lt;div class="mx-auto">
 &lt;a href="https://aakinshin.net/posts/weighted-quantiles/img/moving1-light.svg" target="_blank" class="imgldlink" alt="moving1">
 &lt;picture>
 &lt;source
 theme='dark'
 srcset="https://aakinshin.net/posts/weighted-quantiles/img/moving1-dark.svg"
 media="(prefers-color-scheme: dark)">
 &lt;source
 theme='light'
 srcset="https://aakinshin.net/posts/weighted-quantiles/img/moving1-light.svg"
 media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)">
 &lt;img
 class="mx-auto d-block img-fluid"
 width='600'
 src="https://aakinshin.net/posts/weighted-quantiles/img/moving1-light.svg">
 &lt;/picture>
 &lt;/a>
&lt;/div>
&lt;/div>
&lt;br />
&lt;p>You collect a history of such measurements for 100 days.
Now you want to describe the &amp;ldquo;actual&amp;rdquo; distribution of the performance measurements.&lt;/p>
&lt;p>However, for the latest &amp;ldquo;actual&amp;rdquo; revision, you have only a single measurement, which is not enough to build a distribution.
Also, you can&amp;rsquo;t build a distribution based on the last N measurements because they can contain change points that will spoil your results.
So, what you really want to do is to use all the measurements, but older values should have a lower impact on the final distribution form.&lt;/p>
&lt;p>Such a problem can be solved using the weighted quantiles!
This powerful approach can be applied to any time series regardless of the domain area.
In this post, we learn how to calculate and apply weighted quantiles.&lt;/p></description></item></channel></rss>