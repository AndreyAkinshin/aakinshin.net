<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Harrell-Davis quantile estimator on Andrey Akinshin</title><link>https://aakinshin.net/tags/harrell-davis-quantile-estimator/</link><description>Recent content in Harrell-Davis quantile estimator on Andrey Akinshin</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Tue, 08 Jun 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://aakinshin.net/tags/harrell-davis-quantile-estimator/index.xml" rel="self" type="application/rss+xml"/><item><title>Customization of the nonparametric Cohen's d-consistent effect size</title><link>https://aakinshin.net/posts/nonparametric-effect-size2/</link><pubDate>Tue, 08 Jun 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/nonparametric-effect-size2/</guid><description>&lt;p>One year ago, I publish a post called &lt;a href="https://aakinshin.net/posts/nonparametric-effect-size/">&lt;svg class="rating-icon">&lt;use xlink:href="https://aakinshin.net/img/fa/all.svg#note">&lt;/use>&lt;/svg>Nonparametric Cohen&amp;#39;s d-consistent effect size&lt;/a>.
During this year, I got a lot of internal and external feedback from
my own statistical experiments and
&lt;a href="https://twitter.com/ViljamiSairanen/status/1400457118340108293">people&lt;/a>
&lt;a href="https://sherbold.github.io/autorank/autorank/">who&lt;/a>
&lt;a href="https://github.com/Ramon-Diaz/Thesis-Project/blob/85df6b11050c7e05c4394d873585f701a7e3f32e/_util.py#L100">tried&lt;/a>
to use the suggested approach.
It seems that the nonparametric version of Cohen&amp;rsquo;s d works much better with real-life not-so-normal data.
While the classic Cohen&amp;rsquo;s d based on
the non-robust arithmetic mean and
the &lt;a href="https://aakinshin.net/posts/misleading-stddev/">non-robust standard deviation&lt;/a>
can be easily &lt;a href="https://aakinshin.net/posts/cohend-and-outliers/">corrupted by a single outlier&lt;/a>,
my approach is much more resistant to unexpected extreme values.
Also, it allows exploring
&lt;a href="https://aakinshin.net/posts/comparing-distributions-using-gamma-es/">the difference between specific quantiles of considered samples&lt;/a>,
which can be useful in the non-parametric case.&lt;/p>
&lt;p>However, I wasn&amp;rsquo;t satisfied with the results of all of my experiments.
While I still like the basic idea
(replace the mean with the median; replace the standard deviation with the median absolute deviation),
it turned out that the final results heavily depend on the used quantile estimator.
To be more specific, the original Harrell-Davis quantile estimator is not always optimal;
in most cases, it&amp;rsquo;s better to replace it with its &lt;a href="https://aakinshin.net/posts/trimmed-hdqe/">trimmed&lt;/a> modification.
However, the particular choice of the quantile estimators depends on the situation.
Also, the consistency constant for the median absolute deviation
should be adjusted according to the current sample size and the used quantile estimator.
Of course, it also can be replaced by other dispersion estimators
that can be used as consistent estimators of the standard deviation.&lt;/p>
&lt;p>In this post, I want to get a brief overview of possible customizations of the suggested metrics.&lt;/p></description></item><item><title>Improving the efficiency of the Harrell-Davis quantile estimator for special cases using custom winsorizing and trimming strategies</title><link>https://aakinshin.net/posts/customized-wthdqe/</link><pubDate>Tue, 25 May 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/customized-wthdqe/</guid><description>&lt;p>Let&amp;rsquo;s say we want to
&lt;strong>estimate the median&lt;/strong>
based on a &lt;strong>small sample&lt;/strong> (3 $\leq n \leq 7$)
from a &lt;strong>right-skewed heavy-tailed distribution&lt;/strong>
with &lt;strong>high statistical efficiency&lt;/strong>.&lt;/p>
&lt;p>The traditional median estimator is the most robust estimator, but it&amp;rsquo;s not the most efficient one.
Typically, the Harrell-Davis quantile estimator provides better efficiency,
but it&amp;rsquo;s not robust (its breakdown point is zero),
so it may have worse efficiency in the given case.
The &lt;a href="https://aakinshin.net/posts/winsorized-hdqe/">winsorized&lt;/a> and &lt;a href="https://aakinshin.net/posts/trimmed-hdqe/">trimmed&lt;/a>
modifications of the Harrell-Davis quantile estimator provide a good trade-off
between efficiency and robustness, but they require a proper winsorizing/trimming rule.
A reasonable choice of such a rule for medium-size samples is based on the highest density interval of the Beta function
(as described &lt;a href="https://aakinshin.net/posts/winsorized-hdqe/">here&lt;/a>).
Unfortunately, this approach may be suboptimal for small samples.
E.g., if we use the 99% highest density interval to estimate the median,
it starts to trim sample values only for $n \geq 8$.&lt;/p>
&lt;p>In this post, we are going to discuss custom winsorizing/trimming strategies for special cases of the quantile estimation problem.&lt;/p></description></item><item><title>Dispersion exponential smoothing</title><link>https://aakinshin.net/posts/dispersion-exponential-smoothing/</link><pubDate>Tue, 11 May 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/dispersion-exponential-smoothing/</guid><description>&lt;p>In this &lt;a href="https://aakinshin.net/posts/quantile-exponential-smoothing/">previous post&lt;/a>,
I showed how to apply exponential smoothing to quantiles
using the &lt;a href="https://aakinshin.net/posts/weighted-quantiles/">weighted Harrell-Davis quantile estimator&lt;/a>.
This technique allows getting smooth and stable moving median estimations.
In this post, I&amp;rsquo;m going to discuss how to use the same approach
to estimate moving dispersion.&lt;/p></description></item><item><title>Quantile exponential smoothing</title><link>https://aakinshin.net/posts/quantile-exponential-smoothing/</link><pubDate>Tue, 04 May 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/quantile-exponential-smoothing/</guid><description>&lt;p>One of the popular problems in time series analysis is estimating the moving &amp;ldquo;average&amp;rdquo; value.
Let&amp;rsquo;s define the &amp;ldquo;average&amp;rdquo; as a central tendency metric like the mean or the median.
When we talk about the moving value, we assume that we are interested in
the average value &amp;ldquo;at the end&amp;rdquo; of the time series
instead of the average of all available observations.&lt;/p>
&lt;p>One of the most straightforward approaches to estimate the moving average is the &lt;em>simple moving mean&lt;/em>.
Unfortunately, this approach is not robust: outliers can instantly spoil the evaluated mean value.
As an alternative, we can consider &lt;em>simple moving median&lt;/em>.
I already discussed a few of such methods:
&lt;a href="https://aakinshin.net/posts/mp2-quantile-estimator/">the MP² quantile estimator&lt;/a> and
&lt;a href="https://aakinshin.net/posts/partitioning-heaps-quantile-estimator2/">a moving quantile estimator based on partitioning heaps&lt;/a>
(a modification of the Hardle-Steiger method).
When we talk about &lt;em>simple moving averages&lt;/em>, we typically assume
that we estimate the average value over the last $k$ observations ($k$ is the &lt;em>window size&lt;/em>).
This approach is also known as &lt;em>unweighted moving averages&lt;/em> because
all target observations have the same weight.&lt;/p>
&lt;p>As an alternative to the simple moving average, we can also consider the &lt;em>weighted moving average&lt;/em>.
In this case, we assign a weight for each observation and aggregate the whole time series according to these weights.
A famous example of such a weight function is &lt;em>exponential smoothing&lt;/em>.
And the simplest form of exponential smoothing is the &lt;em>exponentially weighted moving mean&lt;/em>.
This approach estimates the weighted moving mean using exponentially decreasing weights.
Switching from the simple moving mean to the exponentially weighted moving mean provides some benefits
in terms of smoothness and estimation efficiency.&lt;/p>
&lt;p>Although exponential smoothing has advantages over the simple moving mean,
it still estimates the mean value which is not robust.
We can improve the robustness of this approach if we reuse the same idea for weighted moving quantiles.
It&amp;rsquo;s possible because the quantiles also can be estimated for weighted samples.
In one of my previous posts, I &lt;a href="https://aakinshin.net/posts/weighted-quantiles/">showed&lt;/a> how to adapt
the Hyndman-Fan Type 7 and Harrell-Davis quantile estimators to the weighted samples.
In this post, I&amp;rsquo;m going to show how we can use this technique to estimate
the weighted moving quantiles using exponentially decreasing weights.&lt;/p></description></item><item><title>Trimmed modification of the Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/trimmed-hdqe/</link><pubDate>Tue, 30 Mar 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/trimmed-hdqe/</guid><description>&lt;p>In one of &lt;a href="https://aakinshin.net/posts/winsorized-hdqe/">the previous posts&lt;/a>, I discussed winsorized Harrell-Davis quantile estimator.
This estimator is more robust than the classic Harrell-Davis quantile estimator.
In this post, I want to suggest another modification that may be better for some corner cases:
the &lt;em>trimmed&lt;/em> Harrell-Davis quantile estimator.&lt;/p></description></item><item><title>Winsorized modification of the Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/winsorized-hdqe/</link><pubDate>Tue, 02 Mar 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/winsorized-hdqe/</guid><description>&lt;p>The Harrell-Davis quantile estimator is one of my favorite quantile estimators
because of its &lt;a href="https://en.wikipedia.org/wiki/Efficiency_(statistics)">efficiency&lt;/a>.
It has a small mean square error which allows getting accurate estimations.
However, it has a severe drawback: it&amp;rsquo;s not robust.
Indeed, since the estimator includes all sample elements with positive weights,
its &lt;a href="https://en.wikipedia.org/wiki/Robust_statistics#Breakdown_point">breakdown point&lt;/a> is zero.&lt;/p>
&lt;p>In this post, I want to suggest modifications of the Harrell-Davis quantile estimator
which increases its &lt;em>robustness&lt;/em> keeping almost the same level of &lt;em>efficiency&lt;/em>.&lt;/p></description></item><item><title>Unbiased median absolute deviation based on the Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/unbiased-mad-hd/</link><pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/unbiased-mad-hd/</guid><description>&lt;p>The &lt;a href="https://en.wikipedia.org/wiki/Median_absolute_deviation">median absolute deviation&lt;/a> ($\textrm{MAD}$)
is a robust measure of scale.
In the previous post, I &lt;a href="https://aakinshin.net/posts/unbiased-mad/">showed&lt;/a>
how to use the &lt;a href="https://en.wikipedia.org/wiki/Bias_of_an_estimator">unbiased&lt;/a>
version of the $\textrm{MAD}$ estimator
as a robust alternative to the standard deviation.
&amp;ldquo;Unbiasedness&amp;rdquo; means that such estimator&amp;rsquo;s expected value equals the true value of the standard deviation.
Unfortunately, there is such thing as the &lt;a href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff">bias–variance tradeoff&lt;/a>:
when we remove the bias of the $\textrm{MAD}$ estimator,
we increase its variance and mean squared error ($\textrm{MSE}$).&lt;/p>
&lt;p>In this post, I want to suggest a more &lt;a href="https://en.wikipedia.org/wiki/Efficiency_(statistics)">efficient&lt;/a>
unbiased $\textrm{MAD}$ estimator.
It&amp;rsquo;s also a consistent estimator for the standard deviation, but it has smaller $\textrm{MSE}$.
To build this estimator,
we should replace the classic &amp;ldquo;straightforward&amp;rdquo; median estimator with the Harrell-Davis quantile estimator
and adjust bias-correction factors.
Let&amp;rsquo;s discuss this approach in detail.&lt;/p></description></item><item><title>Case study: Accuracy of the MAD estimation using the Harrell-Davis quantile estimator (Gumbel distribution)</title><link>https://aakinshin.net/posts/cs-mad-hd-gumbel/</link><pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/cs-mad-hd-gumbel/</guid><description>&lt;p>In some of my previous posts, I used
the &lt;a href="https://en.wikipedia.org/wiki/Median_absolute_deviation">median absolute deviation&lt;/a> (MAD)
to describe the distribution dispersion:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aakinshin.net/posts/harrell-davis-double-mad-outlier-detector/">DoubleMAD outlier detector based on the Harrell-Davis quantile estimator&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aakinshin.net/posts/nonparametric-effect-size/">Nonparametric Cohen&amp;rsquo;s d-consistent effect size&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aakinshin.net/posts/qad/">Quantile absolute deviation: estimating statistical dispersion around quantiles&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>The MAD estimation depends on the chosen median estimator:
we may get different MAD values with different median estimators.
To get better accuracy,
I always encourage readers to use the Harrell-Davis quantile estimator
instead of the classic Type 7 quantile estimator.&lt;/p>
&lt;p>In this case study, I decided to compare these two quantile estimators using
the &lt;a href="https://en.wikipedia.org/wiki/Gumbel_distribution">Gumbel distribution&lt;/a>
(it&amp;rsquo;s a good model for slightly right-skewed distributions).
According to the performed Monte Carlo simulation,
the Harrell-Davis quantile estimator always has better accuracy:&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/cs-mad-hd-gumbel/img/summary-light.png" target="_blank" alt="summary">
 &lt;img
 src="https://aakinshin.net/posts/cs-mad-hd-gumbel/img/summary-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/cs-mad-hd-gumbel/img/summary-dark.png" target="_blank" alt="summary">
 &lt;img
 src="https://aakinshin.net/posts/cs-mad-hd-gumbel/img/summary-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div></description></item><item><title>Quantile absolute deviation: estimating statistical dispersion around quantiles</title><link>https://aakinshin.net/posts/qad/</link><pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/qad/</guid><description>&lt;p>There are many different metrics for &lt;a href="https://en.wikipedia.org/wiki/Statistical_dispersion">statistical dispersion&lt;/a>.
The most famous one is the &lt;a href="https://en.wikipedia.org/wiki/Standard_deviation">standard deviation&lt;/a>.
The standard deviation is the most popular way to describe the spread around the mean when
you work with normally distributed data.
However, if you work with non-normal distributions, this metric may be misleading.&lt;/p>
&lt;p>In the world of non-parametric distributions,
the most common measure of &lt;a href="https://en.wikipedia.org/wiki/Central_tendency">central tendency&lt;/a> is the median.
For the median, you can describe dispersion using the
&lt;a href="https://en.wikipedia.org/wiki/Median_absolute_deviation">median absolute deviation around the median&lt;/a> (MAD).
It works great if the median is the only &lt;a href="https://en.wikipedia.org/wiki/Summary_statistics">summary statistic&lt;/a> that you care about.
However, if you work with multimodal distributions
(they can be detected using the &lt;a href="https://aakinshin.net/posts/lowland-multimodality-detection/">lowland multimodality detector&lt;/a>),
you may be interested in other quantiles as well.
So, it makes sense to learn how to describe dispersion around the given quantile.
Which metric should we choose?&lt;/p>
&lt;p>Recently, I came up with a great solution to this problem.
We can generalize the median absolute deviation into the quantile absolute deviation (QAD) around the given quantile based on the Harrell-Davis quantile estimator.
I will show how to calculate it, how to interpret it, and how to get insights about distribution properties
from images like this one:&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/qad/img/modal5-light.png" target="_blank" alt="modal5">
 &lt;img
 src="https://aakinshin.net/posts/qad/img/modal5-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/qad/img/modal5-dark.png" target="_blank" alt="modal5">
 &lt;img
 src="https://aakinshin.net/posts/qad/img/modal5-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div></description></item><item><title>Plain-text summary notation for multimodal distributions</title><link>https://aakinshin.net/posts/modality-summary-notation/</link><pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/modality-summary-notation/</guid><description>&lt;p>Let&amp;rsquo;s say you collected a lot of data and want to explore the underlying distributions of collected samples.
If you have only a few distributions, the best way to do that is to look at the density plots
(expressed via histograms, kernel density estimations, or &lt;a href="https://aakinshin.net/posts/qrde-hd/">quantile-respectful density estimations&lt;/a>).
However, it&amp;rsquo;s not always possible.&lt;/p>
&lt;p>Suppose you have to process dozens, hundreds, or even thousands of distributions.
In that case,
it may be extremely time-consuming to manually check visualizations of each distribution.
If you analyze distributions from the command line or send notifications about suspicious samples,
it may be impossible to embed images in the reports.
In these cases, there is a need to present a distribution using plain text.&lt;/p>
&lt;p>One way to do that is plain text histograms.
Unfortunately, this kind of visualization may occupy o lot of space.
In complicated cases, you may need 20 or 30 lines per a single distribution.&lt;/p>
&lt;p>Another way is to present classic &lt;a href="https://en.wikipedia.org/wiki/Summary_statistics">summary statistics&lt;/a>
like mean or median, standard deviation or median absolute deviation, quantiles, skewness, and kurtosis.
There is another problem here:
without experience, it&amp;rsquo;s hard to reconstruct the true distribution shape based on these values.
Even if you are an experienced researcher, the statistical metrics may become misleading in the case of multimodal distributions.
Multimodality is one of the most severe challenges in distribution analysis because it distorts basic summary statistics.
It&amp;rsquo;s important to not only find such distribution but also have a way to present brief information about multimodality effects.&lt;/p>
&lt;p>So, how can we condense the underlying distribution shape of a given sample to a short text line?
I didn&amp;rsquo;t manage to find an approach that works fine in my cases, so I came up with my own notation.
Most of the interpretation problems in my experiments arise from multimodality and outliers,
so I decided to focus on these two things and specifically highlight them.
Let&amp;rsquo;s consider this plot:&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/modality-summary-notation/img/thumbnail-light.svg" target="_blank" alt="thumbnail">
 &lt;img
 src="https://aakinshin.net/posts/modality-summary-notation/img/thumbnail-light.svg" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/modality-summary-notation/img/thumbnail-dark.svg" target="_blank" alt="thumbnail">
 &lt;img
 src="https://aakinshin.net/posts/modality-summary-notation/img/thumbnail-dark.svg" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>I suggest describing it like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="o">{&lt;/span>1.00, 2.00&lt;span class="o">}&lt;/span> + &lt;span class="o">[&lt;/span>7.16&lt;span class="p">;&lt;/span> 13.12&lt;span class="o">]&lt;/span>_100 + &lt;span class="o">{&lt;/span>19.00&lt;span class="o">}&lt;/span> + &lt;span class="o">[&lt;/span>27.69&lt;span class="p">;&lt;/span> 32.34&lt;span class="o">]&lt;/span>_100 + &lt;span class="o">{&lt;/span>37.00..39.00&lt;span class="o">}&lt;/span>_3
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Let me explain the suggested notation in detail.&lt;/p></description></item><item><title>Intermodal outliers</title><link>https://aakinshin.net/posts/intermodal-outliers/</link><pubDate>Tue, 10 Nov 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/intermodal-outliers/</guid><description>&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Outlier">Outlier&lt;/a> analysis is a typical step in distribution exploration.
Usually, we work with the &amp;ldquo;lower outliers&amp;rdquo; (extremely low values) and the &amp;ldquo;upper outliers&amp;rdquo; (extremely high values).
However, outliers are not always extreme values.
In the general case, an outlier is a value that significantly differs from other values in the same sample.
In the case of multimodal distribution, we can also consider outliers in the middle of the distribution.
Let&amp;rsquo;s call such outliers that we found between modes the &amp;ldquo;&lt;em>intermodal outliers&lt;/em>.&amp;rdquo;&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/intermodal-outliers/img/step4-light.svg" target="_blank" alt="step4">
 &lt;img
 src="https://aakinshin.net/posts/intermodal-outliers/img/step4-light.svg" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/intermodal-outliers/img/step4-dark.svg" target="_blank" alt="step4">
 &lt;img
 src="https://aakinshin.net/posts/intermodal-outliers/img/step4-dark.svg" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>Look at the above density plot.
It&amp;rsquo;s a bimodal distribution that is formed as a combination of two unimodal distributions.
Each of the unimodal distributions may have its own lower and upper outliers.
When we merge them, the upper outliers of the first distribution and the lower outliers of the second distribution
stop being lower or upper outliers.
However, if these values don&amp;rsquo;t belong to the modes, they still are a subject of interest.
In this post, I will show you how to detect such intermodal outliers
and how they can be used to form a better distribution description.&lt;/p></description></item><item><title>Lowland multimodality detection</title><link>https://aakinshin.net/posts/lowland-multimodality-detection/</link><pubDate>Tue, 03 Nov 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/lowland-multimodality-detection/</guid><description>&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/lowland-multimodality-detection/img/data5-light.svg" target="_blank" alt="data5">
 &lt;img
 src="https://aakinshin.net/posts/lowland-multimodality-detection/img/data5-light.svg" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/lowland-multimodality-detection/img/data5-dark.svg" target="_blank" alt="data5">
 &lt;img
 src="https://aakinshin.net/posts/lowland-multimodality-detection/img/data5-dark.svg" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>Multimodality is an essential feature of a distribution, which may create many troubles during automatic analysis.
One of the best ways to work with such distributions is to detect all the modes in advance based on the given samples.
Unfortunately, this problem is much harder than it looks like.&lt;/p>
&lt;p>I tried many different approaches for multimodality detection, but none of them was good enough.
During the past several years, my approach of choice was the &lt;a href="http://www.brendangregg.com/FrequencyTrails/modes.html">mvalue-based modal test&lt;/a> by Brendan Gregg.
It works nicely in simple cases, but I was constantly stumbling over noisy samples where this algorithm doesn&amp;rsquo;t produce reliable results.
Also, it has some limitations that make it unapplicable to some corner cases.&lt;/p>
&lt;p>So, I needed a better approach.
Here are my main requirements:&lt;/p>
&lt;ul>
&lt;li>It should detect the exact mode locations and ranges&lt;/li>
&lt;li>It should provide reliable results even on noisy samples&lt;/li>
&lt;li>It should be able to detect multimodality even when some modes are extremely close to each other&lt;/li>
&lt;li>It should work out of the box without tricky parameter tuning for each specific distribution&lt;/li>
&lt;/ul>
&lt;p>I failed to find such an algorithm anywhere, so I came up with my own!
The current working title is &amp;ldquo;the lowland multimodality detector.&amp;rdquo;
It takes an estimation of the probability density function (PDF) and tries to find &amp;ldquo;lowlands&amp;rdquo; (areas that are much lower than neighboring peaks).
Next, it splits the plot by these lowlands and detects modes between them.
For the PDF estimation, it uses the &lt;a href="https://aakinshin.net/posts/qrde-hd/">quantile-respectful density estimation based on the Harrell-Davis quantile estimator&lt;/a> (QRDE-HD).
Let me explain how it works in detail.&lt;/p></description></item><item><title>Quantile-respectful density estimation based on the Harrell-Davis quantile estimator</title><link>https://aakinshin.net/posts/qrde-hd/</link><pubDate>Tue, 27 Oct 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/qrde-hd/</guid><description>&lt;p>The idea of this post was born when I was working on a presentation for my recent &lt;a href="https://dotnext.ru/en/">DotNext&lt;/a> &lt;a href="https://www.youtube.com/watch?v=gc3yVybPuaY&amp;list=PL21xssNXOJNGUROqzSTOC8uZL4W2QZpvK&amp;index=1">talk&lt;/a>.
It had a &lt;a href="https://slides.aakinshin.net/dotnext-piter2020/#193">slide&lt;/a> with a density plot like this:&lt;/p>








&lt;div class="flex my-7 justify-center">
 &lt;a class="img-light hidden" href="https://aakinshin.net/posts/qrde-hd/img/riddle-light.png" target="_blank" alt="riddle">
 &lt;img
 src="https://aakinshin.net/posts/qrde-hd/img/riddle-light.png" 
 width='800'
 />
 &lt;/a>
 &lt;a class="img-dark hidden" href="https://aakinshin.net/posts/qrde-hd/img/riddle-dark.png" target="_blank" alt="riddle">
 &lt;img
 src="https://aakinshin.net/posts/qrde-hd/img/riddle-dark.png" 
 width='800'
 />
 &lt;/a>
&lt;/div>


&lt;p>Here we can see a density plot based on a sample with highlighted &lt;a href="https://en.wikipedia.org/wiki/Decile">decile&lt;/a> locations that split the plot into 10 equal parts.
Before the conference, I have been reviewed by &lt;a href="https://twitter.com/VladimirSitnikv">@VladimirSitnikv&lt;/a>.
He raised a reasonable concern: it doesn&amp;rsquo;t look like all the density plot segments are equal and contain exactly 10% of the whole plot.
And he was right!&lt;/p>
&lt;p>However, I didn&amp;rsquo;t make any miscalculations.
I generated a real sample with 61 elements.
Next, I build a density plot with the kernel density estimation (KDE) using the Sheather &amp;amp; Jones method and the normal kernel.
Next, I calculated decile values using the Harrell-Davis quantile estimator.
Although both the density plot and the decile values are calculated correctly and consistent with the sample,
they are not consistent with each other!
Indeed, such a density plot is just an estimation of the underlying distribution.
It has its own decile values, which are not equal to the sample decile values regardless of the used quantile estimator.
This problem is common for different kinds of visualization that presents density and quantiles at the same time (e.g., &lt;a href="https://towardsdatascience.com/violin-plots-explained-fb1d115e023d">violin plots&lt;/a>)&lt;/p>
&lt;p>It leads us to a question: how should we present the shape of our data together with quantile values without confusing inconsistency in the final image?
Today I will present a good solution: we should use the quantile-respectful density estimation based on the Harrell-Davis quantile estimator!
I know the title is a bit long, but it&amp;rsquo;s not so complicated as it sounds.
In this post, I will show how to build such plots.
Also I will compare them to the classic histograms and kernel density estimations.
As a bonus, I will demonstrate how awesome these plots are for multimodality detection.&lt;/p></description></item><item><title>The median absolute deviation value of the Gumbel distribution</title><link>https://aakinshin.net/posts/gumbel-mad/</link><pubDate>Tue, 06 Oct 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/gumbel-mad/</guid><description>&lt;p>The &lt;a href="https://en.wikipedia.org/wiki/Gumbel_distribution">Gumbel distribution&lt;/a> is not only a useful model in the &lt;a href="https://en.wikipedia.org/wiki/Extreme_value_theory">extreme value theory&lt;/a>,
but it&amp;rsquo;s also a nice example of a slightly right-skewed distribution (skewness $\approx 1.14$).
Here is its density plot:&lt;/p>






&lt;div class="row">
&lt;div class="mx-auto">
 &lt;a href="https://aakinshin.net/posts/gumbel-mad/img/gumbel-light.svg" target="_blank" class="imgldlink" alt="gumbel">
 &lt;picture>
 &lt;source
 theme='dark'
 srcset="https://aakinshin.net/posts/gumbel-mad/img/gumbel-dark.svg"
 media="(prefers-color-scheme: dark)">
 &lt;source
 theme='light'
 srcset="https://aakinshin.net/posts/gumbel-mad/img/gumbel-light.svg"
 media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)">
 &lt;img
 class="mx-auto d-block img-fluid"
 width='600'
 src="https://aakinshin.net/posts/gumbel-mad/img/gumbel-light.svg">
 &lt;/picture>
 &lt;/a>
&lt;/div>
&lt;/div>
&lt;br />
&lt;p>In some of my statistical experiments, I like to use the Gumbel distribution as a sample generator for hypothesis checking or unit tests.
I also prefer the &lt;a href="https://en.wikipedia.org/wiki/Median_absolute_deviation">median absolute deviation&lt;/a> (MAD) over the standard deviation as a measure of dispersion because it&amp;rsquo;s more robust in the case of non-parametric distributions.
Numerical hypothesis verification often requires the exact value of the median absolute deviation of the original distribution.
I didn&amp;rsquo;t find this value in the reference tables, so I decided to do another exercise and derive it myself.
In this post, you will find a short derivation and the result (spoiler: the exact value is &lt;code>0.767049251325708 * β&lt;/code>).
The general approach of the MAD derivation is common for most distributions, so it can be easily reused.&lt;/p></description></item><item><title>Weighted quantile estimators</title><link>https://aakinshin.net/posts/weighted-quantiles/</link><pubDate>Tue, 29 Sep 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/weighted-quantiles/</guid><description>&lt;p>&lt;strong>Update 2021-07-06:
the approach was updated using the &lt;a href="https://aakinshin.net/posts/kish-ess-weighted-quantiles/">Kish&amp;rsquo;s effective sample size&lt;/a>.&lt;/strong>&lt;/p>
&lt;p>In this post, I will show how to calculate weighted quantile estimates and how to use them in practice.&lt;/p>
&lt;p>Let&amp;rsquo;s start with a problem from real life.
Imagine that you measure the total duration of a unit test executed daily on a CI server.
Every day you get a single number that corresponds to the test duration from the latest revision for this day:&lt;/p>






&lt;div class="row">
&lt;div class="mx-auto">
 &lt;a href="https://aakinshin.net/posts/weighted-quantiles/img/moving1-light.svg" target="_blank" class="imgldlink" alt="moving1">
 &lt;picture>
 &lt;source
 theme='dark'
 srcset="https://aakinshin.net/posts/weighted-quantiles/img/moving1-dark.svg"
 media="(prefers-color-scheme: dark)">
 &lt;source
 theme='light'
 srcset="https://aakinshin.net/posts/weighted-quantiles/img/moving1-light.svg"
 media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)">
 &lt;img
 class="mx-auto d-block img-fluid"
 width='600'
 src="https://aakinshin.net/posts/weighted-quantiles/img/moving1-light.svg">
 &lt;/picture>
 &lt;/a>
&lt;/div>
&lt;/div>
&lt;br />
&lt;p>You collect a history of such measurements for 100 days.
Now you want to describe the &amp;ldquo;actual&amp;rdquo; distribution of the performance measurements.&lt;/p>
&lt;p>However, for the latest &amp;ldquo;actual&amp;rdquo; revision, you have only a single measurement, which is not enough to build a distribution.
Also, you can&amp;rsquo;t build a distribution based on the last N measurements because they can contain change points that will spoil your results.
So, what you really want to do is to use all the measurements, but older values should have a lower impact on the final distribution form.&lt;/p>
&lt;p>Such a problem can be solved using the weighted quantiles!
This powerful approach can be applied to any time series regardless of the domain area.
In this post, we learn how to calculate and apply weighted quantiles.&lt;/p></description></item><item><title>Nonparametric Cohen's d-consistent effect size</title><link>https://aakinshin.net/posts/nonparametric-effect-size/</link><pubDate>Thu, 25 Jun 2020 00:00:00 +0000</pubDate><guid>https://aakinshin.net/posts/nonparametric-effect-size/</guid><description>&lt;p>&lt;strong>Update: the second part of this post is available &lt;a href="https://aakinshin.net/posts/nonparametric-effect-size2/">here&lt;/a>.&lt;/strong>&lt;/p>
&lt;p>The effect size is a common way to describe a difference between two distributions.
When these distributions are normal, one of the most popular approaches to express the effect size is &lt;a href="https://en.wikipedia.org/wiki/Effect_size#Cohen's_d">Cohen&amp;rsquo;s d&lt;/a>.
Unfortunately, it doesn&amp;rsquo;t work great for non-normal distributions.&lt;/p>
&lt;p>In this post, I will show a robust Cohen&amp;rsquo;s d-consistent effect size formula for nonparametric distributions.&lt;/p>





&lt;div class="row">
&lt;div class="mx-auto">
 &lt;a href="https://aakinshin.net/posts/nonparametric-effect-size/img/blackboard.png" target="_blank" alt="blackboard">
 &lt;img
 class="mx-auto d-block img-fluid"
 width='800'
 src="https://aakinshin.net/posts/nonparametric-effect-size/img/blackboard.png" />
 &lt;/a>
&lt;/div>
&lt;/div>
&lt;br /></description></item></channel></rss>