<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>NHST on Andrey Akinshin</title><link>https://aakinshin.net/tags/nhst/</link><description>Recent content in NHST on Andrey Akinshin</description><generator>Hugo -- gohugo.io</generator><language>en</language><atom:link href="https://aakinshin.net/tags/nhst/index.xml" rel="self" type="application/rss+xml"/><item><title>Abandon Statistical Significance</title><link>https://aakinshin.net/library/papers/mcshane2019/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/mcshane2019/</guid><description>Reference Blakeley B. McShane, David Gal, Andrew Gelman, Christian Robert, Jennifer L. Tackett “Abandon Statistical Significance” (2019) // The American Statistician. Publisher: Informa UK Limited. Vol. 73. No sup1. Pp. 235–245. DOI: 10.1080/00031305.2018.1527253
Bib @Article{mcshane2019, title = {Abandon Statistical Significance}, volume = {73}, issn = {1537-2731}, url = {http://dx.doi.org/10.1080/00031305.2018.1527253}, doi = {10.1080/00031305.2018.1527253}, number = {sup1}, arxiv = {1709.07588}, journal = {The American Statistician}, publisher = {Informa UK Limited}, author = {McShane, Blakeley B. and Gal, David and Gelman, Andrew and Robert, Christian and Tackett, Jennifer L.}, year = {2019}, month = {mar}, pages = {235–245} }</description></item><item><title>Absence of Evidence is Not Evidence of Absence</title><link>https://aakinshin.net/library/papers/altman1995/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/altman1995/</guid><description>Reference D. G Altman, J M. Bland “Absence of evidence is not evidence of absence” (1995) // BMJ. Publisher: BMJ. Vol. 311. No 7003. Pp. 485–485. DOI: 10.1136/bmj.311.7003.485
Bib @Article{altman1995, title = {Absence of evidence is not evidence of absence}, volume = {311}, issn = {1468-5833}, url = {http://dx.doi.org/10.1136/bmj.311.7003.485}, doi = {10.1136/bmj.311.7003.485}, number = {7003}, journal = {BMJ}, publisher = {BMJ}, author = {Altman, D. G and Bland, J M.}, year = {1995}, month = {aug}, pages = {485–485} }</description></item><item><title>Absence of Evidence is Not Evidence of Absence</title><link>https://aakinshin.net/library/quotes/0881be0d-6149-4d55-8561-87ddbfe9d453/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/0881be0d-6149-4d55-8561-87ddbfe9d453/</guid><description>Absence of Evidence is Not Evidence of Absence</description></item><item><title>Confusion Over Measures of Evidence (p's) Versus Errors (alpha's) In Classical Statistical Testing</title><link>https://aakinshin.net/library/papers/hubbard2003/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/hubbard2003/</guid><description>Reference Raymond Hubbard, Mar'\ia Jes'us Bayarri “Confusion over measures of evidence (p&amp;rsquo;s) versus errors (alpha&amp;rsquo;s) in classical statistical testing” (2003) // The American Statistician. Publisher: Taylor &amp;amp; Francis. Vol. 57. No 3. Pp. 171–178. DOI: 10.1198/0003130031856
Bib @Article{hubbard2003, title = {Confusion over measures of evidence (p&amp;#39;s) versus errors (alpha&amp;#39;s) in classical statistical testing}, author = {Hubbard, Raymond and Bayarri, Mar\&amp;#39;\ia Jes\&amp;#39;us}, journal = {The American Statistician}, volume = {57}, number = {3}, pages = {171--178}, year = {2003}, publisher = {Taylor \&amp;amp; Francis}, doi = {10.1198/0003130031856} }</description></item><item><title>Erroneous Analyses of Interactions in neuroscience: A Problem of Significance</title><link>https://aakinshin.net/library/papers/nieuwenhuis2011/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/nieuwenhuis2011/</guid><description>Reference Sander Nieuwenhuis, Birte U Forstmann, Eric-Jan Wagenmakers “Erroneous analyses of interactions in neuroscience: a problem of significance” (2011) // Nature Neuroscience. Publisher: Springer Science and Business Media LLC. Vol. 14. No 9. Pp. 1105–1107. DOI: 10.1038/nn.2886
Bib @Article{nieuwenhuis2011, title = {Erroneous analyses of interactions in neuroscience: a problem of significance}, volume = {14}, issn = {1546-1726}, url = {http://dx.doi.org/10.1038/nn.2886}, doi = {10.1038/nn.2886}, number = {9}, journal = {Nature Neuroscience}, publisher = {Springer Science and Business Media LLC}, author = {Nieuwenhuis, Sander and Forstmann, Birte U and Wagenmakers, Eric-Jan}, year = {2011}, month = {aug}, pages = {1105–1107} }</description></item><item><title>Incorrect Statistical Procedures in Neuroscience</title><link>https://aakinshin.net/library/quotes/4e6b0a2d-9a6c-4b97-9c15-b7009ef063a5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/4e6b0a2d-9a6c-4b97-9c15-b7009ef063a5/</guid><description>In theory, a comparison of two experimental effects requires a statistical test on their difference. In practice, this comparison is often based on an incorrect procedure involving two separate tests in which researchers conclude that effects differ when one effect is significant (P &amp;lt; 0.05) but the other is not (P &amp;gt; 0.05). We reviewed 513 behavioral, systems and cognitive neuroscience articles in five top-ranking journals (Science, Nature, Nature Neuroscience, Neuron and The Journal of Neuroscience) and found that 78 used the correct procedure and 79 used the incorrect procedure. An additional analysis suggests that incorrect analyses of interactions are even more common in cellular and molecular neuroscience.</description></item><item><title>Neyman-Pearson vs. Fisher</title><link>https://aakinshin.net/library/quotes/e9011bc6-0eaf-4e76-8090-0331bd513617/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/e9011bc6-0eaf-4e76-8090-0331bd513617/</guid><description>It is not generally appreciated that the p value, as conceived by R. A. Fisher, is not compatible with the Neyman-Pearson hypothesis test in which it has become embedded. The p value was meant to be a flexible inferential measure, whereas the hypothesis test was a rule for behavior, not inference. The combination of the two methods has led to a reinterpretation of the p value simultaneously as an &amp;ldquo;observed error rate&amp;rdquo; and as a measure of evidence. Both of these interpretations are problematic, and their combination has obscured the important differences between Neyman and Fisher on the nature of the scientific method and inhibited our understanding of the philosophic implications of the basic methods in use today. An analysis using another method promoted by Fisher, mathematical likelihood, shows that the p value substantially overstates the evidence against the null hypothesis. Likelihood makes clearer the distinction between error rates and inferential evidence and is a quantitative tool for expressing evidential strength that is more appropriate for the purposes of epidemiology than the p value.</description></item><item><title>Neyman–pearson vs. Fisher</title><link>https://aakinshin.net/library/quotes/510b2ea5-0e1c-4aa9-8e13-28240daf157a/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/510b2ea5-0e1c-4aa9-8e13-28240daf157a/</guid><description>Confusion surrounding the reporting and interpretation of results of classical statistical tests is widespread among applied researchers, most of whom erroneously believe that such tests are prescribed by a single coherent theory of statistical inference. This is not the case: Classical statistical testing is an anonymous hybrid of the competing and frequently contradictory approaches formulated by R. A. Fisher on the one hand, and Jerzy Neyman and Egon Pearson on the other. In particular, there is a widespread failure to appreciate the incompatibility of Fisher’s evidential p value with the Type I error rate, α, of Neyman–Pearson statistical orthodoxy. The distinction between evidence (p’s) and error (α ’s) is not trivial. Instead, it reflects the fundamental differences between Fisher’s ideas on significance testing and inductive inference, and Neyman–Pearson’s views on hypothesis testing and inductive behavior. The emphasis of the article is to expose this incompatibility, but we also briefly note a possible reconciliation.</description></item><item><title>NHST</title><link>https://aakinshin.net/library/quotes/f75b2f1f-b183-45f5-a015-f0cf16344a19/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/f75b2f1f-b183-45f5-a015-f0cf16344a19/</guid><description>We are inclined to think that as far as a particular hypothesis is concerned, no test based upon the theory of probability can by itself provide any valuable evidence of the truth or falsehood of that hypothesis.
But we may look at the purpose of tests from another view-point. Without hoping to know whether each separate hypothesis is true or false, we may search for rules to govern our behaviour with regard to them, in following which we insure that, in the long run of experience, we shall not be too often wrong.</description></item><item><title>On the Problem of the Most Efficient Tests of Statistical Hypotheses</title><link>https://aakinshin.net/library/papers/neyman1933/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/neyman1933/</guid><description>Reference Jerzy Neyman, Egon Sharpe Pearson “On the problem of the most efficient tests of statistical hypotheses” (1933) // Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character. Publisher: The Royal Society London. Vol. 231. No 694-706. Pp. 289–337. DOI: 10.1098/rsta.1933.0009
Bib @Article{neyman1933, title = {On the problem of the most efficient tests of statistical hypotheses}, author = {Neyman, Jerzy and Pearson, Egon Sharpe}, journal = {Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character}, volume = {231}, number = {694-706}, pages = {289--337}, year = {1933}, publisher = {The Royal Society London}, doi = {10.1098/rsta.1933.0009} }</description></item><item><title>P values, Hypothesis tests, and likelihood: Implications for Epidemiology of a Neglected Historical Debate</title><link>https://aakinshin.net/library/papers/goodman1993/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/goodman1993/</guid><description>Reference Steven N Goodman “P values, hypothesis tests, and likelihood: implications for epidemiology of a neglected historical debate” (1993) // American Journal of Epidemiology. Publisher: Oxford University Press. Vol. 137. No 5. Pp. 485–496. DOI: 10.1093/oxfordjournals.aje.a116700
Bib @Article{goodman1993, title = {P values, hypothesis tests, and likelihood: implications for epidemiology of a neglected historical debate}, author = {Goodman, Steven N}, journal = {American Journal of Epidemiology}, volume = {137}, number = {5}, pages = {485--496}, year = {1993}, publisher = {Oxford University Press}, doi = {10.1093/oxfordjournals.aje.a116700} }</description></item><item><title>Scientific Method</title><link>https://aakinshin.net/library/quotes/cd4d7cb3-1f80-4fa7-be94-9cb8181e7851/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/cd4d7cb3-1f80-4fa7-be94-9cb8181e7851/</guid><description>The originators of the statistical frameworks that underlie modern epidemiologic studies recognized that their methods could not be interpreted properly without an understanding of their philosophical underpinnings. Neyman held that inductive reasoning was an illusion and that the only meaningful parameters of importance in an experiment were constraints on the number of statistical &amp;ldquo;errors&amp;rdquo; we would make, defined before an experiment. Fisher rejected mechanistic approaches to inference, believing in a more flexible, inductive approach to science. One of Fisher&amp;rsquo;s developments, mathematical likelihood, fit into such an approach. The p value, which Fisher wanted used in a similar manner, invited misinterpretation because it occupied a peculiar middle ground. Because of its resemblance to the pretrial a error, it was absorbed into the hypothesis test framework. This created two illusions: that an &amp;ldquo;error rate&amp;rdquo; could be measured after an experiment and that this posttrial &amp;ldquo;error rate&amp;rdquo; could be regarded as a measure of inductive evidence. Even though Fisher, Neyman, and many others have recognized these as fallacies, their perpetuation has been encouraged by the manner in which we use the p value today. One consequence is that we overestimate the evidence for associations, particularly with p values in the range of 0.001-0.05, creating misleading impressions of their plausibility. Another result is that we minimize the importance of judgment in inference, because its role is unclear when postexperiment evidential strength is thought to be measurable with preexperiment &amp;ldquo;error-rates.&amp;rdquo; Many experienced epidemiologists have tried to correct these problems by offering guidelines about how p values should be used. We may be more effective if, in the spirts of Fisher and Neyman, we instead focus on clarifying what p values mean, and on what we mean by the &amp;ldquo;scientific method.&amp;rdquo;</description></item><item><title>Some Difficulties of Interpretation Encountered in the Application of the Chi-Square Test</title><link>https://aakinshin.net/library/papers/berkson1938/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/berkson1938/</guid><description>Reference Joseph Berkson “Some Difficulties of Interpretation Encountered in the Application of the Chi-Square Test” (1938) // Journal of the American Statistical Association. Publisher: JSTOR. Vol. 33. No 203. Pp. 526. DOI: 10.2307/2279690
Bib @Article{berkson1938, title = {Some Difficulties of Interpretation Encountered in the Application of the Chi-Square Test}, volume = {33}, issn = {0162-1459}, url = {http://dx.doi.org/10.2307/2279690}, doi = {10.2307/2279690}, number = {203}, journal = {Journal of the American Statistical Association}, publisher = {JSTOR}, author = {Berkson, Joseph}, year = {1938}, month = {sep}, pages = {526} }</description></item><item><title>Surely God Loves 51 km/h Nearly as Much as 49 km/h?</title><link>https://aakinshin.net/library/web/6847d5ff77f9ca7d5903f1bd2cc122a5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/web/6847d5ff77f9ca7d5903f1bd2cc122a5/</guid><description/></item><item><title>Testing the Approximate Validity of Statistical Hypotheses</title><link>https://aakinshin.net/library/papers/hodges1954/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/hodges1954/</guid><description>Dicussed P-Value Beyond Any Usual Limit of Significance from berkson1938.
Reference J. L. Hodges, E. L. Lehmann “Testing the Approximate Validity of Statistical Hypotheses” (1954) // Journal of the Royal Statistical Society: Series B (Methodological). Publisher: Wiley. Vol. 16. No 2. Pp. 261–268. DOI: 10.1111/j.2517-6161.1954.tb00169.x
Abstract The distinction between statistical significance and material significance in hypotheses testing is discussed. Modifications of the customary tests, in order to test for the absence of material significance, are derived for several parametric problems, for the chi-square test of goodness of fit, and for Student&amp;rsquo;s hypothesis. The latter permits one to test the hypothesis that the means of two normal populations of equal variance, do not differ by more than a stated amount.
Bib @Article{hodges1954, title = {Testing the Approximate Validity of Statistical Hypotheses}, abstract = {The distinction between statistical significance and material significance in hypotheses testing is discussed. Modifications of the customary tests, in order to test for the absence of material significance, are derived for several parametric problems, for the chi-square test of goodness of fit, and for Student&amp;#39;s hypothesis. The latter permits one to test the hypothesis that the means of two normal populations of equal variance, do not differ by more than a stated amount.}, volume = {16}, issn = {2517-6161}, url = {http://dx.doi.org/10.1111/j.2517-6161.1954.tb00169.x}, doi = {10.1111/j.2517-6161.1954.tb00169.x}, number = {2}, journal = {Journal of the Royal Statistical Society: Series B (Methodological)}, publisher = {Wiley}, author = {Hodges, J. L. and Lehmann, E. L.}, year = {1954}, month = {jul}, pages = {261–268} }</description></item><item><title>The Failure of Null Hypothesis Significance Testing When Studying Incremental Changes, and What to Do about It</title><link>https://aakinshin.net/library/papers/gelman2017/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/gelman2017/</guid><description>Reference Andrew Gelman “The Failure of Null Hypothesis Significance Testing When Studying Incremental Changes, and What to Do About It” (2017) // Personality and Social Psychology Bulletin. Publisher: SAGE Publications. Vol. 44. No 1. Pp. 16–23. DOI: 10.1177/0146167217729162
Bib @Article{gelman2017, title = {The Failure of Null Hypothesis Significance Testing When Studying Incremental Changes, and What to Do About It}, volume = {44}, issn = {1552-7433}, url = {http://dx.doi.org/10.1177/0146167217729162}, doi = {10.1177/0146167217729162}, number = {1}, journal = {Personality and Social Psychology Bulletin}, publisher = {SAGE Publications}, author = {Gelman, Andrew}, year = {2017}, month = {sep}, pages = {16–23} }</description></item></channel></rss>