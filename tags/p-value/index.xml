<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>p-value on Andrey Akinshin</title><link>https://aakinshin.net/tags/p-value/</link><description>Recent content in p-value on Andrey Akinshin</description><generator>Hugo -- gohugo.io</generator><language>en</language><atom:link href="https://aakinshin.net/tags/p-value/index.xml" rel="self" type="application/rss+xml"/><item><title>A Dirty dozen: Twelve p-value Misconceptions</title><link>https://aakinshin.net/library/papers/goodman2008/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/goodman2008/</guid><description>Reference Steven Goodman “A dirty dozen: twelve p-value misconceptions” (2008) // Seminars in hematology. Elsevier. Vol. 45. No 3. Pp. 135–140. DOI: 10.1053/j.seminhematol.2008.04.003
Abstract The P value is a measure of statistical evidence that appears in virtually all medical research papers. Its interpretation is made extraordinarily difficult because it is not part of any formal system of statistical inference. As a result, the P value&amp;rsquo;s inferential meaning is widely and often wildly misconstrued, a fact that has been pointed out in innumerable papers and books appearing since at least the 1940s. This commentary reviews a dozen of these common misinterpretations and explains why each is wrong. It also reviews the possible consequences of these improper understandings or representations of its meaning. Finally, it contrasts the P value with its Bayesian counterpart, the Bayes&amp;rsquo; factor, which has virtually all of the desirable properties of an evidential measure that the P value lacks, most notably interpretability. The most serious consequence of this array of P-value misconceptions is the false belief that the probability of a conclusion being in error can be calculated from the data in a single experiment without reference to external evidence or the plausibility of the underlying mechanism.
Bib @Inproceedings{goodman2008, title = {A dirty dozen: twelve p-value misconceptions}, author = {Goodman, Steven}, abstract = {The P value is a measure of statistical evidence that appears in virtually all medical research papers. Its interpretation is made extraordinarily difficult because it is not part of any formal system of statistical inference. As a result, the P value&amp;#39;s inferential meaning is widely and often wildly misconstrued, a fact that has been pointed out in innumerable papers and books appearing since at least the 1940s. This commentary reviews a dozen of these common misinterpretations and explains why each is wrong. It also reviews the possible consequences of these improper understandings or representations of its meaning.</description></item><item><title>A Practical Solution to the Pervasive Problems of P Values</title><link>https://aakinshin.net/library/papers/wagenmakers2007/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/wagenmakers2007/</guid><description>Reference Eric-Jan Wagenmakers “A practical solution to the pervasive problems of p values” (2007) // Psychonomic Bulletin &amp;amp; Review. Publisher: Springer Science and Business Media LLC. Vol. 14. No 5. Pp. 779–804. DOI: 10.3758/bf03194105
Bib @Article{wagenmakers2007, title = {A practical solution to the pervasive problems of p values}, volume = {14}, issn = {1531-5320}, url = {http://dx.doi.org/10.3758/BF03194105}, doi = {10.3758/bf03194105}, number = {5}, journal = {Psychonomic Bulletin &amp;amp;amp; Review}, publisher = {Springer Science and Business Media LLC}, author = {Wagenmakers, Eric-Jan}, year = {2007}, month = {oct}, pages = {779–804} }</description></item><item><title>Abandon Statistical Significance</title><link>https://aakinshin.net/library/papers/mcshane2019/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/mcshane2019/</guid><description>Reference Blakeley B. McShane, David Gal, Andrew Gelman, Christian Robert, Jennifer L. Tackett “Abandon Statistical Significance” (2019) // The American Statistician. Publisher: Informa UK Limited. Vol. 73. No sup1. Pp. 235–245. DOI: 10.1080/00031305.2018.1527253
Bib @Article{mcshane2019, title = {Abandon Statistical Significance}, volume = {73}, issn = {1537-2731}, url = {http://dx.doi.org/10.1080/00031305.2018.1527253}, doi = {10.1080/00031305.2018.1527253}, number = {sup1}, arxiv = {1709.07588}, journal = {The American Statistician}, publisher = {Informa UK Limited}, author = {McShane, Blakeley B. and Gal, David and Gelman, Andrew and Robert, Christian and Tackett, Jennifer L.}, year = {2019}, month = {mar}, pages = {235–245} }</description></item><item><title>Embarrassignly Large Confidence Intervals</title><link>https://aakinshin.net/library/quotes/a2e73f66-cacd-4065-94d2-b541952903ab/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/a2e73f66-cacd-4065-94d2-b541952903ab/</guid><description>&amp;ldquo;Everyone knows&amp;rdquo; that confidence intervals contain all the information to be found in significance tests and much more. They not only reveal the status of the trivial nil hypothesis but also about the status of non-nil null hypotheses and thus help remind researchers about the possible operation of the crud factor. Yet they are rarely to be found in the literature. I suspect that the main reason they are not reported is that they are so embarrassingly large!</description></item><item><title>Incongruence Between Test Statistics and P Values in Medical Papers</title><link>https://aakinshin.net/library/papers/garc%C3%ADa-berthou2004/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/garc%C3%ADa-berthou2004/</guid><description>Reference Emili García-Berthou, Carles Alcaraz “Incongruence between test statistics and P values in medical papers” (2004) // BMC Medical Research Methodology. Publisher: Springer Science and Business Media LLC. Vol. 4. No 1. DOI: 10.1186/1471-2288-4-13
Bib @Article{garcía-berthou2004, title = {Incongruence between test statistics and P values in medical papers}, volume = {4}, issn = {1471-2288}, url = {http://dx.doi.org/10.1186/1471-2288-4-13}, doi = {10.1186/1471-2288-4-13}, number = {1}, journal = {BMC Medical Research Methodology}, publisher = {Springer Science and Business Media LLC}, author = {García-Berthou, Emili and Alcaraz, Carles}, year = {2004}, month = {may} }</description></item><item><title>Neyman-Pearson vs. Fisher</title><link>https://aakinshin.net/library/quotes/e9011bc6-0eaf-4e76-8090-0331bd513617/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/e9011bc6-0eaf-4e76-8090-0331bd513617/</guid><description>It is not generally appreciated that the p value, as conceived by R. A. Fisher, is not compatible with the Neyman-Pearson hypothesis test in which it has become embedded. The p value was meant to be a flexible inferential measure, whereas the hypothesis test was a rule for behavior, not inference. The combination of the two methods has led to a reinterpretation of the p value simultaneously as an &amp;ldquo;observed error rate&amp;rdquo; and as a measure of evidence. Both of these interpretations are problematic, and their combination has obscured the important differences between Neyman and Fisher on the nature of the scientific method and inhibited our understanding of the philosophic implications of the basic methods in use today. An analysis using another method promoted by Fisher, mathematical likelihood, shows that the p value substantially overstates the evidence against the null hypothesis. Likelihood makes clearer the distinction between error rates and inferential evidence and is a quantitative tool for expressing evidential strength that is more appropriate for the purposes of epidemiology than the p value.</description></item><item><title>NHST</title><link>https://aakinshin.net/library/quotes/0dff54f2-c974-483a-a6b6-81eb944d4882/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/0dff54f2-c974-483a-a6b6-81eb944d4882/</guid><description>What&amp;rsquo;s wrong with NHST? Well, among many other things, it does not tell us what we want to know, and we so much want to know what we want to know that, out of desperation, we nevertheless believe that it does!</description></item><item><title>P values, Hypothesis tests, and likelihood: Implications for Epidemiology of a Neglected Historical Debate</title><link>https://aakinshin.net/library/papers/goodman1993/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/goodman1993/</guid><description>Reference Steven N Goodman “P values, hypothesis tests, and likelihood: implications for epidemiology of a neglected historical debate” (1993) // American Journal of Epidemiology. Publisher: Oxford University Press. Vol. 137. No 5. Pp. 485–496. DOI: 10.1093/oxfordjournals.aje.a116700
Bib @Article{goodman1993, title = {P values, hypothesis tests, and likelihood: implications for epidemiology of a neglected historical debate}, author = {Goodman, Steven N}, journal = {American Journal of Epidemiology}, volume = {137}, number = {5}, pages = {485--496}, year = {1993}, publisher = {Oxford University Press}, doi = {10.1093/oxfordjournals.aje.a116700} }</description></item><item><title>P-Value Beyond Any Usual Limit of Significance</title><link>https://aakinshin.net/library/quotes/7d8010cb-c8b9-4878-801f-c267f591282d/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/7d8010cb-c8b9-4878-801f-c267f591282d/</guid><description>I believe that an observant statistician who has had any considerable experience with applying the chi-square test repeatedly will agree with my statement that, as a matterof observation, when the numbersin the data are quite large, the P&amp;rsquo;s tend to come out small. Having observed this, and on reflection, I make the following dogmatic statement, referring for illustration to the normal curve: &amp;ldquo;If the normal curve is fitted to a body of data representingany real observations whatever of quantitiesin the physical world, hen if the number of observationsis extremely large - for instance, on the order of 200,000-the chi-square P will be small beyond any usual limit of significance.&amp;rdquo;</description></item><item><title>Scientific Method</title><link>https://aakinshin.net/library/quotes/cd4d7cb3-1f80-4fa7-be94-9cb8181e7851/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/cd4d7cb3-1f80-4fa7-be94-9cb8181e7851/</guid><description>The originators of the statistical frameworks that underlie modern epidemiologic studies recognized that their methods could not be interpreted properly without an understanding of their philosophical underpinnings. Neyman held that inductive reasoning was an illusion and that the only meaningful parameters of importance in an experiment were constraints on the number of statistical &amp;ldquo;errors&amp;rdquo; we would make, defined before an experiment. Fisher rejected mechanistic approaches to inference, believing in a more flexible, inductive approach to science. One of Fisher&amp;rsquo;s developments, mathematical likelihood, fit into such an approach. The p value, which Fisher wanted used in a similar manner, invited misinterpretation because it occupied a peculiar middle ground. Because of its resemblance to the pretrial a error, it was absorbed into the hypothesis test framework. This created two illusions: that an &amp;ldquo;error rate&amp;rdquo; could be measured after an experiment and that this posttrial &amp;ldquo;error rate&amp;rdquo; could be regarded as a measure of inductive evidence. Even though Fisher, Neyman, and many others have recognized these as fallacies, their perpetuation has been encouraged by the manner in which we use the p value today. One consequence is that we overestimate the evidence for associations, particularly with p values in the range of 0.001-0.05, creating misleading impressions of their plausibility. Another result is that we minimize the importance of judgment in inference, because its role is unclear when postexperiment evidential strength is thought to be measurable with preexperiment &amp;ldquo;error-rates.&amp;rdquo; Many experienced epidemiologists have tried to correct these problems by offering guidelines about how p values should be used. We may be more effective if, in the spirts of Fisher and Neyman, we instead focus on clarifying what p values mean, and on what we mean by the &amp;ldquo;scientific method.&amp;rdquo;</description></item><item><title>Statistical tests, P values, Confidence intervals, and power: A Guide to Misinterpretations</title><link>https://aakinshin.net/library/papers/greenland2016/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/greenland2016/</guid><description>Reference Sander Greenland, Stephen J Senn, Kenneth J Rothman, John B Carlin, Charles Poole, Steven N Goodman, Douglas G Altman “Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations” (2016) // European Journal of Epidemiology. Vol. 31. No 4. Pp. 337–350. DOI: 10.1007/s10654-016-0149-3
Bib @Article{greenland2016, title = {Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations}, volume = {31}, issn = {0393-2990, 1573-7284}, shorttitle = {Statistical tests, P values, confidence intervals, and power}, url = {http://link.springer.com/10.1007/s10654-016-0149-3}, doi = {10.1007/s10654-016-0149-3}, language = {en}, number = {4}, urldate = {2020-01-08}, journal = {European Journal of Epidemiology}, author = {Greenland, Sander and Senn, Stephen J and Rothman, Kenneth J and Carlin, John B and Poole, Charles and Goodman, Steven N and Altman, Douglas G}, month = {apr}, year = {2016}, note = {ZSCC: 0000855}, pages = {337--350} }</description></item><item><title>The ASA Statement on p-Values: Context, Process, and Purpose</title><link>https://aakinshin.net/library/papers/wasserstein2016/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/wasserstein2016/</guid><description>Reference Ronald L. Wasserstein, Nicole A. Lazar “The ASA Statement on p-Values: Context, Process, and Purpose” (2016) // The American Statistician. Publisher: Informa UK Limited. Vol. 70. No 2. Pp. 129–133. DOI: 10.1080/00031305.2016.1154108
Bib @Article{wasserstein2016, title = {The ASA Statement on p-Values: Context, Process, and Purpose}, volume = {70}, issn = {1537-2731}, url = {http://dx.doi.org/10.1080/00031305.2016.1154108}, doi = {10.1080/00031305.2016.1154108}, number = {2}, journal = {The American Statistician}, publisher = {Informa UK Limited}, author = {Wasserstein, Ronald L. and Lazar, Nicole A.}, year = {2016}, month = {apr}, pages = {129–133} }</description></item><item><title>The Earth is Round (p &lt; .05)</title><link>https://aakinshin.net/library/papers/cohen1994/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/cohen1994/</guid><description>Reference Jacob Cohen “The earth is round (p &amp;lt; .05)” (1994) // American Psychologist. Publisher: American Psychological Association (APA). Vol. 49. No 12. Pp. 997–1003. DOI: 10.1037/0003-066x.49.12.997
Bib @Article{cohen1994, title = {The earth is round (p &amp;amp;lt; .05)}, volume = {49}, issn = {0003-066X}, url = {http://dx.doi.org/10.1037/0003-066X.49.12.997}, doi = {10.1037/0003-066x.49.12.997}, number = {12}, journal = {American Psychologist}, publisher = {American Psychological Association (APA)}, author = {Cohen, Jacob}, year = {1994}, month = {dec}, pages = {997–1003} }</description></item><item><title>The Failure of Null Hypothesis Significance Testing When Studying Incremental Changes, and What to Do about It</title><link>https://aakinshin.net/library/papers/gelman2017/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/gelman2017/</guid><description>Reference Andrew Gelman “The Failure of Null Hypothesis Significance Testing When Studying Incremental Changes, and What to Do About It” (2017) // Personality and Social Psychology Bulletin. Publisher: SAGE Publications. Vol. 44. No 1. Pp. 16–23. DOI: 10.1177/0146167217729162
Bib @Article{gelman2017, title = {The Failure of Null Hypothesis Significance Testing When Studying Incremental Changes, and What to Do About It}, volume = {44}, issn = {1552-7433}, url = {http://dx.doi.org/10.1177/0146167217729162}, doi = {10.1177/0146167217729162}, number = {1}, journal = {Personality and Social Psychology Bulletin}, publisher = {SAGE Publications}, author = {Gelman, Andrew}, year = {2017}, month = {sep}, pages = {16–23} }</description></item><item><title>The Illusion of Attaining Improbability</title><link>https://aakinshin.net/library/quotes/7a038512-b3c5-496a-b7ac-e5c900fca23b/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/7a038512-b3c5-496a-b7ac-e5c900fca23b/</guid><description>One problem arises from a misapplication of deductive syllogistic reasoning. Falk and Greenbaum (in press) called this the &amp;ldquo;illusion of probabilistic proof by contradiction&amp;rdquo; or the &amp;ldquo;illusion of attaining improbability.&amp;rdquo; Gigerenzer (1993) called it the &amp;ldquo;permanent illusion&amp;rdquo; and the &amp;ldquo;Bayesian Id&amp;rsquo;s wishful thinking,&amp;rdquo; part of the &amp;ldquo;hybrid logic&amp;rdquo; of contemporary statistical inference—a mishmash of Fisher and Neyman-Pearson, with invalid Bayesian interpretation.</description></item><item><title>The Null Hypothesis Ritual</title><link>https://aakinshin.net/library/quotes/af7c74d8-e8ac-4736-958a-ef3bd67c4385/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/af7c74d8-e8ac-4736-958a-ef3bd67c4385/</guid><description>After 4 decades of severe criticism, the ritual of null hypothesis significance testing — mechanical dichotomous decisions around a sacred .05 criterion — still persists.</description></item><item><title>The P Value Fallacy</title><link>https://aakinshin.net/library/quotes/aeb58f62-484b-49a5-853c-8f72e49c82e3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/aeb58f62-484b-49a5-853c-8f72e49c82e3/</guid><description>An important problem exists in the interpretation of modern medical research data: Biological understanding and previous research play little formal role in the interpretation of quantitative results. This phenomenon is manifest in the discussion sections of research articles and ultimately can affect the reliability of conclusions. The standard statistical approach has created this situation by promoting the illusion that conclusions can be produced with certain “error rates,” without consideration of information from outside the experiment. This statistical approach, the key components of which are P values and hypothesis tests, is widely perceived as a mathematically coherent approach to inference. There is little appreciation in the medical community that the methodology is an amalgam of incompatible elements, whose utility for scientific inference has been the subject of intense debate among statisticians for almost 70 years. This article introduces some of the key elements of that debate and traces the appeal and adverse impact of this methodology to the P value fallacy, the mistaken idea that a single number can capture both the long-run outcomes of an experiment and the evidential meaning of a single result. This argument is made as a prelude to the suggestion that another measure of evidence should be used—the Bayes factor, which properly separates issues of long-run behavior from evidential strength and allows the integration of background knowledge with statistical findings.</description></item><item><title>Toward evidence-based Medical statistics. 1: The P Value Fallacy</title><link>https://aakinshin.net/library/papers/goodman1999/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/papers/goodman1999/</guid><description>Reference Steven N Goodman “Toward evidence-based medical statistics. 1: The P value fallacy” (1999) // Annals of internal medicine. Publisher: American College of Physicians. Vol. 130. No 12. Pp. 995–1004. DOI: 10.7326/0003-4819-130-12-199906150-00008
Bib @Article{goodman1999, title = {Toward evidence-based medical statistics. 1: The P value fallacy}, author = {Goodman, Steven N}, journal = {Annals of internal medicine}, volume = {130}, number = {12}, pages = {995--1004}, year = {1999}, doi = {10.7326/0003-4819-130-12-199906150-00008}, publisher = {American College of Physicians} }</description></item><item><title>Twelve P-Value Misconceptions</title><link>https://aakinshin.net/library/quotes/ac262184-cdb6-46f8-b7ac-5107d66d8314/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aakinshin.net/library/quotes/ac262184-cdb6-46f8-b7ac-5107d66d8314/</guid><description> Twelve P-Value Misconceptions:
If P =.05, the null hypothesis has only a 5% chance of being true. A nonsignificant difference (eg, P &amp;gt; .05) means there is no difference between groups. A statistically significant finding is clinically important. Studies with P values on opposite sides of .05 are conflicting. Studies with the same P value provide the same evidence against the null hypothesis. P = .05 means that we have observed data that would occur only 5% of the time under the null hypothesis. P = .05 and P &amp;lt;= .05 mean the same thing. P values are properly written as inequalities (eg, “P &amp;lt; .02” when P = .015) P = .05 means that if you reject the null hypothesis, the probability of a type I error is only 5%. With a P = .05 threshold for significance, the chance of a type I error will be 5%. You should use a one-sided P value when you don’t care about a result in one direction, or a difference in that direction is impossible. A scientific conclusion or treatment policy should be based on whether or not the P value is significant.</description></item></channel></rss>