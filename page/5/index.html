<!doctype html><html lang=en class=h-100><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.74.3"><meta name=author content="Andrey Akinshin"><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content><title>Andrey Akinshin's blog (Page 5)</title><meta name=description content="Andrey Akinshin's blog"><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><link href=/css/lumen-bootstrap.min.css theme=light rel=stylesheet type=text/css media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link href=/css/slate-bootstrap.min.css theme=dark rel=stylesheet type=text/css media="(prefers-color-scheme: dark)"><link href=/css/syntax-light.css theme=light rel=stylesheet type=text/css media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link href=/css/syntax-dark.css theme=dark rel=stylesheet type=text/css media="(prefers-color-scheme: dark)"><script src=https://aakinshin.net/js/theme-before.min.26d61b7027fe55e642f0001cef94cb75b567d721086492aab6b4e32d9ee7811d.js></script><script type=module src=https://aakinshin.net/js/dark-mode-toggle.min.882998740b9c4c24677576b997bde5a487246e2e3bd72128a0e922eaa59db029.mjs></script><link href=https://aakinshin.net/css/fontawesome-all.min.50da8736f05b35aac9691de67fe993cbe01b7d88fcf0cb682c3a8f39933fe4a3.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/about.min.2a76db7cc14055b3bafacc363f453917ab54a818a7db2a0a9b2409c0f6bf07c5.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/blog.min.ae812fc71daf5160d927febda5a991cee6c361345e3f685d3736931ed7537986.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZVB6MXSX32"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','G-ZVB6MXSX32');</script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-41419012-5"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-41419012-5');</script><script type=text/javascript>(function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym");ym(28700916,"init",{clickmap:true,trackLinks:true,accurateTrackBounce:true});</script><noscript><div><img src=https://mc.yandex.ru/watch/28700916 style=position:absolute;left:-9999px alt></div></noscript><script src=/js/jquery-3.3.1.slim.min.js></script></head><body><div class=bg-primary><div class="container bg-primary"><nav class="navbar navbar-expand-sm navbar-dark bg-primary"><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link id=nav-link-blog href=https://aakinshin.net/><i class="fas fa-home" title=Home style=color:#fff></i></a></li><li class=nav-item><a class=nav-link id=nav-link-posts href=https://aakinshin.net/posts/>Posts</a></li><li class=nav-item><a class=nav-link id=nav-link-about href=https://aakinshin.net/about/>About</a></li><li class=nav-item><a class=nav-link id=nav-link-pdnb href=https://aakinshin.net/prodotnetbenchmarking/>Pro .NET Benchmarking</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" data-toggle=dropdown href=# role=button aria-haspopup=true aria-expanded=false>EN</a><div class=dropdown-menu><a class=dropdown-item href=https://aakinshin.net/ru/>RU</a></div></li></ul><ul class="navbar-nav ml-auto"><li class=nav-item><dark-mode-toggle permanent=true></dark-mode-toggle></li></ul></nav></div></div><div class=container><main id=main><div class=blog-main><div class=blog-post><h2 class=blog-post-title><a href=/posts/kosqe3/>Quantile estimators based on k order statistics, Part 3: Playing with the Beta function</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-08-17>August 17, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/quantile-estimators/ class="badge badge-info">Quantile Estimators</a>
<a href=https://aakinshin.net/tags/quantile-estimators-based-on-k-order-statistics/ class="badge badge-info">Quantile estimators based on k order statistics</a>
<a href=https://aakinshin.net/tags/research-thdqe/ class="badge badge-info">Research: Building trimmed Harrell-Davis quantile estimator</a></span><br><br><p><strong>Update: this blog post is a part of research that aimed to build a statistically efficient and robust quantile estimator.
A <a href=https://aakinshin.net/posts/pub-thdqe/>paper with final results</a> is available in <em>Communications in Statistics - Simulation and Computation</em> (DOI: <a href=https://www.tandfonline.com/doi/abs/10.1080/03610918.2022.2050396>10.1080/03610918.2022.2050396</a>).
A preprint is available on arXiv: <a href=https://arxiv.org/abs/2111.11776>arXiv:2111.11776 [stat.ME]</a>.</strong></p><p>In the previous two posts, I discussed the idea of quantile estimators based on k order statistics.
A already covered the <a href=https://aakinshin.net/posts/kosqe1/>motivation behind this idea</a>
and the statistical efficiency of such estimators using the <a href=https://aakinshin.net/posts/kosqe2/>extended Hyndman-Fan equations</a>
as a weight function.
Now it&rsquo;s time to experiment with the Beta function as a primary way to aggregate k order statistics
into a single quantile estimation!</p><br><a href=/posts/kosqe3/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/kosqe2/>Quantile estimators based on k order statistics, Part 2: Extending Hyndman-Fan equations</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-08-10>August 10, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/quantile-estimators/ class="badge badge-info">Quantile Estimators</a>
<a href=https://aakinshin.net/tags/quantile-estimators-based-on-k-order-statistics/ class="badge badge-info">Quantile estimators based on k order statistics</a>
<a href=https://aakinshin.net/tags/research-thdqe/ class="badge badge-info">Research: Building trimmed Harrell-Davis quantile estimator</a></span><br><br><p><strong>Update: this blog post is a part of research that aimed to build a statistically efficient and robust quantile estimator.
A <a href=https://aakinshin.net/posts/pub-thdqe/>paper with final results</a> is available in <em>Communications in Statistics - Simulation and Computation</em> (DOI: <a href=https://www.tandfonline.com/doi/abs/10.1080/03610918.2022.2050396>10.1080/03610918.2022.2050396</a>).
A preprint is available on arXiv: <a href=https://arxiv.org/abs/2111.11776>arXiv:2111.11776 [stat.ME]</a>.</strong></p><p>In the <a href=https://aakinshin.net/posts/kosqe1/>previous post</a>,
I described the idea of using quantile estimators based on k order statistics.
Potentially, such estimators could be more robust than estimators based on all samples elements (like
Harrell-Davis,
<a href=https://aakinshin.net/posts/sfakianakis-verginis-quantile-estimator/>Sfakianakis-Verginis</a>, or
<a href=https://aakinshin.net/posts/navruz-ozdemir-quantile-estimator/>Navruz-Özdemir</a>)
and more statistically efficient than traditional quantile estimators (based on 1 or 2 order statistics).
Moreover, we should be able to control this trade-off based on the business requirements
(e.g., setting the desired breakdown point).</p><p>The only challenging thing here is choosing the weight function
that aggregates k order statistics to a single quantile estimation.
We are going to try several options, perform Monte-Carlo simulations for each of them, and compare the results.
A reasonable starting point is an extension of the traditional quantile estimators.
In this post, we are going to extend the Hyndman-Fan Type 7 quantile estimator
(nowadays, it&rsquo;s one of the most popular estimators).
It estimates quantiles as a linear interpolation of two subsequent order statistics.
We are going to make some modifications, so a new version is going to be based on k order statistics.</p><p><strong>Spoiler: this approach doesn&rsquo;t seem like an optimal one.</strong>
I&rsquo;m pretty disappointed with its statistical efficiency on samples from light-tailed distributions.
So, what&rsquo;s the point of writing a blog post about an inefficient approach?
Because of the following reasons:</p><ol><li>I believe it&rsquo;s crucial to share negative results.
Sometimes, knowledge about approaches that don&rsquo;t work
could be more important than knowledge about more effective techniques.
Negative results give you a broader view of the problem
and protect you from wasting your time on potential promising (but not so useful) ideas.</li><li>Negative results improve research completeness.
When we present an approach, it&rsquo;s essential to not only show why it solves problems well,
but also why it solves problems better than other similar approaches.</li><li>While I wouldn&rsquo;t recommend my extension of the Hyndman-Fan Type 7 quantile estimator to the k order statistics case
as the default quantile estimator, there are some specific cases where it could be useful.
For example, if we estimate the median based on small samples from a symmetric light-tailed distribution,
it could outperform not only the original version but also the Harrell-Davis quantile estimator.
The &ldquo;negativity&rdquo; of the negative results always exists in a specific context.
So, there may be cases when negative results for the general case transform to positive results
for a particular niche problem.</li><li>Finally, it&rsquo;s my personal blog, so I have the freedom to write on any topic I like.
My blog posts are not publications to scientific journals (which typically don&rsquo;t welcome negative results),
but rather research notes about conducted experiments.
It&rsquo;s important for me to keep records of all the experiments I perform regardless of the usefulness of the results.</li></ol><p>So, let&rsquo;s briefly look at the results of this not-so-useful approach.</p><div class=row><div class=mx-auto><a href=/posts/kosqe2/img/LightAndHeavy__N15_Efficiency-light.png target=_blank class=imgldlink alt=LightAndHeavy__N15_Efficiency><picture>
<source theme=dark srcset=/posts/kosqe2/img/LightAndHeavy__N15_Efficiency-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/kosqe2/img/LightAndHeavy__N15_Efficiency-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/kosqe2/img/LightAndHeavy__N15_Efficiency-light.png></picture></a></div></div><br><br><a href=/posts/kosqe2/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/kosqe1/>Quantile estimators based on k order statistics, Part 1: Motivation</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-08-03>August 3, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/quantile-estimators/ class="badge badge-info">Quantile Estimators</a>
<a href=https://aakinshin.net/tags/quantile-estimators-based-on-k-order-statistics/ class="badge badge-info">Quantile estimators based on k order statistics</a>
<a href=https://aakinshin.net/tags/research-thdqe/ class="badge badge-info">Research: Building trimmed Harrell-Davis quantile estimator</a></span><br><br><p><strong>Update: this blog post is a part of research that aimed to build a statistically efficient and robust quantile estimator.
A <a href=https://aakinshin.net/posts/pub-thdqe/>paper with final results</a> is available in <em>Communications in Statistics - Simulation and Computation</em> (DOI: <a href=https://www.tandfonline.com/doi/abs/10.1080/03610918.2022.2050396>10.1080/03610918.2022.2050396</a>).
A preprint is available on arXiv: <a href=https://arxiv.org/abs/2111.11776>arXiv:2111.11776 [stat.ME]</a>.</strong></p><p>It&rsquo;s not easy to choose a good quantile estimator.
In my previous posts, I considered several groups of quantile estimators:</p><ul><li>Quantile estimators based 1 or 2 order statistics (Hyndman-Fan Type1-9)</li><li>Quantile estimators based on all order statistics
(the Harrell-Davis quantile estimator,
the <a href=https://aakinshin.net/posts/sfakianakis-verginis-quantile-estimator/>Sfakianakis-Verginis quantile estimator</a>, and
the <a href=https://aakinshin.net/posts/navruz-ozdemir-quantile-estimator/>Navruz-Özdemir quantile estimator</a>)</li><li>Quantile estimators based on a variable number of order statistics
(the <a href=https://aakinshin.net/posts/trimmed-hdqe/>trimmed</a> and <a href=https://aakinshin.net/posts/winsorized-hdqe/>winsorized</a> modifications
of the Harrell-Davis quantile estimator)</li></ul><p>Unfortunately, all of these estimators have significant drawbacks
(e.g., poor statistical efficiency or poor robustness).
In this post, I want to discuss all of the advantages and disadvantages of each approach
and suggest another family of quantile estimators that are based on k order statistics.</p><br><a href=/posts/kosqe1/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/thdqe-overtrimming/>Avoiding over-trimming with the trimmed Harrell-Davis quantile estimator</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-07-27>July 27, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/quantile/ class="badge badge-info">Quantile</a>
<a href=https://aakinshin.net/tags/statistical-efficiency/ class="badge badge-info">Statistical efficiency</a>
<a href=https://aakinshin.net/tags/research-thdqe/ class="badge badge-info">Research: Building trimmed Harrell-Davis quantile estimator</a></span><br><br><p><strong>Update: this blog post is a part of research that aimed to build a statistically efficient and robust quantile estimator.
A <a href=https://aakinshin.net/posts/pub-thdqe/>paper with final results</a> is available in <em>Communications in Statistics - Simulation and Computation</em> (DOI: <a href=https://www.tandfonline.com/doi/abs/10.1080/03610918.2022.2050396>10.1080/03610918.2022.2050396</a>).
A preprint is available on arXiv: <a href=https://arxiv.org/abs/2111.11776>arXiv:2111.11776 [stat.ME]</a>.</strong></p><p>Previously, I already discussed the
<a href=https://aakinshin.net/posts/trimmed-hdqe/>trimmed modification of the Harrell-Davis quantile estimator</a> several times.
I performed several numerical simulations that compare the statistical efficiency of this estimator
with the efficiency of the <a href=https://aakinshin.net/posts/wthdqe-efficiency/>classic Harrell-Davis quantile estimator</a> (HDQE)
and its <a href=https://aakinshin.net/posts/winsorized-hdqe/>winsorized modification</a>;
I showed how we can improve the efficiency using <a href=https://aakinshin.net/posts/customized-wthdqe/>custom trimming strategies</a>
and how to choose a <a href=https://aakinshin.net/posts/thdqe-threshold/>good trimming threshold value</a>.</p><p>In the heavy-tailed cases, the trimmed HDQE provides better estimations than the classic HDQE
because of its higher breakdown point.
However, in the light-tailed cases, we could get efficiency that is worse than
the baseline Hyndman-Fan Type 7 (HF7) quantile estimator.
In many cases, such an effect arises because of the over-trimming effect.
If the trimming percentage is too high or if the evaluated quantile is too far from the median,
the trimming strategy based on the highest-density interval may lead to an estimation
that is based on single order statistics.
In this case, we get an efficiency level similar to the Hyndman-Fan Type 1-3 quantile estimators
(which are also based on single order statistics).
In the light-tailed case, such a result is less preferable than Hyndman-Fan Type 4-9 quantile estimators
(which are based on two subsequent order statistics).</p><p>In order to improve the situation, we could introduce the lower bound for the number of order statistics
that contribute to the final quantile estimations.
In this post, I look at some numerical simulations
that compare trimmed HDQEs with different lower bounds.</p><div class=row><div class=mx-auto><a href=/posts/thdqe-overtrimming/img/LightAndHeavy__N05_Efficiency-light.png target=_blank class=imgldlink alt=LightAndHeavy__N05_Efficiency><picture>
<source theme=dark srcset=/posts/thdqe-overtrimming/img/LightAndHeavy__N05_Efficiency-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/thdqe-overtrimming/img/LightAndHeavy__N05_Efficiency-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/thdqe-overtrimming/img/LightAndHeavy__N05_Efficiency-light.png></picture></a></div></div><br><br><a href=/posts/thdqe-overtrimming/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/thdqe-threshold/>Optimal threshold of the trimmed Harrell-Davis quantile estimator</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-07-20>July 20, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/quantile/ class="badge badge-info">Quantile</a>
<a href=https://aakinshin.net/tags/statistical-efficiency/ class="badge badge-info">Statistical efficiency</a>
<a href=https://aakinshin.net/tags/research-thdqe/ class="badge badge-info">Research: Building trimmed Harrell-Davis quantile estimator</a></span><br><br><p><strong>Update: this blog post is a part of research that aimed to build a statistically efficient and robust quantile estimator.
A <a href=https://aakinshin.net/posts/pub-thdqe/>paper with final results</a> is available in <em>Communications in Statistics - Simulation and Computation</em> (DOI: <a href=https://www.tandfonline.com/doi/abs/10.1080/03610918.2022.2050396>10.1080/03610918.2022.2050396</a>).
A preprint is available on arXiv: <a href=https://arxiv.org/abs/2111.11776>arXiv:2111.11776 [stat.ME]</a>.</strong></p><p>The traditional quantile estimators (which are based on 1 or 2 order statistics) have great robustness.
However, the statistical efficiency of these estimators is not so great.
The Harrell-Davis quantile estimator has much better efficiency (at least in the light-tailed case),
but it&rsquo;s not robust (because it calculates a weighted sum of all sample values).
I already wrote a <a href=https://aakinshin.net/posts/trimmed-hdqe/>post about trimmed Harrell-Davis quantile estimator</a>:
this approach suggest dropping some of the low-weight sample values to improve robustness
(keeping good statistical efficiency).
I also perform a numerical simulations that <a href=https://aakinshin.net/posts/wthdqe-efficiency/>compare efficiency</a>
of the original Harrell-Davis quantile estimator against its trimmed and winsorized modifications.
It&rsquo;s time to discuss how to choose the optimal trimming threshold
and how it affects the estimator efficiency.</p><div class=row><div class=mx-auto><a href=/posts/thdqe-threshold/img/LightAndHeavy__N40_Efficiency-light.png target=_blank class=imgldlink alt=LightAndHeavy__N40_Efficiency><picture>
<source theme=dark srcset=/posts/thdqe-threshold/img/LightAndHeavy__N40_Efficiency-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/thdqe-threshold/img/LightAndHeavy__N40_Efficiency-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/thdqe-threshold/img/LightAndHeavy__N40_Efficiency-light.png></picture></a></div></div><br><br><a href=/posts/thdqe-threshold/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/maritz-jarrett-vs-jackknife/>Estimating quantile confidence intervals: Maritz-Jarrett vs. jackknife</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-07-13>July 13, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/quantile/ class="badge badge-info">Quantile</a>
<a href=https://aakinshin.net/tags/confidence-interval/ class="badge badge-info">Confidence Interval</a>
<a href=https://aakinshin.net/tags/coverage/ class="badge badge-info">Coverage</a></span><br><br><p>When it comes to estimating quantiles of the given sample,
my estimator of choice is the Harrell-Davis quantile estimator
(to be more specific, its <a href=https://aakinshin.net/posts/trimmed-hdqe/>trimmed version</a>).
If I need to get a confidence interval for the obtained quantiles,
I use the <a href=https://aakinshin.net/posts/weighted-quantiles-ci/#the-maritz-jarrett-method>Maritz-Jarrett method</a>
because it provides a <a href=https://aakinshin.net/posts/quantile-ci-coverage/>decent coverage percentage</a>.
Both approaches work pretty nicely together.</p><p>However, in the original paper by <a href=https://doi.org/10.2307/2335999>Harrell and Davis (1982)</a>,
the authors suggest using the jackknife variance estimator in order to get the confidence intervals.
The obvious question here is which approach better: the Maritz-Jarrett method or the jackknife estimator?
In this post, I perform a numerical simulation that compares both techniques using different distributions.</p><br><a href=/posts/maritz-jarrett-vs-jackknife/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/kish-ess-weighted-quantiles/>Using Kish's effective sample size with weighted quantiles</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-07-06>July 6, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/quantiles/ class="badge badge-info">Quantiles</a></span><br><br><p>In my previous posts, I described how to calculate
<a href=https://aakinshin.net/posts/weighted-quantiles/>weighted quantiles</a> and
their <a href=https://aakinshin.net/posts/weighted-quantiles-ci/>confidence intervals</a>
using the Harrell-Davis quantile estimator.
This powerful technique allows applying
<a href=https://aakinshin.net/posts/quantile-exponential-smoothing/>quantile exponential smoothing</a> and
<a href=https://aakinshin.net/posts/dispersion-exponential-smoothing/>dispersion exponential smoothing</a> for
time series in order to get its moving properties.</p><p>When we work with weighted samples, we need a way to calculate the
<a href=https://en.wikipedia.org/wiki/Effective_sample_size>effective samples size</a>.
Previously, I used the sum of all weights normalized by the maximum weight.
In most cases, it worked OK.</p><p>Recently, <a href=https://www.soz.unibe.ch/about_us/people/prof_dr_jann_ben/index_eng.html>Ben Jann</a> pointed out
that it would be better to use the Kish&rsquo;s formula to calculate the effective sample size.
In this post, you find the formula and a few numerical simulations that illustrate the actual impact of
the underlying sample size formula.</p><br><a href=/posts/kish-ess-weighted-quantiles/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/partial-binning-compression/>Partial binning compression of performance series</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-06-29>June 29, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/partial-binning/ class="badge badge-info">Partial binning</a></span><br><br><p>Let&rsquo;s start with a problem from real life.
Imagine we have thousands of application components that should be initialized.
We care about the total initialization time of the whole application,
so we want to automatically track the slowest components using a continuous integration (CI) system.
The easiest way to do it is to measure the initialization time of each component in each CI build
and save all the measurements to a database.
Unfortunately, if the total number of components is huge, the overall artifact size may be quite extensive.
Thus, this approach may introduce an unwanted negative impact on the database size and data processing time.</p><p>However, we don&rsquo;t actually need all the measurements.
We want to track only the slowest components.
Typically, it&rsquo;s possible to introduce a reasonable threshold that defines such components.
For example, we can say that all components that are initialized in less than 1ms are &ldquo;fast enough,&rdquo;
so there is no need to know the exact initialization time for them.
Since these time values are insignificant, we can just omit all the measurements below the given thresholds.
This allows to significantly reduce the data traffic without losing any important information.</p><p>The suggested trick can be named <em>partial binning compression</em>.
Indeed, we introduce a single bin (perform <em>binning</em>) and
omit all the values inside this bin (perform <em>compression</em>).
On the other hand, we don&rsquo;t build an honest histogram since we keep all the raw values outside the given bin
(the binning is <em>partial</em>).</p><p>Let&rsquo;s discuss a few aspects of using partial binning compression.</p><br><a href=/posts/partial-binning-compression/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/zero-mad-gamma-es/>Calculating gamma effect size for samples with zero median absolute deviation</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-06-22>June 22, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/effect-size/ class="badge badge-info">Effect Size</a>
<a href=https://aakinshin.net/tags/research-gamma-es/ class="badge badge-info">Research: Gamma Effect Size</a>
<a href=https://aakinshin.net/tags/mad/ class="badge badge-info">MAD</a></span><br><br><p>In previous posts, I discussed the <a href=https://aakinshin.net/posts/nonparametric-effect-size/>gamma effect size</a>
which is a Cohen&rsquo;s d-consistent nonparametric and robust measure of the effect size.
Also, I discussed <a href=https://aakinshin.net/posts/nonparametric-effect-size2/>various ways to customize this metric</a>
and adjust it to different kinds of business requirements.
In this post, I want to briefly cover one more corner case that requires special adjustments.
We are going to discuss the situation when the median absolute deviation is zero.</p><br><a href=/posts/zero-mad-gamma-es/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/discrete-performance-distributions/>Discrete performance distributions</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-06-15>June 15, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a></span><br><br><p>When we collect software performance measurements, we get a bunch of time intervals.
Typically, we tend to interpret time values as continuous values.
However, the obtained values are actually discrete due to the limited resolution of our measurement tool.
In simple cases, we can treat these discrete values as continuous and get meaningful results.
Unfortunately, discretization may produce strange phenomena like pseudo-multimodality or zero dispersion.
If we want to set up a reliable system that automatically analyzes such distributions,
we should be aware of such problems so we could correctly handle them.</p><p>In this post, I want to share a few of discretization problems in real-life performance data sets
(based on the <a href=https://www.jetbrains.com/rider/>Rider</a> performance tests).</p><br><a href=/posts/discrete-performance-distributions/>Read more</a><br><br><hr></div></div><div class=paginator><ul class=pagination><li class=page-item><a href=/ class=page-link aria-label=First><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/page/4/ class=page-link aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a class=page-link href=/>1</a></li><li class=page-item><a class=page-link href=/page/2/>2</a></li><li class=page-item><a class=page-link href=/page/3/>3</a></li><li class=page-item><a class=page-link href=/page/4/>4</a></li><li class="page-item active"><a class=page-link href=/page/5/>5</a></li><li class=page-item><a class=page-link href=/page/6/>6</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/14/>14</a></li><li class=page-item><a href=/page/6/ class=page-link aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/page/14/ class=page-link aria-label=Last><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></main></div><footer class=blog-footer><div class=container><p>&copy; 2013&mdash;2022 Andrey Akinshin
|
<a href=https://github.com/AndreyAkinshin><i class="fab fa-github" title=GitHub></i></a><a href=https://twitter.com/andrey_akinshin><i class="fab fa-twitter" title=Twitter></i></a><a href=https://aakinshin.net/posts/index.xml><i class="fas fa-rss" title=RSS></i></a>|
<a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></p></div></footer><script src=https://aakinshin.net/js/theme-after.min.082780cb948cc57eabbc0d80172a7a5347d5572b599938b4c9876dfd7978b424.js></script><script src=/js/popper.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/anchor.min.js></script><script src=https://aakinshin.net/js/custom.min.11932490dde776463ed165b345838c701accc0cfdedf2e0868f13415f41f0872.js></script><script>window.MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],processEscapes:true,processEnvironments:true,},options:{skipHtmlTags:['script','noscript','style','textarea','pre'],ignoreHtmlClass:'tex2jax_ignore',processHtmlClass:'tex2jax_process'}};</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></body></html>