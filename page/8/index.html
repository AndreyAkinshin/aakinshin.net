<!doctype html><html lang=en class=h-100><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.103.0-DEV"><meta name=author content="Andrey Akinshin"><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content><title>Andrey Akinshin's blog (Page 8)</title><meta name=description content="Andrey Akinshin's blog"><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><link href=https://aakinshin.net/sass/bootstrap-light.min.css theme=light rel=stylesheet type=text/css media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link href=https://aakinshin.net/sass/bootstrap-dark.min.css theme=dark rel=stylesheet type=text/css media="(prefers-color-scheme: dark)"><script src=https://aakinshin.net/js/theme-before.min.d7f6578e23ad3f0c33c589f9bcb34f995b45121f1f3ce888869c86b26826c845.js></script>
<script type=module src=https://aakinshin.net/js/dark-mode-toggle.min.9e68d431432744c07a43381a8a833ffe0921cc0e006d84ad97f0b0d43c5cd82d.mjs></script>
<link href=https://aakinshin.net/css/fontawesome-all.min.178e95bba6ea2e9a90838cd646658f4bf6667a6ceaa057cb587bf7e6eb8412d3.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/about.min.60773ab7266ecc6e9625306f57c0a82a219b011dc3ea2d83763d1ecdf11c86d2.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/blog.min.7e186db80d8c431d196b3e0718afb0636b82a269a8c92521c11a55267a24fc27.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZVB6MXSX32"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-ZVB6MXSX32")</script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-41419012-5"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","UA-41419012-5")</script><script type=text/javascript>(function(e,t,n,s,o,i,a){e[o]=e[o]||function(){(e[o].a=e[o].a||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym"),ym(28700916,"init",{clickmap:!0,trackLinks:!0,accurateTrackBounce:!0})</script><noscript><div><img src=https://mc.yandex.ru/watch/28700916 style=position:absolute;left:-9999px alt></div></noscript><script src=/js/jquery-3.3.1.slim.min.js></script></head><body><div class=bg-primary><div class="container bg-primary"><nav class="navbar navbar-expand-sm navbar-dark bg-primary"><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link id=nav-link-blog href=https://aakinshin.net/><i class="fas fa-home" title=Home style=color:#fff></i></a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-expanded=false>Blog</a><ul class="dropdown-menu bg-primary"><li><a class=dropdown-item href=https://aakinshin.net/posts/>All Posts</a></li><li><a class=dropdown-item href=https://aakinshin.net/tags/statistics/>Posts about Statistics</a></li><li></li><a class=dropdown-item href=https://aakinshin.net/tags/>All Tags</a></li></ul></li><li class=nav-item><a class=nav-link id=nav-link-about href=https://aakinshin.net/about/>About</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-expanded=false>EN</a><ul class="dropdown-menu bg-primary"><li></li><a class=dropdown-item href=https://aakinshin.net/ru/>RU</a></li></ul></li></ul><ul class="navbar-nav ms-auto"><li class=nav-item><dark-mode-toggle permanent=true></dark-mode-toggle></li></ul></nav></div></div><div class=container><main id=main><div class=blog-main><div class=blog-post><h2 class=blog-post-title><a href=/posts/maritz-jarrett-vs-jackknife/>Estimating quantile confidence intervals: Maritz-Jarrett vs. jackknife</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-07-13>July 13, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>
&nbsp;
<a href=https://aakinshin.net/tags/mathematics/ class="badge badge-info">Mathematics</a>
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research/ class="badge badge-info">Research</a>
<a href=https://aakinshin.net/tags/quantile/ class="badge badge-info">Quantile</a>
<a href=https://aakinshin.net/tags/confidence-interval/ class="badge badge-info">Confidence Interval</a>
<a href=https://aakinshin.net/tags/coverage/ class="badge badge-info">Coverage</a></span><br><br><p>When it comes to estimating quantiles of the given sample,
my estimator of choice is the Harrell-Davis quantile estimator
(to be more specific, its <a href=https://aakinshin.net/posts/trimmed-hdqe/>trimmed version</a>).
If I need to get a confidence interval for the obtained quantiles,
I use the <a href=https://aakinshin.net/posts/weighted-quantiles-ci/#the-maritz-jarrett-method>Maritz-Jarrett method</a>
because it provides a <a href=https://aakinshin.net/posts/quantile-ci-coverage/>decent coverage percentage</a>.
Both approaches work pretty nicely together.</p><p>However, in the original paper by <a href=https://doi.org/10.2307/2335999>Harrell and Davis (1982)</a>,
the authors suggest using the jackknife variance estimator in order to get the confidence intervals.
The obvious question here is which approach better: the Maritz-Jarrett method or the jackknife estimator?
In this post, I perform a numerical simulation that compares both techniques using different distributions.</p><br><a href=/posts/maritz-jarrett-vs-jackknife/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/kish-ess-weighted-quantiles/>Using Kish's effective sample size with weighted quantiles</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-07-06>July 6, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>
&nbsp;
<a href=https://aakinshin.net/tags/mathematics/ class="badge badge-info">Mathematics</a>
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research/ class="badge badge-info">Research</a>
<a href=https://aakinshin.net/tags/quantiles/ class="badge badge-info">Quantiles</a></span><br><br><p>In my previous posts, I described how to calculate
<a href=https://aakinshin.net/posts/weighted-quantiles/>weighted quantiles</a> and
their <a href=https://aakinshin.net/posts/weighted-quantiles-ci/>confidence intervals</a>
using the Harrell-Davis quantile estimator.
This powerful technique allows applying
<a href=https://aakinshin.net/posts/quantile-exponential-smoothing/>quantile exponential smoothing</a> and
<a href=https://aakinshin.net/posts/dispersion-exponential-smoothing/>dispersion exponential smoothing</a> for
time series in order to get its moving properties.</p><p>When we work with weighted samples, we need a way to calculate the
<a href=https://en.wikipedia.org/wiki/Effective_sample_size>effective samples size</a>.
Previously, I used the sum of all weights normalized by the maximum weight.
In most cases, it worked OK.</p><p>Recently, <a href=https://www.soz.unibe.ch/about_us/people/prof_dr_jann_ben/index_eng.html>Ben Jann</a> pointed out
that it would be better to use the Kish&rsquo;s formula to calculate the effective sample size.
In this post, you find the formula and a few numerical simulations that illustrate the actual impact of
the underlying sample size formula.</p><br><a href=/posts/kish-ess-weighted-quantiles/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/partial-binning-compression/>Partial binning compression of performance series</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-06-29>June 29, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>
&nbsp;
<a href=https://aakinshin.net/tags/mathematics/ class="badge badge-info">Mathematics</a>
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research/ class="badge badge-info">Research</a>
<a href=https://aakinshin.net/tags/partial-binning/ class="badge badge-info">Partial binning</a></span><br><br><p>Let&rsquo;s start with a problem from real life.
Imagine we have thousands of application components that should be initialized.
We care about the total initialization time of the whole application,
so we want to automatically track the slowest components using a continuous integration (CI) system.
The easiest way to do it is to measure the initialization time of each component in each CI build
and save all the measurements to a database.
Unfortunately, if the total number of components is huge, the overall artifact size may be quite extensive.
Thus, this approach may introduce an unwanted negative impact on the database size and data processing time.</p><p>However, we don&rsquo;t actually need all the measurements.
We want to track only the slowest components.
Typically, it&rsquo;s possible to introduce a reasonable threshold that defines such components.
For example, we can say that all components that are initialized in less than 1ms are &ldquo;fast enough,&rdquo;
so there is no need to know the exact initialization time for them.
Since these time values are insignificant, we can just omit all the measurements below the given thresholds.
This allows to significantly reduce the data traffic without losing any important information.</p><p>The suggested trick can be named <em>partial binning compression</em>.
Indeed, we introduce a single bin (perform <em>binning</em>) and
omit all the values inside this bin (perform <em>compression</em>).
On the other hand, we don&rsquo;t build an honest histogram since we keep all the raw values outside the given bin
(the binning is <em>partial</em>).</p><p>Let&rsquo;s discuss a few aspects of using partial binning compression.</p><br><a href=/posts/partial-binning-compression/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/zero-mad-gamma-es/>Calculating gamma effect size for samples with zero median absolute deviation</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-06-22>June 22, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>
&nbsp;
<a href=https://aakinshin.net/tags/mathematics/ class="badge badge-info">Mathematics</a>
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research/ class="badge badge-info">Research</a>
<a href=https://aakinshin.net/tags/effect-size/ class="badge badge-info">Effect Size</a>
<a href=https://aakinshin.net/tags/research-gamma-es/ class="badge badge-info">Research: Gamma Effect Size</a>
<a href=https://aakinshin.net/tags/mad/ class="badge badge-info">MAD</a></span><br><br><p>In previous posts, I discussed the <a href=https://aakinshin.net/posts/nonparametric-effect-size/>gamma effect size</a>
which is a Cohen&rsquo;s d-consistent nonparametric and robust measure of the effect size.
Also, I discussed <a href=https://aakinshin.net/posts/nonparametric-effect-size2/>various ways to customize this metric</a>
and adjust it to different kinds of business requirements.
In this post, I want to briefly cover one more corner case that requires special adjustments.
We are going to discuss the situation when the median absolute deviation is zero.</p><br><a href=/posts/zero-mad-gamma-es/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/discrete-performance-distributions/>Discrete performance distributions</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-06-15>June 15, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>
&nbsp;
<a href=https://aakinshin.net/tags/mathematics/ class="badge badge-info">Mathematics</a>
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research/ class="badge badge-info">Research</a></span><br><br><p>When we collect software performance measurements, we get a bunch of time intervals.
Typically, we tend to interpret time values as continuous values.
However, the obtained values are actually discrete due to the limited resolution of our measurement tool.
In simple cases, we can treat these discrete values as continuous and get meaningful results.
Unfortunately, discretization may produce strange phenomena like pseudo-multimodality or zero dispersion.
If we want to set up a reliable system that automatically analyzes such distributions,
we should be aware of such problems so we could correctly handle them.</p><p>In this post, I want to share a few of discretization problems in real-life performance data sets
(based on the <a href=https://www.jetbrains.com/rider/>Rider</a> performance tests).</p><br><a href=/posts/discrete-performance-distributions/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/nonparametric-effect-size2/>Customization of the nonparametric Cohen's d-consistent effect size</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-06-08>June 8, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>
&nbsp;
<a href=https://aakinshin.net/tags/mathematics/ class="badge badge-info">Mathematics</a>
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research/ class="badge badge-info">Research</a>
<a href=https://aakinshin.net/tags/effect-size/ class="badge badge-info">Effect Size</a>
<a href=https://aakinshin.net/tags/research-gamma-es/ class="badge badge-info">Research: Gamma Effect Size</a>
<a href=https://aakinshin.net/tags/mad/ class="badge badge-info">MAD</a>
<a href=https://aakinshin.net/tags/harrell-davis-quantile-estimator/ class="badge badge-info">Harrell-Davis quantile estimator</a></span><br><br><p>One year ago, I publish a post called <a href=https://aakinshin.net/posts/nonparametric-effect-size/>Nonparametric Cohen's d-consistent effect size</a>.
During this year, I got a lot of internal and external feedback from
my own statistical experiments and
<a href=https://twitter.com/ViljamiSairanen/status/1400457118340108293>people</a>
<a href=https://sherbold.github.io/autorank/autorank/>who</a>
<a href=https://github.com/Ramon-Diaz/Thesis-Project/blob/85df6b11050c7e05c4394d873585f701a7e3f32e/_util.py#L100>tried</a>
to use the suggested approach.
It seems that the nonparametric version of Cohen&rsquo;s d works much better with real-life not-so-normal data.
While the classic Cohen&rsquo;s d based on
the non-robust arithmetic mean and
the <a href=https://aakinshin.net/posts/misleading-stddev/>non-robust standard deviation</a>
can be easily <a href=https://aakinshin.net/posts/cohend-and-outliers/>corrupted by a single outlier</a>,
my approach is much more resistant to unexpected extreme values.
Also, it allows exploring
<a href=https://aakinshin.net/posts/comparing-distributions-using-gamma-es/>the difference between specific quantiles of considered samples</a>,
which can be useful in the non-parametric case.</p><p>However, I wasn&rsquo;t satisfied with the results of all of my experiments.
While I still like the basic idea
(replace the mean with the median; replace the standard deviation with the median absolute deviation),
it turned out that the final results heavily depend on the used quantile estimator.
To be more specific, the original Harrell-Davis quantile estimator is not always optimal;
in most cases, it&rsquo;s better to replace it with its <a href=https://aakinshin.net/posts/trimmed-hdqe/>trimmed</a> modification.
However, the particular choice of the quantile estimators depends on the situation.
Also, the consistency constant for the median absolute deviation
should be adjusted according to the current sample size and the used quantile estimator.
Of course, it also can be replaced by other dispersion estimators
that can be used as consistent estimators of the standard deviation.</p><p>In this post, I want to get a brief overview of possible customizations of the suggested metrics.</p><br><a href=/posts/nonparametric-effect-size2/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/robust-statistical-efficiency/>Robust alternative to statistical efficiency</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-06-01>June 1, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>
&nbsp;
<a href=https://aakinshin.net/tags/mathematics/ class="badge badge-info">Mathematics</a>
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research/ class="badge badge-info">Research</a>
<a href=https://aakinshin.net/tags/statistical-efficiency/ class="badge badge-info">Statistical efficiency</a></span><br><br><p>Statistical efficiency is a common measure of the quality of an estimator.
Typically, it&rsquo;s expressed via the mean square error (<span class="math inline">\(\operatorname{MSE}\)</span>).
For the given estimator <span class="math inline">\(T\)</span> and the true parameter value <span class="math inline">\(\theta\)</span>,
the <span class="math inline">\(\operatorname{MSE}\)</span> can be expressed as follows:</p><p><span class="math display">\[\operatorname{MSE}(T) = \operatorname{E}[(T-\theta)^2]
\]</span></p><p>In numerical simulations, the <span class="math inline">\(\operatorname{MSE}\)</span> can&rsquo;t be used as a robust metric
because its breakdown point is zero
(a corruption of a single measurement leads to a corrupted result).
Typically, it&rsquo;s not a problem for light-tailed distributions.
Unfortunately, in the heavy-tailed case,
the <span class="math inline">\(\operatorname{MSE}\)</span> becomes an unreliable and unreproducible metric
because it can be easily spoiled by a single outlier.</p><p>I suggest an alternative way to compare statistical estimators.
Instead of using non-robust <span class="math inline">\(\operatorname{MSE}\)</span>,
we can use robust quantile estimations of the absolute error distribution.
In this post, I want to share numerical simulations
that show a problem of irreproducible <span class="math inline">\(\operatorname{MSE}\)</span> values
and how they can be replaced by reproducible quantile values.</p><br><a href=/posts/robust-statistical-efficiency/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/customized-wthdqe/>Improving the efficiency of the Harrell-Davis quantile estimator for special cases using custom winsorizing and trimming strategies</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-05-25>May 25, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>
&nbsp;
<a href=https://aakinshin.net/tags/mathematics/ class="badge badge-info">Mathematics</a>
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research/ class="badge badge-info">Research</a>
<a href=https://aakinshin.net/tags/statistical-efficiency/ class="badge badge-info">Statistical efficiency</a>
<a href=https://aakinshin.net/tags/harrell-davis-quantile-estimator/ class="badge badge-info">Harrell-Davis quantile estimator</a>
<a href=https://aakinshin.net/tags/winsorizing/ class="badge badge-info">Winsorizing</a>
<a href=https://aakinshin.net/tags/trimming/ class="badge badge-info">Trimming</a>
<a href=https://aakinshin.net/tags/small-samples/ class="badge badge-info">Small samples</a>
<a href=https://aakinshin.net/tags/research-thdqe/ class="badge badge-info">Research: Building trimmed Harrell-Davis quantile estimator</a></span><br><br><p>Let&rsquo;s say we want to
<strong>estimate the median</strong>
based on a <strong>small sample</strong> (3 <span class="math inline">\(\leq n \leq 7\)</span>)
from a <strong>right-skewed heavy-tailed distribution</strong>
with <strong>high statistical efficiency</strong>.</p><p>The traditional median estimator is the most robust estimator, but it&rsquo;s not the most efficient one.
Typically, the Harrell-Davis quantile estimator provides better efficiency,
but it&rsquo;s not robust (its breakdown point is zero),
so it may have worse efficiency in the given case.
The <a href=https://aakinshin.net/posts/winsorized-hdqe/>winsorized</a> and <a href=https://aakinshin.net/posts/trimmed-hdqe/>trimmed</a>
modifications of the Harrell-Davis quantile estimator provide a good trade-off
between efficiency and robustness, but they require a proper winsorizing/trimming rule.
A reasonable choice of such a rule for medium-size samples is based on the highest density interval of the Beta function
(as described <a href=https://aakinshin.net/posts/winsorized-hdqe/>here</a>).
Unfortunately, this approach may be suboptimal for small samples.
E.g., if we use the 99% highest density interval to estimate the median,
it starts to trim sample values only for <span class="math inline">\(n \geq 8\)</span>.</p><p>In this post, we are going to discuss custom winsorizing/trimming strategies for special cases of the quantile estimation problem.</p><br><a href=/posts/customized-wthdqe/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/hd-sv-no-efficiency/>Comparing the efficiency of the Harrell-Davis, Sfakianakis-Verginis, and Navruz-Özdemir quantile estimators</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-05-18>May 18, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>
&nbsp;
<a href=https://aakinshin.net/tags/mathematics/ class="badge badge-info">Mathematics</a>
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research/ class="badge badge-info">Research</a>
<a href=https://aakinshin.net/tags/quantile/ class="badge badge-info">Quantile</a>
<a href=https://aakinshin.net/tags/statistical-efficiency/ class="badge badge-info">Statistical efficiency</a></span><br><br><p>In the previous posts, I discussed the statistical efficiency of different quantile estimators
(<a href=https://aakinshin.net/posts/hdqe-efficiency/>Efficiency of the Harrell-Davis quantile estimator</a> and
<a href=https://aakinshin.net/posts/wthdqe-efficiency/>Efficiency of the winsorized and trimmed Harrell-Davis quantile estimators</a>).</p><p>In this post, I continue this research and compare the efficiency of
the Harrell-Davis quantile estimator,
the <a href=https://aakinshin.net/posts/sfakianakis-verginis-quantile-estimator/>Sfakianakis-Verginis quantile estimators</a>, and
the <a href=https://aakinshin.net/posts/navruz-ozdemir-quantile-estimator/>Navruz-Özdemir quantile estimator</a>.</p><div class=row><div class=mx-auto><a href=/posts/hd-sv-no-efficiency/img/LightAndHeavy_N10_Efficiency-light.png target=_blank class=imgldlink alt=LightAndHeavy_N10_Efficiency><picture><source theme=dark srcset=/posts/hd-sv-no-efficiency/img/LightAndHeavy_N10_Efficiency-dark.png media="(prefers-color-scheme: dark)"><source theme=light srcset=/posts/hd-sv-no-efficiency/img/LightAndHeavy_N10_Efficiency-light.png media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img class="mx-auto d-block img-fluid" width=800 src=/posts/hd-sv-no-efficiency/img/LightAndHeavy_N10_Efficiency-light.png></picture></a></div></div><br><br><a href=/posts/hd-sv-no-efficiency/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/dispersion-exponential-smoothing/>Dispersion exponential smoothing</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-05-11>May 11, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>
&nbsp;
<a href=https://aakinshin.net/tags/mathematics/ class="badge badge-info">Mathematics</a>
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research/ class="badge badge-info">Research</a>
<a href=https://aakinshin.net/tags/quantile/ class="badge badge-info">Quantile</a>
<a href=https://aakinshin.net/tags/harrell-davis-quantile-estimator/ class="badge badge-info">Harrell-Davis quantile estimator</a>
<a href=https://aakinshin.net/tags/exponential-smoothing/ class="badge badge-info">Exponential smoothing</a>
<a href=https://aakinshin.net/tags/moving-quantile/ class="badge badge-info">Moving Quantile</a>
<a href=https://aakinshin.net/tags/mad/ class="badge badge-info">MAD</a>
<a href=https://aakinshin.net/tags/iqr/ class="badge badge-info">IQR</a></span><br><br><p>In this <a href=https://aakinshin.net/posts/quantile-exponential-smoothing/>previous post</a>,
I showed how to apply exponential smoothing to quantiles
using the <a href=https://aakinshin.net/posts/weighted-quantiles/>weighted Harrell-Davis quantile estimator</a>.
This technique allows getting smooth and stable moving median estimations.
In this post, I&rsquo;m going to discuss how to use the same approach
to estimate moving dispersion.</p><br><a href=/posts/dispersion-exponential-smoothing/>Read more</a><br><br><hr></div></div><div class=paginator><ul class="pagination pagination-default"><li class=page-item><a href=/ aria-label=First class=page-link role=button><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/page/7/ aria-label=Previous class=page-link role=button><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a href=/page/6/ aria-label="Page 6" class=page-link role=button>6</a></li><li class=page-item><a href=/page/7/ aria-label="Page 7" class=page-link role=button>7</a></li><li class="page-item active"><a aria-current=page aria-label="Page 8" class=page-link role=button>8</a></li><li class=page-item><a href=/page/9/ aria-label="Page 9" class=page-link role=button>9</a></li><li class=page-item><a href=/page/10/ aria-label="Page 10" class=page-link role=button>10</a></li><li class=page-item><a href=/page/9/ aria-label=Next class=page-link role=button><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/page/17/ aria-label=Last class=page-link role=button><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></main></div><footer class=blog-footer><div class=container><p>&copy; 2013&mdash;2022 Andrey Akinshin
|
<a href=https://github.com/AndreyAkinshin><i class="fab fa-github" title=GitHub></i></a>
<a href=https://twitter.com/andrey_akinshin><i class="fab fa-twitter" title=Twitter></i></a>
<a href=https://aakinshin.net/posts/index.xml><i class="fas fa-rss" title=RSS></i></a>
|
<a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></p></div></footer><script src=https://aakinshin.net/js/theme-after.min.c26550621ac13c2221d7f6f5e6fe862345d3919723c50d730893e3e4856ecf35.js></script>
<script src=/js/bootstrap.bundle.min.js></script>
<script src=/js/anchor.min.js></script>
<script src=https://aakinshin.net/js/custom.min.f6e5d13fe39f305056cc743ee4cb8d117c1aba26176e58c82c79a480d02fe4b7.js></script>
<script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></body></html>