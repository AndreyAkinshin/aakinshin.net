<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.123.8"><meta name=author content='Andrey Akinshin'><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content><title>Andrey Akinshin's blog (Page 18)</title>
<meta name=description content="Andrey Akinshin's blog"><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><script>localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?document.documentElement.classList.add("dark"):document.documentElement.classList.remove("dark")</script><link href=https://aakinshin.net/css/main.min.867ec06f826167a162aebd1233fd1f8bd62a1ad51f8768abaf9f1ae1d746b5cc.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"></head><body class="flex flex-col min-h-screen"><nav><div class="container flex flex-wrap items-center justify-between mx-auto max-w-6xl h-12 px-2 xs:px-6"><div class="flex items-center justify-start justify-self-start"><div class="flex nav-item h-12 w-12 items-center justify-center"><a class=text-white href=https://aakinshin.net/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#house-chimney"/></svg></a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/feed/>Feed</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/library/>Library</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/research-projects/>Research</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/about/>About</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/search/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#magnifying-glass"/></svg></a></div></div><button id=theme-toggle type=button title="Alt+Click to match OS color theme" class="nav-item p-3 content-center justify-self-end"><svg id="theme-toggle-dark-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001.0 1010.586 10.586z"/></svg><svg id="theme-toggle-light-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M10 2a1 1 0 011 1v1A1 1 0 119 4V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707A1 1 0 1113.536 5.05l.707-.707a1 1 0 011.414.0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707A1 1 0 004.343 5.757l.707.707zm1.414 8.486-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z" fill-rule="evenodd" clip-rule="evenodd"/></svg></button></div></nav><div class="main container mx-auto max-w-6xl px-6 flex-grow"><div class=main-content><div><h2><a href=/posts/hd-sv-no-efficiency/>Comparing the efficiency of the Harrell-Davis, Sfakianakis-Verginis, and Navruz-Özdemir quantile estimators</a></h2><div class="flex flex-wrap justify-start items-center"><div class="flex flex-wrap gap-y-1"><span class=label><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#calendar"/></svg>
<time datetime=2021-05-18>May 18, 2021</time>
</span><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#statistics"/></svg>
Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#research"/></svg>
Research
</a><a class=label-link href=https://aakinshin.net/tags/quantile/>Quantile
</a><a class=label-link href=https://aakinshin.net/tags/statistical-efficiency/>Statistical efficiency</a></div></div><br><p>In the previous posts, I discussed the statistical efficiency of different quantile estimators
(<a href=https://aakinshin.net/posts/hdqe-efficiency/>Efficiency of the Harrell-Davis quantile estimator</a> and
<a href=https://aakinshin.net/posts/wthdqe-efficiency/>Efficiency of the winsorized and trimmed Harrell-Davis quantile estimators</a>).</p><p>In this post, I continue this research and compare the efficiency of
the Harrell-Davis quantile estimator,
the <a href=https://aakinshin.net/posts/sfakianakis-verginis-quantile-estimator/>Sfakianakis-Verginis quantile estimators</a>, and
the <a href=https://aakinshin.net/posts/navruz-ozdemir-quantile-estimator/>Navruz-Özdemir quantile estimator</a>.</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/hd-sv-no-efficiency/img/LightAndHeavy_N10_Efficiency-light.png target=_blank alt=LightAndHeavy_N10_Efficiency><img src=/posts/hd-sv-no-efficiency/img/LightAndHeavy_N10_Efficiency-light.png width=800>
</a><a class="img-dark hidden" href=/posts/hd-sv-no-efficiency/img/LightAndHeavy_N10_Efficiency-dark.png target=_blank alt=LightAndHeavy_N10_Efficiency><img src=/posts/hd-sv-no-efficiency/img/LightAndHeavy_N10_Efficiency-dark.png width=800></a></div><a href=/posts/hd-sv-no-efficiency/>Read more</a><br><br><hr></div><div><h2><a href=/posts/dispersion-exponential-smoothing/>Dispersion exponential smoothing</a></h2><div class="flex flex-wrap justify-start items-center"><div class="flex flex-wrap gap-y-1"><span class=label><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#calendar"/></svg>
<time datetime=2021-05-11>May 11, 2021</time>
</span><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#statistics"/></svg>
Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#research"/></svg>
Research
</a><a class=label-link href=https://aakinshin.net/tags/quantile/>Quantile
</a><a class=label-link href=https://aakinshin.net/tags/harrell-davis-quantile-estimator/>Harrell-Davis quantile estimator
</a><a class=label-link href=https://aakinshin.net/tags/exponential-smoothing/>Exponential smoothing
</a><a class=label-link href=https://aakinshin.net/tags/moving-quantile/>Moving quantile
</a><a class=label-link href=https://aakinshin.net/tags/mad/>Median Absolute Deviation
</a><a class=label-link href=https://aakinshin.net/tags/iqr/>IQR</a></div></div><br><p>In this <a href=https://aakinshin.net/posts/quantile-exponential-smoothing/>previous post</a>,
I showed how to apply exponential smoothing to quantiles
using the <a href=https://aakinshin.net/posts/weighted-quantiles/>weighted Harrell-Davis quantile estimator</a>.
This technique allows getting smooth and stable moving median estimations.
In this post, I&rsquo;m going to discuss how to use the same approach
to estimate moving dispersion.</p><a href=/posts/dispersion-exponential-smoothing/>Read more</a><br><br><hr></div><div><h2><a href=/posts/quantile-exponential-smoothing/>Quantile exponential smoothing</a></h2><div class="flex flex-wrap justify-start items-center"><div class="flex flex-wrap gap-y-1"><span class=label><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#calendar"/></svg>
<time datetime=2021-05-04>May 4, 2021</time>
</span><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#statistics"/></svg>
Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#research"/></svg>
Research
</a><a class=label-link href=https://aakinshin.net/tags/quantile/>Quantile
</a><a class=label-link href=https://aakinshin.net/tags/harrell-davis-quantile-estimator/>Harrell-Davis quantile estimator
</a><a class=label-link href=https://aakinshin.net/tags/exponential-smoothing/>Exponential smoothing
</a><a class=label-link href=https://aakinshin.net/tags/moving-quantile/>Moving quantile</a></div></div><br><p>One of the popular problems in time series analysis is estimating the moving &ldquo;average&rdquo; value.
Let&rsquo;s define the &ldquo;average&rdquo; as a central tendency metric like the mean or the median.
When we talk about the moving value, we assume that we are interested in
the average value &ldquo;at the end&rdquo; of the time series
instead of the average of all available observations.</p><p>One of the most straightforward approaches to estimate the moving average is the <em>simple moving mean</em>.
Unfortunately, this approach is not robust: outliers can instantly spoil the evaluated mean value.
As an alternative, we can consider <em>simple moving median</em>.
I already discussed a few of such methods:
<a href=https://aakinshin.net/posts/mp2-quantile-estimator/>the MP² quantile estimator</a> and
<a href=https://aakinshin.net/posts/partitioning-heaps-quantile-estimator2/>a moving quantile estimator based on partitioning heaps</a>
(a modification of the Hardle-Steiger method).
When we talk about <em>simple moving averages</em>, we typically assume
that we estimate the average value over the last $k$ observations ($k$ is the <em>window size</em>).
This approach is also known as <em>unweighted moving averages</em> because
all target observations have the same weight.</p><p>As an alternative to the simple moving average, we can also consider the <em>weighted moving average</em>.
In this case, we assign a weight for each observation and aggregate the whole time series according to these weights.
A famous example of such a weight function is <em>exponential smoothing</em>.
And the simplest form of exponential smoothing is the <em>exponentially weighted moving mean</em>.
This approach estimates the weighted moving mean using exponentially decreasing weights.
Switching from the simple moving mean to the exponentially weighted moving mean provides some benefits
in terms of smoothness and estimation efficiency.</p><p>Although exponential smoothing has advantages over the simple moving mean,
it still estimates the mean value which is not robust.
We can improve the robustness of this approach if we reuse the same idea for weighted moving quantiles.
It&rsquo;s possible because the quantiles also can be estimated for weighted samples.
In one of my previous posts, I <a href=https://aakinshin.net/posts/weighted-quantiles/>showed</a> how to adapt
the Hyndman-Fan Type 7 and Harrell-Davis quantile estimators to the weighted samples.
In this post, I&rsquo;m going to show how we can use this technique to estimate
the weighted moving quantiles using exponentially decreasing weights.</p><a href=/posts/quantile-exponential-smoothing/>Read more</a><br><br><hr></div><div><h2><a href=/posts/qrde-discrete/>Improving quantile-respectful density estimation for discrete distributions using jittering</a></h2><div class="flex flex-wrap justify-start items-center"><div class="flex flex-wrap gap-y-1"><span class=label><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#calendar"/></svg>
<time datetime=2021-04-27>April 27, 2021</time>
</span><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#statistics"/></svg>
Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#research"/></svg>
Research
</a><a class=label-link href=https://aakinshin.net/tags/quantile-estimation/>Quantile Estimation
</a><a class=label-link href=https://aakinshin.net/tags/density-estimation/>Density Estimation
</a><a class=label-link href=https://aakinshin.net/tags/qrde/>Quantile-Respectful Density Estimation
</a><a class=label-link href=https://aakinshin.net/tags/discretization/>Discretization
</a><a class=label-link href=https://aakinshin.net/tags/ties/>Ties
</a><a class=label-link href=https://aakinshin.net/tags/jittering/>Jittering</a></div></div><br><p>In my previous posts, I already discussed the <a href=https://aakinshin.net/posts/kde-discrete/>problem</a> that arises
when we try to build kernel density estimation (KDE) for samples with ties.
We may get such samples in real life from discrete or mixed discrete/continuous distributions.
Even if the original distribution is continuous,
we may observe artificial sample discretization due to the limited resolution of the measuring tool.
Such discretization may lead to inaccurate density plots due to undersmoothing.
The problem can be resolved using a nice technique called <em>jittering</em>.
I also discussed <a href=https://aakinshin.net/posts/discrete-sample-jittering/>how to apply</a> jittering to get a smoother version of KDE.</p><p>However, I&rsquo;m not a huge fan of KDE because of two reasons.
The first one is the <a href=https://aakinshin.net/posts/kde-bw/>problem of choosing a proper bandwidth value</a>.
With poorly chosen bandwidth, we can easily get oversmoothing or undersmoothing even without the discretization problem.
The second one is an inconsistency between the KDE-based probability density function and evaluated sample quantiles.
It could lead to inconsistent visualizations (e.g., KDE-based violin plots with non-KDE-based quantile values)
or it could introduce problems for algorithms that require density function and quantile values at the same time.
The inconsistency could be resolved using <a href=https://aakinshin.net/posts/qrde-hd/>quantile-respectful density estimation</a> (QRDE).
This kind of estimation builds the density function which matches the evaluated sample quantiles.
To get a smooth QRDE, we also need a smooth quantile estimator like the Harrell-Davis quantile estimator.
The robustness and componential efficiency of this approach can be improved using
the <a href=https://aakinshin.net/posts/winsorized-hdqe/>winsorized</a> and <a href=https://aakinshin.net/posts/trimmed-hdqe/>trimmed</a>
modifications of the Harrell-Davis quantile estimator
(which also have a <a href=https://aakinshin.net/posts/wthdqe-efficiency/>decent statistical efficiency level</a>).</p><p>Unfortunately, the straightforward QRDE calculation is not always applicable for samples with ties
because it&rsquo;s impossible to build an &ldquo;honest&rdquo; density function for discrete distributions
without using the Dirac delta function.
This is a severe problem for QRDE-based algorithms like the
<a href=https://aakinshin.net/posts/lowland-multimodality-detection/>lowland multimodality detection algorithm</a>.
In this post, I will show how jittering could help to solve this problem and get a smooth QRDE on samples with ties.</p><a href=/posts/qrde-discrete/>Read more</a><br><br><hr></div><div><h2><a href=/posts/discrete-sample-jittering/>How to build a smooth density estimation for a discrete sample using jittering</a></h2><div class="flex flex-wrap justify-start items-center"><div class="flex flex-wrap gap-y-1"><span class=label><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#calendar"/></svg>
<time datetime=2021-04-20>April 20, 2021</time>
</span><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#statistics"/></svg>
Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#research"/></svg>
Research
</a><a class=label-link href=https://aakinshin.net/tags/density-estimation/>Density Estimation
</a><a class=label-link href=https://aakinshin.net/tags/discrete-distributions/>Discrete Distributions
</a><a class=label-link href=https://aakinshin.net/tags/ties/>Ties
</a><a class=label-link href=https://aakinshin.net/tags/jittering/>Jittering</a></div></div><br><p><strong>Update (2024-03-19): A better approach is presented in <a href=https://aakinshin.net/posts/discrete-sample-jittering2/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#note"/></svg>A better jittering approach for discretization acknowledgment in density estimation</a></strong></p><p>Let&rsquo;s say you have a sample with tied values.
If you draw a kernel density estimation (KDE) for such a sample,
you may get a serrated pattern like this:</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/discrete-sample-jittering/img/intro-light.png target=_blank alt=intro><img src=/posts/discrete-sample-jittering/img/intro-light.png width=800>
</a><a class="img-dark hidden" href=/posts/discrete-sample-jittering/img/intro-dark.png target=_blank alt=intro><img src=/posts/discrete-sample-jittering/img/intro-dark.png width=800></a></div><p>KDE requires samples from continuous distributions
while tied values arise in discrete or mixture distributions.
Even if the original distribution is continuous,
you may observe artificial sample discretization due to the limited resolution of the measuring tool.
This effect may lead to distorted density plots like in the above picture.</p><p>The problem could be solved using a nice technique called <em>jittering</em>.
In the simplest case, jittering just adds random noise to each measurement.
Such a trick removes all ties from the sample and allows building a smooth density estimation.</p><p>However, there are many different ways to apply jittering.
The trickiest question here is how to choose proper noise values.
In this post, I want to share one of my favorite jittering approaches.
It generates a non-randomized noise pattern with a low risk of noticeable sample corruption.</p><a href=/posts/discrete-sample-jittering/>Read more</a><br><br><hr></div><div><h2><a href=/posts/kde-discrete/>Kernel density estimation and discrete values</a></h2><div class="flex flex-wrap justify-start items-center"><div class="flex flex-wrap gap-y-1"><span class=label><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#calendar"/></svg>
<time datetime=2021-04-13>April 13, 2021</time>
</span><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#statistics"/></svg>
Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#research"/></svg>
Research
</a><a class=label-link href=https://aakinshin.net/tags/density-estimation/>Density Estimation
</a><a class=label-link href=https://aakinshin.net/tags/discrete-distribution/>Discrete distribution
</a><a class=label-link href=https://aakinshin.net/tags/ties/>Ties
</a><a class=label-link href=https://aakinshin.net/tags/kde/>KDE</a></div></div><br><p>Kernel density estimation (KDE) is a popular technique of data visualization.
Based on the given sample, it allows estimating the probability density function (PDF) of the underlying distribution.
Here is an example of KDE for <code>x = {3.82, 4.61, 4.89, 4.91, 5.31, 5.6, 5.66, 7.00, 7.00, 7.00}</code>
(normal kernel, Sheather & Jones bandwidth selector):</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/kde-discrete/img/intro-light.png target=_blank alt=intro><img src=/posts/kde-discrete/img/intro-light.png width=800>
</a><a class="img-dark hidden" href=/posts/kde-discrete/img/intro-dark.png target=_blank alt=intro><img src=/posts/kde-discrete/img/intro-dark.png width=800></a></div><p>KDE is a simple and straightforward way to build a PDF, but it&rsquo;s not always the best one.
In addition to my <a href=https://aakinshin.net/posts/kde-bw/>concerns about bandwidth selection</a>,
continuous use of KDE creates an illusion that all distributions are smooth and continuous.
In practice, it&rsquo;s not always true.</p><p>In the above picture, the distribution looks pretty continuous.
However, the picture hides the fact that we have three <code>7.00</code> elements in the original sample.
With continuous distributions, the probability of getting tied observations (that have the same value) is almost zero.
If a sample contains ties, we are most likely working with
either a discrete distribution or a mixture of discrete and continuous distributions.
A KDE for such a sample may significantly differ from the actual PDF.
Thus, this technique may mislead us instead of providing insights about the true underlying distribution.</p><p>In this post, we discuss the usage of PDF and PMF with continuous and discrete distributions.
Also, we look at examples of corrupted density estimation plots for distributions with discrete features.</p><a href=/posts/kde-discrete/>Read more</a><br><br><hr></div><div><h2><a href=/posts/wthdqe-efficiency/>Efficiency of the winsorized and trimmed Harrell-Davis quantile estimators</a></h2><div class="flex flex-wrap justify-start items-center"><div class="flex flex-wrap gap-y-1"><span class=label><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#calendar"/></svg>
<time datetime=2021-04-06>April 6, 2021</time>
</span><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#statistics"/></svg>
Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#research"/></svg>
Research
</a><a class=label-link href=https://aakinshin.net/tags/quantile/>Quantile
</a><a class=label-link href=https://aakinshin.net/tags/statistical-efficiency/>Statistical efficiency
</a><a class=label-link href=https://aakinshin.net/tags/research-thdqe/>[Research] Building trimmed Harrell-Davis quantile estimator</a></div></div><br><p>In previous posts, I suggested two modifications of the Harrell-Davis quantile estimator:
<a href=https://aakinshin.net/posts/winsorized-hdqe/>winsorized</a> and <a href=https://aakinshin.net/posts/trimmed-hdqe/>trimmed</a>.
Both modifications have a higher level of robustness in comparison to the original estimator.
Also, I <a href=https://aakinshin.net/posts/hdqe-efficiency/>discussed</a> the <a href=https://en.wikipedia.org/wiki/Efficiency_(statistics)>efficiency</a>
of the Harrell-Davis quantile estimator.
In this post, I&rsquo;m going to continue numerical simulation and estimate the efficiency of
the winsorized and trimmed modifications.</p><div class="flex my-7 justify-center"><a class="img-light hidden" href=/posts/wthdqe-efficiency/img/LightAndHeavy_N10_Efficiency-light.png target=_blank alt=LightAndHeavy_N10_Efficiency><img src=/posts/wthdqe-efficiency/img/LightAndHeavy_N10_Efficiency-light.png width=800>
</a><a class="img-dark hidden" href=/posts/wthdqe-efficiency/img/LightAndHeavy_N10_Efficiency-dark.png target=_blank alt=LightAndHeavy_N10_Efficiency><img src=/posts/wthdqe-efficiency/img/LightAndHeavy_N10_Efficiency-dark.png width=800></a></div><a href=/posts/wthdqe-efficiency/>Read more</a><br><br><hr></div><div><h2><a href=/posts/trimmed-hdqe/>Trimmed modification of the Harrell-Davis quantile estimator</a></h2><div class="flex flex-wrap justify-start items-center"><div class="flex flex-wrap gap-y-1"><span class=label><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#calendar"/></svg>
<time datetime=2021-03-30>March 30, 2021</time>
</span><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#statistics"/></svg>
Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#research"/></svg>
Research
</a><a class=label-link href=https://aakinshin.net/tags/quantile/>Quantile
</a><a class=label-link href=https://aakinshin.net/tags/trimming/>Trimming
</a><a class=label-link href=https://aakinshin.net/tags/harrell-davis-quantile-estimator/>Harrell-Davis quantile estimator
</a><a class=label-link href=https://aakinshin.net/tags/research-thdqe/>[Research] Building trimmed Harrell-Davis quantile estimator</a></div></div><br><p>In one of <a href=https://aakinshin.net/posts/winsorized-hdqe/>the previous posts</a>, I discussed winsorized Harrell-Davis quantile estimator.
This estimator is more robust than the classic Harrell-Davis quantile estimator.
In this post, I want to suggest another modification that may be better for some corner cases:
the <em>trimmed</em> Harrell-Davis quantile estimator.</p><a href=/posts/trimmed-hdqe/>Read more</a><br><br><hr></div><div><h2><a href=/posts/hdqe-efficiency/>Efficiency of the Harrell-Davis quantile estimator</a></h2><div class="flex flex-wrap justify-start items-center"><div class="flex flex-wrap gap-y-1"><span class=label><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#calendar"/></svg>
<time datetime=2021-03-23>March 23, 2021</time>
</span><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#statistics"/></svg>
Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#research"/></svg>
Research
</a><a class=label-link href=https://aakinshin.net/tags/quantile/>Quantile
</a><a class=label-link href=https://aakinshin.net/tags/statistical-efficiency/>Statistical efficiency
</a><a class=label-link href=https://aakinshin.net/tags/research-thdqe/>[Research] Building trimmed Harrell-Davis quantile estimator</a></div></div><br><p>One of the most essential properties of a quantile estimator is
its <a href=https://en.wikipedia.org/wiki/Efficiency_(statistics)>efficiency</a>.
In simple words, the efficiency describes the estimator accuracy.
The Harrell-Davis quantile estimator is a good option to achieve higher efficiency.
However, this estimator may provide lower efficiency in some special cases.
In this post, we will conduct a set of simulations that show the actual efficiency numbers.
We compare different distributions (symmetric and right-skewed, heavy-tailed and light-tailed),
quantiles, and sample sizes.</p><a href=/posts/hdqe-efficiency/>Read more</a><br><br><hr></div></div><div class=paginator><ul class="pagination pagination-default"><li class=page-item><a href=/ aria-label=First class=page-link role=button><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/page/17/ aria-label=Previous class=page-link role=button><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a href=/page/16/ aria-label="Page 16" class=page-link role=button>16</a></li><li class=page-item><a href=/page/17/ aria-label="Page 17" class=page-link role=button>17</a></li><li class="page-item active"><a aria-current=page aria-label="Page 18" class=page-link role=button>18</a></li><li class=page-item><a href=/page/19/ aria-label="Page 19" class=page-link role=button>19</a></li><li class=page-item><a href=/page/20/ aria-label="Page 20" class=page-link role=button>20</a></li><li class=page-item><a href=/page/19/ aria-label=Next class=page-link role=button><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/page/144/ aria-label=Last class=page-link role=button><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div><script>var themeToggleDarkIcon=document.getElementById("theme-toggle-dark-icon"),themeToggleBtn,themeToggleLightIcon=document.getElementById("theme-toggle-light-icon");const imagesDark=document.querySelectorAll(".img-dark"),imagesLight=document.querySelectorAll(".img-light");localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?(themeToggleLightIcon.classList.remove("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")})):(themeToggleDarkIcon.classList.remove("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}));function toggleTheme(e){e?(document.documentElement.classList.add("dark"),themeToggleLightIcon.classList.remove("hidden"),themeToggleDarkIcon.classList.add("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")}),imagesLight.forEach(e=>{e.classList.add("hidden")})):(document.documentElement.classList.remove("dark"),themeToggleDarkIcon.classList.remove("hidden"),themeToggleLightIcon.classList.add("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}),imagesDark.forEach(e=>{e.classList.add("hidden")}))}themeToggleBtn=document.getElementById("theme-toggle"),themeToggleBtn.addEventListener("click",function(){themeToggleDarkIcon.classList.toggle("hidden"),themeToggleLightIcon.classList.toggle("hidden"),imagesLight.forEach(e=>{e.classList.toggle("hidden")}),imagesDark.forEach(e=>{e.classList.toggle("hidden")}),event.altKey?(localStorage.removeItem("color-theme"),toggleTheme(window.matchMedia("(prefers-color-scheme: dark)").matches)):localStorage.getItem("color-theme")?localStorage.getItem("color-theme")==="light"?(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark")):(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):document.documentElement.classList.contains("dark")?(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark"))}),window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",e=>{if(localStorage.getItem("color-theme")===null){const t=e.matches?"dark":"light";toggleTheme(t==="dark")}})</script><footer class="z-20 p-4 md:p-6 mt-3 w-full border-t border-gray-200 shadow flex items-center justify-center dark:border-gray-600 bg-white dark:bg-zinc-800"><span class="dark:text-gray-400 text-center">© 2013—2024 <span class=whitespace-nowrap>Andrey Akinshin</span></span><ul class="flex flex-wrap items-center px-4 mb-1"><li><a href=https://github.com/AndreyAkinshin><svg class="fai fai-link w-5 h-5"><title>GitHub</title><use xlink:href="/img/fa/all.svg#github"/></svg></a></li><li><a href=https://twitter.com/andrey_akinshin><svg class="fai fai-link w-5 h-5"><title>Twitter</title><use xlink:href="/img/fa/all.svg#twitter"/></svg></a></li><li><a href=https://aakinshin.net/posts/index.xml><svg class="fai fai-link w-5 h-5"><title>RSS</title><use xlink:href="/img/fa/all.svg#rss"/></svg></a></li></ul><div class=main-content><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></div></footer><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+=" has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script></body></html>