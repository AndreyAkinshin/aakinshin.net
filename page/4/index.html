<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.103.0-DEV"><meta name=author content="Andrey Akinshin"><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content><title>Andrey Akinshin's blog (Page 4)</title><meta name=description content="Andrey Akinshin's blog"><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><script>localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?document.documentElement.classList.add("dark"):document.documentElement.classList.remove("dark")</script><link href=https://aakinshin.net/css/main.min.fe1c45a5bb1462c47792274eba884723afa28a87c7a92405ed21b423927e7fbf.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"></head><body><nav><div class="container flex flex-wrap items-center justify-between mx-auto max-w-6xl h-12 px-6"><div class="flex items-center justify-start justify-self-start"><div class="flex nav-item h-12 w-12 items-center justify-center"><a class=text-white href=https://aakinshin.net/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#house-chimney"/></svg></a></div><div class="flex nav-item h-12 items-center"><a class="px-3 text-white" href=https://aakinshin.net/posts/>Posts</a></div><div class="flex nav-item h-12 items-center"><a class="px-3 text-white" href=https://aakinshin.net/research/>Research</a></div><div class="flex nav-item h-12 items-center"><a class="px-3 text-white" href=https://aakinshin.net/about/>About</a></div></div><button id=theme-toggle type=button title="Alt+Click to match OS color theme" class="nav-item p-3 content-center justify-self-end"><svg id="theme-toggle-dark-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001.0 1010.586 10.586z"/></svg><svg id="theme-toggle-light-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M10 2a1 1 0 011 1v1A1 1 0 119 4V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707A1 1 0 1113.536 5.05l.707-.707a1 1 0 011.414.0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707A1 1 0 004.343 5.757l.707.707zm1.414 8.486-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z" fill-rule="evenodd" clip-rule="evenodd"/></svg></button></div></nav><div class="main container mx-auto max-w-6xl px-6"><div class=main-content><div><h2><a href=/posts/mw-edgeworth2/>Edgeworth expansion for the Mann-Whitney U test, Part 2: increased accuracy</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg><time datetime=2023-06-06>June 6, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/>Mathematics</a>
<a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics</a>
<a class=label-link href=https://aakinshin.net/tags/research/>Research</a>
<a class=label-link href=https://aakinshin.net/tags/mann-whitney/>Mann-Whitney U-test</a></div></div><br><p>In the <a href=https://aakinshin.net/posts/mw-edgeworth/>previous post</a>,
we showed how the Edgeworth expansion can improve the accuracy of obtained p-values in the Mann-Whitney U test.
However, we considered only the Edgeworth expansion to terms of order <span class="math inline">\(1/m\)</span>.
In this post, we explore how to improve the accuracyk of this approach using
the Edgeworth expansion to terms of order <span class="math inline">\(1/m^2\)</span>.</p><br><a href=/posts/mw-edgeworth2/>Read more</a><br><br><hr></div><div><h2><a href=/posts/mw-edgeworth/>Edgeworth expansion for the Mann-Whitney U test</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg><time datetime=2023-05-30>May 30, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/>Mathematics</a>
<a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics</a>
<a class=label-link href=https://aakinshin.net/tags/research/>Research</a>
<a class=label-link href=https://aakinshin.net/tags/mann-whitney/>Mann-Whitney U-test</a></div></div><br><p>In <a href=https://aakinshin.net/posts/r-mann-whitney-incorrect-p-value/>previous posts</a>,
I have shown a severe drawback of the classic Normal approximation for the Mann-Whitney U test:
under certain conditions, can lead to quite substantial p-value errors,
distorting the significance level of the test.</p><p>In this post, we will explore the potential of the Edgeworth expansion
as a more accurate alternative for approximating the distribution of the Mann-Whitney U statistic.</p><br><a href=/posts/mw-edgeworth/>Read more</a><br><br><hr></div><div><h2><a href=/posts/mw-confusing-tie-correction/>Confusing tie correction in the classic Mann-Whitney U test implementation</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg><time datetime=2023-05-23>May 23, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/>Mathematics</a>
<a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics</a>
<a class=label-link href=https://aakinshin.net/tags/research/>Research</a>
<a class=label-link href=https://aakinshin.net/tags/mann-whitney/>Mann-Whitney U-test</a></div></div><br><p>In this post, we discuss the classic implementation of the Mann-Whitney U test for cases
in which the considered samples contain tied values.
This approach is used the same way in all the popular statistical packages.</p><p>Unfortunately, in some situations, this approach produces confusing p-values, which may be surprising for researchers
who do not have a deep understanding of ties correction.
Moreover, some statistical textbooks argue against the validity of the default tie correction.
The controversialness and counterintuitiveness of this approach may become a severe issue which may lead
to incorrect experiment design and flawed result interpretation.
In order to prevent such problems, it is essential to clearly understand
the actual impact of tied observations on the true p-value and
the impact of tie correction on the approximated p-value estimation.
In this post, we discuss the tie correction for the Mann-Whitney U test
and review examples that illustrate potential problems.
We also provide examples of the Mann-Whitney U test implementations from popular statistical packages:
<code>wilcox.test</code> from <code>stats</code> (R),
<code>mannwhitneyu</code> from <code>SciPy</code> (Python), and
<code>MannWhitneyUTest</code> from <code>HypothesisTests</code> (Julia).
At the end of the post, we discuss how to avoid possible problems related to the tie correction.</p><br><a href=/posts/mw-confusing-tie-correction/>Read more</a><br><br><hr></div><div><h2><a href=/posts/central-tendency-efficiency-uniform/>Efficiency of the central tendency measures under the uniform distribution</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg><time datetime=2023-05-16>May 16, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/>Mathematics</a>
<a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics</a>
<a class=label-link href=https://aakinshin.net/tags/research/>Research</a>
<a class=label-link href=https://aakinshin.net/tags/hodges-lehmann/>Hodges-Lehmann estimator</a></div></div><br><p>Statistical efficiency is one of the primary ways to compare various estimators.
Since the normality assumption is often used, Gaussian efficiency (efficiency under the normality distribution)
is typically considered.
For example, the asymptotic Gaussian efficiency values of
the median and the Hodges-Lehmann location estimator (the pseudo-median)
are <span class="math inline">\(\approx 64\%\)</span> and <span class="math inline">\(\approx 96\%\)</span> respectively (assuming the baseline is the mean).</p><p>But what if the underlying distribution is not normal, but uniform?
What would happen to the relative statistical efficiency values in this case?
Let&rsquo;s find out!
In this post, we calculate
the relative efficiency of the median, the Hodges-Lehmann location estimator, and the midrange
to the mean under the uniform distribution (or under uniformity).</p><br><a href=/posts/central-tendency-efficiency-uniform/>Read more</a><br><br><hr></div><div><h2><a href=/posts/r-hodges-lehmann-problems/>Unobvious problems of using the R's implementation of the Hodges-Lehmann estimator</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg><time datetime=2023-05-09>May 9, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/>Mathematics</a>
<a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics</a>
<a class=label-link href=https://aakinshin.net/tags/research/>Research</a>
<a class=label-link href=https://aakinshin.net/tags/hodges-lehmann/>Hodges-Lehmann estimator</a>
<a class=label-link href=https://aakinshin.net/tags/r/>R</a></div></div><br><p>The Hodges-Lehmann location estimator (also known as pseudo-median) is a robust, non-parametric statistic
used as a measure of the central tendency.
For a sample <span class="math inline">\(\mathbf{x} = \{ x_1, x_2, \ldots, x_n \}\)</span>, it is defined as follows:</p><p><span class="math display">\[\operatorname{HL}(\mathbf{x}) =
\underset{1 \leq i \leq j \leq n}{\operatorname{median}} \left(\frac{x_i + x_j}{2} \right).
\]</span></p><p>Essentially, it&rsquo;s the median of the Walsh (pairwise) averages.</p><p>For two samples <span class="math inline">\(\mathbf{x} = \{ x_1, x_2, \ldots, x_n \}\)</span> and <span class="math inline">\(\mathbf{y} = \{ y_1, y_2, \ldots, y_m \}\)</span>,
we can also consider the Hodges-Lehmann location shift estimator:</p><p><span class="math display">\[\operatorname{HL}(\mathbf{x}, \mathbf{y}) =
\underset{1 \leq i \leq n,\,\, 1 \leq j \leq m}{\operatorname{median}} \left(x_i - y_j \right).
\]</span></p><p>In R, both estimators are available via
the <a href=https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html>wilcox.test</a> function.
Here is a usage example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=cl><span class=nf>set.seed</span><span class=p>(</span><span class=m>1729</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>x</span> <span class=o>&lt;-</span> <span class=nf>rnorm</span><span class=p>(</span><span class=m>2000</span><span class=p>,</span> <span class=m>5</span><span class=p>)</span> <span class=c1># A sample of size 2000 from the normal distribution N(5, 1)</span>
</span></span><span class=line><span class=cl><span class=n>y</span> <span class=o>&lt;-</span> <span class=nf>rnorm</span><span class=p>(</span><span class=m>2000</span><span class=p>,</span> <span class=m>2</span><span class=p>)</span> <span class=c1># A sample of size 2000 from the normal distribution N(2, 1)</span>
</span></span><span class=line><span class=cl><span class=nf>wilcox.test</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>conf.int</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>)</span><span class=o>$</span><span class=n>estimate</span>
</span></span><span class=line><span class=cl><span class=c1># (pseudo)median</span>
</span></span><span class=line><span class=cl><span class=c1>#       5.000984</span>
</span></span><span class=line><span class=cl><span class=nf>wilcox.test</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=n>conf.int</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>)</span><span class=o>$</span><span class=n>estimate</span>
</span></span><span class=line><span class=cl><span class=c1># (pseudo)median</span>
</span></span><span class=line><span class=cl><span class=c1>#       1.969096</span>
</span></span><span class=line><span class=cl><span class=nf>wilcox.test</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>conf.int</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>)</span><span class=o>$</span><span class=n>estimate</span>
</span></span><span class=line><span class=cl><span class=c1># difference in location</span>
</span></span><span class=line><span class=cl><span class=c1>#               3.031782</span>
</span></span></code></pre></div><p>In most cases, this function works fine.
However, there is an unobvious corner case, in which it returns wrong values.
In this post, we discuss the underlying problem and provide a correct implementation for the Hodges-Lehmann estimators.</p><br><a href=/posts/r-hodges-lehmann-problems/>Read more</a><br><br><hr></div><div><h2><a href=/posts/python-mann-whitney-incorrect-p-value/>When Python's Mann-Whitney U test returns extremely distorted p-values</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg><time datetime=2023-05-02>May 2, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/>Mathematics</a>
<a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics</a>
<a class=label-link href=https://aakinshin.net/tags/research/>Research</a>
<a class=label-link href=https://aakinshin.net/tags/mann-whitney/>Mann-Whitney U-test</a>
<a class=label-link href=https://aakinshin.net/tags/python/>python</a></div></div><br><p>In the <a href=https://aakinshin.net/posts/r-mann-whitney-incorrect-p-value/>previous post</a>,
I have discussed a huge difference between p-values evaluated via the R implementation of
the <a href=https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test>Mann-Whitney U test</a>
between the exact and asymptotic implementations.
This issue is not unique only to R, it is relevant for other statistical packages in other languages as well.
In this post, we review this problem in the Python package <a href=https://scipy.org/>SciPy</a>.</p><br><a href=/posts/python-mann-whitney-incorrect-p-value/>Read more</a><br><br><hr></div><div><h2><a href=/posts/r-mann-whitney-incorrect-p-value/>When R's Mann-Whitney U test returns extremely distorted p-values</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg><time datetime=2023-04-25>April 25, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/>Mathematics</a>
<a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics</a>
<a class=label-link href=https://aakinshin.net/tags/research/>Research</a>
<a class=label-link href=https://aakinshin.net/tags/mann-whitney/>Mann-Whitney U-test</a>
<a class=label-link href=https://aakinshin.net/tags/r/>R</a></div></div><br><p>The <a href=https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test>Mann–Whitney U test</a>
(also known as the Wilcoxon rank-sum test)
is one of the most popular nonparametric statistical tests.
In R, it can be accessed using
the <a href=https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html>wilcox.test</a> function,
which has been <a href=https://github.com/wch/r-source/blob/tags/R-1-0/src/library/ctest/R/wilcox.test.R>available</a>
since R 1.0.0 (February 2000).
With its extensive adoption and long-standing presence in R,
the <code>wilcox.test</code> function has become a trusted tool for many researchers.
But is it truly reliable, and to what extent can we rely on its accuracy by default?</p><p>In my work,
I often encounter the task of comparing a large sample (e.g., of size 50+) with a small sample (e.g., of size 5).
In some cases, the ranges of these samples do not overlap with each other,
which is the extreme case of the Mann–Whitney U test: it gives the minimum possible p-value.
In <a href=https://aakinshin.net/posts/mann-whitney-min-stat-level/>one of the previous posts</a>,
I presented the exact equation for such a p-value.
If we compare two samples of sizes <span class="math inline">\(n\)</span> and <span class="math inline">\(m\)</span>,
the minimum p-value we can observe with the one-tailed Mann–Whitney U test is <span class="math inline">\(1/C_{n+m}^n\)</span>.
For example, if <span class="math inline">\(n=50\)</span> and <span class="math inline">\(m=5\)</span>, we get <span class="math inline">\(1/C_{55}^5 \approx 0.0000002874587\)</span>.
Let&rsquo;s check these calculations using R:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=cl><span class=o>&gt;</span> <span class=nf>wilcox.test</span><span class=p>(</span><span class=m>101</span><span class=o>:</span><span class=m>105</span><span class=p>,</span> <span class=m>1</span><span class=o>:</span><span class=m>50</span><span class=p>,</span> <span class=n>alternative</span> <span class=o>=</span> <span class=s>&#34;greater&#34;</span><span class=p>)</span><span class=o>$</span><span class=n>p.value</span>
</span></span><span class=line><span class=cl><span class=n>[1]</span> <span class=m>0.0001337028</span>
</span></span></code></pre></div><p>The obtained p-value is <span class="math inline">\(\approx 0.0001337028\)</span>, which is <span class="math inline">\(\approx 465\)</span> times larger than we expected!
Have we discovered a critical bug in <code>wilcox.test</code>?
Can we now trust this function?
Let&rsquo;s find out!</p><br><a href=/posts/r-mann-whitney-incorrect-p-value/>Read more</a><br><br><hr></div><div><h2><a href=/posts/preprint-wqe/>Preprint announcement: 'Weighted quantile estimators'</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg><time datetime=2023-04-18>April 18, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/>Mathematics</a>
<a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics</a>
<a class=label-link href=https://aakinshin.net/tags/research/>Research</a>
<a class=label-link href=https://aakinshin.net/tags/paper-announcement/>Paper announcement</a>
<a class=label-link href=https://aakinshin.net/tags/research-wqe/>Research: Weighted quantile estimators</a></div></div><br><p>I have just published a preprint of a paper &lsquo;Weighted quantile estimators&rsquo;.
It&rsquo;s based on a series of my <a href=https://aakinshin.net/tags/research-wqe/>research notes</a> that I have been writing since September 2020.</p><p>The paper preprint is available on arXiv:
<a href=https://arxiv.org/abs/2304.07265>arXiv:2304.07265 [stat.ME]</a>.
The paper source code is available on GitHub:
<a href=https://github.com/AndreyAkinshin/paper-wqe>AndreyAkinshin/paper-wqe</a>.
You can cite it as follows:</p><ul><li>Andrey Akinshin (2023)
&ldquo;Weighted quantile estimators&rdquo;
<a href=https://arxiv.org/abs/2304.07265>arXiv:2304.07265</a></li></ul><p>Abstract:</p><blockquote><p>In this paper, we consider a generic scheme that allows building weighted versions of various quantile estimators,
such as traditional quantile estimators based on linear interpolation of two order statistics,
the Harrell-Davis quantile estimator and its trimmed modification.
The obtained weighted quantile estimators are especially useful
in the problem of estimating a distribution at the tail of a time series using quantile exponential smoothing.
The presented approach can also be applied to other problems,
such as quantile estimation of weighted mixture distributions.</p></blockquote><br><a href=/posts/preprint-wqe/>Read more</a><br><br><hr></div><div><h2><a href=/posts/rethinking-type-i-ii-errors/>Rethinking Type I/II error rates with power curves</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg><time datetime=2023-04-11>April 11, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/>Mathematics</a>
<a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics</a>
<a class=label-link href=https://aakinshin.net/tags/research/>Research</a>
<a class=label-link href=https://aakinshin.net/tags/thoughts/>Thoughts</a></div></div><br><p>When it comes to the analysis of a statistical significance test design,
many people tend to overfocus purely on the Type I error rate.
Those who are aware of the importance of power analysis
often stop at expressing the Type II error rate as a single number.
It is better than nothing, but such an approach always confuses me.</p><p>Let us say that the declared Type II error rate is 20% (or the declared statistical power is 80%).
What does it actually mean?
If the sample size and the significance level (or any other significance criteria) are given,
the Type II error rate is a function of the effect size.
When we express the Type II error rate as a single number,
we always (implicitly or explicitly) assume the target effect size.
In most cases, it is an arbitrary number
that is somehow chosen to reflect our expectations of the &ldquo;reasonable&rdquo; effect size.
However, the actual Type II error rate and the corresponding statistical power
depend on the actual effect size that we do not know.
Some researchers estimate the Type II error rate / statistical power using the measured effect size,
but it does not make a lot of sense since
it does not provide new information in addition to the measured effect size or p-value.
In reality, we have high statistical power (low Type II error rate) for large effect sizes
and low statistical power (high Type II error rate) for small effect sizes.
Without the knowledge of the actual effect size (which we do not have),
the Type II error rate expressed as a single number mostly describes this arbitrarily chosen expected effect size,
rather than the actual properties of our statistical test.</p><br><a href=/posts/rethinking-type-i-ii-errors/>Read more</a><br><br><hr></div><div><h2><a href=/posts/scale-measure-for-discrete-case/>Adaptation of continuous scale measures to discrete distributions</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg><time datetime=2023-04-04>April 4, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/>Mathematics</a>
<a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics</a>
<a class=label-link href=https://aakinshin.net/tags/research/>Research</a></div></div><br><p>In statistics, it is often important to have a reliable measure of scale
since it is required for estimating many types of the effect size and for statistical tests.
If we work with continuous distributions,
there are plenty of available scale measures with various levels of statistical efficiency and robustness.
However, when distribution becomes discrete (e.g. because of the limited resolution of the measure tools),
classic measures of scale can collapse to zero due to tied values in collected samples.
This can be a severe problem in the analysis
since the scale measures are often used as denominators in various equations.
To make the calculations more reliable,
it is important to handle such situations somehow and ensure that the target scale measure never becomes zero.
In this post,
I discuss a simple approach to work around this problem and adapt any given measure of scale to the discrete case.</p><br><a href=/posts/scale-measure-for-discrete-case/>Read more</a><br><br><hr></div></div><div class=paginator><ul class="pagination pagination-default"><li class=page-item><a href=/ aria-label=First class=page-link role=button><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/page/3/ aria-label=Previous class=page-link role=button><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a href=/page/2/ aria-label="Page 2" class=page-link role=button>2</a></li><li class=page-item><a href=/page/3/ aria-label="Page 3" class=page-link role=button>3</a></li><li class="page-item active"><a aria-current=page aria-label="Page 4" class=page-link role=button>4</a></li><li class=page-item><a href=/page/5/ aria-label="Page 5" class=page-link role=button>5</a></li><li class=page-item><a href=/page/6/ aria-label="Page 6" class=page-link role=button>6</a></li><li class=page-item><a href=/page/5/ aria-label=Next class=page-link role=button><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/page/24/ aria-label=Last class=page-link role=button><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div><script>var themeToggleDarkIcon=document.getElementById("theme-toggle-dark-icon"),themeToggleBtn,themeToggleLightIcon=document.getElementById("theme-toggle-light-icon");const imagesDark=document.querySelectorAll(".img-dark"),imagesLight=document.querySelectorAll(".img-light");localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?(themeToggleLightIcon.classList.remove("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")})):(themeToggleDarkIcon.classList.remove("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}));function toggleTheme(e){e?(document.documentElement.classList.add("dark"),themeToggleLightIcon.classList.remove("hidden"),themeToggleDarkIcon.classList.add("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")}),imagesLight.forEach(e=>{e.classList.add("hidden")})):(document.documentElement.classList.remove("dark"),themeToggleDarkIcon.classList.remove("hidden"),themeToggleLightIcon.classList.add("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}),imagesDark.forEach(e=>{e.classList.add("hidden")}))}themeToggleBtn=document.getElementById("theme-toggle"),themeToggleBtn.addEventListener("click",function(){themeToggleDarkIcon.classList.toggle("hidden"),themeToggleLightIcon.classList.toggle("hidden"),imagesLight.forEach(e=>{e.classList.toggle("hidden")}),imagesDark.forEach(e=>{e.classList.toggle("hidden")}),event.altKey?(localStorage.removeItem("color-theme"),toggleTheme(window.matchMedia("(prefers-color-scheme: dark)").matches)):localStorage.getItem("color-theme")?localStorage.getItem("color-theme")==="light"?(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark")):(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):document.documentElement.classList.contains("dark")?(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark"))}),window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",e=>{if(localStorage.getItem("color-theme")===null){const t=e.matches?"dark":"light";toggleTheme(t==="dark")}})</script><footer class="z-20 p-4 md:p-6 mt-3 w-full border-t border-gray-200 shadow flex items-center justify-center dark:border-gray-600 bg-white dark:bg-zinc-800"><span class="dark:text-gray-400 text-center">© 2013—2024 <span class=whitespace-nowrap>Andrey Akinshin</span></span><ul class="flex flex-wrap items-center px-4 mb-1"><li><a href=https://github.com/AndreyAkinshin><svg class="fai fai-link w-5 h-5"><title>GitHub</title><use xlink:href="/img/fa/all.svg#github"/></svg></a></li><li><a href=https://twitter.com/andrey_akinshin><svg class="fai fai-link w-5 h-5"><title>Twitter</title><use xlink:href="/img/fa/all.svg#twitter"/></svg></a></li><li><a href=https://aakinshin.net/posts/index.xml><svg class="fai fai-link w-5 h-5"><title>RSS</title><use xlink:href="/img/fa/all.svg#rss"/></svg></a></li></ul><div class=main-content><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></div></footer><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script></body></html>