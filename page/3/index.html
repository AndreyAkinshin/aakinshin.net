<!doctype html><html lang=en class=h-100><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.74.3"><meta name=author content="Andrey Akinshin"><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content><title>Andrey Akinshin's blog (Page 3)</title><meta name=description content="Andrey Akinshin's blog"><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><link href=/css/lumen-bootstrap.min.css theme=light rel=stylesheet type=text/css media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link href=/css/slate-bootstrap.min.css theme=dark rel=stylesheet type=text/css media="(prefers-color-scheme: dark)"><link href=/css/syntax-light.css theme=light rel=stylesheet type=text/css media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link href=/css/syntax-dark.css theme=dark rel=stylesheet type=text/css media="(prefers-color-scheme: dark)"><script src=https://aakinshin.net/js/theme-before.min.26d61b7027fe55e642f0001cef94cb75b567d721086492aab6b4e32d9ee7811d.js></script><script type=module src=https://aakinshin.net/js/dark-mode-toggle.min.882998740b9c4c24677576b997bde5a487246e2e3bd72128a0e922eaa59db029.mjs></script><link href=https://aakinshin.net/css/fontawesome-all.min.50da8736f05b35aac9691de67fe993cbe01b7d88fcf0cb682c3a8f39933fe4a3.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/about.min.2a76db7cc14055b3bafacc363f453917ab54a818a7db2a0a9b2409c0f6bf07c5.css rel=stylesheet type=text/css media=all><link href=https://aakinshin.net/css/blog.min.b7c11be17efd31d4852ff062694551596a7625c992103c0605c98f85d6569f11.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZVB6MXSX32"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','G-ZVB6MXSX32');</script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-41419012-5"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-41419012-5');</script><script type=text/javascript>(function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym");ym(28700916,"init",{clickmap:true,trackLinks:true,accurateTrackBounce:true});</script><noscript><div><img src=https://mc.yandex.ru/watch/28700916 style=position:absolute;left:-9999px alt></div></noscript><script src=/js/jquery-3.3.1.slim.min.js></script></head><body><div class=bg-primary><div class="container bg-primary"><nav class="navbar navbar-expand-sm navbar-dark bg-primary"><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link id=nav-link-blog href=https://aakinshin.net/><i class="fas fa-home" title=Home style=color:#fff></i></a></li><li class=nav-item><a class=nav-link id=nav-link-posts href=https://aakinshin.net/posts/>Posts</a></li><li class=nav-item><a class=nav-link id=nav-link-about href=https://aakinshin.net/about/>About</a></li><li class=nav-item><a class=nav-link id=nav-link-pdnb href=https://aakinshin.net/prodotnetbenchmarking/>Pro .NET Benchmarking</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" data-toggle=dropdown href=# role=button aria-haspopup=true aria-expanded=false>EN</a><div class=dropdown-menu><a class=dropdown-item href=https://aakinshin.net/ru/>RU</a></div></li></ul><ul class="navbar-nav ml-auto"><li class=nav-item><dark-mode-toggle permanent=true></dark-mode-toggle></li></ul></nav></div></div><div class=container><main id=main><div class=blog-main><div class=blog-post><h2 class=blog-post-title><a href=/posts/unbiased-mad-thd/>Unbiased median absolute deviation based on the trimmed Harrell-Davis quantile estimator</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2022-02-08>February 8, 2022</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research-unbiased-mad/ class="badge badge-info">Research: Unbiased median absolute deviation</a></span><br><br><p>The <a href=https://en.wikipedia.org/wiki/Median_absolute_deviation>median absolute deviation</a> (<span class="math inline">\(\operatorname{MAD}\)</span>)
is a robust measure of scale.
For a sample <span class="math inline">\(x = \{ x_1, x_2, \ldots, x_n \}\)</span>, it&rsquo;s defined as follows:</p><p><span class="math display">\[\operatorname{MAD}_n = C_n \cdot \operatorname{median}(|x - \operatorname{median}(x)|)
\]</span></p><p>where <span class="math inline">\(\operatorname{median}\)</span> is a median estimator, <span class="math inline">\(C_n\)</span> is a scale factor.
Using the right scale factor, we can use <span class="math inline">\(\operatorname{MAD}\)</span> as a consistent estimator
for the estimation of the standard deviation under the normal distribution.
For huge samples, we can use the asymptotic value of <span class="math inline">\(C_n\)</span> which is</p><p><span class="math display">\[C_\infty = \dfrac{1}{\Phi^{-1}(3/4)} \approx 1.4826022185056.
\]</span></p><p>For small samples, we should use adjusted values <span class="math inline">\(C_n\)</span> which depend on the sample size.
However, <span class="math inline">\(C_n\)</span> depends not only on the sample size but also on the median estimator.
I have already covered how to obtain this values for
<a href=https://aakinshin.net/posts/unbiased-mad/>the traditional median estimator</a> and
<a href=https://aakinshin.net/posts/unbiased-mad-hd/>the Harrell-Davis median estimator</a>.
It&rsquo;s time to get the <span class="math inline">\(C_n\)</span> values for
<a href=https://aakinshin.net/posts/preprint-thdqe/>the trimmed Harrell-Davis median estimator</a>.</p><br><a href=/posts/unbiased-mad-thd/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/mad-vs-shamos/>Median absolute deviation vs. Shamos estimator</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2022-02-01>February 1, 2022</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a></span><br><br><p>There are multiple ways to estimate statistical dispersion.
The standard deviation is the most popular one, but it&rsquo;s not robust:
a single outlier could heavily corrupt the results.
Fortunately, we have robust measures of dispersions like the <em>median absolute deviation</em> and the <em>Shamos estimator</em>.
In this post, we perform numerical simulations and
compare these two estimators on different distributions and sample sizes.</p><br><a href=/posts/mad-vs-shamos/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/moving-ex-p2-quantile-estimator/>Moving extended P² quantile estimator</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2022-01-25>January 25, 2022</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research-p2qe/ class="badge badge-info">Research: P² quantile estimator</a></span><br><br><p>In the previous posts, I discussed
<a href=https://aakinshin.net/posts/p2-quantile-estimator/>the P² quantile estimator</a>
(a sequential estimator which takes <span class="math inline">\(O(1)\)</span> memory and estimates a single predefined quantile),
<a href=https://aakinshin.net/posts/mp2-quantile-estimator/>the moving P² quantile estimator</a>
(a moving modification of P² which estimates quantiles within the moving window),
and <a href=https://aakinshin.net/posts/ex-p2-quantile-estimator/>the extended P² quantile estimator</a>
(a sequential estimator which takes <span class="math inline">\(O(m)\)</span> memory and estimates <span class="math inline">\(m\)</span> predefined quantiles).</p><p>Now it&rsquo;s time to build <em>the moving modification of the extended P² quantile estimator</em>
which estimates <span class="math inline">\(m\)</span> predefined quantiles using <span class="math inline">\(O(m)\)</span> memory within the moving window.</p><br><a href=/posts/moving-ex-p2-quantile-estimator/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/ex-p2-quantile-estimator/>Extended P² quantile estimator</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2022-01-18>January 18, 2022</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research-p2qe/ class="badge badge-info">Research: P² quantile estimator</a></span><br><br><p>I already covered <em>the P² quantile estimator</em> and its possible implementation improvements
in <a href=https://aakinshin.net/tags/research-p2qe/>several blog posts</a>.
This sequential estimator uses <span class="math inline">\(O(1)\)</span> memory and allows estimating a single predefined quantile.
Now it&rsquo;s time to discuss <em>the extended P² quantile estimator</em> that allows estimating multiple predefined quantiles.
This extended version was suggested in the paper
<a href=https://doi.org/10.1177/003754978704900405>&ldquo;Simultaneous estimation of several percentiles&rdquo;</a>.
In this post, we briefly discuss the approach from this paper and how we can improve its implementation.</p><br><a href=/posts/ex-p2-quantile-estimator/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/p2-quantile-estimator-adjusting-order/>P² quantile estimator marker adjusting order</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2022-01-11>January 11, 2022</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research-p2qe/ class="badge badge-info">Research: P² quantile estimator</a></span><br><br><p>I have already written a few blog posts about the P² quantile estimator
(which is a sequential estimator that uses <span class="math inline">\(O(1)\)</span> memory):</p><ul><li><a href=https://aakinshin.net/posts/p2-quantile-estimator/>P² quantile estimator: estimating the median without storing values</a></li><li><a href=https://aakinshin.net/posts/p2-quantile-estimator-rounding-issue/>P² quantile estimator rounding issue</a></li><li><a href=https://aakinshin.net/posts/p2-quantile-estimator-initialization/>P² quantile estimator initialization strategy</a></li></ul><p>In this post, we continue improving the P² implementation
so that it gives better estimations for streams with a small number of elements.</p><br><a href=/posts/p2-quantile-estimator-adjusting-order/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/p2-quantile-estimator-initialization/>P² quantile estimator initialization strategy</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2022-01-04>January 4, 2022</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a>
<a href=https://aakinshin.net/tags/research-p2qe/ class="badge badge-info">Research: P² quantile estimator</a></span><br><br><p><strong>Update: the estimator accuracy could be improved using a bunch of <a href=https://aakinshin.net/tags/research-p2qe/>patches</a>.</strong></p><p>The P² quantile estimator is a sequential estimator that uses <span class="math inline">\(O(1)\)</span> memory.
Thus, for the given sequence of numbers, it allows estimating quantiles without storing values.
I have already written a few blog posts about it:</p><ul><li><a href=https://aakinshin.net/posts/p2-quantile-estimator/>P² quantile estimator: estimating the median without storing values</a></li><li><a href=https://aakinshin.net/posts/p2-quantile-estimator-rounding-issue/>P² quantile estimator rounding issue</a></li></ul><p>I tried this estimator in various contexts, and it shows pretty decent results.
However, recently I stumbled on a corner case:
if we want to estimate extreme quantile (<span class="math inline">\(p < 0.1\)</span> or <span class="math inline">\(p > 0.9\)</span>),
this estimator provides inaccurate results on small number streams (<span class="math inline">\(n < 10\)</span>).
While it looks like a minor issue, it would be nice to fix it.
In this post, we briefly discuss choosing a better initialization strategy to workaround this problem.</p><br><a href=/posts/p2-quantile-estimator-initialization/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/misleading-geometric-mean/>Misleading geometric mean</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-12-28>December 28, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a></span><br><br><p>There are multiple ways to compute the &ldquo;average&rdquo; value of an array of numbers.
One of such ways is the <em>geometric mean</em>.
For a sample <span class="math inline">\(x = \{ x_1, x_2, \ldots, x_n \}\)</span>, the geometric means is defined as follows:</p><p><span class="math display">\[\operatorname{GM}(x) = \sqrt[n]{x_1 x_2 \ldots x_n}
\]</span></p><p>This approach is widely recommended for some specific tasks.
Let&rsquo;s say we want to compare the performance of two machines <span class="math inline">\(M_x\)</span> and <span class="math inline">\(M_y\)</span>.
In order to do this, we design a set of benchmarks <span class="math inline">\(b = \{b_1, b_2, \ldots, b_n \}\)</span>
and obtain two sets of measurements
<span class="math inline">\(x = \{ x_1, x_2, \ldots, x_n \}\)</span> and <span class="math inline">\(y = \{ y_1, y_2, \ldots, y_n \}\)</span>.
Once we have these two samples, we may have a desire to express the difference
between two machines as a single number and get a conclusion like
&ldquo;Machine <span class="math inline">\(M_y\)</span> works two times faster than <span class="math inline">\(M_x\)</span>.&rdquo;
I think that this approach is flawed because such a difference couldn&rsquo;t be expressed as a single number:
the result heavily depends on the workloads that we analyze.
For example, imagine that <span class="math inline">\(M_x\)</span> is a machine with HDD and fast CPU, <span class="math inline">\(M_y\)</span> is a machine with SSD and slow CPU.
In this case, <span class="math inline">\(M_x\)</span> could be faster on CPU-bound workloads while <span class="math inline">\(M_y\)</span> could be faster on disk-bound workloads.
I really like this summary from
<a href=https://www.eecs.umich.edu/techreports/cse/95/CSE-TR-231-95.pdf>&ldquo;Notes on Calculating Computer Performance&rdquo;</a>
by Bruce Jacob and Trevor Mudge (in the same paper, the authors criticize the approach with the geometric mean):</p><blockquote><p>Performance is therefore not a single number, but really a collection of implications.
It is nothing more or less than the measure of
how much time <em>we</em> save running <em>our</em> tests on the machines in question.
If someone else has similar needs to ours, our performance numbers will be useful to them.
However, two people with different sets of criteria will likely walk away
with two completely different performance numbers for the same machine.</p></blockquote><p>However, some other authors (e.g., <a href=https://doi.org/10.1145/5666.5673>&ldquo;How not to lie with statistics: the correct way to summarize benchmark results&rdquo;</a>)
actually recommend using the geometric mean to get such a number
that describes the performance ratio of <span class="math inline">\(M_x\)</span> and <span class="math inline">\(M_y\)</span>.
I have to admit that the geometric mean <em>could</em> provide a reasonable result in <em>some simple cases</em>.
Indeed, on normalized numbers, it works much better than the arithmetic mean
(that provides meaningless result) because of its nice <a href=https://en.wikipedia.org/wiki/Geometric_mean#Application_to_normalized_values>property</a>:
<span class="math inline">\(\operatorname{GM}(x_i/y_i) = \operatorname{GM}(x_i) / \operatorname{GM}(y_i)\)</span>.
However, it doesn&rsquo;t work properly in the general case.
Firstly, the desire to express the difference between two machines is vicious:
the result heavily depends on the chosen workloads.
Secondly, the performance of a single benchmark <span class="math inline">\(b_i\)</span> couldn&rsquo;t be described as a single number <span class="math inline">\(x_i\)</span>:
we should consider the whole performance distributions.
In order to describe the difference between two distributions,
we could consider the <a href=https://aakinshin.net/posts/shift-and-ratio-functions/>shift and ration functions</a>
(that work much better than the <a href=https://aakinshin.net/posts/shift-function-vs-distribution/>shift</a> and
<a href=https://aakinshin.net/posts/ratio-function-vs-distribution/>ratio</a> distributions).</p><p>Even if you consider a pretty homogenous set of benchmarks and all the distributions are pretty narrow,
the geometric mean has severe drawbacks that you should keep in mind.
In this post, I briefly cover some of these drawbacks and highlight problems that you may have if you use this metric.</p><br><a href=/posts/misleading-geometric-mean/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/binomial-quantile-likelihood/>Matching quantile sets using likelihood based on the binomial coefficients</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-12-21>December 21, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a></span><br><br><p>Let&rsquo;s say we have a distribution <span class="math inline">\(X\)</span> that is given by its <span class="math inline">\(s\)</span>-quantile values:</p><p><span class="math display">\[q_{X_1} = Q_X(p_1),\; q_{X_2} = Q_X(p_2),\; \ldots,\; q_{X_{s-1}} = Q_X(p_{s-1})
\]</span></p><p>where <span class="math inline">\(Q_X\)</span> is the quantile function of <span class="math inline">\(X\)</span>, <span class="math inline">\(p_j = j / s\)</span>.</p><p>We also have a sample <span class="math inline">\(y = \{y_1, y_2, \ldots, y_n \}\)</span> that is given by its <span class="math inline">\(s\)</span>-quantile estimations:</p><p><span class="math display">\[q_{y_1} = Q_y(p_1),\; q_{y_2} = Q_y(p_2),\; \ldots,\; q_{y_{s-1}} = Q_y(p_{s-1}),
\]</span></p><p>where <span class="math inline">\(Q_y\)</span> is the quantile estimation function for sample <span class="math inline">\(y\)</span>.
We also assume that <span class="math inline">\(q_{y_0} = \min(y)\)</span>, <span class="math inline">\(q_{y_s} = \max(y)\)</span>.</p><p>We want to know the likelihood of &ldquo;<span class="math inline">\(y\)</span> is drawn from <span class="math inline">\(X\)</span>&rdquo;.
In this post, I want to suggest a nice way to do this using the binomial coefficients.</p><br><a href=/posts/binomial-quantile-likelihood/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/ratio-function-vs-distribution/>Ratio function vs. ratio distribution</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-12-14>December 14, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a></span><br><br><p>Let&rsquo;s say we have two distributions <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.
In the <a href=https://aakinshin.net/posts/shift-function-vs-distribution/>previous post</a>,
we discussed how to express the &ldquo;absolute difference&rdquo; between them
using the shift function and the shift distribution.
Now let&rsquo;s discuss how to express the &ldquo;relative difference&rdquo; between them.
This abstract term also could be expressed in various ways.
My favorite approach is to build the <a href=https://aakinshin.net/posts/shift-and-ratio-functions/>ratio function</a>.
In order to do this, for each quantile <span class="math inline">\(p\)</span>, we should calculate <span class="math inline">\(Q_Y(p)/Q_X(p)\)</span> where <span class="math inline">\(Q\)</span> is the quantile function.
However, some people prefer using the <a href=https://en.wikipedia.org/wiki/Ratio_distribution>ratio distribution</a> <span class="math inline">\(Y/X\)</span>.
While both approaches may provide similar results for narrow positive non-overlapping distributions,
they are not equivalent in the general case.
In this post, we briefly consider examples of both approaches.</p><br><a href=/posts/ratio-function-vs-distribution/>Read more</a><br><br><hr></div><div class=blog-post><h2 class=blog-post-title><a href=/posts/shift-function-vs-distribution/>Shift function vs. shift distribution</a></h2><span class=blog-post-meta><div class=faicon><i class="far fa-calendar-alt"></i></div><time datetime=2021-12-07>December 7, 2021</time>
&nbsp;&nbsp;
<i class="fas fa-tag"></i>&nbsp;
<a href=https://aakinshin.net/tags/statistics/ class="badge badge-info">Statistics</a></span><br><br><p>Let&rsquo;s say we have two distributions <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>,
and we want to express the &ldquo;absolute difference&rdquo; between them.
This abstract term could be expressed in various ways.
My favorite approach is to build the <a href=https://aakinshin.net/posts/shift-and-ratio-functions/>Doksum&rsquo;s shift function</a>.
In order to do this, for each quantile <span class="math inline">\(p\)</span>, we should calculate <span class="math inline">\(Q_Y(p)-Q_X(p)\)</span> where <span class="math inline">\(Q\)</span> is the quantile function.
However, some people prefer using the shift distribution <span class="math inline">\(Y-X\)</span>.
While both approaches may provide similar results for narrow non-overlapping distributions,
they are not equivalent in the general case.
In this post, we briefly consider examples of both approaches.</p><br><a href=/posts/shift-function-vs-distribution/>Read more</a><br><br><hr></div></div><div class=paginator><ul class=pagination><li class=page-item><a href=/ class=page-link aria-label=First><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/page/2/ class=page-link aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a class=page-link href=/>1</a></li><li class=page-item><a class=page-link href=/page/2/>2</a></li><li class="page-item active"><a class=page-link href=/page/3/>3</a></li><li class=page-item><a class=page-link href=/page/4/>4</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/15/>15</a></li><li class=page-item><a href=/page/4/ class=page-link aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/page/15/ class=page-link aria-label=Last><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></main></div><footer class=blog-footer><div class=container><p>&copy; 2013&mdash;2022 Andrey Akinshin
|
<a href=https://github.com/AndreyAkinshin><i class="fab fa-github" title=GitHub></i></a><a href=https://twitter.com/andrey_akinshin><i class="fab fa-twitter" title=Twitter></i></a><a href=https://aakinshin.net/posts/index.xml><i class="fas fa-rss" title=RSS></i></a>|
<a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></p></div></footer><script src=https://aakinshin.net/js/theme-after.min.082780cb948cc57eabbc0d80172a7a5347d5572b599938b4c9876dfd7978b424.js></script><script src=/js/popper.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/anchor.min.js></script><script src=https://aakinshin.net/js/custom.min.11932490dde776463ed165b345838c701accc0cfdedf2e0868f13415f41f0872.js></script><script>window.MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],processEscapes:true,processEnvironments:true,},options:{skipHtmlTags:['script','noscript','style','textarea','pre'],ignoreHtmlClass:'tex2jax_ignore',processHtmlClass:'tex2jax_process'}};</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></body></html>