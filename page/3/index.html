<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.123.3"><meta name=author content='Andrey Akinshin'><link href=/img/favicon.ico rel=icon type=image/x-icon><meta name=keywords content><title>Andrey Akinshin's blog (Page 3)</title>
<meta name=description content="Andrey Akinshin's blog"><meta name=twitter:site content="@andrey_akinshin"><meta name=twitter:creator content="@andrey_akinshin"><script>localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?document.documentElement.classList.add("dark"):document.documentElement.classList.remove("dark")</script><link href=https://aakinshin.net/css/main.min.5108205eaabc89b26ffd82359e0fe4fb2b5e8c9825e57ed51687cc18a3c75b9b.css rel=stylesheet type=text/css media=all><link rel=alternate type=application/rss+xml href=https://aakinshin.net/posts/index.xml title="RSS Feed"></head><body><nav><div class="container flex flex-wrap items-center justify-between mx-auto max-w-6xl h-12 px-2 xs:px-6"><div class="flex items-center justify-start justify-self-start"><div class="flex nav-item h-12 w-12 items-center justify-center"><a class=text-white href=https://aakinshin.net/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#house-chimney"/></svg></a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/posts/>Posts</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/research/>Research</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/library/>Library</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/about/>About</a></div><div class="flex nav-item h-12 items-center"><a class=text-white href=https://aakinshin.net/search/><svg class="fai w-5 h-5 pr-0 mb-0.5"><use xlink:href="/img/fa/all.svg#magnifying-glass"/></svg></a></div></div><button id=theme-toggle type=button title="Alt+Click to match OS color theme" class="nav-item p-3 content-center justify-self-end"><svg id="theme-toggle-dark-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001.0 1010.586 10.586z"/></svg><svg id="theme-toggle-light-icon" class="hidden w-6 h-6" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M10 2a1 1 0 011 1v1A1 1 0 119 4V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707A1 1 0 1113.536 5.05l.707-.707a1 1 0 011.414.0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707A1 1 0 004.343 5.757l.707.707zm1.414 8.486-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z" fill-rule="evenodd" clip-rule="evenodd"/></svg></button></div></nav><div class="main container mx-auto max-w-6xl px-6"><div class=main-content><div><h2><a href=/posts/ansari-power/>Exploring the Power Curve of the Ansari-Bradley Test</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg>
<time datetime=2023-10-17>October 17, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/>Research</a></div></div><br><p>The Ansari-Bradley test is a popular rank-based nonparametric test for a difference in scale/dispersion parameters.
In this post, we explore its power curve in a numerical simulation.</p><a href=/posts/ansari-power/>Read more</a><br><br><hr></div><div><h2><a href=/posts/lepage-power/>Exploring the Power Curve of the Lepage Test</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg>
<time datetime=2023-10-10>October 10, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/>Research</a></div></div><br><p>Previously, I already <a href=https://aakinshin.net/posts/cucconi-power/>discussed the Cucconi test</a>.
In this post, I continue the topic of nonparametric tests and
check out the <a href=https://en.wikipedia.org/wiki/Lepage_test>Lepage test</a>.</p><a href=/posts/lepage-power/>Read more</a><br><br><hr></div><div><h2><a href=/posts/whl-mixture/>Weighted Hodges-Lehmann Location Estimator and Mixture Distributions</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg>
<time datetime=2023-10-03>October 3, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/>Research</a></div></div><br><p>The classic non-weighted Hodges-Lehmann location estimator of a sample $\mathbf{x} = (x_1, x_2, \ldots, x_n)$
is defined as follows:</p>$$
\operatorname{HL}(\mathbf{x}) =
\underset{1 \leq i \leq j \leq n}{\operatorname{median}} \left(\frac{x_i + x_j}{2} \right),
$$<p>where $\operatorname{median}$ is the sample median.
<a href=https://aakinshin.net/posts/whl/>Previously</a>, we have defined a weighted version of the Hodges-Lehmann location estimator as follows:</p>$$
\operatorname{WHL}(\mathbf{x}, \mathbf{w}) =
\underset{1 \leq i \leq j \leq n}{\operatorname{wmedian}} \left(\frac{x_i + x_j}{2},\; w_i \cdot w_j \right),
$$<p>where $\mathbf{w} = (w_1, w_2, \ldots, w_n)$ is the vector of weights,
$\operatorname{wmedian}$ is the <a href=https://aakinshin.net/posts/preprint-wqe/>weighted median</a>.
For simplicity, in the scope of the current post,
Hyndman-Fan Type 7 quantile estimator is used as the base for the weighted median.</p><p>In this post, we consider a numerical simulation in which we compare sampling distribution of
$\operatorname{HL}$ and $\operatorname{WHL}$ in a case of mixture distribution.</p><a href=/posts/whl-mixture/>Read more</a><br><br><hr></div><div><h2><a href=/posts/carling-outlier-detector/>Carling’s Modification of the Tukey's Fences</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg>
<time datetime=2023-09-26>September 26, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/>Research</a></div></div><br><p>Let us consider the classic problem of outlier detection in one-dimensional sample.
One of the most popular approaches is Tukey&rsquo;s fences, that defines the following range:</p>$$
[Q_1 - k(Q_3 - Q_1);\; Q_3 + k(Q_3 - Q_1)],
$$<p>where $Q_1$ and $Q_3$ are the first and the third quartiles of the given sample.</p><p>All the values outside the given range are classified as outliers.
The typical values of $k$ are $1.5$ for &ldquo;usual outliers&rdquo; and $3.0$ for &ldquo;far out&rdquo; outliers.
In the classic Tukey&rsquo;s fences approach, $k$ is often a predefined constant.
However, there are alternative approaches that define $k$ dynamically based on the given sample.
One of the possible variations of Tukey&rsquo;s fences is Carling&rsquo;s modification that defines $k$ as follows:</p>$$
k = \frac{17.63n - 23.64}{7.74n - 3.71},
$$<p>where $n$ is the sample size.</p><p>In this post, we compare the classic Tukey&rsquo;s fences with $k=1.5$ and $k=3.0$ against Carling&rsquo;s modification.</p><a href=/posts/carling-outlier-detector/>Read more</a><br><br><hr></div><div><h2><a href=/posts/clt-lnorm/>Central Limit Theorem and Log-Normal Distribution</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg>
<time datetime=2023-09-19>September 19, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/>Research</a></div></div><br><p>It is inconvenient to work with samples from a distribution of unknown form.
Therefore, researchers often switch to considering the sample mean value and
hope that thanks to the <a href=https://en.wikipedia.org/wiki/Central_limit_theorem>central limit theorem</a>,
the distribution of the sample means should be approximately normal.
They say that if we consider samples of size $n \geq 30$, we can expect practically acceptable convergence to normality
thanks to <a href=https://en.wikipedia.org/wiki/Berry%E2%80%93Esseen_theorem>Berry–Esseen theorem</a>.
Indeed, this statement is almost valid for many real data sets.
However, we can actually expect the applicability of this approach only for light-tailed distributions.
In the case of heavy-tailed distributions, converging to normality is so slow,
that we cannot imply the normality assumption for the distribution of the sample means.
In this post, I provide an illustration of this effect using the log-normal distribution.</p><a href=/posts/clt-lnorm/>Read more</a><br><br><hr></div><div><h2><a href=/posts/hl-loc-shift-vs-shift-loc/>Hodges-Lehmann Gaussian Efficiency: Location Shift vs. Shift of Locations</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg>
<time datetime=2023-09-12>September 12, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/>Research
</a><a class=label-link href=https://aakinshin.net/tags/hodges-lehmann/>Hodges-Lehmann Estimator</a></div></div><br><p>Let us consider two samples $\mathbf{x} = (x_1, x_2, \ldots, x_n)$ and $\mathbf{y} = (y_1, y_2, \ldots, y_m)$.
The one-sample Hodges-Lehman location estimator is defined as the median of the Walsh (pairwise) averages:</p>$$
\operatorname{HL}(\mathbf{x}) =
\underset{1 \leq i \leq j \leq n}{\operatorname{median}} \left(\frac{x_i + x_j}{2} \right),
\quad
\operatorname{HL}(\mathbf{y}) =
\underset{1 \leq i \leq j \leq m}{\operatorname{median}} \left(\frac{y_i + y_j}{2} \right).
$$<p>For these two samples, we can also define the shift between these two estimations:</p>$$
\Delta_{\operatorname{HL}}(\mathbf{x}, \mathbf{y}) = \operatorname{HL}(\mathbf{x}) - \operatorname{HL}(\mathbf{y}).
$$<p>The two-sample Hodges-Lehmann location shift estimator is defined as the median of pairwise differences:</p>$$
\operatorname{HL}(\mathbf{x}, \mathbf{y}) =
\underset{1 \leq i \leq n,\,\, 1 \leq j \leq m}{\operatorname{median}} \left(x_i - y_j \right).
$$<p>Previously, I already compared the location shift estimator with the difference of median estimators
(<a href=https://aakinshin.net/posts/median-shift-vs-shift-median1/>1</a>, <a href=https://aakinshin.net/posts/median-shift-vs-shift-median2/>2</a>).
In this post, I compare the difference between two location estimations and the shift estimations
in terms of Gaussian efficiency.
Before I started this study, I expected that $\operatorname{HL}$ should be more efficient
than $\Delta_{\operatorname{HL}}$.
Let us find out if my intuition is correct or not!</p><a href=/posts/hl-loc-shift-vs-shift-loc/>Read more</a><br><br><hr></div><div><h2><a href=/posts/thoughts-on-broken-assumptions/>Thoughts on Automatic Statistical Methods and Broken Assumptions</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg>
<time datetime=2023-09-05>September 5, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/>Research
</a><a class=label-link href=https://aakinshin.net/tags/ds/>Defensive Statistics
</a><a class=label-link href=https://aakinshin.net/tags/thoughts/>Thoughts</a></div></div><br>In the old times of applied statistics existence, all statistical experiments used to be performed by hand. In manual investigations, an investigator is responsible not only for interpreting the research results but also for the applicability validation of the used statistical approaches. Nowadays, more and more data processing is performed automatically on enormously huge data sets. Due to the extraordinary number of data samples, it is often almost impossible to verify each output individually using human eyes. Unfortunately, since we typically have no full control over the input data, we cannot guarantee certain assumptions that are required by classic statistical methods. These assumptions can be violated not only due to real-life phenomena we were not aware of during the experiment design stage, but also due to data corruption. In such corner cases, we may get misleading results, wrong automatic decisions, unacceptably high Type I/II error rates, or even a program crash because of a division by zero or another invalid operation. If we want to make an automatic analysis system reliable and trustworthy, the underlying mathematical procedures should correctly process malformed data.
The normality assumption is probably the most popular one. There are well-known methods of robust statistics that focus only on slight deviations from normality and the appearance of extreme outliers. However, it is only a violation of one specific consequence from the normality assumption: light-tailedness. In practice, this sub-assumption is often interpreted as &ldquo;the probability of observing extremely large outliers is negligible.&rdquo; Meanwhile, there are other implicit derived sub-assumptions: continuity (we do not expect tied values in the input samples), symmetry (we do not expect highly-skewed distributions), unimodality (we do not expect multiple modes), nondegeneracy (we do not expect all sample values to be equal), sample size sufficiency (we do not expect extremely small samples like single-element samples), and others.
<a href=/posts/thoughts-on-broken-assumptions/>Read more</a><br><br><hr></div><div><h2><a href=/posts/hl-ratio/>Ratio Estimator Based on the Hodges-Lehmann Approach</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg>
<time datetime=2023-08-29>August 29, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/>Research
</a><a class=label-link href=https://aakinshin.net/tags/hodges-lehmann/>Hodges-Lehmann Estimator</a></div></div><br><p>For two samples $\mathbf{x} = ( x_1, x_2, \ldots, x_n )$ and $\mathbf{y} = ( y_1, y_2, \ldots, y_m )$,
the Hodges-Lehmann location shift estimator is defined as follows:</p>$$
\operatorname{HL}(\mathbf{x}, \mathbf{y}) =
\underset{1 \leq i \leq n,\,\, 1 \leq j \leq m}{\operatorname{median}} \left(x_i - y_j \right).
$$<p>Now, let us consider the problem of estimating the ratio of the location measures instead of the shift between them.
While there are multiple approaches to providing such an estimation,
one of the options that can be considered is based on the Hodges-Lehmann ideas.</p><a href=/posts/hl-ratio/>Read more</a><br><br><hr></div><div><h2><a href=/posts/wmw2/>Weighted Mann-Whitney U Test, Part 2</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg>
<time datetime=2023-08-22>August 22, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/>Research
</a><a class=label-link href=https://aakinshin.net/tags/research-wmw/>Research: Weighted Mann-Whitney U Test
</a><a class=label-link href=https://aakinshin.net/tags/mann-whitney/>Mann-Whitney U-Test</a></div></div><br><p>Previously, I <a href=https://aakinshin.net/posts/wmw1/>suggested</a> a weighted version of the Mann–Whitney $U$ test.
The distribution of the weighted normalized $U_\circ^\star$ can be obtained via bootstrap.
However, it is always nice if we can come up with an exact solution for the statistic distribution or
at least provide reasonable approximations.
In this post, we start exploring this distribution.</p><a href=/posts/wmw2/>Read more</a><br><br><hr></div><div><h2><a href=/posts/cucconi-power/>Exploring the Power Curve of the Cucconi Test</a></h2><div class="flex flex-wrap justify-start items-center"><svg class="fai text-accent-l dark:text-front-d"><title>Date</title><use xlink:href="/img/fa/all.svg#calendar-days"/></svg>
<time datetime=2023-08-15>August 15, 2023</time><svg class="fai ml-3 text-accent-l dark:text-front-d"><title>Tags</title><use xlink:href="/img/fa/all.svg#tag"/></svg><div class="flex flex-wrap gap-y-1"><a class=label-link href=https://aakinshin.net/tags/mathematics/><svg class="rating-icon"><use xlink:href="/img/fa/all.svg#math"/></svg>
Mathematics
</a><a class=label-link href=https://aakinshin.net/tags/statistics/>Statistics
</a><a class=label-link href=https://aakinshin.net/tags/research/>Research</a></div></div><br><p>The <a href=https://en.wikipedia.org/wiki/Cucconi_test>Cucconi test</a>
is a nonparametric two-sample test that compares both location and scale.
It is a classic example of the family of tests that
perform such a comparison simultaneously
instead of combining the results of a location test and a scale test.
Intuitively, such an approach should fit well unimodal distributions.
Moreover, it has the potential to outperform more generic nonparametric tests
that do not rely on the unimodality assumption.</p><p>In this post, we briefly show the equations behind the Cucconi test and
present a power curve that compares it with the Student&rsquo;s t-test and the Mann-Whitney U test under normality.</p><a href=/posts/cucconi-power/>Read more</a><br><br><hr></div></div><div class=paginator><ul class="pagination pagination-default"><li class=page-item><a href=/ aria-label=First class=page-link role=button><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/page/2/ aria-label=Previous class=page-link role=button><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a href=/ aria-label="Page 1" class=page-link role=button>1</a></li><li class=page-item><a href=/page/2/ aria-label="Page 2" class=page-link role=button>2</a></li><li class="page-item active"><a aria-current=page aria-label="Page 3" class=page-link role=button>3</a></li><li class=page-item><a href=/page/4/ aria-label="Page 4" class=page-link role=button>4</a></li><li class=page-item><a href=/page/5/ aria-label="Page 5" class=page-link role=button>5</a></li><li class=page-item><a href=/page/4/ aria-label=Next class=page-link role=button><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/page/104/ aria-label=Last class=page-link role=button><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div><script>var themeToggleDarkIcon=document.getElementById("theme-toggle-dark-icon"),themeToggleBtn,themeToggleLightIcon=document.getElementById("theme-toggle-light-icon");const imagesDark=document.querySelectorAll(".img-dark"),imagesLight=document.querySelectorAll(".img-light");localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?(themeToggleLightIcon.classList.remove("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")})):(themeToggleDarkIcon.classList.remove("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}));function toggleTheme(e){e?(document.documentElement.classList.add("dark"),themeToggleLightIcon.classList.remove("hidden"),themeToggleDarkIcon.classList.add("hidden"),imagesDark.forEach(e=>{e.classList.remove("hidden")}),imagesLight.forEach(e=>{e.classList.add("hidden")})):(document.documentElement.classList.remove("dark"),themeToggleDarkIcon.classList.remove("hidden"),themeToggleLightIcon.classList.add("hidden"),imagesLight.forEach(e=>{e.classList.remove("hidden")}),imagesDark.forEach(e=>{e.classList.add("hidden")}))}themeToggleBtn=document.getElementById("theme-toggle"),themeToggleBtn.addEventListener("click",function(){themeToggleDarkIcon.classList.toggle("hidden"),themeToggleLightIcon.classList.toggle("hidden"),imagesLight.forEach(e=>{e.classList.toggle("hidden")}),imagesDark.forEach(e=>{e.classList.toggle("hidden")}),event.altKey?(localStorage.removeItem("color-theme"),toggleTheme(window.matchMedia("(prefers-color-scheme: dark)").matches)):localStorage.getItem("color-theme")?localStorage.getItem("color-theme")==="light"?(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark")):(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):document.documentElement.classList.contains("dark")?(document.documentElement.classList.remove("dark"),localStorage.setItem("color-theme","light")):(document.documentElement.classList.add("dark"),localStorage.setItem("color-theme","dark"))}),window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",e=>{if(localStorage.getItem("color-theme")===null){const t=e.matches?"dark":"light";toggleTheme(t==="dark")}})</script><footer class="z-20 p-4 md:p-6 mt-3 w-full border-t border-gray-200 shadow flex items-center justify-center dark:border-gray-600 bg-white dark:bg-zinc-800"><span class="dark:text-gray-400 text-center">© 2013—2024 <span class=whitespace-nowrap>Andrey Akinshin</span></span><ul class="flex flex-wrap items-center px-4 mb-1"><li><a href=https://github.com/AndreyAkinshin><svg class="fai fai-link w-5 h-5"><title>GitHub</title><use xlink:href="/img/fa/all.svg#github"/></svg></a></li><li><a href=https://twitter.com/andrey_akinshin><svg class="fai fai-link w-5 h-5"><title>Twitter</title><use xlink:href="/img/fa/all.svg#twitter"/></svg></a></li><li><a href=https://aakinshin.net/posts/index.xml><svg class="fai fai-link w-5 h-5"><title>RSS</title><use xlink:href="/img/fa/all.svg#rss"/></svg></a></li></ul><div class=main-content><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a></div></footer><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+=" has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script></body></html>